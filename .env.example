# Agent Green Environment Configuration

# Project paths
PROJECT_ROOT=/path/to/agent-green

# ========================================================================================
# BACKEND SELECTION
# ========================================================================================

# Set to "true" to use RunPod/vLLM, "false" for local Ollama
USE_RUNPOD=false

# ========================================================================================
# LOCAL OLLAMA CONFIGURATION (USE_RUNPOD=false)
# ========================================================================================

OLLAMA_HOST=http://localhost:11434

# Toggle reasoning: "true" for thinking model, "false" for baseline
ENABLE_REASONING=false

# Local Ollama models
REASONING_MODEL=qwen3:4b-thinking
BASELINE_MODEL=qwen3:4b

# Endpoints (use OLLAMA_HOST by default)
REASONING_ENDPOINT=http://localhost:11434
BASELINE_ENDPOINT=http://localhost:11434

# ========================================================================================
# RUNPOD/vLLM CONFIGURATION (USE_RUNPOD=true)
# ========================================================================================

# IMPORTANT: When using RunPod:
# 1. Set USE_RUNPOD=true
# 2. Uncomment and update the lines below with your actual RunPod endpoints
# 3. Update model names to use HuggingFace format

# Example RunPod vLLM endpoints (replace XXX with your pod ID)
# REASONING_ENDPOINT=https://XXX-8000.proxy.runpod.net/v1
# BASELINE_ENDPOINT=https://XXX-8000.proxy.runpod.net/v1

# RunPod models (use HuggingFace model names, not Ollama tags)
# REASONING_MODEL=Qwen/QwQ-32B-Preview
# BASELINE_MODEL=Qwen/Qwen2.5-Coder-7B-Instruct

# API Keys (optional, only if your RunPod setup requires authentication)
# REASONING_API_KEY=your_api_key_here
# BASELINE_API_KEY=your_api_key_here

# ========================================================================================
# DATASET CONFIGURATION
# ========================================================================================

# Override dataset path (optional, defaults to full 386-sample dataset)
# VULN_DATASET=/path/to/custom/dataset.jsonl

# ========================================================================================
# NOTES
# ========================================================================================

# Local Ollama Setup:
# - USE_RUNPOD=false
# - ENABLE_REASONING=true/false (toggles between qwen3:4b-thinking and qwen3:4b)
# - Endpoints default to localhost:11434

# RunPod/vLLM Setup:
# - USE_RUNPOD=true
# - ENABLE_REASONING=true/false (toggles between reasoning and baseline models)
# - Must provide RunPod endpoint URLs (with /v1 suffix)
# - Model names use HuggingFace format (e.g., Qwen/QwQ-32B-Preview)
# - API keys optional (depends on your RunPod configuration)

# Recommended RunPod Models:
# - Reasoning: Qwen/QwQ-32B-Preview (32B reasoning model)
# - Baseline: Qwen/Qwen2.5-Coder-7B-Instruct (7B standard instruct model)
# - Budget: Qwen/Qwen2.5-Coder-3B-Instruct (3B for faster/cheaper runs)
