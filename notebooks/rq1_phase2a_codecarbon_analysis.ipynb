{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RQ1 Phase 2a CodeCarbon Detailed Analysis - Qwen3-30B-A3B Models\n\nThis notebook provides detailed hardware-level energy analysis for Phase 2a using CodeCarbon emissions data.\n\n**Phase 2a**: Qwen3-30B-A3B models (MoE: 30B total, 3B active per token)\n\n**Complement to**: `rq1_phase2a_analysis.ipynb` (main performance analysis)\n\n**Focus**: Hardware component breakdown (CPU, GPU, RAM), power consumption, cross-validation\n\n**Infrastructure**: RunPod H100 SXM 80GB"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\n# Set style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (14, 6)\n\n# Paths - Phase 2a results from RunPod\nRESULTS_DIR = Path('../results/runpod')\nOUTPUT_DIR = Path('../results/analysis_phase2a')\nOUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n\nprint(f\"Results directory: {RESULTS_DIR}\")\nprint(f\"Output directory: {OUTPUT_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Phase 2a Experiment directories and file mappings\nRESULT_DIRS = {\n    'instruct_zero': 'instruct_zero_20251020_194844',\n    'instruct_few': 'instruct_few_20251020_200040',\n    'thinking_zero': 'thinking_zero_20251020_215332',\n    'thinking_few': 'thinking_few_20251020_214835',\n}\n\n# Experiment to CodeCarbon directory mapping\nEXPERIMENTS = {\n    'instruct_zero': {\n        'name': 'Instruct Zero-shot',\n        'result_dir': RESULT_DIRS['instruct_zero'],\n        'codecarbon': 'codecarbon_baseline_sa-zero',\n        'energy_json': 'Sa-zero_Qwen-Qwen3-30B-A3B-Instruct-2507_20251020-104948_energy_tracking.json',\n        'exp_base': 'Sa-zero_Qwen-Qwen3-30B-A3B-Instruct-2507_20251020-104948'\n    },\n    'instruct_few': {\n        'name': 'Instruct Few-shot',\n        'result_dir': RESULT_DIRS['instruct_few'],\n        'codecarbon': 'codecarbon_baseline_sa-few',\n        'energy_json': 'Sa-few_Qwen-Qwen3-30B-A3B-Instruct-2507_20251020-111953_energy_tracking.json',\n        'exp_base': 'Sa-few_Qwen-Qwen3-30B-A3B-Instruct-2507_20251020-111953'\n    },\n    'thinking_zero': {\n        'name': 'Thinking Zero-shot',\n        'result_dir': RESULT_DIRS['thinking_zero'],\n        'codecarbon': 'codecarbon_thinking_sa-zero',\n        'energy_json': 'Sa-zero_Qwen-Qwen3-30B-A3B-Thinking-2507_20251020-104530_energy_tracking.json',\n        'exp_base': 'Sa-zero_Qwen-Qwen3-30B-A3B-Thinking-2507_20251020-104530'\n    },\n    'thinking_few': {\n        'name': 'Thinking Few-shot',\n        'result_dir': RESULT_DIRS['thinking_few'],\n        'codecarbon': 'codecarbon_thinking_sa-few',\n        'energy_json': 'Sa-few_Qwen-Qwen3-30B-A3B-Thinking-2507_20251020-111009_energy_tracking.json',\n        'exp_base': 'Sa-few_Qwen-Qwen3-30B-A3B-Thinking-2507_20251020-111009'\n    }\n}\n\ndef load_energy_json(exp_info):\n    \"\"\"Load energy tracking JSON for an experiment\"\"\"\n    result_dir = RESULTS_DIR / exp_info['result_dir']\n    energy_file = result_dir / exp_info['energy_json']\n    \n    if energy_file.exists():\n        with open(energy_file) as f:\n            return json.load(f)\n    return None\n\ndef load_codecarbon_csv(exp_info):\n    \"\"\"Load CodeCarbon emissions CSV for an experiment\"\"\"\n    result_dir = RESULTS_DIR / exp_info['result_dir']\n    cc_dir = result_dir / exp_info['codecarbon']\n    emissions_file = cc_dir / 'emissions.csv'\n    \n    if emissions_file.exists():\n        return pd.read_csv(emissions_file)\n    return None\n\n# Load CodeCarbon and energy tracking data\ndata = {}\n\nprint(\"Loading Phase 2a data from RunPod experiments...\")\nprint(\"=\" * 70)\nprint()\n\nfor exp_key, exp_info in EXPERIMENTS.items():\n    print(f\"{exp_info['name']} (Qwen3-30B-A3B):\")\n    \n    # Load energy tracking JSON\n    energy_json = load_energy_json(exp_info)\n    if energy_json:\n        print(f\"  Energy JSON: {energy_json['total_emissions']:.8f} kg CO2\")\n        print(f\"  Sessions: {energy_json['sessions']}\")\n    else:\n        print(f\"  Energy JSON: No data\")\n    \n    # Load CodeCarbon CSV (no filtering needed - Phase 2a has clean single sessions)\n    cc_df = load_codecarbon_csv(exp_info)\n    if cc_df is not None:\n        print(f\"  CodeCarbon CSV: {len(cc_df)} rows\")\n        print(f\"  Total CO2: {cc_df['emissions'].sum():.8f} kg\")\n    else:\n        print(f\"  CodeCarbon: No data\")\n    \n    data[exp_key] = {\n        'name': exp_info['name'],\n        'codecarbon': cc_df,\n        'energy_json': energy_json\n    }\n    print()\n\nprint(\"=\" * 70)\nprint(\"✓ All Phase 2a data loaded\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Phase 2a Data Notes\n\n**Simplified Data**: Phase 2a experiments were run on fresh RunPod H100 pods with clean CodeCarbon sessions.\n\n**Key differences from Phase 1**:\n- Each experiment ran on a dedicated pod (no session mixing)\n- Most experiments have single CodeCarbon sessions (clean runs)\n- Thinking few-shot has 2 sessions (one interruption/resume)\n- No complex filtering needed unlike Phase 1 Mars server experiments\n\n**Infrastructure**: RunPod H100 SXM 80GB\n- 160 CPU cores (Intel Xeon Platinum 8460Y+)\n- 1x NVIDIA H100 80GB HBM3\n- ~2TB RAM\n\n## 3. Cross-Validation: energy_tracking.json vs emissions.csv"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CROSS-VALIDATION: energy_tracking.json vs CodeCarbon emissions.csv\n",
      "======================================================================\n",
      "\n",
      "Baseline Zero-shot:\n",
      "  energy_tracking.json: 0.15475279 kg CO2\n",
      "  emissions.csv:        0.15475279 kg CO2\n",
      "  Difference:           0.0000000000 kg (0.000000%) ✓ MATCH\n",
      "\n",
      "Baseline Few-shot:\n",
      "  energy_tracking.json: 0.11340120 kg CO2\n",
      "  emissions.csv:        0.11340120 kg CO2\n",
      "  Difference:           0.0000000000 kg (0.000000%) ✓ MATCH\n",
      "\n",
      "Thinking Zero-shot:\n",
      "  energy_tracking.json: 0.73142843 kg CO2\n",
      "  emissions.csv:        0.73142843 kg CO2\n",
      "  Difference:           0.0000000000 kg (0.000000%) ✓ MATCH\n",
      "\n",
      "Thinking Few-shot:\n",
      "  energy_tracking.json: 0.44690007 kg CO2\n",
      "  emissions.csv:        0.44690007 kg CO2\n",
      "  Difference:           0.0000000000 kg (0.000000%) ✓ MATCH\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>JSON Total (kg)</th>\n",
       "      <th>CSV Total (kg)</th>\n",
       "      <th>Difference (kg)</th>\n",
       "      <th>Difference (%)</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Zero-shot</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>1.793543e-14</td>\n",
       "      <td>✓ MATCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Few-shot</td>\n",
       "      <td>0.113401</td>\n",
       "      <td>0.113401</td>\n",
       "      <td>8.326673e-17</td>\n",
       "      <td>7.342667e-14</td>\n",
       "      <td>✓ MATCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thinking Zero-shot</td>\n",
       "      <td>0.731428</td>\n",
       "      <td>0.731428</td>\n",
       "      <td>4.440892e-16</td>\n",
       "      <td>6.071533e-14</td>\n",
       "      <td>✓ MATCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinking Few-shot</td>\n",
       "      <td>0.446900</td>\n",
       "      <td>0.446900</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>4.968552e-14</td>\n",
       "      <td>✓ MATCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Experiment  JSON Total (kg)  CSV Total (kg)  Difference (kg)  \\\n",
       "0  Baseline Zero-shot         0.154753        0.154753     2.775558e-17   \n",
       "1   Baseline Few-shot         0.113401        0.113401     8.326673e-17   \n",
       "2  Thinking Zero-shot         0.731428        0.731428     4.440892e-16   \n",
       "3   Thinking Few-shot         0.446900        0.446900     2.220446e-16   \n",
       "\n",
       "   Difference (%)    Match  \n",
       "0    1.793543e-14  ✓ MATCH  \n",
       "1    7.342667e-14  ✓ MATCH  \n",
       "2    6.071533e-14  ✓ MATCH  \n",
       "3    4.968552e-14  ✓ MATCH  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the two data sources\n",
    "validation_data = []\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CROSS-VALIDATION: energy_tracking.json vs CodeCarbon emissions.csv\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for exp_key, exp_data in data.items():\n",
    "    cc = exp_data['codecarbon']\n",
    "    ej = exp_data['energy_json']\n",
    "    \n",
    "    if cc is not None and ej is not None:\n",
    "        json_total = ej['total_emissions']\n",
    "        csv_total = cc['emissions'].sum()\n",
    "        diff = abs(json_total - csv_total)\n",
    "        diff_pct = (diff / json_total * 100) if json_total > 0 else 0\n",
    "        \n",
    "        match = \"✓ MATCH\" if diff_pct < 0.01 else \"⚠️ DIFF\"\n",
    "        \n",
    "        print(f\"{exp_data['name']}:\")\n",
    "        print(f\"  energy_tracking.json: {json_total:.8f} kg CO2\")\n",
    "        print(f\"  emissions.csv:        {csv_total:.8f} kg CO2\")\n",
    "        print(f\"  Difference:           {diff:.10f} kg ({diff_pct:.6f}%) {match}\")\n",
    "        print()\n",
    "        \n",
    "        validation_data.append({\n",
    "            'Experiment': exp_data['name'],\n",
    "            'JSON Total (kg)': json_total,\n",
    "            'CSV Total (kg)': csv_total,\n",
    "            'Difference (kg)': diff,\n",
    "            'Difference (%)': diff_pct,\n",
    "            'Match': match\n",
    "        })\n",
    "\n",
    "validation_df = pd.DataFrame(validation_data)\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hardware Component Breakdown (Filtered Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate hardware metrics across all Phase 2a experiments\nhardware_summary = []\n\nfor exp_key, exp_data in data.items():\n    cc = exp_data['codecarbon']\n    \n    if cc is not None:\n        hardware_summary.append({\n            'Experiment': exp_data['name'],\n            'Model': 'Thinking' if 'Thinking' in exp_data['name'] else 'Instruct',\n            'Prompting': 'Few-shot' if 'Few' in exp_data['name'] else 'Zero-shot',\n            'Total CO2 (kg)': cc['emissions'].sum(),\n            'Duration (hours)': cc['duration'].sum() / 3600,\n            'CPU Energy (kWh)': cc['cpu_energy'].sum(),\n            'GPU Energy (kWh)': cc['gpu_energy'].sum(),\n            'RAM Energy (kWh)': cc['ram_energy'].sum(),\n            'Total Energy (kWh)': cc['energy_consumed'].sum(),\n            'Avg CPU Power (W)': cc['cpu_power'].mean(),\n            'Avg GPU Power (W)': cc['gpu_power'].mean(),\n            'Avg RAM Power (W)': cc['ram_power'].mean(),\n            'Sessions': len(cc)\n        })\n\nhardware_df = pd.DataFrame(hardware_summary)\nhardware_df"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy Distribution by Component:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>CPU %</th>\n",
       "      <th>GPU %</th>\n",
       "      <th>RAM %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline Zero-shot</td>\n",
       "      <td>21.23</td>\n",
       "      <td>43.16</td>\n",
       "      <td>35.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline Few-shot</td>\n",
       "      <td>21.23</td>\n",
       "      <td>43.15</td>\n",
       "      <td>35.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thinking Zero-shot</td>\n",
       "      <td>21.21</td>\n",
       "      <td>43.19</td>\n",
       "      <td>35.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thinking Few-shot</td>\n",
       "      <td>21.22</td>\n",
       "      <td>43.18</td>\n",
       "      <td>35.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Experiment  CPU %  GPU %  RAM %\n",
       "0  Baseline Zero-shot  21.23  43.16  35.61\n",
       "1   Baseline Few-shot  21.23  43.15  35.62\n",
       "2  Thinking Zero-shot  21.21  43.19  35.59\n",
       "3   Thinking Few-shot  21.22  43.18  35.60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate energy percentages by component\n",
    "hardware_df['CPU %'] = (hardware_df['CPU Energy (kWh)'] / hardware_df['Total Energy (kWh)'] * 100).round(2)\n",
    "hardware_df['GPU %'] = (hardware_df['GPU Energy (kWh)'] / hardware_df['Total Energy (kWh)'] * 100).round(2)\n",
    "hardware_df['RAM %'] = (hardware_df['RAM Energy (kWh)'] / hardware_df['Total Energy (kWh)'] * 100).round(2)\n",
    "\n",
    "print(\"Energy Distribution by Component:\")\n",
    "hardware_df[['Experiment', 'CPU %', 'GPU %', 'RAM %']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 1: Stacked bar chart of energy by component\nfig, ax = plt.subplots(figsize=(12, 6))\n\nx = np.arange(len(hardware_df))\nwidth = 0.6\n\n# Stacked bars\ncolors = ['#3498db', '#e74c3c', '#2ecc71']\nax.bar(x, hardware_df['CPU Energy (kWh)'], width, label='CPU', color=colors[0])\nax.bar(x, hardware_df['GPU Energy (kWh)'], width, bottom=hardware_df['CPU Energy (kWh)'], label='GPU', color=colors[1])\nax.bar(x, hardware_df['RAM Energy (kWh)'], width, \n       bottom=hardware_df['CPU Energy (kWh)'] + hardware_df['GPU Energy (kWh)'], label='RAM', color=colors[2])\n\nax.set_ylabel('Energy Consumption (kWh)', fontsize=12)\nax.set_title('Phase 2a Energy Consumption by Hardware Component (Qwen3-30B-A3B)', fontsize=14, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(hardware_df['Experiment'], rotation=15, ha='right')\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'phase2a_energy_by_component.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"✓ Saved to {OUTPUT_DIR / 'phase2a_energy_by_component.png'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 2: Power consumption comparison\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Average power by component\nx = np.arange(len(hardware_df))\nwidth = 0.25\n\nax1.bar(x - width, hardware_df['Avg CPU Power (W)'], width, label='CPU', color=colors[0])\nax1.bar(x, hardware_df['Avg GPU Power (W)'], width, label='GPU', color=colors[1])\nax1.bar(x + width, hardware_df['Avg RAM Power (W)'], width, label='RAM', color=colors[2])\n\nax1.set_ylabel('Average Power (W)', fontsize=12)\nax1.set_title('Phase 2a: Average Power Consumption by Component', fontsize=12, fontweight='bold')\nax1.set_xticks(x)\nax1.set_xticklabels(hardware_df['Experiment'], rotation=15, ha='right')\nax1.legend()\nax1.grid(axis='y', alpha=0.3)\n\n# Total energy comparison\nmodel_colors = {'Instruct': '#3498db', 'Thinking': '#e74c3c'}\ncolors_map = [model_colors[m] for m in hardware_df['Model']]\n\nax2.bar(x, hardware_df['Total Energy (kWh)'], color=colors_map)\nax2.set_ylabel('Total Energy (kWh)', fontsize=12)\nax2.set_title('Phase 2a: Total Energy Consumption', fontsize=12, fontweight='bold')\nax2.set_xticks(x)\nax2.set_xticklabels(hardware_df['Experiment'], rotation=15, ha='right')\nax2.grid(axis='y', alpha=0.3)\n\n# Add legend for model types\nfrom matplotlib.patches import Patch\nlegend_elements = [Patch(facecolor='#3498db', label='Instruct (30B-A3B)'),\n                  Patch(facecolor='#e74c3c', label='Thinking (30B-A3B)')]\nax2.legend(handles=legend_elements)\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'phase2a_power_consumption.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"✓ Saved to {OUTPUT_DIR / 'phase2a_power_consumption.png'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 3: Pie charts showing energy distribution\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.ravel()\n\ncolors = ['#3498db', '#e74c3c', '#2ecc71']\n\nfor idx, (_, row) in enumerate(hardware_df.iterrows()):\n    if idx < 4:  # We have 4 experiments\n        energy_values = [\n            row['CPU Energy (kWh)'],\n            row['GPU Energy (kWh)'],\n            row['RAM Energy (kWh)']\n        ]\n        \n        axes[idx].pie(energy_values, labels=['CPU', 'GPU', 'RAM'], \n                     autopct='%1.1f%%', colors=colors, startangle=90)\n        axes[idx].set_title(row['Experiment'], fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'phase2a_energy_distribution_pies.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"✓ Saved to {OUTPUT_DIR / 'phase2a_energy_distribution_pies.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Energy-Performance Tradeoff Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load performance metrics from rq1_phase2a_summary_table.csv\nperf_df = pd.read_csv(OUTPUT_DIR / 'rq1_phase2a_summary_table.csv')\n\n# Merge with hardware data\n# Map experiment names\nname_mapping = {\n    'Instruct Zero': 'Instruct Zero-shot',\n    'Instruct Few': 'Instruct Few-shot',\n    'Thinking Zero': 'Thinking Zero-shot',\n    'Thinking Few': 'Thinking Few-shot'\n}\nperf_df['Experiment_Full'] = perf_df['Experiment'].map(name_mapping)\n\n# Merge performance and energy data\ntradeoff_df = perf_df.merge(\n    hardware_df[['Experiment', 'Total Energy (kWh)', 'Total CO2 (kg)']],\n    left_on='Experiment_Full',\n    right_on='Experiment'\n)\n\ntradeoff_df[['Experiment_x', 'Model', 'Prompting', 'F1-Score', 'Total Energy (kWh)', 'Total CO2 (kg)']]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create scatter plot: F1 Score vs Energy Consumption (Phase 2a)\nfig, ax = plt.subplots(figsize=(10, 7))\n\n# Define colors and markers\nmodel_colors = {'Instruct': '#3498db', 'Thinking': '#e74c3c'}\nprompting_markers = {'Zero-shot': 'o', 'Few-shot': 's'}\n\n# Plot each point with appropriate color and marker\nfor _, row in tradeoff_df.iterrows():\n    ax.scatter(row['Total Energy (kWh)'], float(row['F1-Score']) * 100,  # Convert to percentage\n              color=model_colors[row['Model']], \n              marker=prompting_markers[row['Prompting']],\n              s=200, alpha=0.7, edgecolors='black', linewidth=1.5)\n    \n    # Add labels for each point\n    label = row['Experiment_x']\n    ax.annotate(label, \n               (row['Total Energy (kWh)'], float(row['F1-Score']) * 100),\n               xytext=(8, 5), textcoords='offset points',\n               fontsize=9, ha='left')\n\n# Add title and labels\nax.set_xlabel('Energy Consumption (kWh)', fontsize=12, fontweight='bold')\nax.set_ylabel('F1 Score (%)', fontsize=12, fontweight='bold')\nax.set_title('Phase 2a: Energy-Performance Tradeoff (Qwen3-30B-A3B Models)', \n            fontsize=14, fontweight='bold', pad=20)\n\n# Add grid\nax.grid(True, alpha=0.3, linestyle='--')\n\n# Create custom legend\nfrom matplotlib.lines import Line2D\nlegend_elements = [\n    Line2D([0], [0], marker='o', color='w', markerfacecolor='#3498db', \n           markersize=10, label='Instruct (30B-A3B)', markeredgecolor='black', markeredgewidth=1),\n    Line2D([0], [0], marker='o', color='w', markerfacecolor='#e74c3c', \n           markersize=10, label='Thinking (30B-A3B)', markeredgecolor='black', markeredgewidth=1),\n    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', \n           markersize=10, label='Zero-shot', markeredgecolor='black', markeredgewidth=1),\n    Line2D([0], [0], marker='s', color='w', markerfacecolor='gray', \n           markersize=10, label='Few-shot', markeredgecolor='black', markeredgewidth=1)\n]\nax.legend(handles=legend_elements, loc='best', fontsize=10, framealpha=0.9)\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'phase2a_energy_performance_tradeoff.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"✓ Saved to {OUTPUT_DIR / 'phase2a_energy_performance_tradeoff.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Summary\n\nThis notebook analyzed hardware-level energy consumption for Phase 2a using CodeCarbon emissions data.\n\n**Phase 2a Outputs:**\n- `phase2a_energy_by_component.png` - Stacked bar chart of CPU/GPU/RAM energy\n- `phase2a_power_consumption.png` - Power usage and total energy comparison\n- `phase2a_energy_distribution_pies.png` - Pie charts showing component breakdown\n- `phase2a_energy_performance_tradeoff.png` - Scatter plot of F1 score vs energy consumption\n- `phase2a_codecarbon_detailed.xlsx` - Complete hardware data tables (if exported)\n- Hardware metrics saved for further analysis\n\n**Data quality (Phase 2a):**\n- ✓ CodeCarbon emissions.csv data from clean RunPod H100 pods\n- ✓ Cross-validation confirms < 0.01% difference with energy_tracking.json\n- ✓ All hardware component metrics based on verified sessions\n- ✓ Simplified data structure (no complex session filtering needed)\n\n**Phase 2a Infrastructure:**\n- RunPod H100 SXM 80GB (160 CPU cores, 1x H100 80GB, ~2TB RAM)\n- Qwen3-30B-A3B models (MoE: 30B total, 3B active per token)\n- Fresh pod per experiment (clean experimental isolation)\n\n**For complete findings**: See `docs/COMPLETION_STATUS.md` and compare with Phase 1 results"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erp_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}