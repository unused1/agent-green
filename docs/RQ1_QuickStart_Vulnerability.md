# RQ1 Quick Start: Vulnerability Detection with Qwen3 Thinking

## Setup Your Environment

### 1. Configure .env File

Create or update `/Users/shanetan/Documents/Code_Projects/SMU/SCIS_EngD/agent-green/.env`:

```bash
# Project paths
PROJECT_ROOT=/Users/shanetan/Documents/Code_Projects/SMU/SCIS_EngD/agent-green

# ============================================================================
# LOCAL OLLAMA (for testing)
# ============================================================================
OLLAMA_HOST=http://localhost:11434

# ============================================================================
# REASONING MODE TOGGLE
# ============================================================================
# Set to "true" for reasoning-enabled model, "false" for baseline
ENABLE_REASONING=true

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
# Reasoning model (thinking enabled)
REASONING_MODEL=qwen3:4b-thinking
REASONING_ENDPOINT=http://localhost:11434
REASONING_API_KEY=

# Baseline model (thinking disabled)
BASELINE_MODEL=qwen3:4b
BASELINE_ENDPOINT=http://localhost:11434
BASELINE_API_KEY=

# Manual override (optional)
# LLM_MODEL=qwen3:4b-thinking
```

### 2. Ensure Ollama Models are Available

```bash
# Pull both models
ollama pull qwen3:4b-thinking
ollama pull qwen3:4b

# Verify models are available
ollama list | grep qwen3
```

### 3. Start Ollama Server

```bash
# In a separate terminal
ollama serve
```

## Running Experiments

### Experiment 1: Reasoning-Enabled Model (SA-zero)

```bash
# Set environment
export ENABLE_REASONING=true

# Run single agent with zero-shot prompting
cd /Users/shanetan/Documents/Code_Projects/SMU/SCIS_EngD/agent-green
python src/single_agent_vuln.py SA-zero
```

**Expected Output:**
```
[CONFIG] Reasoning mode: ENABLED
[CONFIG] Model: qwen3:4b-thinking
[CONFIG] Endpoint: http://localhost:11434
Running with design: SA-zero
Loading vulnerability dataset...
Loaded 386 code samples
...
```

### Experiment 2: Baseline Model (SA-zero)

```bash
# Set environment
export ENABLE_REASONING=false

# Run single agent with zero-shot prompting
python src/single_agent_vuln.py SA-zero
```

**Expected Output:**
```
[CONFIG] Reasoning mode: DISABLED
[CONFIG] Model: qwen3:4b
[CONFIG] Endpoint: http://localhost:11434
Running with design: SA-zero
Loading vulnerability dataset...
Loaded 386 code samples
...
```

### Experiment 3: Reasoning-Enabled with Few-Shot

```bash
export ENABLE_REASONING=true
python src/single_agent_vuln.py SA-few
```

### Experiment 4: Baseline with Few-Shot

```bash
export ENABLE_REASONING=false
python src/single_agent_vuln.py SA-few
```

## Alternative: Using Command Line Override

Instead of setting `ENABLE_REASONING`, you can directly specify the model:

```bash
# Reasoning model
LLM_MODEL=qwen3:4b-thinking python src/single_agent_vuln.py SA-zero

# Baseline model
LLM_MODEL=qwen3:4b python src/single_agent_vuln.py SA-zero
```

## Output Files

Results will be saved in `results/` directory:

```
results/
├── SA-zero_qwen3-4b-thinking_TIMESTAMP_detailed_results.jsonl
├── SA-zero_qwen3-4b-thinking_TIMESTAMP_detailed_results.csv
├── SA-zero_qwen3-4b-thinking_TIMESTAMP_energy_tracking.json
├── SA-zero_qwen3-4b-thinking_TIMESTAMP_predictions.json
├── SA-zero_qwen3-4b-thinking_TIMESTAMP_eval_*.json
└── emissions.csv
```

## Comparing Results

### Check Accuracy

```bash
# View basic evaluation
cat results/SA-zero_qwen3-4b-thinking_*_eval_basic.json
cat results/SA-zero_qwen3-4b_*_eval_basic.json
```

### Check Energy Consumption

```bash
# View energy tracking
cat results/SA-zero_qwen3-4b-thinking_*_energy_tracking.json
cat results/SA-zero_qwen3-4b_*_energy_tracking.json
```

### Quick Comparison Script

```python
import json
import glob

def compare_results():
    # Find latest results
    thinking_files = glob.glob("results/*thinking*eval_basic.json")
    baseline_files = glob.glob("results/*qwen3-4b_*eval_basic.json")

    if thinking_files and baseline_files:
        with open(thinking_files[-1]) as f:
            thinking = json.load(f)
        with open(baseline_files[-1]) as f:
            baseline = json.load(f)

        print("Reasoning Model (qwen3:4b-thinking):")
        print(f"  Accuracy: {thinking['accuracy']:.4f}")
        print(f"  Precision: {thinking.get('precision', 'N/A')}")
        print(f"  Recall: {thinking.get('recall', 'N/A')}")

        print("\nBaseline Model (qwen3:4b):")
        print(f"  Accuracy: {baseline['accuracy']:.4f}")
        print(f"  Precision: {baseline.get('precision', 'N/A')}")
        print(f"  Recall: {baseline.get('recall', 'N/A')}")

        print(f"\nAccuracy Improvement: {(thinking['accuracy'] - baseline['accuracy'])*100:.2f}%")

compare_results()
```

## Batch Execution for Complete RQ1

Create a shell script `scripts/run_rq1_vuln.sh`:

```bash
#!/bin/bash

# RQ1 Vulnerability Detection Experiments
# Compares reasoning-enabled vs baseline Qwen3 models

echo "============================================"
echo "RQ1 Vulnerability Detection Experiments"
echo "============================================"

# Experiment 1: Reasoning + Zero-shot
echo "\n[1/4] Reasoning model (qwen3:4b-thinking) with zero-shot..."
export ENABLE_REASONING=true
python src/single_agent_vuln.py SA-zero
echo "✓ Completed"

# Experiment 2: Baseline + Zero-shot
echo "\n[2/4] Baseline model (qwen3:4b) with zero-shot..."
export ENABLE_REASONING=false
python src/single_agent_vuln.py SA-zero
echo "✓ Completed"

# Experiment 3: Reasoning + Few-shot
echo "\n[3/4] Reasoning model (qwen3:4b-thinking) with few-shot..."
export ENABLE_REASONING=true
python src/single_agent_vuln.py SA-few
echo "✓ Completed"

# Experiment 4: Baseline + Few-shot
echo "\n[4/4] Baseline model (qwen3:4b) with few-shot..."
export ENABLE_REASONING=false
python src/single_agent_vuln.py SA-few
echo "✓ Completed"

echo "\n============================================"
echo "All experiments completed!"
echo "Results saved in: results/"
echo "============================================"
```

Run it:
```bash
chmod +x scripts/run_rq1_vuln.sh
./scripts/run_rq1_vuln.sh
```

## Using RunPod/vLLM (For Production)

Update `.env` for RunPod deployment:

```bash
# Reasoning model on RunPod Pod 1
REASONING_MODEL=Qwen/Qwen3-4B-Thinking
REASONING_ENDPOINT=https://xxx-8000.proxy.runpod.net/v1
REASONING_API_KEY=your_secure_key_1

# Baseline model on RunPod Pod 2
BASELINE_MODEL=Qwen/Qwen3-4B-Instruct
BASELINE_ENDPOINT=https://yyy-8000.proxy.runpod.net/v1
BASELINE_API_KEY=your_secure_key_2

# Enable reasoning toggle
ENABLE_REASONING=true
```

Then run the same commands - the code will automatically use RunPod endpoints!

## Troubleshooting

### Model Not Found
```bash
# Check if model is available
ollama list

# Pull if missing
ollama pull qwen3:4b-thinking
ollama pull qwen3:4b
```

### Server Connection Error
```bash
# Ensure Ollama is running
ollama serve

# Check port
curl http://localhost:11434/api/version
```

### Config Not Loading
```bash
# Verify .env file location
ls -la .env

# Check Python can read it
python -c "from dotenv import load_dotenv; load_dotenv(); import os; print(os.getenv('ENABLE_REASONING'))"
```

## Next Steps

After completing vulnerability detection:
1. Analyze results for accuracy differences
2. Compare energy consumption
3. Proceed to log parsing experiments
4. Then code generation experiments

