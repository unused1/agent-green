{"idx": 360829, "project": "linux", "commit_id": "47abea041f897d64dbd5777f0cf7745148f85d75", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/47abea041f897d64dbd5777f0cf7745148f85d75", "commit_message": "io_uring: fix off-by-one in sync cancelation file check\n\nThe passed in index should be validated against the number of registered\nfiles we have, it needs to be smaller than the index value to avoid going\none beyond the end.\n\nFixes: 78a861b94959 (\"io_uring: add sync cancelation API through io_uring_register()\")\nReported-by: Luo Likang <luolikang@nsfocus.com>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>", "ground_truth": 0, "cwe": ["CWE-193"], "cve": "CVE-2022-3103", "cve_desc": "off-by-one in io_uring module.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `__io_sync_cancel` is part of the io_uring subsystem in the Linux kernel and handles cancellation of asynchronous I/O operations.\n\n2. The function takes a file descriptor `fd` and checks if it is valid using `ctx->nr_user_files`. Specifically:\n   - It checks if `fd >= ctx->nr_user_files` and returns `-EBADF` if true.\n   - Then it uses `array_index_nospec(fd, ctx->nr_user_files)` to safely index into the file table.\n\n3. The `array_index_nospec` macro is a kernel mechanism designed to prevent speculative execution attacks and ensure that array indexing is safe even under certain compiler optimizations. It effectively bounds-checks the index and returns a safe value.\n\n4. The condition `if (unlikely(fd >= ctx->nr_user_files))` is used to catch invalid file descriptors early. This is a standard defensive programming practice.\n\n5. The use of `array_index_nospec` after the bounds check ensures that even if the bounds check is bypassed (e.g., due to a race condition or compiler optimization), the index is still clamped to a valid range.\n\n6. The code then retrieves a file pointer from the fixed file table using `io_fixed_file_slot`, extracts the `file_ptr`, masks it with `FFS_MASK`, and assigns it to `cd->file`. The check `if (!cd->file)` ensures that the file pointer is valid.\n\n7. The function then calls `__io_async_cancel` with the prepared `cd` and `tctx`.\n\n8. There is no evidence of buffer overflows, use-after-free, or improper input validation. The bounds check and safe indexing are properly implemented using kernel-safe patterns.\n\n9. The use of `unlikely` macro is appropriate for error paths and does not affect correctness.\n\n10. Overall, the code follows secure kernel programming practices: input validation, safe array indexing, and null checks.\n\n(2) NO: No security vulnerability."}
{"idx": 464942, "project": "php-src", "commit_id": "2bcbc95f033c31b00595ed39f79c3a99b4ed0501", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commit;h=2bcbc95f033c31b00595ed39f79c3a99b4ed0501", "commit_message": "Fix bug #79037 (global buffer-overflow in `mbfl_filt_conv_big5_wchar`)", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2020-7060", "cve_desc": "When using certain mbstring functions to convert multibyte encodings, in PHP versions 7.2.x below 7.2.27, 7.3.x below 7.3.14 and 7.4.x below 7.4.2 it is possible to supply data that will cause function mbfl_filt_conv_big5_wchar to read past the allocated buffer. This may lead to information disclosure or crash.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. Function Overview:\n   - The function `mbfl_filt_conv_big5_wchar` is a character encoding conversion filter that converts Big5 (or CP950) encoded bytes into Unicode (wchar_t).\n   - It uses a state machine with `filter->status` to handle multi-byte characters (DBCS - Double Byte Character Set).\n   - The function processes input bytes and outputs Unicode code points via `filter->output_function`.\n\n2. State Handling:\n   - `status == 0`: First byte of a potential DBCS character.\n     - If input byte `c` is in 0x00\u20130x80: treated as ASCII, output directly.\n     - If `c == 0xff`: outputs a special value `0xf8f8` (likely a placeholder or error indicator).\n     - If `c > c1` and `c < 0xff`: assumes it's a DBCS lead byte, sets `status = 1` and caches the byte.\n     - Otherwise: maps `c` to a Unicode value using `MBFL_WCSGROUP_MASK` and `MBFL_WCSGROUP_THROUGH`, then outputs it.\n   - `status == 1`: Second byte of a DBCS character.\n     - The lead byte is in `filter->cache`.\n     - Checks if the second byte `c` is in valid ranges: `(0x39 < c < 0x7f)` or `(0xa0 < c < 0xff)`.\n       - Note: The condition uses `|` (bitwise OR), but it should be `||` (logical OR). This is a critical syntax error.\n       - However, in C, `|` is not short-circuiting, so both sides are evaluated. But the logic is still correct in terms of range checking, though it's a bug in style and could lead to confusion.\n     - If valid, computes a Unicode value `w` based on Big5/CP950 mapping tables.\n     - If `w <= 0`, it falls back to using `(c1 << 8) | c` and masks it with `MBFL_WCSPLANE_MASK`, then sets the plane to `MBFL_WCSPLANE_BIG5`.\n     - If `c` is a control character (0\u20130x20 or 0x7f), it outputs `c` directly.\n     - Otherwise, it outputs a \"through\" value using `MBFL_WCSGROUP_THROUGH`.\n\n3. Potential Vulnerabilities:\n   - **Incorrect Logical Operator**: The condition:\n     ```c\n     if ((c > 0x39 && c < 0x7f) | (c > 0xa0 && c < 0xff))\n     ```\n     uses `|` instead of `||`. While this may not cause a crash, it's a bug that could lead to unexpected behavior if the compiler optimizes differently or if the code is misread. However, it's not a direct security vulnerability.\n   - **Unvalidated Input in Table Lookup**:\n     - The code uses `cp950_pua_tbl` to map private use area (PUA) characters.\n     - The loop:\n       ```c\n       for (k = 0; k < sizeof(cp950_pua_tbl)/(sizeof(unsigned short)*4); k++) {\n           if (c2 >= cp950_pua_tbl[k][2] && c2 <= cp950_pua_tbl[k][3]) {\n               break;\n           }\n       }\n       ```\n       This loop does not check if `k` exceeds the array bounds. If no match is found, `k` will be equal to the loop limit, and then the code accesses `cp950_pua_tbl[k][2]` and `cp950_pua_tbl[k][3]`, which is **out-of-bounds access**.\n     - This is a **buffer overflow** in the array access, which is a **serious security vulnerability**.\n     - Even though the loop condition is correct, the array access after the loop is not bounded. If the table is empty or no match is found, `k` will be equal to the number of entries, and accessing `cp950_pua_tbl[k]` is undefined behavior and can lead to memory corruption.\n\n4. Other Considerations:\n   - The use of `CK()` macro (likely a check macro) suggests error handling, but it doesn't prevent the out-of-bounds access.\n   - The fallback logic for `w <= 0` is safe, but the PUA handling is not.\n\n5. Conclusion:\n   - The code contains a **buffer overflow** due to out-of-bounds array access in the `cp950_pua_tbl` lookup.\n   - This is a **critical security vulnerability** that could lead to arbitrary code execution or denial of service.\n\n(1) YES: A security vulnerability detected."}
{"idx": 251946, "project": "tensorflow", "commit_id": "15691e456c7dc9bd6be203b09765b063bf4a380c", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/15691e456c7dc9bd6be203b09765b063bf4a380c", "commit_message": "Prevent dereferencing of null pointers in TFLite's `add.cc`.\n\nPiperOrigin-RevId: 387244946\nChange-Id: I56094233327fbd8439b92e1dbb1262176e00eeb9", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-37688", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can craft a TFLite model that would trigger a null pointer dereference, which would result in a crash and denial of service. The [implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L268-L285) unconditionally dereferences a pointer. We have patched the issue in GitHub commit 15691e456c7dc9bd6be203b09765b063bf4a380c. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `BinaryBroadcastFiveFold` is a template function that performs element-wise operations (like addition, multiplication, etc.) between two tensors with broadcasting support. It is part of a tensor computation framework (likely TensorFlow Lite).\n\n2. The function takes several parameters:\n   - `unswitched_params`: Arithmetic parameters (e.g., offsets, multipliers, shifts) used for quantized operations.\n   - `unswitched_input1_shape`, `unswitched_input2_shape`: Shapes of the two input tensors.\n   - `unswitched_input1_data`, `unswitched_input2_data`: Pointers to the input data.\n   - `output_shape`, `output_data`: Output shape and data pointer.\n   - `elementwise_f`: A function pointer for element-wise operations.\n   - `scalar_broadcast_f`: A function pointer for scalar broadcasting.\n\n3. The function uses a \"fivefold\" loop pattern to handle broadcasting across 5 dimensions (y0 to y4), which is a common optimization in tensor libraries for handling broadcasted operations efficiently.\n\n4. The code carefully manages:\n   - Input data pointers (`input1_data_ptr`, `input2_data_ptr`, `input2_data_reset`) to traverse the data correctly.\n   - Loop bounds derived from `params.broadcast_shape`, which is based on the input shapes.\n   - A conditional branch between general case (`y4 > 1`) and special case (`y4 == 1`), which handles scalar broadcasting efficiently.\n\n5. Critical checks:\n   - The function does not perform any bounds checking on the input pointers (`input1_data`, `input2_data`, `output_data`) or their sizes.\n   - However, the loop bounds are derived from `params.broadcast_shape`, which itself is computed from the input shapes (`unswitched_input1_shape`, `unswitched_input2_shape`).\n   - The `RuntimeShape` objects are assumed to be valid and consistent with the data pointers.\n   - The function uses `FlatSize()` implicitly via the loop structure (e.g., `y0 * y1 * y2 * y3 * y4`), but this is not explicitly checked.\n\n6. Potential vulnerabilities:\n   - If the `RuntimeShape` objects are malformed (e.g., negative dimensions, inconsistent with actual data), the loop bounds could be invalid.\n   - However, the function does not validate the `RuntimeShape` or the `broadcast_shape` values before using them in loops.\n   - If `broadcast_shape` contains invalid values (e.g., negative or extremely large), this could lead to:\n     - Buffer overflows (if loops run too long).\n     - Out-of-bounds memory access (if `input1_data_ptr` or `input2_data_ptr` go beyond allocated memory).\n   - The function does not check whether `input1_data` or `input2_data` are null, but this is likely handled earlier in the call chain (e.g., in the caller).\n   - The `elementwise_f` and `scalar_broadcast_f` function pointers are passed in and called with data, but they are assumed to be safe and not perform unsafe operations.\n\n7. However, the function does not perform any bounds checking on the `broadcast_shape` or the `RuntimeShape` values. If these are corrupted (e.g., due to a malformed model or malicious input), the loops could iterate beyond the actual data size, leading to memory corruption.\n\n8. But note: This function is part of a trusted runtime (e.g., TensorFlow Lite), and such shape validation is typically done earlier in the execution pipeline (e.g., during model loading or tensor allocation). The function assumes that the input shapes and parameters are valid.\n\n9. In the context of static analysis, we must assess whether the code itself contains a security vulnerability. The absence of bounds checking on `broadcast_shape` and the use of it in loops without validation is a red flag. However, if the `broadcast_shape` is derived from `RuntimeShape` objects that are validated elsewhere, then this function is not the source of the vulnerability.\n\n10. Since the function does not validate the `broadcast_shape` or `RuntimeShape` values before using them in loops, and if those values are user-controlled (e.g., from a model file), then this could lead to a buffer overflow or out-of-bounds access.\n\n11. The function uses `y4`, `y3`, etc., as loop bounds directly from `params.broadcast_shape`. If `broadcast_shape` is corrupted (e.g., contains a huge value), the loops could run indefinitely or access memory beyond the allocated buffers.\n\n12. Therefore, this code is vulnerable to a buffer overflow or memory access violation if the `broadcast_shape` is not properly validated.\n\n(1) YES: A security vulnerability detected."}
{"idx": 444900, "project": "cifs-utils", "commit_id": "f6eae44a3d05b6515a59651e6bed8b6dde689aec", "project_url": "https://github.com/piastry/cifs-utils", "commit_url": "http://git.samba.org/?p=cifs-utils.git;a=commitdiff;h=f6eae44a3d05b6515a59651e6bed8b6dde689aec", "commit_message": "mtab: handle ENOSPC/EFBIG condition properly when altering mtab\n\nIt's possible that when mount.cifs goes to append the mtab that there\nwon't be enough space to do so, and the mntent won't be appended to the\nfile in its entirety.\n\nAdd a my_endmntent routine that will fflush and then fsync the FILE if\nthat succeeds. If either fails then it will truncate the file back to\nits provided size. It will then call endmntent unconditionally.\n\nHave add_mtab call fstat on the opened mtab file in order to get the\nsize of the file before it has been appended. Assuming that that\nsucceeds, use my_endmntent to ensure that the file is not corrupted\nbefore closing it. It's possible that we'll have a small race window\nwhere the mtab is incorrect, but it should be quickly corrected.\n\nThis was reported some time ago as CVE-2011-1678:\n\n    http://openwall.com/lists/oss-security/2011/03/04/9\n\n...and it seems to fix the reproducer that I was able to come up with.\n\nSigned-off-by: Jeff Layton <jlayton@samba.org>\nReviewed-by: Suresh Jayaraman <sjayaraman@suse.de>", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2011-1678", "cve_desc": "smbfs in Samba 3.5.8 and earlier attempts to use (1) mount.cifs to append to the /etc/mtab file and (2) umount.cifs to append to the /etc/mtab.tmp file without first checking whether resource limits would interfere, which allows local users to trigger corruption of the /etc/mtab file via a process with a small RLIMIT_FSIZE value, a related issue to CVE-2011-1089.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `add_mtab` is responsible for adding an entry to the `/etc/mtab` file (or a similar mount table), which tracks currently mounted filesystems.\n\n2. The function starts by checking the user's UID. If the user is not root (uid != 0), it attempts to get the username via `getusername(uid)`. This is used later to add a `user=` option in the mount options.\n\n3. The function calls `setreuid(geteuid(), -1)` to set the real UID to the effective UID. This is intended to drop privileges and prevent unprivileged users from sending signals to the process. This is a reasonable security practice.\n\n4. Signal handling is modified using `sigfillset` and `sigprocmask` to block all signals. This prevents signal injection or interference during critical operations. This is a good security practice.\n\n5. The function calls `toggle_dac_capability(1, 1)` to enable DAC (Discretionary Access Control) capability, which is likely needed to access or modify system files like `/etc/mtab`. This is a common pattern in privileged operations.\n\n6. The function locks the mtab file using `lock_mtab()` and opens it with `setmntent(MOUNTED, \"a+\")`, which opens the file in append mode. This is correct for updating the mount table.\n\n7. The `mntent` structure is populated with:\n   - `devname` (device name)\n   - `mountpoint` (mount point)\n   - `fstype` (filesystem type)\n   - `mnt_opts` (options string built using `strlcat`)\n\n8. The `mnt_opts` string is built by concatenating various mount options (ro/rw, mand, noexec, nosuid, nodev, sync) based on the `flags` parameter. If the user is not root, it appends `user=<username>`.\n\n9. The `strlcat` function is used to append strings to `mnt_opts`. The buffer size is `MTAB_OPTIONS_LEN`, and `strlcat` ensures that the destination is null-terminated and does not overflow, as long as the buffer size is correctly specified.\n\n10. The function calls `addmntent(pmntfile, &mountent)` to write the entry to the file.\n\n11. After writing, it calls `my_endmntent(pmntfile, statbuf.st_size)` to close the file and truncate it to the original size if needed.\n\n12. The function properly cleans up: unlocks the mtab, frees `mnt_opts`, restores signal mask, and disables DAC capability.\n\nNow, let's look for potential vulnerabilities:\n\n- **Input validation**: The function takes `devname`, `mountpoint`, and `fstype` as input. These are passed directly into the `mntent` structure. However, `addmntent` is designed to handle these strings safely as long as they are null-terminated and do not contain invalid characters. The function does not validate the content of these strings (e.g., checking for null bytes, invalid characters, or path traversal in `mountpoint`), but `addmntent` itself is not known to be vulnerable to injection in this context.\n\n- **User-controlled input in `mnt_opts`**: The `mount_user` string is obtained via `getusername(uid)`, which is derived from the UID. This is not user-controlled input in the sense of arbitrary input from the user \u2014 it's a system call that returns the username associated with the UID. This is safe.\n\n- **Use of `strlcat`**: The function uses `strlcat` with a fixed buffer size (`MTAB_OPTIONS_LEN`). This prevents buffer overflow as long as `MTAB_OPTIONS_LEN` is large enough and the total length of the options does not exceed it. However, if `MTAB_OPTIONS_LEN` is too small, or if the options are excessively long, it could truncate. But this is not a buffer overflow vulnerability per se \u2014 it's a potential data loss issue, not a security vulnerability.\n\n- **File handling**: The function uses `fstat` to get the file size before truncating, and `ftruncate` is used to restore the file size if `addmntent` fails. This is correct and prevents corruption.\n\n- **Privilege dropping**: The function drops privileges early via `setreuid`, and restores the original signal mask and DAC capability at the end. This is good.\n\n- **No use of unsafe functions**: No `strcpy`, `sprintf`, or `gets` are used. `strlcat` is used safely with bounds checking.\n\n- **No injection vectors**: The only user-controlled inputs are `devname`, `mountpoint`, and `fstype`. These are not used in a way that could lead to command injection or format string vulnerabilities. The `addmntent` function writes them directly to the file in a structured format.\n\n- **No race conditions**: The function locks the mtab file before writing, so no race condition in file access.\n\nConclusion: The code uses safe string functions (`strlcat`), properly manages file locks, handles signals, and drops privileges. It does not expose any obvious security vulnerabilities such as buffer overflows, injection, or privilege escalation.\n\n(2) NO: No security vulnerability."}
{"idx": 226029, "project": "gpac", "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "commit_message": "fixed #2092", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-4043", "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `gitn_box_del` is designed to safely deallocate memory associated with a `GroupIdToNameBox` structure, which is a type of box in a media file format (likely ISO/IEC 14496-12, commonly known as MP4).\n\n2. The function first casts the generic `GF_Box *s` to `GroupIdToNameBox *ptr`. This cast is safe only if the input `s` is indeed a valid `GroupIdToNameBox` instance. However, the function checks for `ptr == NULL` at the beginning, which prevents a null pointer dereference.\n\n3. The function then checks if `ptr->entries` is non-null. If it is, it iterates over `ptr->nb_entries` (the number of entries) and frees each `ptr->entries[i].name` if it is non-null.\n\n4. After freeing all individual names, it frees the `entries` array itself.\n\n5. Finally, it frees the `ptr` structure itself.\n\n6. Key observations:\n   - The loop iterates from `i = 0` to `i < ptr->nb_entries`, which is correct as long as `nb_entries` is a valid, non-negative value.\n   - The function checks for `ptr->entries` being non-null before the loop, so no dereference of a null pointer occurs.\n   - Each `name` is checked for null before calling `gf_free`, which is safe.\n   - The `gf_free` calls are properly ordered: individual names first, then the array, then the structure.\n\n7. There is no indication of integer overflow or underflow in the loop bounds (e.g., `nb_entries` is of type `u32`, which is unsigned, so it cannot be negative, and the loop condition `i < ptr->nb_entries` is safe).\n\n8. The function does not perform any input validation on `ptr->nb_entries` itself, but since this value is assumed to be part of the structure that was previously allocated and populated (e.g., during parsing), and the function is only responsible for cleanup, it is reasonable to assume that `nb_entries` is valid if the structure is valid.\n\n9. No buffer overflow, use-after-free, or double-free vulnerabilities are present in this code. The order of freeing is correct: inner allocations first, then the container, then the top-level structure.\n\n10. The function is well-structured and follows safe memory deallocation patterns.\n\n(2) NO: No security vulnerability."}
{"idx": 483469, "project": "mongo", "commit_id": "a5e2f9b0a236462a6d1ca129583c617f111367b4", "project_url": "https://github.com/mongodb/mongo", "commit_url": "https://github.com/mongodb/mongo/commit/a5e2f9b0a236462a6d1ca129583c617f111367b4", "commit_message": "SERVER-59071 Treat '$sample' as unsharded when connecting directly to shards\n\n(cherry picked from commit f3604b901d688c194de5e430c7fbab060c9dc8e0)", "ground_truth": 0, "cwe": ["CWE-617"], "cve": "CVE-2021-32037", "cve_desc": "An authorized user may trigger an invariant which may result in denial of service or server exit if a relevant aggregation request is sent to a shard. Usually, the requests are sent via mongos and special privileges are required in order to know the address of the shards and to log in to the shards of an auth enabled environment.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Context and Purpose**:\n   - The function `createRandomCursorExecutor` is part of a database query execution system (likely MongoDB).\n   - It creates a plan executor for a `$sample` aggregation stage, using either a random cursor (for efficiency) or falling back to a collection scan.\n   - It uses a `TrialStage` to dynamically choose between two plans based on early sampling results.\n\n2. **Input Validation and Bounds Checking**:\n   - The function checks `sampleSize` against `numRecords` using thresholds (`kMaxSampleRatioForRandCursor`, `kCoefficient`, etc.).\n   - These checks prevent the use of random cursors when the sample size is too large relative to the total number of records, which is a performance and correctness safeguard.\n   - For time-series collections, it uses `gTimeseriesBucketMaxCount` to estimate maximum possible measurements and applies a threshold based on expected bucket fullness.\n\n3. **Use of `TrialStage` for Safe Fallback**:\n   - The `TrialStage` is used to run a trial of the optimized plan (e.g., `SampleFromTimeseriesBucket`) against a backup plan (e.g., `CollectionScan`).\n   - The decision to use the optimized plan is based on observed performance (advanced/work ratio) during the trial.\n   - This is a well-known pattern to avoid inefficient or incorrect optimizations in the face of unexpected data distribution.\n\n4. **Memory and Resource Safety**:\n   - The code uses `std::unique_ptr` and `std::make_unique` appropriately, ensuring RAII and preventing memory leaks.\n   - `WorkingSet` is managed correctly via `std::unique_ptr`.\n   - The `invariant` check ensures that the collection is already locked, which is required for correctness and avoids double-locking issues.\n\n5. **No User Input Directly Manipulating Execution**:\n   - The function takes `sampleSize`, `numRecords`, and `bucketUnpacker` as inputs, but these are internal metadata or configuration values.\n   - There is no direct string concatenation, dynamic query construction, or untrusted input being passed to system calls or interpreters.\n   - The `bucketUnpacker` is passed by reference and used in a controlled way within `SampleFromTimeseriesBucket` and `UnpackTimeseriesBucket`.\n\n6. **No Known Vulnerability Patterns**:\n   - No buffer overflows (no `strcpy`, `strncpy`, or manual memory management).\n   - No SQL injection (no query string construction).\n   - No XSS (no HTML/JS output).\n   - No unsafe casting or pointer arithmetic.\n   - No use of `eval`, `system`, or similar dangerous functions.\n\n7. **Security Best Practices Followed**:\n   - Input validation and bounds checking.\n   - Fallback mechanisms (trial-based decision).\n   - Proper use of smart pointers.\n   - Locking assumptions enforced via `invariant`.\n\n8. **Conclusion**:\n   - The code is well-structured, uses safe patterns, and includes safeguards against performance degradation and incorrect optimization.\n   - There is no evidence of a security vulnerability such as buffer overflow, injection, or unsafe memory access.\n   - The use of `TrialStage` is a defensive design choice, not a vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 291761, "project": "linux", "commit_id": "8700af2cc18c919b2a83e74e0479038fd113c15d", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/8700af2cc18c919b2a83e74e0479038fd113c15d", "commit_message": "RDMA/rtrs-clt: Fix possible double free in error case\n\nCallback function rtrs_clt_dev_release() for put_device() calls kfree(clt)\nto free memory. We shouldn't call kfree(clt) again, and we can't use the\nclt after kfree too.\n\nReplace device_register() with device_initialize() and device_add() so that\ndev_set_name can() be used appropriately.\n\nMove mutex_destroy() to the release function so it can be called in\nthe alloc_clt err path.\n\nFixes: eab098246625 (\"RDMA/rtrs-clt: Refactor the failure cases in alloc_clt\")\nLink: https://lore.kernel.org/r/20220217030929.323849-1-haris.iqbal@ionos.com\nReported-by: Miaoqian Lin <linmq006@gmail.com>\nSigned-off-by: Md Haris Iqbal <haris.iqbal@ionos.com>\nReviewed-by: Jack Wang <jinpu.wang@ionos.com>\nSigned-off-by: Jason Gunthorpe <jgg@nvidia.com>", "ground_truth": 0, "cwe": ["CWE-415"], "cve": "CVE-2022-29156", "cve_desc": "drivers/infiniband/ulp/rtrs/rtrs-clt.c in the Linux kernel before 5.16.12 has a double free related to rtrs_clt_dev_release.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `rtrs_clt_dev_release` is a cleanup function called when a device is being released, likely in a Linux kernel driver context.\n\n2. It takes a `struct device *dev` as input and uses `container_of` to get a pointer to the containing `struct rtrs_clt_sess` object (`clt`), which is a session structure associated with the device.\n\n3. The function then calls `mutex_destroy` twice:\n   - `mutex_destroy(&clt->paths_ev_mutex)`\n   - `mutex_destroy(&clt->paths_mutex)`\n   These are kernel mutexes that were presumably initialized earlier during session setup.\n\n4. After destroying the mutexes, it calls `kfree(clt)` to free the memory allocated for the `rtrs_clt_sess` structure.\n\n5. Key considerations:\n   - `mutex_destroy` is safe to call only if the mutex was previously initialized with `mutex_init`. If the mutex was not initialized, calling `mutex_destroy` leads to undefined behavior, which could be a security issue.\n   - However, the code assumes that the mutexes were properly initialized earlier (as is typical in kernel drivers), and the cleanup function is only called after proper setup.\n   - The `container_of` macro is used correctly, assuming `dev` is indeed part of a `rtrs_clt_sess` structure.\n   - The function does not perform any null checks on `dev` or `clt`, but in kernel driver code, such checks are often assumed to be handled earlier in the call chain (e.g., by the device model).\n   - The use of `kfree` after destroying the mutexes is safe because the mutexes are part of the structure being freed, and `kfree` is called only once.\n\n6. There is no evidence of buffer overflows, use-after-free, race conditions, or improper memory management in this snippet. The operations are standard for kernel driver cleanup.\n\n7. The only potential risk would be if the mutexes were not properly initialized before this function is called, but that would be a bug in the initialization path, not in this function itself.\n\n8. Since the function correctly destroys the mutexes and frees the memory in a safe order (destroy mutexes before freeing memory), and no unsafe operations are performed, this code does not introduce a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 344242, "project": "lua", "commit_id": "42d40581dd919fb134c07027ca1ce0844c670daf", "project_url": "https://github.com/lua/lua", "commit_url": "https://github.com/lua/lua/commit/42d40581dd919fb134c07027ca1ce0844c670daf", "commit_message": "Save stack space while handling errors\n\nBecause error handling (luaG_errormsg) uses slots from EXTRA_STACK,\nand some errors can recur (e.g., string overflow while creating an\nerror message in 'luaG_runerror', or a C-stack overflow before calling\nthe message handler), the code should use stack slots with parsimony.\n\nThis commit fixes the bug \"Lua-stack overflow when C stack overflows\nwhile handling an error\".", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-33099", "cve_desc": "An issue in the component luaG_runerror of Lua v5.4.4 and below leads to a heap-buffer overflow when a recursive error occurs.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `luaG_runerror` is a Lua runtime error handler that is called when a runtime error occurs in Lua code.\n\n2. It takes a format string `fmt` and variable arguments (`...`) via `va_list`, which are used to format an error message using `luaO_pushvfstring`. This function is responsible for formatting the error message with the provided arguments.\n\n3. The `luaO_pushvfstring` function is a safe string formatting function in Lua that uses `vsnprintf`-like behavior to format the string. It is designed to prevent buffer overflows by limiting the output size based on available stack space and the size of the buffer.\n\n4. The function then checks if the current call frame (`ci`) is a Lua function (via `isLua(ci)`). If so, it adds source file and line number information to the error message using `luaG_addinfo`. This is useful for debugging but does not introduce security risks.\n\n5. The code then manipulates the Lua stack: it copies the formatted message to the stack, removes the original message, and adjusts the stack pointer. These operations are standard in Lua's internal stack management and are safe when used correctly.\n\n6. Finally, `luaG_errormsg` is called, which typically triggers a longjmp to the error handler, terminating the current execution context.\n\n7. Key security considerations:\n   - The use of `va_list` and `luaO_pushvfstring` is safe because Lua's string formatting functions are designed to prevent buffer overflows by using stack-based buffers with size checks.\n   - There is no direct use of user-controlled data in unsafe string operations (like `strcpy`, `sprintf`, etc.) without bounds checking.\n   - The error message is not directly exposed to external systems in a way that could be exploited (e.g., via network or file output), and the function is internal to Lua's runtime.\n\n8. No evidence of buffer overflow, format string vulnerability, or improper input handling is present. The formatting is done through a safe, controlled interface.\n\n(2) NO: No security vulnerability."}
{"idx": 387593, "project": "linux", "commit_id": "5934d9a0383619c14df91af8fd76261dc3de2f5f", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/5934d9a0383619c14df91af8fd76261dc3de2f5f", "commit_message": "ALSA: control: Re-order bounds checking in get_ctl_id_hash()\n\nThese two checks are in the reverse order so it might read one element\nbeyond the end of the array.  First check if the \"i\" is within bounds\nbefore using it.\n\nFixes: 6ab55ec0a938 (\"ALSA: control: Fix an out-of-bounds bug in get_ctl_id_hash()\")\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nLink: https://lore.kernel.org/r/YwjgNh/gkG1hH7po@kili\nSigned-off-by: Takashi Iwai <tiwai@suse.de>", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2022-3170", "cve_desc": "An out-of-bounds access issue was found in the Linux kernel sound subsystem. It could occur when the 'id->name' provided by the user did not end with '\\0'. A privileged local user could pass a specially crafted name through ioctl() interface and crash the system or potentially escalate their privileges on the system.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `get_ctl_id_hash` computes a hash value for a `snd_ctl_elem_id` structure, which is used in the ALSA (Advanced Linux Sound Architecture) sound system to identify control elements.\n\n2. The hash is computed iteratively:\n   - It starts with `h = id->iface`\n   - Then iteratively applies: `h = MULTIPLIER * h + id->field`\n   - This is done for `id->device`, `id->subdevice`, each character of `id->name`, and finally `id->index`.\n\n3. The loop over `id->name` uses:\n   ```c\n   for (i = 0; i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN && id->name[i]; i++)\n       h = MULTIPLIER * h + id->name[i];\n   ```\n   - This ensures that the loop stops either at the maximum length (`SNDRV_CTL_ELEM_ID_NAME_MAXLEN`) or when a null terminator is encountered.\n   - This prevents reading beyond the buffer, as the loop condition checks both the length limit and the null terminator.\n\n4. The final step is:\n   ```c\n   h &= LONG_MAX;\n   ```\n   - This masks the hash to ensure it fits within a signed long (removing any sign extension issues).\n   - This is a safe operation and does not introduce overflow or underflow issues.\n\n5. The `MULTIPLIER` is assumed to be a constant (typically a prime number like 31 or 33), which is common in hash functions to reduce collisions.\n\n6. There is no use of unsafe functions like `strcpy`, `strcat`, or `sprintf`. The input is not copied or manipulated in a way that could overflow a buffer.\n\n7. The `id->name` field is accessed only within bounds due to the loop condition (`i < SNDRV_CTL_ELEM_ID_NAME_MAXLEN && id->name[i]`), so no buffer overflow can occur.\n\n8. The function does not perform any dynamic memory allocation or pointer arithmetic that could lead to memory corruption.\n\n9. The hash computation is deterministic and safe, with no known vulnerabilities in the algorithm itself when used with properly bounded input.\n\n10. The `snd_ctl_elem_id` structure is assumed to be validated before this function is called (as is typical in kernel code), so we are not concerned with malformed or malicious input at this stage.\n\nConclusion: The function correctly computes a hash using bounded input and safe arithmetic. It does not contain any buffer overflows, integer overflows (assuming `MULTIPLIER` is small and `h` is large enough), or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 506696, "project": "openssl", "commit_id": "97ab3c4b538840037812c8d9164d09a1f4bf11a1", "project_url": "https://github.com/openssl/openssl", "commit_url": "https://github.com/openssl/openssl/commit/97ab3c4b538840037812c8d9164d09a1f4bf11a1", "commit_message": "Add a test for GENERAL_NAME_cmp\n\nBased on a boringssl test contributed by David Benjamin\n\nReviewed-by: Tomas Mraz <tmraz@fedoraproject.org>", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2020-1971", "cve_desc": "The X.509 GeneralName type is a generic type for representing different types of names. One of those name types is known as EDIPartyName. OpenSSL provides a function GENERAL_NAME_cmp which compares different instances of a GENERAL_NAME to see if they are equal or not. This function behaves incorrectly when both GENERAL_NAMEs contain an EDIPARTYNAME. A NULL pointer dereference and a crash may occur leading to a possible denial of service attack. OpenSSL itself uses the GENERAL_NAME_cmp function for two purposes: 1) Comparing CRL distribution point names between an available CRL and a CRL distribution point embedded in an X509 certificate 2) When verifying that a timestamp response token signer matches the timestamp authority name (exposed via the API functions TS_RESP_verify_response and TS_RESP_verify_token) If an attacker can control both items being compared then that attacker could trigger a crash. For example if the attacker can trick a client or server into checking a malicious certificate against a malicious CRL then this may occur. Note that some applications automatically download CRLs based on a URL embedded in a certificate. This checking happens prior to the signatures on the certificate and CRL being verified. OpenSSL's s_server, s_client and verify tools have support for the \"-crl_download\" option which implements automatic CRL downloading and this attack has been demonstrated to work against those tools. Note that an unrelated bug means that affected versions of OpenSSL cannot parse or construct correct encodings of EDIPARTYNAME. However it is possible to construct a malformed EDIPARTYNAME that OpenSSL's parser will accept and hence trigger this attack. All OpenSSL 1.1.1 and 1.0.2 versions are affected by this issue. Other OpenSSL releases are out of support and have not been checked. Fixed in OpenSSL 1.1.1i (Affected 1.1.1-1.1.1h). Fixed in OpenSSL 1.0.2x (Affected 1.0.2-1.0.2w).", "vuln": 0, "reasoning": "Let's think step-by-step. This code defines a function `setup_tests` that appears to be part of a test suite, likely in a C program using OpenSSL's testing framework (based on the use of `ADD_ALL_TESTS`, `OSSL_NELEM`, and `ADD_TEST`). The function:\n\n1. Calls `ADD_ALL_TESTS(call_run_cert, OSSL_NELEM(name_fns))`, which presumably adds a set of tests based on a list of function names (`name_fns`). The `OSSL_NELEM` macro computes the number of elements in the array `name_fns`, which is used to determine how many tests to add.\n\n2. Then calls `ADD_TEST(test_GENERAL_NAME_cmp)` to add a specific test.\n\n3. Returns 1, indicating success.\n\nNow, consider potential security vulnerabilities:\n\n- The function does not involve user input, dynamic memory allocation, string manipulation, or system calls.\n- It is purely a test setup function, used during testing, not in production code.\n- The use of `OSSL_NELEM` is safe as long as `name_fns` is a valid array, which is assumed to be correct in the context of the test framework.\n- There is no buffer overflow, injection, or memory corruption risk here.\n- The function does not perform any operations that could lead to privilege escalation, information disclosure, or other security issues.\n\nSince this is a test initialization function and does not handle untrusted input or perform unsafe operations, there is no indication of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 432346, "project": "qemu", "commit_id": "b05b267840515730dbf6753495d5b7bd8b04ad1c", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://github.com/qemu/qemu/commit/b05b267840515730dbf6753495d5b7bd8b04ad1c", "commit_message": "i2c-ddc: fix oob read\n\nSuggested-by: Michael Hanselmann <public@hansmi.ch>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>\nReviewed-by: Michael Hanselmann <public@hansmi.ch>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <philmd@redhat.com>\nMessage-id: 20190108102301.1957-1-kraxel@redhat.com", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2019-3812", "cve_desc": "QEMU, through version 2.10 and through version 3.1.0, is vulnerable to an out-of-bounds read of up to 128 bytes in the hw/i2c/i2c-ddc.c:i2c_ddc() function. A local attacker with permission to execute i2c commands could exploit this to read stack memory of the qemu process on the host.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `i2c_ddc_rx` is part of an I2C DDC (Display Data Channel) implementation, likely in a QEMU emulator or similar virtualization environment.\n2. It reads a byte from an EDID (Extended Display Identification Data) blob stored in the `s->edid_blob` array.\n3. The index used to access the array is `s->reg % sizeof(s->edid_blob)`. This modulo operation ensures that the index wraps around within the bounds of the array, which is a common technique to simulate a circular buffer.\n4. The `s->reg` variable is incremented after each read, so it will eventually wrap around due to the modulo operation.\n5. The key concern is whether `s->reg` can be manipulated by an attacker to cause out-of-bounds access or other issues.\n6. However, since the index is computed as `s->reg % sizeof(s->edid_blob)`, and `sizeof(s->edid_blob)` is a fixed size (e.g., 128 bytes for EDID), the modulo operation guarantees that the index is always in the valid range [0, sizeof(s->edid_blob) - 1], regardless of the value of `s->reg`.\n7. Therefore, even if `s->reg` becomes very large or negative (though in practice it's likely unsigned), the modulo operation ensures safe indexing.\n8. There is no buffer overflow, no out-of-bounds access, and no potential for arbitrary memory reads.\n9. The code is correctly using modulo arithmetic to safely index into a fixed-size array.\n\n(2) NO: No security vulnerability."}
{"idx": 349259, "project": "squashfs-tools", "commit_id": "e0485802ec72996c20026da320650d8362f555bd", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/e0485802ec72996c20026da320650d8362f555bd", "commit_message": "Unsquashfs: additional write outside destination directory exploit fix\n\nAn issue on github (https://github.com/plougher/squashfs-tools/issues/72)\nshowed how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and '..') can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nSince then it has been shown that specially crafted Squashfs filesystems\nthat contain a symbolic link pointing outside of the destination directory,\ncoupled with an identically named file within the same directory, can\ncause Unsquashfs to write files outside of the destination directory.\n\nSpecifically the symbolic link produces a pathname pointing outside\nof the destination directory, which is then followed when writing the\nduplicate identically named file within the directory.\n\nThis commit fixes this exploit by explictly checking for duplicate\nfilenames within a directory.  As directories in v2.1, v3.x, and v4.0\nfilesystems are sorted, this is achieved by checking for consecutively\nidentical filenames.  Additionally directories are checked to\nensure they are sorted, to avoid attempts to evade the duplicate\ncheck.\n\nVersion 1.x and 2.0 filesystems (where the directories were unsorted)\nare sorted and then the above duplicate filename check is applied.\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2021-41072", "cve_desc": "squashfs_opendir in unsquash-2.c in Squashfs-Tools 4.5 allows Directory Traversal, a different vulnerability than CVE-2021-40153. A squashfs filesystem that has been crafted to include a symbolic link and then contents under the same filename in a filesystem can cause unsquashfs to first create the symbolic link pointing outside the expected directory, and then the subsequent write operation will cause the unsquashfs process to write through the symbolic link elsewhere in the filesystem.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Buffer Handling**:\n   - The function `squashfs_opendir` reads directory data from a compressed filesystem (SquashFS) using `read_directory_data` to read headers and entries.\n   - A fixed-size buffer `buffer` is declared with size `sizeof(squashfs_dir_entry_3) + SQUASHFS_NAME_LEN + 1`, and it's aligned. This buffer is used to hold a directory entry.\n   - The `dire` pointer is cast to point into this buffer. The size of the buffer is sufficient to hold a directory entry (including the name) plus one extra byte for null termination.\n\n2. **Bounds Checking on Name Length**:\n   - After reading the `dire->size`, the code checks: `if(dire->size >= SQUASHFS_NAME_LEN) { ... }`.\n   - This is a critical check: if the name size is too large (equal to or greater than `SQUASHFS_NAME_LEN`), it reports corruption and exits.\n   - This prevents buffer overflow when copying the name into `dire->name`.\n\n3. **Name Copy and Null Termination**:\n   - The name is read using `read_directory_data(dire->name, &start, &offset, dire->size + 1)`.\n   - Then, `dire->name[dire->size + 1] = '\\0';` is executed.\n   - However, this line is **dangerous** because:\n     - `dire->name` is a field within the `buffer`, which is of size `sizeof(squashfs_dir_entry_3) + SQUASHFS_NAME_LEN + 1`.\n     - The `dire->size` is read from the directory entry, which comes from untrusted filesystem data.\n     - If `dire->size` is greater than or equal to `SQUASHFS_NAME_LEN`, the earlier check would have caught it and exited.\n     - But even if `dire->size` is less than `SQUASHFS_NAME_LEN`, the `dire->name` array is only `SQUASHFS_NAME_LEN + 1` bytes long.\n     - The code writes `dire->name[dire->size + 1] = '\\0'`, which is **one byte beyond the end of the name** if `dire->size + 1` is the last index.\n     - Wait: `dire->name` is an array of size `SQUASHFS_NAME_LEN + 1`, so valid indices are `0` to `SQUASHFS_NAME_LEN`.\n     - `dire->size + 1` could be up to `SQUASHFS_NAME_LEN` (if `dire->size == SQUASHFS_NAME_LEN - 1`), so `dire->name[dire->size + 1]` would be `dire->name[SQUASHFS_NAME_LEN]`, which is the last valid index (since array is 0-indexed and size is `SQUASHFS_NAME_LEN + 1`).\n     - So `dire->name[dire->size + 1] = '\\0'` is **safe** as long as `dire->size + 1 <= SQUASHFS_NAME_LEN`, which is ensured by the earlier check: `if(dire->size >= SQUASHFS_NAME_LEN)` \u2192 exit.\n     - Therefore, `dire->size < SQUASHFS_NAME_LEN`, so `dire->size + 1 <= SQUASHFS_NAME_LEN`, so `dire->name[dire->size + 1]` is within bounds.\n\n4. **Null Termination**:\n   - The code sets `dire->name[dire->size + 1] = '\\0'`, but the name was already read with `read_directory_data(dire->name, ..., dire->size + 1)`, which should have read `dire->size + 1` bytes.\n   - That means the name is already null-terminated by the read operation, so this line is redundant but not harmful.\n   - However, if `read_directory_data` does not null-terminate, this line ensures it does.\n\n5. **Memory Allocation and Copying**:\n   - `ent = malloc(sizeof(struct dir_ent))` \u2192 safe.\n   - `ent->name = strdup(dire->name)` \u2192 `strdup` copies the name, which is null-terminated and within bounds (due to earlier checks), so no overflow.\n\n6. **Directory Entry Processing Loop**:\n   - The loop reads `dir_count` entries, each with a size check (`dire->size < SQUASHFS_NAME_LEN`), and ensures the name is valid via `check_name`.\n   - The `check_name` function likely checks for invalid characters like `/`, `.`, `..`, which is good for security.\n\n7. **Final Directory Validation**:\n   - `check_directory(dir)` ensures no duplicate names and proper sorting \u2014 this is a good integrity check.\n\n8. **Potential Issues**:\n   - The `read_directory_data` function is assumed to be safe, but if it doesn't validate the size of data it reads, it could be a problem. However, the code uses `sizeof(dirh)` and `sizeof(*dire)` as the size to read, which are fixed and known.\n   - The `start` and `offset` are updated correctly in the loop.\n   - The `bytes` counter tracks how much data has been read, and it's compared to `size`, which is derived from `(*i)->data + bytes - 3`. This seems to be a calculation based on the inode data, but note: `bytes` is incremented inside the loop, and `size` is computed once at the beginning. This could be a problem if `(*i)->data` is corrupted or maliciously large.\n\n   However, `size = (*i)->data + bytes - 3` \u2014 but `bytes` is initialized to 0 and incremented in the loop. This means `size` is computed as `(*i)->data - 3` at the start, and then `bytes` increases. So the loop condition `bytes < size` is based on a fixed `size` value. This is **correct** because `(*i)->data` is the total size of the directory data, and `bytes` tracks how much has been read. The `-3` might be due to header overhead, but it's consistent.\n\n   But wait: `size = (*i)->data + bytes - 3` \u2014 this is **incorrect** because `bytes` is used in the computation of `size`, but `bytes` is being incremented in the loop. This creates a **circular dependency**.\n\n   Let's re-express:\n   - `size = (*i)->data + bytes - 3`\n   - But `bytes` starts at 0, so `size = (*i)->data - 3`\n   - Then, in the loop, `bytes` is incremented by `sizeof(dirh)` and then by `sizeof(*dire)` and `dire->size + 1` for each entry.\n   - So `size` is fixed at `(*i)->data - 3`, and the loop runs while `bytes < size`.\n\n   This is **correct** only if `(*i)->data` is the total size of the directory data, and the `-3` accounts for the header or something. But the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   This is **wrong** because `bytes` is not known at the time of computing `size`. It's initialized to 0, so `size = (*i)->data - 3`, which is fine. But then `bytes` is incremented, and the loop condition is `bytes < size`. This is acceptable only if `(*i)->data` is the total size of the directory data, and the `-3` is a fixed offset.\n\n   However, the comment says: `size = (*i)->data + bytes - 3;` \u2014 this is **incorrect** because `bytes` is not a constant. It's being used in the computation of `size`, but `bytes` is being updated in the loop. This is a **logic error**.\n\n   But wait: `bytes` is initialized to 0, and `size` is computed once at the start of the loop. So `size = (*i)->data - 3` (since `bytes = 0`). Then the loop runs while `bytes < size`. This is **correct** only if `(*i)->data` is the total size of the directory data, and the `-3` is a fixed offset (e.g., for header or metadata). But the code uses `(*i)->data` as the size of the directory data, and `bytes` is the amount read so far.\n\n   However, the `size` variable is used to control the loop, and it's computed as `(*i)->data + bytes - 3`. But `bytes` is 0 at the start, so `size = (*i)->data - 3`. Then, as `bytes` increases, the loop continues until `bytes >= size`.\n\n   But this means the loop will read `size` bytes, but `size` is `(*i)->data - 3`, so it reads `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes. So it's missing 3 bytes? Or the `-3` is intentional?\n\n   Actually, the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   But `bytes` is 0, so `size = (*i)->data - 3`. Then the loop runs while `bytes < size`. So it reads `size` bytes, i.e., `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes. So it's not reading the full data.\n\n   This is a **bug**, but is it a security vulnerability?\n\n   The `read_directory_data` function reads `sizeof(dirh)` or `sizeof(*dire)` or `dire->size + 1` bytes, which are all bounded by the `size` variable. But if `(*i)->data` is maliciously large, and `bytes` is 0, then `size = (*i)->data - 3` could be huge, leading to a potential infinite loop or memory exhaustion.\n\n   However, `(*i)->data` is read from the filesystem inode, which is part of the compressed filesystem. If the filesystem is corrupted or malicious, `(*i)->data` could be very large (e.g., 2^32 - 1). Then `size` becomes huge, and the loop runs many times, potentially consuming all memory.\n\n   But the code has a check: `if(dir_count > SQUASHFS_DIR_COUNT)` \u2192 exit. And `SQUASHFS_DIR_COUNT` is a small constant (e.g., 1024). So even if `(*i)->data` is large, the loop will only run `dir_count` times per header, and `dir_count` is limited.\n\n   However, the outer loop is `while(bytes < size)`, and `size` is `(*i)->data - 3`. But `(*i)->data` is the size of the directory data, so it should be the total size. But the code uses `(*i)->data + bytes - 3`, which is wrong because `bytes` is not constant.\n\n   This is a **critical bug**: the `size` variable is computed using `bytes`, which is being updated in the loop. But `size` is computed only once at the start of the loop. So if `(*i)->data` is large, `size` becomes large, and the loop runs many times, but each iteration reads a fixed amount of data (e.g., `sizeof(dirh)` or `sizeof(*dire)`), and `bytes` increases accordingly.\n\n   But the problem is: `size = (*i)->data + bytes - 3` \u2014 this is **incorrect** because `bytes` is not known at the time of computation. It should be `size = (*i)->data - 3` (if the `-3` is a fixed offset), or `size = (*i)->data` (if no offset). But the current code is `size = (*i)->data + bytes - 3`, which means `size` increases as `bytes` increases \u2014 this is **nonsensical**.\n\n   For example:\n   - Initially: `bytes = 0`, `size = (*i)->data - 3`\n   - After first header: `bytes += sizeof(dirh)`, so `bytes = sizeof(dirh)`\n   - Then `size` is still `(*i)->data - 3`, so the loop continues if `sizeof(dirh) < (*i)->data - 3`\n   - But the next iteration computes `size` again? No \u2014 the `size` variable is computed only once at the start of the loop.\n\n   Actually, the `size` variable is computed **once** at the beginning of the function, before the loop. So it's fixed.\n\n   But the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   And `bytes` is 0, so `size = (*i)->data - 3`.\n\n   Then the loop is:\n   ```c\n   while(bytes < size) {\n       ...\n   }\n   ```\n\n   So it's correct: it reads until `bytes >= (*i)->data - 3`.\n\n   But why `-3`? It might be a typo. It should be `size = (*i)->data` or `size = (*i)->data - 3` if the header is 3 bytes. But the code uses `(*i)->data + bytes - 3`, which is `(*i)->data - 3` when `bytes=0`.\n\n   So the `+ bytes` is a **bug** \u2014 it should not be there.\n\n   But even with the bug, the loop condition is `bytes < size`, and `size` is `(*i)->data - 3`, so it reads `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes, so it's missing 3 bytes. This is a **data corruption issue**, but not a security vulnerability per se.\n\n   However, the `read_directory_data` function reads data based on the size passed to it (e.g., `sizeof(dirh)`), which is fixed. So it won't read more than that. The `size` variable is only used to control the loop, not to limit the amount read per call.\n\n   Therefore, the loop will not read more than the actual data, because `read_directory_data` reads a fixed amount each time, and `bytes` is incremented accordingly.\n\n   But if `(*i)->data` is maliciously large (e.g., 2^32 - 1), then `size` becomes huge, and the loop runs many times, potentially causing a denial of service (DoS) by consuming excessive CPU or memory.\n\n   However, the `dir_count` is limited by `SQUASHFS_DIR_COUNT`, so the number of entries is bounded. But the loop is not bounded by `dir_count` \u2014 it's bounded by `size`.\n\n   But `dir_count` is read from the header, and the code checks `if(dir_count > SQUASHFS_DIR_COUNT)` \u2192 exit. So `dir_count` is at most `SQUASHFS_DIR_COUNT`, which is small.\n\n   So the loop runs at most `SQUASHFS_DIR_COUNT` times per header, and the number of headers is limited by the total data size.\n\n   But if `(*i)->data` is huge, and the directory has many headers, the loop could run many times.\n\n   However, the `dir_count` is read from each header, and it's limited. So the total number of entries is bounded.\n\n   But the `size` variable is `(*i)->data - 3`, which could be huge, but the loop condition is `bytes < size`, and `bytes` increases by `sizeof(dirh)` and then by `sizeof(*dire)` and `dire->size + 1` for each entry.\n\n   But the total number of entries is bounded by `dir_count` per header, and `dir_count` is bounded by `SQUASHFS_DIR_COUNT`.\n\n   So the loop will not run more than a few thousand times, even if `(*i)->data` is huge.\n\n   Therefore, it's not a DoS vulnerability.\n\n   But the `size` computation is still wrong: `size = (*i)->data + bytes - 3` \u2014 this is incorrect because `bytes` is not used in the computation. It should be `size = (*i)->data - 3` or `size = (*i)->data`.\n\n   However, this is a **logic bug**, not a security vulnerability.\n\n9. **Conclusion**:\n   - The code performs proper bounds checking on `dire->size` (prevents name overflow).\n   - The name is read with `read_directory_data` and null-terminated safely.\n   - The `strdup` call is safe because the name is within bounds.\n   - The `check_name` function prevents invalid characters.\n   - The `check_directory` function ensures integrity.\n   - The loop is bounded by the number of entries, which is limited by `SQUASHFS_DIR_COUNT`.\n   - The `size` computation has a bug (using `bytes` in the formula), but it doesn't lead to a security vulnerability because the actual data read is bounded by the fixed-size reads and the entry count.\n\nTherefore, there is no exploitable security vulnerability in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 386565, "project": "qcad", "commit_id": "1eeffc5daf5a06cf6213ffc19e95923cdebb2eb8", "project_url": "https://github.com/qcad/qcad", "commit_url": "https://github.com/qcad/qcad/commit/1eeffc5daf5a06cf6213ffc19e95923cdebb2eb8", "commit_message": "check vertexIndex which might be -1 for broken DXF", "ground_truth": 0, "cwe": ["CWE-191"], "cve": "CVE-2021-21897", "cve_desc": "A code execution vulnerability exists in the DL_Dxf::handleLWPolylineData functionality of Ribbonsoft dxflib 3.17.0. A specially-crafted .dxf file can lead to a heap buffer overflow. An attacker can provide a malicious file to trigger this vulnerability.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `handleLWPolylineData` processes DXF (Drawing Exchange Format) data for lightweight polylines. It handles group codes 90 (number of vertices), 10/20/30 (X/Y/Z coordinates), and 42 (bulge value).\n\n2) The function first handles group code 90 to set the maximum number of vertices:\n   - It reads `maxVertices` from `groupValue` using `toInt()`\n   - It allocates a buffer `vertices` of size `4*maxVertices` (4 values per vertex: X, Y, Z, bulge)\n   - It initializes all values to 0.0\n\n3) The vulnerability analysis:\n   - The function uses `toInt(groupValue)` to convert the group value to an integer. If `groupValue` is a very large number, this could lead to integer overflow or excessive memory allocation.\n   - The function does not validate that `maxVertices` is within a reasonable range (e.g., bounded by a maximum limit like 10000 or 100000).\n   - If an attacker provides a very large value for group code 90 (e.g., 1000000000), the `new double[4*maxVertices]` call could cause:\n     - Memory exhaustion (denial of service)\n     - Integer overflow in the array size calculation (if `maxVertices` is so large that `4*maxVertices` overflows an int)\n   - The function does not check for integer overflow or bounds on `maxVertices` before allocating memory.\n\n4) The subsequent processing of vertex data (group codes 10, 20, 30, 42) uses `vertexIndex` to access the `vertices` array. The bounds checking is:\n   - `vertexIndex < maxVertices - 1` for X coordinate (group code 10)\n   - `vertexIndex >= 0 && vertexIndex < maxVertices` for other coordinates\n   - However, if `maxVertices` was set to an extremely large value due to unvalidated input, this could still lead to memory exhaustion.\n\n5) The critical issue is that there is no upper bound check on `maxVertices` after `toInt(groupValue)`. This allows an attacker to trigger excessive memory allocation, leading to denial of service (DoS) via resource exhaustion.\n\n(1) YES: A security vulnerability detected."}
{"idx": 372352, "project": "Singular", "commit_id": "5f28fbf066626fa9c4a8f0e6408c0bb362fb386c", "project_url": "https://github.com/Singular/Singular", "commit_url": "https://github.com/Singular/Singular/commit/5f28fbf066626fa9c4a8f0e6408c0bb362fb386c", "commit_message": "use mkstemp for sdb", "ground_truth": 0, "cwe": ["CWE-269"], "cve": "CVE-2022-40299", "cve_desc": "In Singular before 4.3.1, a predictable /tmp pathname is used (e.g., by sdb.cc), which allows local users to gain the privileges of other users via a procedure in a file under /tmp. NOTE: this CVE Record is about sdb.cc and similar files in the Singular interface that have predictable /tmp pathnames; this CVE Record is not about the lack of a safe temporary-file creation capability in the Singular language.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `sdb_edit` is designed to edit a procedure body by:\n   - Creating a temporary file using `mkstemp` with a filename pattern `/tmp/sdXXXXXX`.\n   - Writing the current procedure body (`pi->data.s.body`) to this temporary file.\n   - Forking a child process to invoke an editor (from environment variables `EDITOR`, `VISUAL`, or defaulting to `vi`).\n   - After the editor exits, reading the modified content back into the procedure body.\n   - Cleaning up the temporary file and memory.\n\n2. Key security considerations:\n\n   a. **Temporary file creation**: `mkstemp` is used, which is secure because it creates a unique temporary file and returns a file descriptor. The filename is generated safely, so no race condition (e.g., TOCTOU) is expected here.\n\n   b. **Editor execution**:\n      - The editor is determined from environment variables (`EDITOR`, `VISUAL`), defaulting to `vi`.\n      - If the editor name contains a space, the code constructs a command string using `sprintf(p, \"%s %s\", editor, filename)` and calls `system(p)`.\n      - This is a **critical vulnerability**: `system()` executes the command in a shell, and if the `EDITOR` environment variable contains malicious content (e.g., `; rm -rf /` or `| cat /etc/passwd`), it can lead to **arbitrary command execution**.\n\n   c. **Use of `execlp` vs `system`**:\n      - If the editor name has no space, `execlp` is used, which is safer because it directly executes the program with arguments.\n      - However, when there is a space, the code falls back to `system()`, which is dangerous because it invokes the shell and allows command injection.\n\n   d. **Input validation**: There is no sanitization of the `EDITOR` or `VISUAL` environment variables. An attacker can set these to malicious values (e.g., `EDITOR='sh -c \"rm -rf /\"'`) and trigger arbitrary code execution when `sdb_edit` is called.\n\n   e. **File cleanup**: The temporary file is unlinked (`si_unlink`) and memory freed at the end, which is good practice.\n\n3. Conclusion:\n   - The use of `system()` with untrusted input (environment variables) is a well-known security vulnerability.\n   - This is a classic **command injection** vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 450812, "project": "gnulib", "commit_id": "2d1bd71ec70a31b01d01b734faa66bb1ed28961f", "project_url": "https://github.com/coreutils/gnulib", "commit_url": "http://git.savannah.gnu.org/cgit/gnulib.git/commit/?id=2d1bd71ec70a31b01d01b734faa66bb1ed28961f", "commit_message": "glob: fix heap buffer overflow\n\n* lib/glob.c (glob): Fix off-by-one error introduced into\nglibc in commit dd7d45e838a42b0ed470c44b55901ea98d0c2bab\ndated 1997-10-29 20:33:40.  Problem reported by Tim R\u00fchsen in:\nhttps://sourceware.org/bugzilla/show_bug.cgi?id=22320\nFix suggested by Bruno Haible.", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2017-15670", "cve_desc": "The GNU C Library (aka glibc or libc6) before 2.27 contains an off-by-one error leading to a heap-based buffer overflow in the glob function in glob.c, related to the processing of home directories using the ~ operator followed by a long string.", "vuln": 0, "reasoning": "Let's analyze the provided `glob` function step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function\nThe `glob` function is a standard C library function used to expand shell-style wildcards (like `*.c`, `file[1-3].txt`) into matching filenames. It is commonly used in command-line tools and shell scripts.\n\nThe function takes:\n- A pattern string (e.g., `*.txt`)\n- Flags to control behavior (e.g., `GLOB_NOCHECK`, `GLOB_TILDE`, etc.)\n- A callback for error handling\n- A `glob_t` structure to store results\n\nIt returns a list of matching file paths, or an error code.\n\n---\n\n### Step 2: Identify potential security issues\n\n#### (a) Input validation\nThe function starts with:\n```c\nif (pattern == NULL || pglob == NULL || (flags & ~__GLOB_FLAGS) != 0)\n{\n    __set_errno (EINVAL);\n    return -1;\n}\n```\nThis checks for null pointers and invalid flags. This is good \u2014 it prevents crashes due to null dereferences and invalid flag combinations.\n\n#### (b) Buffer handling and memory allocation\nThe function uses:\n- `malloc`, `free`, `realloc`, `alloca`, and `alloca_account` for dynamic memory.\n- `mempcpy`, `strncpy`, `strcpy`, `strlen` \u2014 all of which are used carefully with bounds checks.\n\nKey points:\n- `alloca_account` and `glob_use_alloca` are used to prefer stack allocation when safe.\n- Memory is freed appropriately using `free` and `globfree`.\n- `realloc` is used with proper bounds checks (e.g., `SIZE_MAX / sizeof(char*) - 2`).\n- No use of unsafe functions like `strcpy` without bounds checking.\n\n#### (c) Path traversal and injection\nThe function processes user-provided patterns and expands them into file paths. However:\n- It does **not** directly execute the pattern or run shell commands.\n- It uses `glob_in_dir` and `is_dir` to check file existence and type.\n- It handles `~` expansion safely (via `getenv(\"HOME\")`, `getpwnam`, etc.), with proper fallbacks.\n- It avoids path traversal by using `strrchr` and `strchr` to split path components, and only uses `dirname` and `filename` in controlled ways.\n\n#### (d) Use of `strrchr` and `strchr` for path splitting\n```c\nfilename = strrchr (pattern, '/');\n```\nThis is standard and safe. It correctly identifies the last `/` to split into directory and filename.\n\nOn Windows, it also handles `:` for drive letters, which is correct.\n\n#### (e) Handling of `~` and user home directories\n- The function checks for `~` and expands it using `getenv(\"HOME\")` or `getpwnam`.\n- It avoids infinite recursion by disallowing wildcards in drive specs.\n- It uses `getpwnam_r` with a scratch buffer to avoid buffer overflows.\n- It properly handles escaping (`\\`), including unescaping in `~user` cases.\n\n#### (f) Use of `fnmatch`-like logic\nThe function uses `__glob_pattern_type` and `__glob_pattern_p` to detect metacharacters. These are internal functions that are assumed to be safe and well-tested.\n\n#### (g) Recursive globbing\nThe function calls itself recursively for brace expansion (`{a,b}`) and directory globbing. However:\n- It uses `GLOB_APPEND` to avoid overwriting results.\n- It uses `globfree` to clean up intermediate results.\n- It checks for `GLOB_NOCHECK` and `GLOB_NOMATCH` correctly.\n\n#### (h) No use of `system`, `exec`, or shell execution\nThe function does **not** invoke a shell or execute commands. It only performs file system operations via `opendir`, `readdir`, `stat`, etc., which are safe when used correctly.\n\n#### (i) No format string vulnerabilities\nNo `printf`-style functions are used with user input.\n\n#### (j) No integer overflows\nThe function checks for `SIZE_MAX / sizeof(char*) - 2` before `realloc`, preventing integer overflow.\n\n#### (k) Proper cleanup on error\nAll paths use `goto out` with cleanup (`free`, `globfree`) to prevent memory leaks.\n\n---\n\n### Step 3: Known vulnerabilities in `glob`?\nHistorically, `glob` has had vulnerabilities in older versions (e.g., CVE-2016-10228), but those were due to:\n- Improper handling of `GLOB_TILDE` with untrusted input\n- Buffer overflows in `glob_in_dir` or `prefix_array`\n\nHowever, in this code:\n- `GLOB_TILDE` is handled safely with `getenv` and `getpwnam_r`.\n- `prefix_array` is used with proper bounds checks.\n- The code uses `__glibc_unlikely` and `alloca` safely.\n\nThis version appears to be from glibc and is well-hardened.\n\n---\n\n### Step 4: Conclusion\nAfter thorough analysis:\n- All input is validated.\n- Memory is managed safely.\n- No unsafe functions are used.\n- No path traversal or command injection is possible.\n- The function correctly handles edge cases (empty strings, `~`, `~user`, `d:`, etc.).\n- Recursive calls are safe and bounded.\n\nThere is **no detectable security vulnerability** in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 259619, "project": "libjpeg", "commit_id": "187035b9726710b4fe11d565c7808975c930895d", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/187035b9726710b4fe11d565c7808975c930895d", "commit_message": "The code now checks for consistency of the MCU sizes across\nhierarchical levels, and fails in case they are different.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-31796", "cve_desc": "libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester::FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `PrepareForEncoding` is part of a hierarchical bitmap requester, likely used in image encoding (possibly JPEG or similar).\n\n2) The code is wrapped in `#if ACCUSOFT_CODE`, meaning it's conditional compilation - only compiled if ACCUSOFT_CODE is defined. This is not a security issue in itself, but it means we're only analyzing this code path when the macro is defined.\n\n3) The function calls `BuildCommon()` - this is a helper function that likely sets up common state. No obvious issues here.\n\n4) Memory allocation for `m_ppEncodingMCU`:\n   - Allocates `sizeof(struct Line *) * m_ucCount * 8` bytes\n   - Uses `m_pEnviron->AllocMem()` which is presumably a custom memory allocator\n   - Initializes with `memset` to zero\n   - No bounds checking on `m_ucCount`, but this is likely a valid count from the frame structure\n\n5) Memory allocation for `m_ppDownsampler`:\n   - Allocates `sizeof(class DownsamplerBase *) * m_ucCount` bytes\n   - Initializes with `memset` to zero\n   - Loops through components and creates downsamplers based on subsampling factors (sx, sy)\n   - Only creates downsamplers if sx > 1 or sy > 1 (i.e., actual subsampling)\n   - Uses `DownsamplerBase::CreateDownsampler()` which appears to be a factory method\n\n6) The code checks `m_pLargestScale` and calls `PrepareForEncoding()` on it if it exists.\n\n7) Key observations:\n   - All memory allocations use `sizeof` with proper type casting\n   - Memory is zero-initialized with `memset`\n   - The loop bounds are based on `m_ucCount`, which is likely a valid component count\n   - The downsampler creation is conditional on actual subsampling (sx > 1 or sy > 1)\n   - No direct user input is being processed or copied into buffers\n   - No string operations, no format strings, no buffer copying\n   - No obvious integer overflows or underflows (no arithmetic on sizes that could wrap)\n   - The code appears to be handling image component data safely\n\n8) The code follows safe memory management patterns:\n   - Allocates only what's needed\n   - Initializes memory to zero\n   - Uses proper bounds checking via loop conditions\n   - No direct manipulation of raw buffers with unbounded copying\n\n9) There are no obvious security vulnerabilities such as buffer overflows, use-after-free, null pointer dereferences, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 325821, "project": "gnutls", "commit_id": "20a98e817713764b9df5306286091df1b61190d9", "project_url": "http://git.savannah.gnu.org/cgit/gnutls", "commit_url": "https://gitlab.com/gnutls/gnutls/commit/20a98e817713764b9df5306286091df1b61190d9", "commit_message": "handshake: check inappropriate fallback against the configured max version\n\nThat allows to operate on a server which is explicitly configured to\nutilize earlier than TLS 1.2 versions.", "ground_truth": 0, "cwe": ["CWE-310"], "cve": "CVE-2014-3566", "cve_desc": "The SSL protocol 3.0, as used in OpenSSL through 1.0.1i and other products, uses nondeterministic CBC padding, which makes it easier for man-in-the-middle attackers to obtain cleartext data via a padding-oracle attack, aka the \"POODLE\" issue.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Bounds Checking**:\n   - The function `gnutls_server_select_suite` takes `data` and `datalen` as inputs, representing the list of cipher suites sent by the client.\n   - The loop iterates over `datalen` in steps of 2, assuming each cipher suite is 2 bytes. This is correct for TLS cipher suite identifiers (which are 2-byte values).\n   - The code checks `if (datalen % 2 != 0)` at the end, which ensures that the input length is even \u2014 a necessary condition for valid cipher suite lists. If not, it returns `GNUTLS_E_UNEXPECTED_PACKET_LENGTH`. This prevents processing malformed data with odd length, which could lead to buffer overflows or out-of-bounds access.\n\n2. **Buffer Size and Copy Safety**:\n   - The function uses `cipher_suites[MAX_CIPHERSUITE_SIZE]` and `pk_algos[MAX_ALGOS]` \u2014 both are fixed-size arrays with defined maximums.\n   - The function calls `_gnutls_supported_ciphersuites(session, cipher_suites, sizeof(cipher_suites))`, which populates `cipher_suites` with supported cipher suites. The size passed is `sizeof(cipher_suites)`, so it won't overflow.\n   - The `memcpy` used to copy the selected cipher suite into `session->security_parameters.cipher_suite` copies exactly 2 bytes, which is safe because:\n     - The cipher suite is known to be 2 bytes.\n     - The source is validated via `memcmp` against valid entries from `cipher_suites`, which were already bounded by `sizeof(cipher_suites)`.\n\n3. **Use of `memcmp` and Safe Comparison**:\n   - The code compares 2-byte cipher suite values using `memcmp(&cipher_suites[i], &data[j], 2)`. This is safe because:\n     - Both `cipher_suites[i]` and `data[j]` are within valid, bounded arrays.\n     - The comparison is only done on 2-byte chunks, and the loop bounds are properly enforced.\n\n4. **Authentication and Credential Checks**:\n   - After selecting a cipher suite, the code checks for valid credentials using `_gnutls_get_kx_cred`, which ensures that the key exchange algorithm has appropriate credentials.\n   - It also sets `session->internals.auth_struct` based on the KX algorithm, which is derived from the selected cipher suite. This is safe because the KX algorithm is extracted from a validated cipher suite.\n\n5. **Log and Error Handling**:\n   - The function uses `gnutls_assert()` and `gnutls_assert_val()` for debugging and error reporting. These are not security vulnerabilities.\n   - The function returns appropriate error codes (`GNUTLS_E_UNKNOWN_CIPHER_SUITE`, `GNUTLS_E_INAPPROPRIATE_FALLBACK`, etc.) when invalid inputs or unsupported configurations are detected.\n\n6. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, or other unsafe string functions.\n   - All memory operations use `memcpy`, `memset`, or `memcmp` with explicit size parameters, and all sizes are bounded by known maximums.\n\n7. **No Buffer Overflows or Memory Corruption**:\n   - All array accesses are within bounds due to:\n     - Proper loop bounds (`i < datalen`, `j < datalen`, etc.).\n     - The `datalen % 2 != 0` check.\n     - Use of `sizeof` and fixed-size arrays with known limits.\n\n8. **Security-Critical Logic**:\n   - The selection of cipher suites is based on the client's list and the server's supported list, with proper filtering via `_gnutls_remove_unwanted_ciphersuites`.\n   - The server precedence logic is correctly implemented: either client-preferred (first match in client list) or server-preferred (first match in server list), both of which are safe.\n\nConclusion: The code performs proper input validation, uses bounded buffers, avoids unsafe memory operations, and correctly handles cipher suite selection with appropriate error checking. There are no exploitable vulnerabilities such as buffer overflows, use-after-free, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 448562, "project": "frr", "commit_id": "ff6db1027f8f36df657ff2e5ea167773752537ed", "project_url": "https://github.com/FRRouting/frr", "commit_url": "https://github.com/FRRouting/frr/commit/ff6db1027f8f36df657ff2e5ea167773752537ed", "commit_message": "bgpd: Make sure hdr length is at a minimum of what is expected\n\nEnsure that if the capability length specified is enough data.\n\nSigned-off-by: Donald Sharp <sharpd@nvidia.com>", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2022-37032", "cve_desc": "An out-of-bounds read in the BGP daemon of FRRouting FRR before 8.4 may lead to a segmentation fault and denial of service. This occurs in bgp_capability_msg_parse in bgpd/bgp_packet.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `bgp_capability_msg_parse` processes a BGP capability message from a peer.\n   - It starts by setting `end = pnt + length`, which defines the end of the input buffer.\n   - The loop processes the message byte by byte, ensuring that each capability block is within bounds.\n\n2. **Initial Length Check**:\n   - Before processing any capability, it checks: `if (pnt + 3 > end)`. This ensures that at least 3 bytes (action, code, length) are available.\n   - This is a correct and necessary check to prevent reading beyond the buffer.\n\n3. **Action Value Validation**:\n   - It checks that `action` is either `CAPABILITY_ACTION_SET` or `CAPABILITY_ACTION_UNSET`.\n   - If not, it logs an error and sends a BGP notification, then returns `BGP_Stop`. This prevents invalid actions from being processed.\n\n4. **Capability Length Validation**:\n   - It checks that `hdr->length >= sizeof(struct capability_mp_data)`. This ensures the data portion is large enough to contain the expected structure.\n   - If not, it returns `BGP_Stop` \u2014 a safe response.\n\n5. **Final Bounds Check**:\n   - It checks: `(pnt + hdr->length + 3) > end`. This ensures that the entire capability (header + data) fits within the message.\n   - If not, it logs an error and sends a BGP notification, then returns `BGP_Stop`.\n\n6. **Memory Copy**:\n   - It uses `memcpy(&mpc, pnt + 3, sizeof(struct capability_mp_data))` to copy the capability data.\n   - The size copied is exactly `sizeof(struct capability_mp_data)`, which is validated earlier (via `hdr->length >= ...`).\n   - Since the `hdr->length` is checked to be at least the size of the structure, and the total buffer is checked to contain the full capability, this copy is safe.\n\n7. **Data Processing**:\n   - The `mpc.afi` is read and converted using `ntohs`, which is safe as long as the data is properly aligned and within bounds \u2014 which is ensured by prior checks.\n   - The `bgp_map_afi_safi_iana2int` function is called to map IANA values to internal ones. This function is assumed to be safe and not perform unsafe operations.\n   - The rest of the logic (setting flags, announcing routes, clearing routes) is based on validated data.\n\n8. **Unrecognized Capability Handling**:\n   - For unrecognized capability codes, it logs a warning and continues (`continue`), which is acceptable behavior \u2014 it doesn't crash or process invalid data.\n\n9. **No Buffer Overflows or Unsafe Operations**:\n   - There are no calls to unsafe functions like `strcpy`, `sprintf`, or `memcpy` without proper size checks.\n   - All memory accesses are bounded by the `pnt` and `end` checks.\n   - The `memcpy` is used with a fixed, validated size.\n\n10. **Error Handling and Graceful Degradation**:\n    - The function sends BGP notifications and returns `BGP_Stop` on invalid input, which is appropriate for a protocol parser.\n    - It does not continue processing after a malformed packet, preventing potential exploitation.\n\nConclusion: All input validation and bounds checks are properly implemented. The code safely parses the BGP capability message without any risk of buffer overflow, out-of-bounds access, or other memory safety issues. The use of `memcpy` is safe due to prior size validation.\n\n(2) NO: No security vulnerability."}
{"idx": 382797, "project": "php-src", "commit_id": "cc08cbc84d46933c1e9e0149633f1ed5d19e45e9", "project_url": "https://github.com/php/php-src", "commit_url": "https://git.php.net/?p=php-src.git;a=commit;h=cc08cbc84d46933c1e9e0149633f1ed5d19e45e9", "commit_message": "Fix #73280: Stack Buffer Overflow in GD dynamicGetbuf\n\nWe make sure to never pass a negative `rlen` as size to memcpy().\n\nCf. <https://github.com/libgd/libgd/commit/53110871>.", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2016-8670", "cve_desc": "Integer signedness error in the dynamicGetbuf function in gd_io_dp.c in the GD Graphics Library (aka libgd) through 2.2.3, as used in PHP before 5.6.28 and 7.x before 7.0.13, allows remote attackers to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a crafted imagecreatefromstring call.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `dynamicGetbuf` is a callback function used in a library (likely libgd or similar) for reading data from a dynamic buffer context (`gdIOCtxPtr`). It reads up to `len` bytes into the buffer `buf` from the internal data structure pointed to by `dp`.\n\n2. The function first casts the `ctx` to `dpIOCtxPtr` and retrieves the `dynamicPtr *dp` from it. This is a standard pattern for accessing private data in I/O context structures.\n\n3. It calculates `remain`, which is the number of bytes remaining in the buffer (`dp->logicalSize - dp->pos`). This represents how much data is available from the current position.\n\n4. The function then checks if `remain >= len`. If so, it reads `len` bytes. Otherwise, it reads only `remain` bytes (which is less than `len`).\n\n5. If `remain <= 0`, it returns `EOF`, indicating end-of-file or no more data.\n\n6. It uses `memcpy` to copy `rlen` bytes from the data buffer starting at `dp->data + dp->pos` into the user-provided `buf`.\n\n7. It updates `dp->pos` by adding `rlen` to it, advancing the read position.\n\nNow, let's analyze for security vulnerabilities:\n\n- The function does not perform any bounds checking on the `len` parameter passed by the caller. However, it uses `remain` to cap the number of bytes read, so it will never read more than what is available in the buffer.\n- The `memcpy` call is safe because `rlen` is derived from `remain`, which is calculated as `dp->logicalSize - dp->pos`, and `rlen` is never greater than `remain`.\n- The function ensures that `rlen` is at most `remain`, and `remain` is non-negative (checked via `if (remain <= 0)`), so no underflow or overflow occurs.\n- The `memcpy` destination is `buf`, which is provided by the caller. However, the function only copies `rlen` bytes, and `rlen` is guaranteed to be \u2264 `len`, so it does not write beyond the provided buffer if `len` is valid.\n- The only potential issue would be if `len` is negative, but `len` is of type `int`, and the function uses it in comparisons. However, if `len` is negative, the condition `remain >= len` would be true only if `remain` is also negative, but `remain` is calculated as `logicalSize - pos`, and `logicalSize` and `pos` are non-negative (assuming proper initialization). So `remain` should be non-negative, and thus `len` being negative would cause `remain >= len` to be true, and `rlen = len` (negative), which would lead to `memcpy` with a negative size \u2014 this is undefined behavior.\n\nWait \u2014 this is critical: if `len` is negative, then `rlen = len` (negative), and `memcpy(buf, ..., rlen)` is called with a negative size, which is undefined behavior and can lead to crashes or memory corruption.\n\nBut is `len` ever negative? The function signature is `int dynamicGetbuf(gdIOCtxPtr ctx, void *buf, int len)`. The `len` parameter is passed by the caller (e.g., from `gdGetBuf` or similar). If the caller passes a negative `len`, this function will attempt to copy a negative number of bytes, which is undefined behavior.\n\nHowever, in practice, `len` is typically a size parameter and should be non-negative. But the function does not validate that `len` is non-negative.\n\nSo, the vulnerability is: **The function does not check if `len` is negative, which could lead to undefined behavior (e.g., `memcpy` with negative size), potentially causing crashes or memory corruption.**\n\nThis is a classic example of a missing input validation issue, and while it may not be exploitable in all contexts, it is a security vulnerability because it can lead to denial of service (crash) or potentially more serious issues if the undefined behavior is leveraged.\n\nTherefore, this is a security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 296226, "project": "vim", "commit_id": "37f47958b8a2a44abc60614271d9537e7f14e51a", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/37f47958b8a2a44abc60614271d9537e7f14e51a", "commit_message": "patch 8.2.4253: using freed memory when substitute with function call\n\nProblem:    Using freed memory when substitute uses a recursive function call.\nSolution:   Make a copy of the substitute text.", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-0413", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThe function `ex_substitute` is part of the Vim editor's internal codebase and handles the `:s` (substitute) command. It performs regular expression-based search and replace operations on lines in a buffer. The function is responsible for:\n- Parsing the substitution command (e.g., `:s/pat/repl/g`)\n- Compiling the regular expression\n- Applying substitutions line by line\n- Handling flags like `g` (global), `c` (confirm), `i` (ignore case), etc.\n- Managing undo, cursor position, and buffer modifications\n\nThis is a core editing function in a text editor, so it must be robust against malformed input, especially since it processes user-provided regular expressions and replacement strings.\n\n---\n\n### Step 2: Identify potential vulnerabilities\n\n#### A. **Input validation for regular expression**\n- The function uses `skip_regexp_ex()` and `search_regcomp()` to parse and compile the regex.\n- It checks for valid delimiters using `check_regexp_delim()`.\n- It handles special cases like `\\n`, `\\?`, `\\/`, `\\&` (Vi compatibility).\n- The regex is compiled via `search_regcomp()`, which is a well-tested function in Vim.\n\n\u2705 **No obvious buffer overflow or injection in regex parsing.**\n\n#### B. **Substitution string handling**\n- The substitution string (`sub`) is processed with:\n  - `vim_strsave()` for copying\n  - `regtilde()` to replace `~` with the previous pattern\n  - Special handling for `\\=` (expression evaluation)\n- If `sub[0] == '\\\\' && sub[1] == '='`, it treats the string as an expression and saves a copy.\n- Otherwise, it calls `regtilde()` which safely replaces `~` with the last pattern.\n\n\u26a0\ufe0f **Potential concern**: The use of `regtilde()` and expression evaluation (`\\=`) could be dangerous if not properly sandboxed.\n\nHowever:\n- The code explicitly checks for `sub[0] == '\\\\' && sub[1] == '='` and uses `sandbox++` to prevent unintended side effects.\n- The `sandbox` variable is used to disable modifications to the buffer during expression evaluation.\n- The `subflags.do_count` flag is used to prevent actual substitution when counting.\n\n\u2705 **This is a controlled environment. Expression evaluation is sandboxed and not allowed to modify the buffer unless explicitly intended.**\n\n#### C. **Memory management and buffer overflows**\n- The function uses `alloc()` and `vim_free()` for dynamic memory.\n- It checks for `NULL` returns from `alloc()` and handles `outofmem` via `goto outofmem`.\n- Temporary buffers (`new_start`, `sub_firstline`) are properly freed.\n- The code uses `mch_memmove()` and `STRMOVE()` safely with bounds checks via `STRLEN()`.\n\n\u2705 **No buffer overflow or memory corruption is evident.**\n\n#### D. **User input in command line**\n- The command string `eap->arg` is parsed and processed.\n- The function uses `skipwhite()`, `getdigits()`, and `skip_regexp_ex()` to parse the command.\n- It validates syntax and rejects malformed input (e.g., invalid delimiters, trailing garbage).\n- It uses `set_nextcmd()` to handle trailing commands.\n\n\u2705 **Input is well-parsed and validated. No direct injection into shell or system calls.**\n\n#### E. **Security-sensitive operations**\n- The function modifies the buffer (`ml_replace`, `ml_append`, `ml_delete`).\n- It updates undo history (`u_savesub`, `u_savedel`).\n- It updates cursor position and marks.\n\nBut:\n- All modifications are done within the editor's internal buffer model.\n- The `b_p_ma` (modifiable) flag is checked before any modification.\n- The `sandbox` mechanism prevents unintended side effects during expression evaluation.\n\n\u2705 **No privilege escalation, no arbitrary code execution, no system call injection.**\n\n#### F. **Cross-site scripting (XSS) or script injection?**\n- This is a command-line editor, not a web application.\n- No HTML, JavaScript, or DOM manipulation.\n- No output to a browser.\n\n\u274c **Not applicable.**\n\n#### G. **Reentrancy and recursion**\n- The function uses `subflags_save` to preserve state during recursive calls.\n- It uses `sandbox` to prevent side effects.\n- It checks `aborting()` and `got_int` to handle interruptions.\n\n\u2705 **Safe handling of recursion and interrupts.**\n\n---\n\n### Step 3: Conclusion\n\nAfter a thorough analysis:\n- The code handles user input (regex and substitution strings) with proper validation.\n- It uses safe memory management.\n- It sandboxed dangerous operations (like `:s/\\=...`).\n- It avoids buffer overflows, injection, and unintended side effects.\n- No evidence of exploitable vulnerabilities.\n\nThis is a well-structured, secure function typical of Vim\u2019s robust codebase.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 500663, "project": "libssh", "commit_id": "4d8420f3282ed07fc99fc5e930c17df27ef1e9b2", "project_url": "http://git.libssh.org/projects/libssh", "commit_url": "http://git.libssh.org/projects/libssh.git/commit/?h=v0-5&id=4d8420f3282ed07fc99fc5e930c17df27ef1e9b2", "commit_message": "sftp: Fix bug in sftp_mkdir not returning on error.\n\nresolves: #84\n(cherry picked from commit a92c97b2e17715c1b3cdd693d14af6c3311d8e44)", "ground_truth": 0, "cwe": ["CWE-399"], "cve": "CVE-2012-4559", "cve_desc": "Multiple double free vulnerabilities in the (1) agent_sign_data function in agent.c, (2) channel_request function in channels.c, (3) ssh_userauth_pubkey function in auth.c, (4) sftp_parse_attr_3 function in sftp.c, and (5) try_publickey_from_file function in keyfiles.c in libssh before 0.5.3 allow remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via unspecified vectors.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step:\n\n1. The function `sftp_mkdir` is designed to create a directory on an SFTP server using the SFTP protocol. It constructs a request packet and sends it to the server.\n\n2. The function uses `ssh_buffer_new()` to allocate a buffer for the packet. If allocation fails, it sets an out-of-memory error and returns -1. This is a proper error handling pattern.\n\n3. The directory path is converted to an `ssh_string` using `ssh_string_from_char(directory)`. If this fails, it sets an OOM error, frees the buffer, and returns -1. Again, this is safe.\n\n4. The `attr` structure is initialized with `ZERO_STRUCT(attr)`, then `mode` is assigned to `attr.permissions` and `SSH_FILEXFER_ATTR_PERMISSIONS` is set in `attr.flags`. This correctly sets up the attributes for the new directory.\n\n5. A new request ID is obtained via `sftp_get_new_id(sftp)`, which is used to track the response. This is standard for SFTP request-response patterns.\n\n6. The function then adds the ID, the path (as an SSH string), and the attributes to the buffer using `buffer_add_u32`, `buffer_add_ssh_string`, and `buffer_add_attributes`. These functions are part of the libssh library and are designed to safely serialize data into the buffer.\n\n7. The packet is sent via `sftp_packet_write(sftp, SSH_FXP_MKDIR, buffer)`. If any step fails, the function cleans up resources (buffer and string) and returns -1.\n\n8. After sending, the function enters a loop waiting for a response with the matching ID using `sftp_read_and_dispatch(sftp)` and `sftp_dequeue(sftp, id)`. This is a standard asynchronous SFTP pattern.\n\n9. Upon receiving a message, it checks if the packet type is `SSH_FXP_STATUS`. According to the SFTP protocol specification, `MKDIR` should return a `STATUS` message, so this check is correct.\n\n10. The `parse_status_msg(msg)` function is called to extract the status. If parsing fails, it returns -1.\n\n11. The function handles two main status codes:\n    - `SSH_FX_OK`: Success, returns 0.\n    - `SSH_FX_FAILURE`: This is handled specially. The code calls `sftp_lstat(sftp, directory)` to check if the directory already exists. If `sftp_lstat` returns a valid attribute, it frees it and sets the error to `SSH_FX_FILE_ALREADY_EXISTS`. This is a correct workaround for the SFTP server's behavior of returning `FAILURE` even when the directory exists (which is not POSIX-compliant).\n\n12. For any other status code, it sets a fatal error and returns -1.\n\n13. If the received packet is not `SSH_FXP_STATUS`, it logs a fatal error and returns -1.\n\n14. All allocated resources (buffer, string, message) are properly freed before returning.\n\n15. The code does not perform any direct string manipulation or user input parsing that could lead to buffer overflows, format string vulnerabilities, or injection attacks. The path is passed through `ssh_string_from_char`, which is designed to handle arbitrary strings safely. The `buffer_add_ssh_string` function is also designed to safely encode strings in the SFTP wire format.\n\n16. The use of `sftp_lstat` to check for existence after a `FAILURE` is a correct and safe workaround for the SFTP protocol's non-POSIX behavior.\n\n17. There are no known vulnerabilities such as buffer overflows, use-after-free, or improper input validation.\n\nConclusion: The code follows secure coding practices, properly handles errors, uses safe library functions, and correctly implements the SFTP protocol semantics, including handling the non-POSIX behavior of `MKDIR`.\n\n(2) NO: No security vulnerability."}
{"idx": 439495, "project": "squashfs-tools", "commit_id": "79b5a555058eef4e1e7ff220c344d39f8cd09646", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/79b5a555058eef4e1e7ff220c344d39f8cd09646", "commit_message": "Unsquashfs: fix write outside destination directory exploit\n\nAn issue on Github (https://github.com/plougher/squashfs-tools/issues/72)\nshows how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and ..) can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nThis commit fixes this exploit by checking all names for\nvalidity.\n\nIn doing so I have also added checks for '.' and for names that\nare shorter than they should be (names in the file system should\nnot have '\\0' terminators).\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 0, "cwe": ["CWE-22"], "cve": "CVE-2021-40153", "cve_desc": "squashfs_opendir in unsquash-1.c in Squashfs-Tools 4.5 stores the filename in the directory entry; this is then used by unsquashfs to create the new file during the unsquash. The filename is not validated for traversal outside of the destination directory, and thus allows writing to locations outside of the destination.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its directory entries, and populating a `struct dir` with metadata about the entries.\n\n2. A buffer `buffer` of size `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` is declared and aligned. This buffer is used to hold a single directory entry (`dire`) during processing.\n\n3. The function reads the directory header (`dirh`) and then iterates over each directory entry (`dire`) in the directory data.\n\n4. For each entry:\n   - It copies the entry from `directory_table` into `dire` using `memcpy`, with size `sizeof(*dire)`.\n   - It then copies the name from `directory_table + bytes` into `dire->name`, using `dire->size + 1` bytes (including null terminator).\n   - It checks that `dire->size < SQUASHFS_NAME_LEN` to prevent overly long filenames.\n   - It calls `check_name(dire->name, dire->size + 1)` to validate the name (e.g., no `/`, `.` or `..`).\n   - It then copies the name into `dir->dirs[dir->dir_count].name` using `strcpy`.\n\n5. The critical point is in the `strcpy(dir->dirs[dir->dir_count].name, dire->name)` call.\n\n   - `dire->name` is copied from `directory_table + bytes` using `memcpy(dire->name, ..., dire->size + 1)`, and then `dire->name[dire->size + 1] = '\\0'` is explicitly set. This ensures that `dire->name` is null-terminated and the length is at most `dire->size + 1`, which is \u2264 `SQUASHFS_NAME_LEN + 1`.\n\n   - However, `dir->dirs[dir->dir_count].name` is a field in a `struct dir_ent` that is presumably declared as a fixed-size character array (e.g., `char name[SQUASHFS_NAME_LEN + 1]`), which is the same size as the buffer used for `dire->name`.\n\n   - Since `dire->size < SQUASHFS_NAME_LEN` is enforced, the name length is strictly less than `SQUASHFS_NAME_LEN`, so `dire->name` is at most `SQUASHFS_NAME_LEN` characters plus null terminator.\n\n   - Therefore, `strcpy` will copy at most `SQUASHFS_NAME_LEN` characters, which fits in the destination buffer.\n\n6. The code also checks `dire->size >= SQUASHFS_NAME_LEN` and exits with an error if true \u2014 this prevents any name from being too long.\n\n7. The `check_name` function is called to prevent invalid characters (like `/`, `.` or `..`), which is a good security practice.\n\n8. The `memcpy` operations are bounded by known sizes (`sizeof(*dire)` and `dire->size + 1`), and the `directory_table` is assumed to be a valid, trusted filesystem image (since this is a filesystem driver).\n\n9. There is no user-controlled input directly used in a way that could overflow buffers \u2014 the input is from a filesystem image, which is validated at the filesystem level.\n\n10. The only potential issue is the `strcpy` call. However, because:\n    - `dire->size < SQUASHFS_NAME_LEN` is enforced,\n    - `dire->name` is null-terminated,\n    - and the destination buffer is at least `SQUASHFS_NAME_LEN + 1` in size,\n    the `strcpy` is safe.\n\n11. The `memcpy(dire->name, ..., dire->size + 1)` ensures that the name is copied safely, and the null terminator is explicitly set.\n\n12. No buffer overflow occurs because all sizes are bounded and validated.\n\n(2) NO: No security vulnerability."}
{"idx": 299319, "project": "ImageMagick", "commit_id": "389ecc365a7c61404ba078a72c3fa5a3cf1b4101", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/389ecc365a7c61404ba078a72c3fa5a3cf1b4101", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1221", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2018-14551", "cve_desc": "The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Parsing**:\n   - The function `ReadMATImageV4` reads a MAT file (MATLAB format) and parses its header.\n   - It reads `ldblk` (a long value) from the blob using `ReadBlobLSBLong` or `ReadBlobMSBLong`, depending on the header.\n   - The code checks if `ldblk > 9999` or `ldblk < 0`, and breaks if so. This is a sanity check to prevent parsing malformed headers.\n   - The header type is extracted by decomposing `ldblk` into 4 digits: `HDR.Type[0]` to `HDR.Type[3]`. The code checks that `HDR.Type[3] == 0` and `HDR.Type[2] == 0`, which are expected for valid MAT v4 files. This is a valid check to ensure the file format is correct.\n\n2. **Size Validation**:\n   - After reading `HDR.nameLen`, the code checks: `if (HDR.nameLen > 0xFFFF)` \u2192 returns `DestroyImageList(image)`. This prevents reading excessively large names, which could lead to memory exhaustion or buffer overflows.\n   - The `image->columns` and `image->rows` are set from `HDR.nRows` and `HDR.nCols`, but these are read from the file using `ReadBlobLSBLong` or `ReadBlobMSBLong`. However, the code does not validate that these values are within reasonable bounds (e.g., not extremely large, like 2^31 or more). This could lead to integer overflow or memory exhaustion if the file is crafted to have huge dimensions.\n\n3. **Memory Allocation and Buffer Handling**:\n   - The code uses `SetImageExtent(image, image->columns, image->rows, exception)` to allocate image data. This function should validate the dimensions and fail if they are too large.\n   - `GetQuantumPixels(quantum_info)` is used to get a pointer to pixel data. The size of this buffer is determined by `depth/8 * image->columns * image->rows`. If `image->columns` or `image->rows` are extremely large, this could cause integer overflow in the multiplication (e.g., `depth/8 * image->columns * image->rows` could wrap around to a small number, leading to undersized buffer allocation).\n   - The code reads pixel data using `ReadBlob(image, depth/8 * image->columns, ...)` \u2014 this is a critical point. If `image->columns` or `image->rows` are large, this read could cause a buffer overflow if the allocated buffer is too small due to integer overflow.\n\n4. **Integer Overflow Risk**:\n   - The expression `depth/8 * image->columns * image->rows` is used to compute the number of bytes to read. If `image->columns` and `image->rows` are large (e.g., 100,000), and `depth` is 64, this product could easily exceed `INT_MAX` or `SIZE_MAX`, leading to integer overflow and a smaller-than-expected buffer size.\n   - The `ReadBlob` call then reads more data than the buffer can hold, causing a buffer overflow.\n\n5. **Lack of Bounds Checking on Image Dimensions**:\n   - The code does not validate that `HDR.nRows` and `HDR.nCols` are within safe limits (e.g., less than a reasonable maximum like 100,000 or 1,000,000). This allows an attacker to craft a MAT file with extremely large dimensions, leading to memory exhaustion or buffer overflow.\n\n6. **Use of `ReadBlob` with Untrusted Input**:\n   - The `ReadBlob` function reads data from a file (untrusted input) into a buffer. The size of the read is based on `depth/8 * image->columns`, which is derived from the file header. Without bounds checking on `image->columns` and `image->rows`, this is a classic vector for integer overflow and buffer overflow.\n\n7. **Other Security Measures**:\n   - The code does validate `HDR.nameLen` and `HDR.imagf`, and checks for EOF.\n   - It uses `SetImageExtent` and `AcquireQuantumInfo`, which are part of ImageMagick's safe image handling.\n   - However, these functions may not protect against integer overflow in the size calculation.\n\nConclusion:\nThe code fails to validate the size of `image->columns` and `image->rows` after reading from the file. This allows an attacker to craft a MAT file with extremely large dimensions, leading to integer overflow in the buffer size calculation, which results in a buffer overflow during `ReadBlob`. This is a serious security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 301016, "project": "ghostpdl", "commit_id": "2793769ff107d8d22dadd30c6e68cd781b569550", "project_url": "https://github.com/ArtifexSoftware/ghostpdl", "commit_url": "https://git.ghostscript.com/?p=ghostpdl.git;a=commitdiff;h=2793769ff107d8d22dadd30c6e68cd781b569550", "commit_message": "Bug 701819: fixed ordering in if expression to avoid out-of-bounds access.\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r965 -sOutputFile=tmp -sDEVICE=pcx16 ../bug-701819.pdf", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2020-16305", "cve_desc": "A buffer overflow vulnerability in pcx_write_rle() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `pcx_write_rle` is implementing Run-Length Encoding (RLE) for PCX image format, where repeated bytes are compressed into a count and value pair.\n\n2) The function uses a constant `MAX_RUN_COUNT` set to 15, which limits the maximum run length to 15 repetitions per encoded chunk. This is done because some PCX readers can't handle run counts greater than 15.\n\n3) The variable `max_run` is calculated as `step * MAX_RUN_COUNT`, which determines the maximum number of bytes that can be encoded in a single RLE packet.\n\n4) The main loop processes data in chunks of `step` bytes. For each byte, it checks if the next byte (in steps of `step`) is the same.\n\n5) When a run is detected, the code enters a nested loop that processes runs in chunks of `max_run` bytes. It writes `0xc0 + MAX_RUN_COUNT` (i.e., 0xd0) followed by the data byte for each full chunk.\n\n6) After processing full chunks, it handles the remainder: if there's any remaining data (`from > start`) or if the data byte is >= 0xc0, it writes a final RLE packet with the actual run length.\n\n7) The key issue is in the condition: `if (from > start || data >= 0xc0) gp_fputc((from - start) / step + 0xc1, file);`\n\n8) The expression `(from - start) / step` calculates the number of bytes in the remaining run. Since `from` and `start` are pointers incremented by `step`, this division gives the count of elements in the run.\n\n9) However, there's a potential problem: if `step` is large (e.g., 4 for RGBA), and the remaining run is very long, the division `(from - start) / step` could result in a value that exceeds 15, which would be invalid for the RLE format (since the maximum allowed run count is 15).\n\n10) But wait - the code already limits the run length to `max_run` in the while loop, so the remaining run should be at most `max_run` bytes. Since `max_run = step * MAX_RUN_COUNT = step * 15`, the maximum number of elements in the remaining run is 15.\n\n11) Therefore, `(from - start) / step` will be at most 15, which is valid for the RLE format (0xc1 to 0xd0).\n\n12) The code correctly handles the case where the data byte is >= 0xc0 by using the special encoding (0xc1), which is appropriate for data that might be confused with RLE codes.\n\n13) The function properly bounds the run length to 15 repetitions per packet, and the remaining run is handled correctly with the proper encoding.\n\n14) There are no buffer overflows, integer overflows, or other exploitable vulnerabilities in the code.\n\n(2) NO: No security vulnerability."}
{"idx": 411926, "project": "heimdal", "commit_id": "04171147948d0a3636bc6374181926f0fb2ec83a", "project_url": "https://github.com/heimdal/heimdal", "commit_url": "https://github.com/heimdal/heimdal/commit/04171147948d0a3636bc6374181926f0fb2ec83a", "commit_message": "kdc: validate sname in TGS-REQ\n\nIn tgs_build_reply(), validate the server name in the TGS-REQ is present before\ndereferencing.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-3671", "cve_desc": "A null pointer de-reference was found in the way samba kerberos server handled missing sname in TGS-REQ (Ticket Granting Server - Request). An authenticated user could use this flaw to crash the samba server.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThis is a KDC (Key Distribution Center) function in a Kerberos implementation, specifically `tgs_build_reply`, which handles TGS-REQ (Ticket-Granting Service Request) messages. It is responsible for:\n- Validating client and service principals.\n- Decrypting and verifying tickets (including TGTs and additional tickets).\n- Performing authorization checks (e.g., S4U2Self, constrained delegation).\n- Generating a reply ticket (TGT or service ticket).\n- Handling referrals and error reporting.\n\nThis is a high-privilege, security-critical function in a Kerberos server.\n\n---\n\n### Step 2: Look for potential vulnerabilities\n\n#### A. **Input validation and bounds checking**\n- The function receives various inputs: `priv`, `krbtgt`, `replykey`, `ticket`, `from_addr`, etc.\n- It performs extensive validation:\n  - Checks for `NULL` pointers (e.g., `if (!dest || !src || dest_size == 0)` is not present here, but similar checks exist via `if (ret)` after calls).\n  - Uses `krb5_unparse_name`, `krb5_principal_get_realm`, etc., which are safe if used correctly.\n  - Validates `b->additional_tickets` length before accessing `b->additional_tickets->val[0]`.\n  - Checks `b->etype.len` before accessing `b->etype.val[i]`.\n\n\u2705 No buffer overflows or unchecked array accesses.\n\n#### B. **Memory management and cleanup**\n- The function uses `free()` and `_kdc_free_ent()` appropriately.\n- All dynamically allocated strings (`tpn`, `cpn`, `dpn`, `krbtgt_out_n`, `ref_realm`, `capath`, etc.) are freed in the `out` label.\n- `krb5_free_keyblock_contents()` is called on `sessionkey`.\n- `free_METHOD_DATA(&enc_pa_data)` is called.\n- `free_EncTicketPart(&adtkt)` is called.\n\n\u2705 No memory leaks or dangling pointers.\n\n#### C. **Use of unsafe functions**\n- No use of `strcpy`, `strcat`, `sprintf`, `gets`, or similar unsafe C string functions.\n- Uses `strdup`, `krb5_unparse_name`, `krb5_make_principal`, etc., which are safe when used with proper error checking.\n\n\u2705 No unsafe string operations.\n\n#### D. **Authentication and authorization checks**\n- **TGT validation**: The function verifies the TGT's integrity via `check_PAC`, `check_KRB5SignedPath`, and decryption.\n- **S4U2Self**: Validates checksums, checks impersonation permissions, and ensures the impersonated client exists.\n- **Constrained delegation**: Checks forwardable flag, validates the delegation ticket, and verifies `KRB5SignedPath`.\n- **Address validation**: Uses `_kdc_check_addresses` to validate client IP address.\n- **Realm consistency**: Ensures the client and server are in the correct realm and that the TGT matches the server.\n\n\u2705 All critical security checks are present and properly implemented.\n\n#### E. **Error handling and audit logging**\n- Uses `goto out` for error cleanup.\n- Logs errors with `kdc_log` and adds audit reasons via `_kdc_audit_addreason`.\n- Uses `krb5_get_error_message` and `krb5_free_error_message` correctly.\n- Handles `HDB_ERR_NOENTRY`, `HDB_ERR_NOT_FOUND_HERE`, etc., appropriately.\n\n\u2705 Proper error handling and audit trail.\n\n#### F. **Referral handling**\n- Handles referrals via `ref_realm` and `capath`.\n- Builds `PA_DATA_SERVER_REFERRAL` only when needed.\n- Uses `krb5_crypto_init` and `build_server_referral` safely.\n\n\u2705 No injection or buffer overflow in referral logic.\n\n#### G. **Key and encryption handling**\n- Uses `krb5_generate_random_keyblock` to generate session keys.\n- Uses `krb5_decrypt_ticket` with proper key material.\n- Uses `krb5_verify_checksum` and `krb5_crypto_init` correctly.\n- Ensures `ekey` is valid before use.\n\n\u2705 No key reuse or weak key generation.\n\n#### H. **Potential for logic flaws?**\n- The only potential concern is in the **S4U2Self** and **constrained delegation** logic, where:\n  - The impersonated client is fetched from the database without `HDB_F_SYNTHETIC_OK`.\n  - The function checks `client->entry.flags.trusted_for_delegation` and `forwardable` flags.\n  - It removes `forwardable` if not allowed.\n\nBut these are **correct** security checks \u2014 they prevent abuse of impersonation and delegation.\n\nAlso, the function explicitly **does not allow synthetic clients** in S4U2Self, which is a security hardening.\n\n\u2705 No logic flaws.\n\n---\n\n### Step 3: Final assessment\nThe code:\n- Performs comprehensive input validation.\n- Uses safe memory management.\n- Implements proper cryptographic operations.\n- Enforces strict authorization and delegation policies.\n- Handles errors and logging correctly.\n- Avoids unsafe functions.\n\nThere are **no detectable security vulnerabilities** in this code.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 313850, "project": "vim", "commit_id": "395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/395bd1f6d3edc9f7edb5d1f2d7deaf5a9e3ab93c", "commit_message": "patch 8.2.4956: reading past end of line with \"gf\" in Visual block mode\n\nProblem:    Reading past end of line with \"gf\" in Visual block mode.\nSolution:   Do not include the NUL in the length.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-1720", "cve_desc": "Buffer Over-read in function grab_file_name in GitHub repository vim/vim prior to 8.2.4956. This vulnerability is capable of crashing the software, memory modification, and possible remote execution.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `get_visual_text` is designed to retrieve the selected text in a visual mode editor (likely Vim or a similar text editor). It takes parameters:\n   - `cap`: command argument (possibly for error reporting)\n   - `pp`: pointer to a pointer to return the start of selected text\n   - `lenp`: pointer to an integer to return the length of selected text\n\n2. The function first checks if the visual mode is not 'V' (line-wise visual mode), and if so, calls `unadjust_for_sel()` \u2014 this is a standard cleanup step and not a vulnerability.\n\n3. It checks if the current cursor line (`curwin->w_cursor.lnum`) is different from the visual selection's line (`VIsual.lnum`). If so, it clears the operation beep (if `cap` is not NULL) and returns `FAIL`. This is a valid check to ensure the selection is on the same line \u2014 no vulnerability here.\n\n4. If the visual mode is 'V' (line-wise), it gets the current line using `ml_get_curline()` and sets the length to the full length of the line using `STRLEN`. This is safe because `ml_get_curline()` returns a valid string pointer, and `STRLEN` is safe for null-terminated strings.\n\n5. For other visual modes (character or block), it determines the start of the selection based on the relative position of the cursor and the visual selection (`LT_POS` checks if cursor is before visual). It then:\n   - Gets the text from the appropriate position using `ml_get_pos()`\n   - Computes the length based on column differences\n   - Handles edge cases:\n     - If the text is empty (`**pp == NUL`), sets length to 0.\n     - If the length is positive, it adjusts for:\n       - Multibyte characters: uses `mb_ptr2len` to correct the length to include all bytes of the last character. This is correct and safe.\n       - Single-byte: if the last character is NUL, it subtracts 1 to exclude the null terminator.\n\n6. The function then calls `reset_VIsual_and_resel()` to clean up the visual selection state, which is standard and safe.\n\n7. The function returns `OK` on success.\n\nKey security considerations:\n- All string access is bounded by the actual text length and proper checks.\n- `ml_get_curline()` and `ml_get_pos()` are internal Vim functions that return valid, null-terminated strings.\n- The length calculation is carefully adjusted for multibyte characters and null terminators \u2014 this prevents buffer overflows or incorrect length reporting.\n- No user input is directly used in string operations without proper bounds checking.\n- No unsafe functions like `strcpy`, `strcat`, or `sprintf` are used.\n- The code handles edge cases (empty text, null terminators, multibyte) correctly.\n\nConclusion: The code performs proper bounds checking, handles multibyte characters correctly, avoids buffer overflows, and uses safe string operations. There are no exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 343298, "project": "pure-ftpd", "commit_id": "37ad222868e52271905b94afea4fc780d83294b4", "project_url": "https://github.com/jedisct1/pure-ftpd", "commit_url": "https://github.com/jedisct1/pure-ftpd/commit/37ad222868e52271905b94afea4fc780d83294b4", "commit_message": "Initialize the max upload file size when quotas are enabled\n\nDue to an unwanted check, files causing the quota to be exceeded\nwere deleted after the upload, but not during the upload.\n\nThe bug was introduced in 2009 in version 1.0.23\n\nSpotted by @DroidTest, thanks!", "ground_truth": 0, "cwe": ["CWE-434"], "cve": "CVE-2021-40524", "cve_desc": "In Pure-FTPd before 1.0.50, an incorrect max_filesize quota mechanism in the server allows attackers to upload files of unbounded size, which may lead to denial of service or a server hang. This occurs because a certain greater-than-zero test does not anticipate an initial -1 value. (Versions 1.0.23 through 1.0.49 are affected.)", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Sanitization\nThe function `dostor` handles file upload operations in a FTP server (likely Pure-FTPd). It takes parameters:\n- `char *name`: the filename provided by the client.\n- `const int append`: whether to append to an existing file.\n- `const int autorename`: whether to auto-rename on conflict.\n\nThe code performs several checks:\n- `checknamesanity(name, dot_write_ok) != 0` \u2192 checks for unsafe filenames (e.g., containing `..`, leading dots, etc.). This is a good practice.\n- `ul_check_free_space(name, -1.0)` \u2192 checks available disk space.\n- `restartat > (off_t) 0` \u2192 used for resuming uploads.\n\nThese checks help prevent path traversal and resource exhaustion.\n\n---\n\n### Step 2: File Operations and Race Conditions\nThe code uses `atomic_file` to avoid race conditions during upload:\n- `get_atomic_file(name)` \u2192 generates a temporary filename (e.g., `.upload.XXXXXX`).\n- If `restartat > 0` or `no_truncate != 0`, it renames the original file to the atomic file.\n- After upload, it renames the atomic file back to the original name.\n\nThis is a standard technique to prevent partial writes and ensure atomicity.\n\nHowever, note:\n- `atomic_file` is derived from `name` via `get_atomic_file()`, which should be safe.\n- The code checks `errno != ENOENT` when renaming, which is correct (i.e., ignore if file doesn't exist).\n\nSo far, no obvious race condition.\n\n---\n\n### Step 3: File Truncation and Overwrite Protection\n- If `restartat > st.st_size`, it sets `restartat = st.st_size` \u2192 prevents over-truncation.\n- If `restartat < st.st_size`, it calls `ftruncate(f, restartat)` \u2192 truncates the file to the resume point.\n- This is correct for resuming uploads.\n\nBut here\u2019s a **critical observation**:\n- The `ftruncate` call is done **before** the upload starts.\n- The file is opened with `O_WRONLY` or `O_CREAT | O_WRONLY`.\n- The file is truncated to `restartat` **before** the upload, which is correct for resume.\n\nHowever, **if `restartat` is not properly validated**, this could lead to a **truncation attack**.\n\nBut `restartat` is set from `st.st_size` or `0`, and `restartat > st.st_size` is capped. So it's bounded.\n\nAlso, `restartat` is only set to `st.st_size` if `append != 0`, and `append` is a user-controlled flag.\n\nBut `append` is only used if the file is non-empty and not anonymous (with `ANON_CAN_RESUME` disabled). So it's not fully unrestricted.\n\nStill, **no direct buffer overflow or format string vulnerability**.\n\n---\n\n### Step 4: Quota Handling\n- Quotas are checked via `quota_update` and `ul_quota_update`.\n- `ul_quota_update` is called with `atomic_file_size - original_file_size` or `ulhandler.total_uploaded`.\n- The code checks `overflow > 0` and reports quota exceeded.\n\nThis is properly implemented.\n\n---\n\n### Step 5: Atomic File Renaming and Cleanup\n- After upload, `atomic_file` is renamed to `name` via `rename(atomic_file, name)`.\n- If `autorename != 0` and `restartat == 0`, it calls `tryautorename()` to find a unique name.\n- If `autorename` fails, it reports an error.\n\nThis is safe.\n\nAlso, at the end:\n```c\nif (atomic_file != NULL) {\n    unlink(atomic_file);\n    atomic_file = NULL;\n}\n```\nThis ensures cleanup of temporary files.\n\n---\n\n### Step 6: Potential Vulnerability: `name` is User-Controlled and Used in `memcpy` and `rename`\nThe most critical part is:\n```c\nif (sl < sizeof shm_data_cur->filename) {\n    memcpy(shm_data_cur->filename, name, sl);\n    shm_data_cur->filename[sl] = 0;\n} else {\n    memcpy(shm_data_cur->filename,\n           &name[sl - sizeof shm_data_cur->filename - 1U],\n           sizeof shm_data_cur->filename);\n}\n```\n\nHere:\n- `name` is user-controlled.\n- `shm_data_cur->filename` is a fixed-size buffer (likely `sizeof shm_data_cur->filename` is 256 or similar).\n- The code copies `name` into `shm_data_cur->filename` **without bounds checking** in the `else` branch.\n\nIn the `else` branch:\n```c\nmemcpy(shm_data_cur->filename,\n       &name[sl - sizeof shm_data_cur->filename - 1U],\n       sizeof shm_data_cur->filename);\n```\n\nThis copies `sizeof shm_data_cur->filename` bytes from a position near the end of `name`.\n\nBut if `name` is very long (e.g., 10000 characters), and `sizeof shm_data_cur->filename` is 256, then:\n- `sl - sizeof shm_data_cur->filename - 1U` could be negative if `sl < 256 + 1`.\n- But the condition is `sl >= sizeof shm_data_cur->filename`, so `sl` is at least 256.\n- So `sl - 256 - 1` is at least 0 \u2192 safe.\n\nBut the **real issue** is: **this code copies `sizeof shm_data_cur->filename` bytes from `name` starting at `sl - 256 - 1`**, which is a **fixed offset from the end**.\n\nThis is **not** a buffer overflow in `shm_data_cur->filename` because it copies exactly `sizeof shm_data_cur->filename` bytes, and the destination is that size.\n\nSo **no buffer overflow**.\n\nBut is there a **security issue**?\n\nYes \u2014 **this is a potential information disclosure or denial-of-service vector**.\n\n- The `shm_data_cur->filename` is used in `ftpwho` to display upload status.\n- The code copies a **substring from the end of the filename** into the shared memory.\n- If the filename is crafted to contain sensitive data (e.g., path traversal, session tokens), it could be exposed in logs or monitoring tools.\n\nBut more importantly: **this is not a buffer overflow**, and the copy is bounded.\n\nHowever, **the real vulnerability is in the `tryautorename` and `rename` calls**.\n\nLet\u2019s look at:\n```c\nif (autorename != 0 && restartat == (off_t) 0) {\n    if ((atomic_file_size = get_file_size(atomic_file)) < (off_t) 0) {\n        goto afterquota;\n    }\n    if (tryautorename(atomic_file, name, &name2) != 0) {\n        error(553, MSG_RENAME_FAILURE);\n        goto afterquota;\n    } else {\n#ifdef QUOTAS\n        ul_quota_update(name2 ? name2 : name, 1, atomic_file_size);\n#endif\n        atomic_file = NULL;\n    }\n}\n```\n\nHere:\n- `tryautorename(atomic_file, name, &name2)` \u2192 attempts to find a unique filename by appending numbers.\n- `name2` is set to a new filename.\n- Then `ul_quota_update` is called with `name2`.\n\nBut `name2` is **user-controlled** via `tryautorename`, which may be influenced by `name`.\n\nHowever, `tryautorename` is likely a safe function that appends numbers (e.g., `file.txt`, `file_1.txt`, etc.).\n\nBut **if `tryautorename` does not sanitize the filename**, and `name` contains `..`, `//`, or other path traversal, it could lead to **directory traversal**.\n\nBut `checknamesanity(name, dot_write_ok)` is called earlier \u2014 this should prevent `..`, `.` at start, etc.\n\nSo if `checknamesanity` is properly implemented, this is safe.\n\n---\n\n### Step 7: Final Check: `name` is used in `rename`, `open`, `stat`, etc.\n- `name` is used in `open(ul_name, ...)` \u2192 but `ul_name` is either `name` or `atomic_file`.\n- `atomic_file` is generated via `get_atomic_file(name)` \u2192 should be safe.\n- `rename(atomic_file, name)` \u2192 only if `atomic_file` is valid.\n\nAll these operations are protected by `checknamesanity` and `get_atomic_file`.\n\n---\n\n### Step 8: Summary of Findings\n- Input validation (`checknamesanity`) is performed.\n- File operations are protected by atomic renaming.\n- Truncation and resume logic is bounded.\n- Quota handling is correct.\n- Shared memory copy is bounded (no overflow).\n- No format string, no buffer overflow, no command injection.\n\nThe only potential issue is **if `tryautorename` or `get_atomic_file` is vulnerable to path traversal**, but that depends on their implementation.\n\nHowever, **the code as written does not contain any obvious, exploitable security vulnerability**.\n\nThe use of `memcpy` with a fixed-size copy from a user-controlled string is safe because:\n- The destination size is known.\n- The copy size is exactly the destination size.\n- The source offset is validated (only if `sl >= size`).\n\nThus, **no buffer overflow**.\n\n---\n\n### Final Decision:\n(2) NO: No security vulnerability."}
{"idx": 337848, "project": "linux", "commit_id": "a2d859e3fc97e79d907761550dbc03ff1b36479c", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=a2d859e3fc97e79d907761550dbc03ff1b36479c", "commit_message": "sctp: account stream padding length for reconf chunk\n\nsctp_make_strreset_req() makes repeated calls to sctp_addto_chunk()\nwhich will automatically account for padding on each call. inreq and\noutreq are already 4 bytes aligned, but the payload is not and doing\nSCTP_PAD4(a + b) (which _sctp_make_chunk() did implicitly here) is\ndifferent from SCTP_PAD4(a) + SCTP_PAD4(b) and not enough. It led to\npossible attempt to use more buffer than it was allocated and triggered\na BUG_ON.\n\nCc: Vlad Yasevich <vyasevich@gmail.com>\nCc: Neil Horman <nhorman@tuxdriver.com>\nCc: Greg KH <gregkh@linuxfoundation.org>\nFixes: cc16f00f6529 (\"sctp: add support for generating stream reconf ssn reset request chunk\")\nReported-by: Eiichi Tsukata <eiichi.tsukata@nutanix.com>\nSigned-off-by: Eiichi Tsukata <eiichi.tsukata@nutanix.com>\nSigned-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>\nSigned-off-by: Marcelo Ricardo Leitner <mleitner@redhat.com>\nReviewed-by: Xin Long <lucien.xin@gmail.com>\nLink: https://lore.kernel.org/r/b97c1f8b0c7ff79ac4ed206fc2c49d3612e0850c.1634156849.git.mleitner@redhat.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>", "ground_truth": 0, "cwe": ["CWE-704"], "cve": "CVE-2022-0322", "cve_desc": "A flaw was found in the sctp_make_strreset_req function in net/sctp/sm_make_chunk.c in the SCTP network protocol in the Linux kernel with a local user privilege access. In this flaw, an attempt to use more buffer than is allocated triggers a BUG_ON issue, leading to a denial of service (DOS).", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `sctp_make_strreset_req` constructs a reconfiguration chunk for SCTP (Stream Control Transmission Protocol) that includes stream reset requests.\n\n2) The function calculates `outlen` and `inlen` based on whether `out` and `in` flags are true, using:\n   - `outlen = (sizeof(outreq) + stream_len) * out`\n   - `inlen = (sizeof(inreq) + stream_len) * in`\n\n   This means if `out` is false, `outlen` becomes 0, and similarly for `inlen`. This is correct behavior.\n\n3) The function allocates a chunk using `sctp_make_reconf` with total length: `SCTP_PAD4(outlen) + SCTP_PAD4(inlen)`. The `SCTP_PAD4` macro ensures 4-byte alignment, which is standard for SCTP chunks.\n\n4) The function then adds the `outreq` structure to the chunk if `outlen > 0`, and appends the `stream_list` if `stream_len > 0`.\n\n5) Similarly, it adds the `inreq` structure and the `stream_list` again if `inlen > 0`.\n\n6) The key point: `stream_len = stream_num * sizeof(__u16)` \u2014 this is the total size of the stream list in bytes.\n\n7) The function uses `sctp_addto_chunk(retval, stream_len, stream_list)` to append the stream list. This function is assumed to be safe if the length is correctly calculated and the buffer is large enough.\n\n8) The total allocated size is `SCTP_PAD4(outlen) + SCTP_PAD4(inlen)`, which accounts for both the `outreq` and `inreq` headers and the stream list.\n\n9) The `stream_list` is passed directly to `sctp_addto_chunk` without bounds checking. However, the length used is `stream_len = stream_num * sizeof(__u16)`, which is derived from `stream_num` \u2014 the number of streams.\n\n10) The function does not validate `stream_num` before using it to compute `stream_len`. If `stream_num` is very large (e.g., near UINT16_MAX), then `stream_len` could overflow or become extremely large, leading to:\n    - Buffer overflow if the allocated chunk is smaller than the actual data being added\n    - Memory corruption or denial of service\n\n11) Although `SCTP_PAD4(outlen) + SCTP_PAD4(inlen)` is used to allocate the chunk, if `stream_num` is maliciously large, `outlen` and `inlen` could be huge, but the allocation might still fail (returning NULL), which is handled.\n\n12) However, the critical issue is that `stream_num` is not validated for reasonableness. For example, if `stream_num` is 65535, then `stream_len = 65535 * 2 = 131070` bytes. If this is added twice (once for out, once for in), and the chunk is not large enough, it could cause a buffer overflow.\n\n13) The function assumes that `stream_list` is valid and that `stream_num` is a reasonable number. But there is no check that `stream_num` is within a safe range (e.g., less than a maximum allowed number of streams).\n\n14) This lack of bounds checking on `stream_num` could allow an attacker to trigger a buffer overflow if `stream_num` is crafted to be very large, leading to memory corruption.\n\n15) Therefore, this is a potential integer overflow or buffer overflow vulnerability due to lack of input validation on `stream_num`.\n\n(1) YES: A security vulnerability detected."}
{"idx": 502735, "project": "openssl", "commit_id": "939b4960276b040fc0ed52232238fcc9e2e9ec21", "project_url": "https://github.com/openssl/openssl", "commit_url": "https://github.com/openssl/openssl/commit/939b4960276b040fc0ed52232238fcc9e2e9ec21", "commit_message": "Fix race condition in NewSessionTicket\n\nIf a NewSessionTicket is received by a multi-threaded client when\nattempting to reuse a previous ticket then a race condition can occur\npotentially leading to a double free of the ticket data.\n\nCVE-2015-1791\n\nThis also fixes RT#3808 where a session ID is changed for a session already\nin the client session cache. Since the session ID is the key to the cache\nthis breaks the cache access.\n\nParts of this patch were inspired by this Akamai change:\nhttps://github.com/akamai/openssl/commit/c0bf69a791239ceec64509f9f19fcafb2461b0d3\n\nReviewed-by: Rich Salz <rsalz@openssl.org>\n(cherry picked from commit 27c76b9b8010b536687318739c6f631ce4194688)\n\nConflicts:\n\tssl/ssl.h\n\tssl/ssl_err.c", "ground_truth": 0, "cwe": ["CWE-362"], "cve": "CVE-2015-1791", "cve_desc": "Race condition in the ssl3_get_new_session_ticket function in ssl/s3_clnt.c in OpenSSL before 0.9.8zg, 1.0.0 before 1.0.0s, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b, when used for a multi-threaded client, allows remote attackers to cause a denial of service (double free and application crash) or possibly have unspecified other impact by providing a NewSessionTicket during an attempt to reuse a ticket that had been obtained earlier.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `ssl3_get_new_session_ticket` is responsible for processing a NEWSESSION_TICKET message in an SSL/TLS handshake, which is used to establish session resumption via a ticket.\n\n2. The function first calls `ssl_get_message` to read the incoming message, with a maximum size of 16384 bytes. This is a reasonable limit and prevents unbounded memory allocation.\n\n3. It checks if the message length `n` is less than 6. This is correct because the message must contain at least:\n   - 4 bytes for `ticket_lifetime_hint`\n   - 2 bytes for `ticket_length`\n   So, 6 bytes is the minimum required. If not, it returns an error with `SSL_AD_DECODE_ERROR`. This prevents processing malformed or truncated messages.\n\n4. It then parses `ticket_lifetime_hint` (4 bytes) and `ticklen` (2 bytes) using `n2l` and `n2s`, which are safe macros that read from the input buffer `p` and advance the pointer.\n\n5. The critical check is:\n   ```c\n   if (ticklen + 6 != n) {\n       al = SSL_AD_DECODE_ERROR;\n       SSLerr(...);\n       goto f_err;\n   }\n   ```\n   This ensures that the total length of the ticket data (ticket_lifetime_hint + ticket_length + ticket) exactly matches the received message length. This is a correct validation: the total length should be 6 (header) + ticklen (ticket data). If not, it's a length mismatch and the message is rejected.\n\n6. The code then allocates memory for the ticket using `OPENSSL_malloc(ticklen)`. This is safe because `ticklen` comes from the parsed message and is validated against the total length `n`. Since `ticklen` is derived from the message and the sum `ticklen + 6 == n`, `ticklen` cannot exceed `n - 6`, which is at most 16384 - 6 = 16378. This is a bounded allocation.\n\n7. The ticket data is copied using `memcpy(s->session->tlsext_tick, p, ticklen)`. The source `p` is a pointer into the message buffer `s->init_msg`, which is of size `n`. Since `ticklen` is validated and `p` is advanced by 6 bytes (4 for lifetime hint, 2 for length), the remaining data is exactly `ticklen` bytes. So `memcpy` is safe and does not overflow.\n\n8. The session ID is set to the hash of the ticket (SHA256 or SHA1), which is a standard way to derive a session ID from a ticket. This is secure and prevents session ID collisions.\n\n9. The function returns 1 on success, -1 on error, and handles cleanup appropriately.\n\n10. There are no buffer overflows, use-after-free, or memory corruption issues. All allocations are bounded by the validated message length. The input is validated before any processing or memory allocation.\n\n11. The code correctly handles error paths, including freeing memory and setting appropriate alert messages.\n\nConclusion: The code performs proper bounds checking, validates message length, uses safe parsing macros, and allocates memory only after validating the size. There are no exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 220100, "project": "linux", "commit_id": "ab0fc21bc7105b54bafd85bd8b82742f9e68898a", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/ab0fc21bc7105b54bafd85bd8b82742f9e68898a", "commit_message": "Revert \"NFSv4: Handle the special Linux file open access mode\"\n\nThis reverts commit 44942b4e457beda00981f616402a1a791e8c616e.\n\nAfter secondly opening a file with O_ACCMODE|O_DIRECT flags,\nnfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().\n\nReproducer:\n  1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/\n  2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)\n  3. close(fd)\n  4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)\n  5. lseek(fd)\n\nReported-by: Lyu Tao <tao.lyu@epfl.ch>\nSigned-off-by: ChenXiaoSong <chenxiaosong2@huawei.com>\nSigned-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>", "ground_truth": 0, "cwe": ["CWE-909"], "cve": "CVE-2022-24448", "cve_desc": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `nfs4_file_open` is called when a file is opened in the NFSv4 filesystem. It handles the open operation for a file that already has a cached positive dentry.\n\n2. The function first checks for valid file flags using `nfs_check_flags(openflags)`. If invalid flags are provided, it returns an error immediately. This is a good security practice.\n\n3. The code modifies `openflags` by decrementing it when `O_ACCMODE` is 3 (i.e., both read and write), which is a known workaround to avoid certain race conditions in NFS. This is a well-documented behavior in the NFS codebase and is not a vulnerability.\n\n4. The code clears `O_CREAT` and `O_EXCL` flags because NFSv4 does not allow file creation during open. This is correct and expected behavior.\n\n5. The function retrieves the parent directory dentry and inode using `dget_parent` and `d_inode`. It then allocates an `nfs_open_context` using `alloc_nfs_open_context`, which is properly checked for errors using `IS_ERR`.\n\n6. The `attr` structure is initialized with `ATTR_OPEN`, and if `O_TRUNC` is set, it sets `ATTR_SIZE` and `ia_size = 0`, and calls `filemap_write_and_wait` to ensure all dirty pages are written. This is safe and correct.\n\n7. The actual open operation is performed via `NFS_PROTO(dir)->open_context(...)`, which is a function pointer to the NFSv4-specific open context handler. The return value is checked for errors, and specific error codes like `-ENOENT`, `-ESTALE`, `-EISDIR`, etc., are handled by dropping the dentry and returning `-EOPENSTALE`, which causes the VFS to retry the operation. This is a standard NFS recovery mechanism.\n\n8. The code checks if the returned `inode` matches the `d_inode(dentry)`. If not, it drops the dentry and returns `-EOPENSTALE`. This prevents stale dentry issues and is a correct safety check.\n\n9. If everything is successful, the context is set on the file using `nfs_file_set_open_context`, and caching is initialized with `nfs_fscache_open_file`.\n\n10. The function properly cleans up resources: `put_nfs_open_context` is called in `out_put_ctx`, and `dput(parent)` is called at the end.\n\n11. All error paths are handled correctly, with proper cleanup and return codes. There are no use-after-free, buffer overflows, or improper input validation issues.\n\n12. The code does not perform any unsafe memory operations, does not use untrusted input in unsafe ways (e.g., string formatting, direct pointer arithmetic), and does not expose any known vulnerabilities such as race conditions or privilege escalation vectors.\n\nConclusion: The code follows secure coding practices, includes proper error handling, input validation, and resource management. It is part of the Linux kernel's NFSv4 implementation and has been reviewed extensively.\n\n(2) NO: No security vulnerability."}
{"idx": 462566, "project": "newsbeuter", "commit_id": "96e9506ae9e252c548665152d1b8968297128307", "project_url": "https://github.com/akrennmair/newsbeuter", "commit_url": "https://github.com/akrennmair/newsbeuter/commit/96e9506ae9e252c548665152d1b8968297128307", "commit_message": "Sanitize inputs to bookmark-cmd (#591)\n\nNewsbeuter didn't properly shell-escape the arguments passed to\nbookmarking command, which allows a remote attacker to perform remote\ncode execution by crafting an RSS item whose title and/or URL contain\nsomething interpretable by the shell (most notably subshell\ninvocations.)\n\nThis has been reported by Jeriko One <jeriko.one@gmx.us>, complete with\nPoC and a patch.\n\nThis vulnerability was assigned CVE-2017-12904.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2017-12904", "cve_desc": "Improper Neutralization of Special Elements used in an OS Command in bookmarking function of Newsbeuter versions 0.7 through 2.9 allows remote attackers to perform user-assisted code execution by crafting an RSS item that includes shell code in its title and/or URL.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `controller::bookmark` constructs a command line string (`cmdline`) by combining a user-configurable command (`bookmark_cmd`) with four user-provided strings: `url`, `title`, `description`, and `feed_title`.\n\n2) The function uses `strprintf::fmt` to format the command line, inserting the four strings into the command. Before insertion, it calls `utils::replace_all(url, \"'\", \"%27\")` and similar replacements for the other strings. This replaces single quotes with `%27` (URL-encoded form of a single quote).\n\n3) The key concern is whether this escaping is sufficient to prevent command injection. While single quotes are escaped, the command is being passed to `/bin/sh -c`, which interprets shell metacharacters. Even though single quotes are replaced, other dangerous characters (like `;`, `&`, `|`, `$()`, backticks, etc.) are not escaped or sanitized.\n\n4) The `bookmark_cmd` is user-configurable via configuration. If an attacker can control `bookmark-cmd` (e.g., via configuration file or admin interface), they could set it to something like `bash -c 'malicious_command'`, and then inject malicious content via the other parameters.\n\n5) Even if `bookmark_cmd` is trusted, the `url`, `title`, `description`, and `feed_title` are user-provided and are directly inserted into the command line without proper shell escaping. The replacement of only single quotes is insufficient to prevent shell injection.\n\n6) The function uses `utils::run_program(my_argv, \"\")` with `my_argv` constructed from `\"/bin/sh\"`, `\"-c\"`, and the full `cmdline`. This means the entire `cmdline` is interpreted as a shell command, making it vulnerable to shell injection if any of the input contains shell metacharacters.\n\n7) The `utils::replace_all` function only handles single quotes, which is not enough. For example, a URL like `http://example.com; rm -rf /` would be passed as-is (after replacing `'` with `%27`, but `;` remains), and would be executed as a command.\n\n8) The use of `strprintf::fmt` with unescaped user input is a classic recipe for command injection.\n\n(1) YES: A security vulnerability detected."}
{"idx": 229165, "project": "qemu", "commit_id": "7882080388be5088e72c425b02223c02e6cb4295", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://github.com/qemu/qemu/commit/7882080388be5088e72c425b02223c02e6cb4295", "commit_message": "virtio-serial: fix ANY_LAYOUT\n\nDon't assume a specific layout for control messages.\nRequired by virtio 1.\n\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Amit Shah <amit.shah@redhat.com>\nReviewed-by: Jason Wang <jasowang@redhat.com>", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2015-5745", "cve_desc": "Buffer overflow in the send_control_msg function in hw/char/virtio-serial-bus.c in QEMU before 2.4.0 allows guest users to cause a denial of service (QEMU process crash) via a crafted virtio control message.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `send_control_msg` is responsible for sending a control message through a VirtIO serial device.\n2. It takes a buffer `buf` and its length `len` as input.\n3. It retrieves the input VirtQueue (`vq`) from the VirtIOSerial structure (`vser->c_ivq`).\n4. It checks if the queue is ready using `virtio_queue_ready(vq)`. If not, it returns 0.\n5. It attempts to pop a VirtQueueElement from the queue using `virtqueue_pop(vq, &elem)`. If no element is available, it returns 0.\n6. The function then uses `iov_from_buf` to copy data from the input buffer `buf` into the scatter-gather list (`elem.in_sg`) of the VirtQueueElement. The copy is done with a length of `len`, starting at offset 0.\n7. After copying, it calls `virtqueue_push` to push the element back into the queue with `len` bytes.\n8. Finally, it calls `virtio_notify` to signal the device that new data is available.\n\nNow, let's analyze for potential vulnerabilities:\n\n- The `iov_from_buf` function is used to copy data from `buf` into the scatter-gather list (`elem.in_sg`). This function is typically designed to copy data safely into the provided I/O vector, but it relies on the caller ensuring that the buffer `buf` is valid and that the length `len` does not exceed the available space in the scatter-gather list.\n- The code does not validate whether `len` exceeds the total size of the scatter-gather list (`elem.in_sg` and `elem.in_num`). This is a critical issue because if `len` is larger than the available space in the I/O vector, `iov_from_buf` may write past the end of the allocated memory, leading to a buffer overflow.\n- The comment \"TODO: detect a buffer that's too short, set NEEDS_RESET\" explicitly acknowledges this missing check, indicating that the code is incomplete and potentially vulnerable.\n- Since the function does not verify that `len` is within the bounds of the available I/O buffer space, it is susceptible to a buffer overflow if an attacker can control the `len` parameter or the `buf` content.\n\nTherefore, this code contains a security vulnerability due to lack of bounds checking on the `len` parameter when copying into the scatter-gather list.\n\n(1) YES: A security vulnerability detected."}
{"idx": 355014, "project": "pjproject", "commit_id": "8b621f192cae14456ee0b0ade52ce6c6f258af1e", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/8b621f192cae14456ee0b0ade52ce6c6f258af1e", "commit_message": "Merge pull request from GHSA-3qx3-cg72-wrh9", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2021-43804", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In affected versions if the incoming RTCP BYE message contains a reason's length, this declared length is not checked against the actual received packet size, potentially resulting in an out-of-bound read access. This issue affects all users that use PJMEDIA and RTCP. A malicious actor can send a RTCP BYE message with an invalid reason length. Users are advised to upgrade as soon as possible. There are no known workarounds.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `parse_rtcp_bye` processes an RTCP BYE packet, which is part of the RTP Control Protocol used in multimedia communications.\n\n2. The function attempts to extract a \"reason\" string from the packet, starting at offset 9 in the packet data (after the first 9 bytes, which include the header and the number of sources).\n\n3. The length of the reason string is determined by:\n   - The value at offset 8 (`*((pj_uint8_t*)pkt+8)`), which is expected to be the length of the reason.\n   - The size of the buffer `sess->stat.peer_sdes_buf_`.\n   - The remaining packet size after offset 9: `size - 9`.\n\n   The actual length used is the minimum of these three values: `PJ_MIN(sizeof(sess->stat.peer_sdes_buf_), *((pj_uint8_t*)pkt+8))`, then `PJ_MIN(..., size-9)`.\n\n4. The code then copies up to `reason.slen` bytes from the packet into `sess->stat.peer_sdes_buf_` using `pj_memcpy`.\n\n5. The buffer `sess->stat.peer_sdes_buf_` is used to store the reason string, and it is later logged using `PJ_LOG` with `%.*s` format, which prints exactly `reason.slen` characters from `reason.ptr`.\n\n6. The key concern: Is the `reason.slen` value properly bounded?\n\n   - The first `PJ_MIN` ensures that the length does not exceed the buffer size.\n   - The second `PJ_MIN` ensures it does not exceed the available packet data (`size - 9`).\n   - Therefore, the copy operation is bounded by both the buffer size and the packet size.\n\n7. Additionally, the `reason.ptr` is set to point into `sess->stat.peer_sdes_buf_`, and the `PJ_LOG` uses `%.*s` with `reason.slen`, which is safe because the string is not null-terminated in the log, but the length is explicitly controlled.\n\n8. However, note that the `reason` string is not null-terminated. But since the logging uses `%.*s` with a known length, this is not a problem \u2014 it's the correct way to print a non-null-terminated string safely.\n\n9. There is no buffer overflow because:\n   - The copy is limited by `reason.slen`, which is capped by the buffer size.\n   - The buffer `sess->stat.peer_sdes_buf_` is assumed to be large enough (as per the code's intent).\n   - The `pj_memcpy` is bounded by `reason.slen`, which is derived from safe min operations.\n\n10. The code does not perform any unsafe operations like `strcpy`, `strcat`, or unbounded `memcpy`. All operations are bounded by size checks.\n\nConclusion: The code correctly bounds the copy operation and safely handles the reason string extraction and logging. No buffer overflow or other security vulnerability is present.\n\n(2) NO: No security vulnerability."}
{"idx": 292609, "project": "puma", "commit_id": "acdc3ae571dfae0e045cf09a295280127db65c7f", "project_url": "https://github.com/puma/puma", "commit_url": "https://github.com/puma/puma/commit/acdc3ae571dfae0e045cf09a295280127db65c7f", "commit_message": "Merge pull request from GHSA-48w2-rm65-62xx\n\n* Fix HTTP request smuggling vulnerability\n\nSee GHSA-48w2-rm65-62xx or CVE-2021-41136 for more info.\n\n* 4.3.9 release note\n\n* 5.5.1 release note\n\n* 5.5.1", "ground_truth": 0, "cwe": ["CWE-444"], "cve": "CVE-2021-41136", "cve_desc": "Puma is a HTTP 1.1 server for Ruby/Rack applications. Prior to versions 5.5.1 and 4.3.9, using `puma` with a proxy which forwards HTTP header values which contain the LF character could allow HTTP request smugggling. A client could smuggle a request through a proxy, causing the proxy to send a response back to another unknown client. The only proxy which has this behavior, as far as the Puma team is aware of, is Apache Traffic Server. If the proxy uses persistent connections and the client adds another request in via HTTP pipelining, the proxy may mistake it as the first request's body. Puma, however, would see it as two requests, and when processing the second request, send back a response that the proxy does not expect. If the proxy has reused the persistent connection to Puma to send another request for a different client, the second response from the first client will be sent to the second client. This vulnerability was patched in Puma 5.5.1 and 4.3.9. As a workaround, do not use Apache Traffic Server with `puma`.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `puma_parser_execute` is a parser for HTTP/1.1 messages, likely generated by a state machine (e.g., Ragel). It processes a buffer of data (`buffer`) of length `len`, starting from offset `off`.\n\n2. The function uses a state machine with multiple states (st0, st2, st3, etc.) and transitions based on character values. It uses `MARK(mark, p)` to record positions in the buffer for later extraction of fields like request method, URI, headers, etc.\n\n3. Key safety checks:\n   - `assert(off <= len && \"offset past end of buffer\");` ensures the offset is valid.\n   - `p = buffer + off; pe = buffer + len;` sets the parsing range.\n   - `assert((size_t)(pe - p) == len - off && ...)` verifies pointer arithmetic consistency.\n   - `assert(p <= pe && \"buffer overflow after parsing execute\");` checks that the parser didn't go past the buffer.\n   - `assert(parser->nread <= len && ...)` ensures the number of bytes read doesn't exceed input length.\n   - Other assertions check that `body_start`, `mark`, `field_start`, and `field_len` are within bounds.\n\n4. The parser uses `p` as a pointer into the buffer and increments it with `++p`. The loop continues until `p == pe` (end of buffer), and the parser only accesses `*p` when `p < pe`, so no out-of-bounds access occurs.\n\n5. The parser calls user-provided callbacks like:\n   - `parser->request_method(...)`\n   - `parser->request_uri(...)`\n   - `parser->http_field(...)`\n   - `parser->header_done(...)`\n   - etc.\n\n   These callbacks receive pointers (`PTR_TO(mark)`, `LEN(mark, p)`) into the original buffer. However, the parser ensures that:\n   - `mark` is set only when `p` is within bounds.\n   - `LEN(mark, p)` is always non-negative and within the buffer.\n   - The final `parser->nread` is updated only after valid parsing.\n\n6. The parser does not perform any dynamic memory allocation or string copying. It only passes pointers into the original buffer to callbacks. Therefore, there is no risk of buffer overflow in the parser itself.\n\n7. The only potential risk would be if the callbacks themselves are unsafe (e.g., they copy data without bounds checking). However, the question is about the code provided \u2014 the parser function \u2014 not the callbacks. Since the parser correctly bounds-checks all accesses and only passes valid pointers to callbacks, it does not introduce a vulnerability.\n\n8. The use of `assert` statements ensures that internal invariants are maintained, and the final return value `parser->nread` is guaranteed to be \u2264 `len`.\n\nConclusion: The code correctly implements a state machine parser with proper bounds checking, pointer arithmetic, and validation. It does not contain buffer overflows, use-after-free, or other classic vulnerabilities. The parser is designed to be safe when used with valid input.\n\n(2) NO: No security vulnerability."}
{"idx": 259515, "project": "gpac", "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "commit_message": "fixed #2212", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-2453", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Buffer Handling**:\n   - The function `BD_DecMFFieldVec` takes a bitstream (`GF_BitStream *bs`) as input, which is read using `gf_bs_read_int(bs, NbBits)`.\n   - `NbBits` is read using 5 bits, so the maximum value is 31 (2^5 - 1). This limits `nbFields` to a maximum of 31, which is a small, bounded number.\n   - `nbFields` is used to allocate memory via `gf_sg_vrml_mf_alloc` and to loop over `i < nbFields`. Since `nbFields` is bounded by 31, there is no risk of integer overflow or unbounded memory allocation.\n\n2. **Memory Allocation and Initialization**:\n   - `gf_sg_vrml_mf_alloc` is called with `nbFields` as the size. This function is assumed to be safe and properly bounds-checked, as it's part of a well-designed library (GPAC).\n   - The `sffield` structure is initialized with `memset(&sffield, 0, sizeof(GF_FieldInfo))`, which prevents uninitialized memory access.\n\n3. **Loop and Array Access**:\n   - The loop `for (i=0; i<nbFields; i++)` runs at most 31 times, so no risk of buffer overflow or out-of-bounds access.\n   - `gf_sg_vrml_mf_get_item` is used to get a pointer to the i-th element of the MF (multi-field), and this is assumed to be safe as long as `nbFields` is valid.\n\n4. **Node Creation and Registration**:\n   - `gf_bifs_dec_node(codec, bs, field->NDTtype)` creates a new node from the bitstream. This function is part of the BIFS decoder and is expected to validate input.\n   - `gf_node_register` and `gf_node_list_add_child_last` are used to manage the node list. These functions are part of a well-structured object model and are expected to handle edge cases safely.\n   - The code checks for `new_node` being `NULL`, and if so, sets an error and jumps to `exit`. This prevents use of invalid pointers.\n\n5. **Quantization Parameter (QP) Handling**:\n   - The code handles QP nodes with special logic: it checks if a QP node is local, removes previous QP if needed, and sets the new one.\n   - The `qp_on` and `qp_local` flags are used to track state, and `gf_bifs_dec_qp_remove` is called appropriately at the end.\n   - The logic is complex but does not involve unbounded loops, unsafe memory access, or unchecked user input.\n\n6. **Error Handling and Cleanup**:\n   - The `goto exit` pattern is used for error handling, which ensures that cleanup (like removing QP) is done even on error.\n   - The final `gf_bifs_dec_qp_remove(codec, GF_TRUE)` ensures that any active QP is removed when exiting the function.\n\n7. **Potential Risks**:\n   - The only potential risk would be if `gf_bs_read_int(bs, NbBits)` could be manipulated to read more than 31 elements, but since `NbBits` is only 5 bits, the maximum `nbFields` is 31, which is safe.\n   - The bitstream is parsed in a controlled way, and all loops are bounded.\n   - No use of unsafe functions like `strcpy`, `sprintf`, or direct memory copying without bounds.\n\n8. **Conclusion**:\n   - All input sizes are bounded.\n   - No unbounded loops or memory allocations.\n   - Proper error handling and cleanup.\n   - No evidence of buffer overflows, use-after-free, or injection vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 263521, "project": "tensorflow", "commit_id": "bb6a0383ed553c286f87ca88c207f6774d5c4a8f", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/bb6a0383ed553c286f87ca88c207f6774d5c4a8f", "commit_message": "Prevent heap OOB read in TFLite's `gather_nd.cc`.\n\nPassing negative indices is illegal but there was a missing check so that resulted in OOB accesses.\n\nPiperOrigin-RevId: 387208551\nChange-Id: I6b7a8a62d3e7c13a16d81619e5bc23ae2cdbc7fd", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2021-37687", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions TFLite's [`GatherNd` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather_nd.cc#L124) does not support negative indices but there are no checks for this situation. Hence, an attacker can read arbitrary data from the heap by carefully crafting a model with negative values in `indices`. Similar issue exists in [`Gather` implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/gather.cc). We have patched the issue in GitHub commits bb6a0383ed553c286f87ca88c207f6774d5c4a8f and eb921122119a6b6e470ee98b89e65d721663179d. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `EvalGatherNd` is part of a TensorFlow Lite operation that performs a \"gather_nd\" operation, which gathers elements from a tensor (`params`) using index tensors (`indices`) to form an output tensor.\n\n2. The function first checks whether all elements in the `indices` tensor are non-negative (i.e., >= 0). It does this by iterating through the `indices_values` array and setting a flag `indices_has_only_positive_elements` to false if any negative value is found. Then, it uses `TF_LITE_ENSURE` to assert that this flag is true.\n\n3. The `TF_LITE_ENSURE` macro is a runtime assertion that will cause the function to return an error (likely `kTfLiteError`) if the condition is false. This means that if any negative index is present, the function will fail early and not proceed with the gather operation.\n\n4. The purpose of this check is to prevent negative indexing, which could lead to out-of-bounds memory access or undefined behavior. In many tensor operations, negative indices are not valid or are interpreted as offsets from the end (like in Python), but in TensorFlow Lite, this behavior may not be supported or may be unsafe if not properly handled.\n\n5. However, the key point is: the code explicitly checks for negative indices and fails early if any are found. This is a defensive programming practice that prevents potential out-of-bounds access or memory corruption due to invalid indices.\n\n6. The function then dispatches to a template function `GatherNd` based on the data type of `params`, which is a standard and safe pattern in TensorFlow Lite.\n\n7. There is no evidence of buffer overflows, use of unsafe string functions, or improper memory management. The index validation is sufficient and appropriate for the context.\n\n8. The only potential concern could be whether negative indices should be allowed in some cases (e.g., for backward indexing), but the code explicitly disallows them and reports an error. This is a deliberate design choice, not a vulnerability.\n\n9. Since the function correctly validates input indices and prevents invalid access, and no unsafe operations are performed, there is no security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 484732, "project": "libmobi", "commit_id": "ab5bf0e37e540eac682a14e628853b918626e72b", "project_url": "https://github.com/bfabiszewski/libmobi", "commit_url": "https://github.com/bfabiszewski/libmobi/commit/ab5bf0e37e540eac682a14e628853b918626e72b", "commit_message": "fix oob write bug inside libmobi", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-3751", "cve_desc": "libmobi is vulnerable to Out-of-bounds Write", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `mobi_buffer_move` is designed to move data within a buffer (`buf`) by a specified `offset` and copy `len` bytes.\n\n2) The function first calculates `aoffset` as the absolute value of `offset` using `abs(offset)`. This is correct for handling both positive and negative offsets.\n\n3) The `source` pointer is initialized to `buf->data + buf->offset`, which is the current position in the buffer.\n\n4) For positive `offset` (offset >= 0):\n   - It checks if `buf->offset + aoffset + len > buf->maxlen`\n   - This ensures that the source data (starting at `buf->offset + aoffset`) and the copy of `len` bytes don't exceed the buffer bounds.\n   - This check is correct and prevents buffer overflow.\n\n5) For negative `offset` (offset < 0):\n   - It checks two conditions:\n     a) `(buf->offset < aoffset)` - ensures we don't go before the start of the buffer\n     b) `(buf->offset + len > buf->maxlen)` - ensures the destination doesn't exceed buffer bounds\n   - However, this second condition is problematic. It only checks if the destination (starting at `buf->offset`) exceeds `maxlen`, but it doesn't check if the source (which is at `buf->offset - aoffset`) is valid.\n\n6) The critical issue is in the negative offset case:\n   - The source is set to `source -= aoffset`, so it points to `buf->data + buf->offset - aoffset`\n   - The function checks `buf->offset < aoffset` to ensure we don't go before the buffer start, which is correct.\n   - But it doesn't verify that the source data (at `buf->offset - aoffset`) is within bounds for a read of `len` bytes.\n   - The check `(buf->offset + len > buf->maxlen)` only ensures the destination doesn't overflow, but doesn't ensure the source has enough data to read.\n\n7) For example, if `buf->offset = 10`, `aoffset = 5`, `len = 100`, then:\n   - `buf->offset < aoffset` is false (10 >= 5), so the first check passes\n   - `buf->offset + len = 110`, which might be <= `maxlen`, so second check passes\n   - But the source is at `buf->offset - aoffset = 5`, and we're trying to read 100 bytes from position 5, which could go beyond `maxlen` if `maxlen` is less than 105.\n\n8) The function uses `memmove` to copy data from `source` to `buf->data + buf->offset`, but there's no bounds check on the source data range (from `source` to `source + len`).\n\n9) This creates a potential buffer read overflow when `offset` is negative, as the source data might be outside the valid buffer range.\n\n(1) YES: A security vulnerability detected."}
{"idx": 228563, "project": "hhvm", "commit_id": "dbeb9a56a638e3fdcef8b691c2a2967132dae692", "project_url": "https://github.com/facebook/hhvm", "commit_url": "https://github.com/facebook/hhvm/commit/dbeb9a56a638e3fdcef8b691c2a2967132dae692", "commit_message": "string_number_format: Correctly handles return value of snprintf\n\nSummary: `snprintf` can return a value greater than the number of bytes copied. In case the first byte of the string is not a digit (could be '-'), size of `tmpstr` was being updated without checking `tmplen`. This resulted in either an assertion error or a heap overflow depending on whether the assertion is compiled or not.\n\nReviewed By: mofarrell, qianxuweiren\n\nDifferential Revision: D17327899\n\nfbshipit-source-id: ee53875d21e02608c6d870388eecf1464de24ff1", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2019-11929", "cve_desc": "Insufficient boundary checks when formatting numbers in number_format allows read/write access to out-of-bounds memory, potentially leading to remote code execution. This issue affects HHVM versions prior to 3.30.10, all versions between 4.0.0 and 4.8.5, all versions between 4.9.0 and 4.18.2, and versions 4.19.0, 4.19.1, 4.20.0, 4.20.1, 4.20.2, 4.21.0, 4.22.0, 4.23.0.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Function Overview\nThe function `string_number_format` formats a floating-point number `d` into a string with:\n- A specified number of decimal places (`dec`)\n- Custom decimal point (`dec_point`)\n- Custom thousand separator (`thousand_sep`)\n\nIt uses `snprintf` to format the number into a temporary buffer (`tmpbuf`), then processes the result to insert thousand separators and format the decimal point.\n\n---\n\n### Step 2: Buffer Handling and Size Management\n\n- The function first allocates a temporary buffer `tmpbuf` via `tmpstr.mutableData()` with a size of 63 bytes (plus 1 for null terminator), so 64 bytes total.\n- It calls `snprintf(tmpbuf, 64, \"%.*F\", dec, d)` to format the number.\n- According to the `snprintf` man page, it returns the number of characters that would have been written (excluding null), so if `tmplen >= 64`, it means the output would have exceeded the buffer.\n\n#### Handling of Large Output:\n- If `tmplen >= 64`, the code reallocates `tmpstr` to `tmplen + 1` bytes and calls `snprintf` again with the larger buffer.\n- This is correct and avoids buffer overflow in the temporary buffer.\n\nSo far, the temporary buffer handling is safe: it checks the return value of `snprintf` and resizes if needed.\n\n---\n\n### Step 3: Overflow Checks\n\nThe code includes several checks for integer overflow:\n\n- After calculating `integral` (number of digits before decimal point), it computes:\n  ```c\n  integral += ((integral-1) / 3) * thousand_sep.size();\n  ```\n  Then checks:\n  ```c\n  if (integral + thousand_sep.size() * ((integral-1) / 3) < integral) {\n    raise_error(\"String overflow\");\n  }\n  ```\n  This is a **correct check** for integer overflow in the thousand separator calculation.\n\n- Later, when computing `reslen`, it checks:\n  ```c\n  if (reslen + dec_point.size() < dec_point.size()) {\n    raise_error(\"String overflow\");\n  }\n  ```\n  This is a **standard overflow check** for `reslen += dec_point.size()`.\n\n- Also checks for overflow when adding the minus sign.\n\nThese checks are **correct and sufficient** to prevent integer overflow in buffer size calculations.\n\n---\n\n### Step 4: Final Buffer and Copying\n\n- A final result buffer `resstr` is allocated with size `reslen`.\n- The function copies digits from `tmpbuf` to `resbuf` in reverse, inserting thousand separators and decimal point as needed.\n- It uses `memcpy` with calculated offsets and ensures that:\n  - The `t` pointer is decremented appropriately.\n  - The `s` pointer moves from the end of `tmpbuf` to the beginning.\n  - The `t` pointer is never written beyond the allocated `resbuf`.\n\nThe copying logic is careful:\n- It uses `s` and `t` as pointers into the source and target buffers.\n- It checks `s >= tmpbuf` before copying.\n- It uses `memcpy` with known lengths and correct offsets.\n- It ensures that `t` is not moved past the start of `resbuf`.\n\nNo buffer overflows occur during copying.\n\n---\n\n### Step 5: Input Validation\n\n- The function checks `dec < 0` and sets it to 0 \u2014 safe.\n- It uses `php_math_round` to round the number \u2014 this is a safe operation.\n- It checks `tmpbuf == nullptr` and `!isdigit(...)` after `snprintf`, but only returns early if the first character is not a digit \u2014 this is a sanity check, but not a vulnerability.\n\n---\n\n### Step 6: Potential Issues?\n\n- **Use of `snprintf` with `%.*F`**: This is safe as long as the format is correct. The `F` format specifier is non-standard (not in C99), but in many implementations (e.g., glibc), it's supported as an alias for `f` (for floating-point). However, if the implementation doesn't support `%F`, it could lead to undefined behavior.\n\nBut the code assumes `snprintf` supports `%.*F`, and the function is likely used in a context where this is guaranteed (e.g., PHP's internal codebase). So this is not a vulnerability **if** the environment supports it.\n\n- **No user-controlled input directly**: The function takes `double d`, `int dec`, and two `String` objects (`dec_point`, `thousand_sep`). If these are derived from user input, the function itself does not perform unsafe operations.\n\nBut the function **does not sanitize or validate** the `dec_point` or `thousand_sep` strings. However, since they are used only in `memcpy` with known lengths and are not used in format strings, **they are not exploitable via format string vulnerabilities**.\n\n- **No use of unsafe string functions**: No `strcpy`, `strcat`, `sprintf`, etc. are used. All copying uses `memcpy` with known lengths.\n\n---\n\n### Step 7: Conclusion\n\n- All buffer sizes are calculated with overflow checks.\n- Temporary buffers are resized when needed.\n- Final output buffer is sized correctly.\n- Copying is done with bounds-checked pointer arithmetic.\n- No format string vulnerabilities.\n- No buffer overflows.\n\nEven though the use of `%F` is non-standard, it's not a vulnerability **if** the environment supports it (which is assumed in the context of PHP's internal code).\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 439114, "project": "ImageMagick6", "commit_id": "210474b2fac6a661bfa7ed563213920e93e76395", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/210474b2fac6a661bfa7ed563213920e93e76395", "commit_message": "Fix ultra rare but potential memory-leak", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2019-13133", "cve_desc": "ImageMagick before 7.0.8-50 has a memory leak vulnerability in the function ReadBMPImage in coders/bmp.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and File Header Parsing**:\n   - The function `ReadBMPImage` begins by validating input parameters (`image_info`, `exception`) and asserting their signatures.\n   - It reads the first 2 bytes of the file to check for \"BM\" or \"CI\" identifiers, which is standard for BMP files.\n   - It then reads the BMP header fields (file size, offset, width, height, bits per pixel, etc.) using `ReadBlobLSBLong`, `ReadBlobLSBShort`, etc., which are designed to read little-endian values safely.\n   - The code checks for malformed headers: negative or zero image dimensions, invalid number of planes, unsupported bits per pixel, and invalid compression types.\n   - These checks are thorough and prevent processing of malformed or malicious BMP files.\n\n2. **Memory Allocation and Buffer Handling**:\n   - Memory is allocated using `AcquireVirtualMemory` and `AcquireQuantumMemory`, which are safe memory allocation functions that check for overflow and return NULL on failure.\n   - The code checks the return value of these allocations and throws an exception if allocation fails, preventing use-after-free or buffer overflow.\n   - The `pixels` buffer is allocated based on `image->columns` and `image->rows`, with bounds checked via `bytes_per_line` and `length`.\n   - Before reading data into `pixels`, the code checks: `if (((MagickSizeType) length/8) > GetBlobSize(image))` \u2014 this ensures the expected data size does not exceed the actual file size, preventing buffer over-reads.\n\n3. **Bounds Checking in Loops and Data Processing**:\n   - All loops (e.g., over `y`, `x`, `bit`) use `ssize_t` and `size_t` appropriately, with bounds checked against `image->columns` and `image->rows`.\n   - The code uses `QueueAuthenticPixels` and `GetAuthenticIndexQueue` to access image pixel data safely, and checks for NULL returns.\n   - When processing pixel data (e.g., 1-bit, 4-bit, 8-bit, 16-bit, 24-bit, 32-bit), the code uses bit masks and shifts correctly based on the `bmp_info` structure, which is validated earlier.\n   - For RLE-compressed data, the code uses `DecodeImage` function, which is assumed to be safe and handle edge cases.\n\n4. **Use of `SeekBlob` and `TellBlob`**:\n   - The code uses `SeekBlob` to jump to specific offsets (e.g., colormap, pixel data), but only after validating that the offset is within the file bounds.\n   - It checks `offset < 0` after `SeekBlob`, which prevents invalid seeks.\n\n5. **File Size and Data Consistency Checks**:\n   - The code checks: `if ((MagickSizeType) bmp_info.file_size > GetBlobSize(image))` \u2014 this prevents reading beyond the file size.\n   - It also issues a warning if the file size is smaller than expected, which is a good defensive practice.\n\n6. **No Use of Unsafe Functions**:\n   - The code avoids functions like `strcpy`, `strcat`, `sprintf`, `gets`, etc., which are common sources of buffer overflows.\n   - All data copying is done via `ReadBlob`, `memcpy`, or safe pixel access functions.\n\n7. **Error Handling and Exception Throwing**:\n   - The code uses `ThrowReaderException` and `ThrowMagickException` to handle errors gracefully.\n   - It checks return values of `ReadBlob`, `SeekBlob`, `AcquireVirtualMemory`, etc., and aborts early on failure.\n\n8. **No Known Vulnerabilities in BMP Parsing Logic**:\n   - The code handles multiple BMP variants (OS/2, Windows, Version 5) correctly.\n   - It validates compression types and refuses unsupported ones (e.g., BI_JPEG, BI_PNG).\n   - It correctly handles bitfield masks and color depth conversions.\n\n9. **Final Checks**:\n   - The code checks `EOFBlob(image)` at the end to detect premature EOF.\n   - It properly closes the blob with `CloseBlob`.\n   - It returns `GetFirstImageInList(image)` only after successful processing.\n\nAfter thorough analysis, the code demonstrates strong defensive programming practices:\n- Input validation\n- Bounds checking\n- Safe memory allocation\n- Proper error handling\n- No use of unsafe string or memory functions\n\nThere are no detectable buffer overflows, use-after-free, integer overflows, or other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 447053, "project": "exiv2", "commit_id": "6e3855aed7ba8bb4731fc4087ca7f9078b2f3d97", "project_url": "https://github.com/Exiv2/exiv2", "commit_url": "https://github.com/Exiv2/exiv2/commit/6e3855aed7ba8bb4731fc4087ca7f9078b2f3d97", "commit_message": "Fix https://github.com/Exiv2/exiv2/issues/55", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2017-17723", "cve_desc": "In Exiv2 0.26, there is a heap-based buffer over-read in the Exiv2::Image::byteSwap4 function in image.cpp. Remote attackers can exploit this vulnerability to disclose memory data or cause a denial of service via a crafted TIFF file.", "vuln": 1, "reasoning": "Let's analyze the provided C++ code step by step to identify any potential security vulnerabilities.\n\n---\n\n### Step 1: Understanding the Function\nThe function `Image::printIFDStructure` is part of a TIFF image parsing library (Exiv2). It recursively prints the structure of TIFF Image File Directories (IFDs), reading metadata from a file via a `BasicIo` interface. It handles byte order (endianness), validates input, and supports recursive printing of nested IFDs (e.g., SubIFDs, Exif, IPTC, MakerNote).\n\nKey inputs:\n- `io`: Input/output interface to read from a file.\n- `start`: Starting offset of the IFD.\n- `bSwap`: Whether byte swapping is needed (endianness).\n- `c`: A character used in output formatting.\n- `depth`: Recursion depth for indentation.\n\n---\n\n### Step 2: Buffer and Memory Management\n- A fixed-size buffer `dir` of 32 bytes is used: `DataBuf dir(dirSize);`.\n- This buffer is used to read:\n  - 2 bytes: directory length (`dirLength`).\n  - 12 bytes per tag: tag, type, count, offset.\n- The code reads 12 bytes per tag in a loop: `io.read(dir.pData_, 12);`.\n\nThis is safe as long as the number of tags (`dirLength`) is reasonable and the file is well-formed.\n\n---\n\n### Step 3: Input Validation\n- `dirLength` is checked: `if (dirLength > 500) throw Error(55);`\n  - This prevents excessive iteration and potential DoS via large IFD counts.\n- `typeValid(type)` is checked before processing any tag.\n  - Invalid types lead to an error and break the loop.\n- `byteSwap2`, `byteSwap4` are used safely with `bSwap` flag.\n\nSo, **input validation is present and reasonable**.\n\n---\n\n### Step 4: Memory Allocation Based on User Input\nThis is a **critical point**.\n\nThe code computes:\n```cpp\nlong long allocate = (long long) (size * count + pad + 20);\nif (allocate > (long long) io.size()) {\n    throw Error(57);\n}\nDataBuf buf(allocate);\n```\n\n- `size` depends on `type` (1, 2, 4, 8, or 1).\n- `count` comes from the IFD entry (`byteSwap4(dir,4,bSwap)`).\n- `pad` is 1 if string type, else 0.\n\nSo, `allocate` is derived from `count` and `type`, both of which are **controlled by the input file**.\n\nHowever, the code **validates**:\n```cpp\nif (allocate > (long long) io.size()) throw Error(57);\n```\n\nThis prevents allocation larger than the file size, which is a **good defense against heap exhaustion (DoS)**.\n\nBut note: `io.size()` is the size of the file being read. If the file is large, this check may not prevent allocation of large buffers, but it does prevent allocation larger than the file.\n\nStill, **this is not a buffer overflow**, but rather a **potential denial-of-service (DoS) via memory exhaustion**.\n\nHowever, the check `allocate > io.size()` **does prevent allocation larger than the file**, so it limits the worst-case memory usage.\n\nBut wait: `allocate` is computed as `size * count + pad + 20`. If `count` is huge (e.g., 2^32), and `size` is 4, then `allocate` could be ~16 GB, even if `io.size()` is only 100 MB.\n\nBut the check `if (allocate > io.size())` **will catch this** and throw an error.\n\nSo, **this check prevents allocation larger than the file**, which is a good defense.\n\nBut: **what if `io.size()` is not accurate?** For example, if `io` is a stream that reports a wrong size (e.g., a malicious file that claims to be small but is actually large)? That would be a problem.\n\nBut `io.size()` is typically from the underlying file or stream. If the stream is malicious and lies about its size, then this check could be bypassed.\n\nHowever, in practice, `io.size()` is usually reliable for regular files. For streams, it may be unreliable, but that\u2019s a separate issue.\n\nStill, **the check is in place and prevents allocation larger than the file size**, so it mitigates the risk.\n\n---\n\n### Step 5: Use of `new` and `delete[]`\nThe code uses:\n```cpp\nbyte* bytes = new byte[count];\n...\ndelete[] bytes;\n```\n\nThis is **safe** because:\n- `count` is validated via `dirLength` and `typeValid`, and `allocate` is checked.\n- `count` is read from the file, but the `allocate` check ensures it's not too large.\n- `count` is used in `new byte[count]`, but only if `count` is not too large (due to `allocate` check).\n\nSo, **no buffer overflow or memory corruption here**.\n\n---\n\n### Step 6: Recursive Calls\nThe function calls itself recursively for:\n- SubIFDs (`0x014a`)\n- Exif (`0x8769`)\n- MakerNote (`0x927c`) with `count > 10`\n- IPTC (`0x83bb`)\n\nEach recursive call uses `printIFDStructure(io, out, option, offset, bSwap, c, depth)`.\n\nThe recursion depth is limited by:\n- `depth` (passed in, but not bounded in this function).\n- The file structure (IFDs can be nested, but typically not deeply).\n\nBut there is **no explicit recursion depth limit**.\n\nThis could lead to **stack overflow** if the IFD structure is deeply nested (e.g., 1000 levels).\n\nHowever, **this is a DoS via stack exhaustion**, not a direct memory corruption or code execution vulnerability.\n\nBut: **is this a security vulnerability?**\n\nYes \u2014 **if an attacker crafts a TIFF file with deeply nested IFDs**, it could cause a stack overflow, leading to a crash or potentially exploitable behavior.\n\nBut: **is this a known issue?**\n\nYes \u2014 this is a **classic vulnerability pattern** in image parsers: **unbounded recursion leading to stack overflow**.\n\nEven though the function uses `depth++` and `depth--`, there is **no maximum depth check**.\n\nSo, **this is a security vulnerability**.\n\n---\n\n### Step 7: Other Potential Issues\n- `io.read(buf.pData_, count*size)` \u2014 `count*size` is derived from user input, but:\n  - `allocate` is checked against `io.size()`, so `count*size` cannot exceed `io.size()`.\n  - `io.read` is safe as long as the buffer is large enough and the file is not truncated.\n\n- `Internal::binaryToString(buf, kount)` \u2014 `kount` is limited to 32 for strings, so no overflow.\n\n- `printTiffStructure(memIo, out, option, depth)` \u2014 called only if `chars == \"Nikon\"`, so not arbitrary.\n\n---\n\n### Final Assessment\n\n- **Buffer overflow?** No \u2014 all reads are bounded by `io.size()` and `allocate` checks.\n- **Use-after-free?** No \u2014 `delete[]` is used correctly.\n- **Memory corruption?** No \u2014 all allocations are checked.\n- **DoS via memory exhaustion?** Prevented by `allocate > io.size()` check.\n- **DoS via stack overflow?** **YES** \u2014 unbounded recursion depth in nested IFDs can cause stack overflow.\n\nThis is a **security vulnerability** because:\n- An attacker can craft a TIFF file with deeply nested IFDs (e.g., IFD pointing to itself, or long chain of SubIFDs).\n- This leads to **unbounded recursion**, which can crash the program or cause denial of service.\n\nEven though it's not a code execution vulnerability, **stack overflow due to unbounded recursion is a recognized security issue** in parsers.\n\n---\n\n### Conclusion\n\n(1) YES: A security vulnerability detected."}
{"idx": 255932, "project": "tensorflow", "commit_id": "ee119d4a498979525046fba1c3dd3f13a039fbb1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ee119d4a498979525046fba1c3dd3f13a039fbb1", "commit_message": "Fix segmentation fault in shape inference logic.\n\nWhen running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1d", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-37690", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions when running shape functions, some functions (such as `MutableHashTableShape`) produce extra output information in the form of a `ShapeAndType` struct. The shapes embedded in this struct are owned by an inference context that is cleaned up almost immediately; if the upstream code attempts to access this shape information, it can trigger a segfault. `ShapeRefiner` is mitigating this for normal output shapes by cloning them (and thus putting the newly created shape under ownership of an inference context that will not die), but we were not doing the same for shapes and types. This commit fixes that by doing similar logic on output shapes and types. We have patched the issue in GitHub commit ee119d4a498979525046fba1c3dd3f13a039fbb1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of a shape inference system in a machine learning framework (likely TensorFlow), responsible for inferring shapes of nodes in a computation graph, particularly for function sub-nodes (like function inputs and outputs).\n\n2) The function handles two special node types:\n   - kArgOp: function input nodes\n   - kRetvalOp: function output nodes\n\n3) For kArgOp:\n   - It validates the \"index\" attribute to ensure it's within bounds of outer_context->num_inputs()\n   - It checks if the input shape is unknown (ShapeHandle() == empty), and if so, sets the output shape to unknown\n   - It copies shape and type information from outer context to node context\n\n4) For kRetvalOp:\n   - It validates the \"index\" attribute to ensure it's within bounds of outer_context->num_outputs()\n   - It transfers shape information from node_context (which is for the function body) back to outer_context (which is for the function caller)\n   - It properly copies ShapeAndType information by converting ShapeHandles to proto, then reconstructing them in the outer context to avoid dangling references\n\n5) Key security considerations:\n   - Input validation is performed on the \"index\" attribute for both cases\n   - Bounds checking is done with proper conditions (index < 0 || outer_context->num_inputs() <= index)\n   - The code uses TF_RETURN_IF_ERROR for error handling, which prevents further execution on failure\n   - Shape and type information is properly transferred between contexts with proper ownership semantics\n   - No direct string manipulation, memory copying, or unbounded operations that could lead to buffer overflows\n   - No user input is directly processed without validation\n   - The code is operating within a well-defined type system with proper context management\n\n6) The code follows safe patterns:\n   - Input validation before use\n   - Proper bounds checking\n   - Safe handling of shape and type information with proper context ownership\n   - No use of unsafe functions or direct memory manipulation\n\n7) There are no obvious vulnerabilities such as:\n   - Buffer overflows\n   - Use-after-free\n   - Integer overflows/underflows\n   - Improper input validation\n   - Memory corruption\n   - Unchecked array accesses\n\nThe code appears to be carefully written with proper error handling and context management.\n\n(2) NO: No security vulnerability."}
{"idx": 465854, "project": "linux", "commit_id": "d270453a0d9ec10bb8a802a142fb1b3601a83098", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/d270453a0d9ec10bb8a802a142fb1b3601a83098", "commit_message": "nfc: nfcmrvl: main: reorder destructive operations in nfcmrvl_nci_unregister_dev to avoid bugs\n\nThere are destructive operations such as nfcmrvl_fw_dnld_abort and\ngpio_free in nfcmrvl_nci_unregister_dev. The resources such as firmware,\ngpio and so on could be destructed while the upper layer functions such as\nnfcmrvl_fw_dnld_start and nfcmrvl_nci_recv_frame is executing, which leads\nto double-free, use-after-free and null-ptr-deref bugs.\n\nThere are three situations that could lead to double-free bugs.\n\nThe first situation is shown below:\n\n   (Thread 1)                 |      (Thread 2)\nnfcmrvl_fw_dnld_start         |\n ...                          |  nfcmrvl_nci_unregister_dev\n release_firmware()           |   nfcmrvl_fw_dnld_abort\n  kfree(fw) //(1)             |    fw_dnld_over\n                              |     release_firmware\n  ...                         |      kfree(fw) //(2)\n                              |     ...\n\nThe second situation is shown below:\n\n   (Thread 1)                 |      (Thread 2)\nnfcmrvl_fw_dnld_start         |\n ...                          |\n mod_timer                    |\n (wait a time)                |\n fw_dnld_timeout              |  nfcmrvl_nci_unregister_dev\n   fw_dnld_over               |   nfcmrvl_fw_dnld_abort\n    release_firmware          |    fw_dnld_over\n     kfree(fw) //(1)          |     release_firmware\n     ...                      |      kfree(fw) //(2)\n\nThe third situation is shown below:\n\n       (Thread 1)               |       (Thread 2)\nnfcmrvl_nci_recv_frame          |\n if(..->fw_download_in_progress)|\n  nfcmrvl_fw_dnld_recv_frame    |\n   queue_work                   |\n                                |\nfw_dnld_rx_work                 | nfcmrvl_nci_unregister_dev\n fw_dnld_over                   |  nfcmrvl_fw_dnld_abort\n  release_firmware              |   fw_dnld_over\n   kfree(fw) //(1)              |    release_firmware\n                                |     kfree(fw) //(2)\n\nThe firmware struct is deallocated in position (1) and deallocated\nin position (2) again.\n\nThe crash trace triggered by POC is like below:\n\nBUG: KASAN: double-free or invalid-free in fw_dnld_over\nCall Trace:\n  kfree\n  fw_dnld_over\n  nfcmrvl_nci_unregister_dev\n  nci_uart_tty_close\n  tty_ldisc_kill\n  tty_ldisc_hangup\n  __tty_hangup.part.0\n  tty_release\n  ...\n\nWhat's more, there are also use-after-free and null-ptr-deref bugs\nin nfcmrvl_fw_dnld_start. If we deallocate firmware struct, gpio or\nset null to the members of priv->fw_dnld in nfcmrvl_nci_unregister_dev,\nthen, we dereference firmware, gpio or the members of priv->fw_dnld in\nnfcmrvl_fw_dnld_start, the UAF or NPD bugs will happen.\n\nThis patch reorders destructive operations after nci_unregister_device\nin order to synchronize between cleanup routine and firmware download\nroutine.\n\nThe nci_unregister_device is well synchronized. If the device is\ndetaching, the firmware download routine will goto error. If firmware\ndownload routine is executing, nci_unregister_device will wait until\nfirmware download routine is finished.\n\nFixes: 3194c6870158 (\"NFC: nfcmrvl: add firmware download support\")\nSigned-off-by: Duoming Zhou <duoming@zju.edu.cn>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-1734", "cve_desc": "A flaw in Linux Kernel found in nfcmrvl_nci_unregister_dev() in drivers/nfc/nfcmrvl/main.c can lead to use after free both read or write when non synchronized between cleanup routine and firmware download routine.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `nfcmrvl_nci_unregister_dev` is responsible for unregistering an NFC device and cleaning up associated resources.\n\n2. The function starts by retrieving the `nci_dev` structure from the private data (`priv->ndev`).\n\n3. It calls `nci_unregister_device(ndev)` \u2014 this is a standard NCI (NFC Controller Interface) function to unregister the device. This is safe and expected.\n\n4. Next, it checks if `priv->ndev->nfc_dev->fw_download_in_progress` is true. If so, it calls `nfcmrvl_fw_dnld_abort(priv)` to abort any ongoing firmware download. This is a good safety measure to prevent race conditions or inconsistent states during cleanup.\n\n5. Then, `nfcmrvl_fw_dnld_deinit(priv)` is called to deinitialize firmware download state. This is appropriate for cleanup.\n\n6. The code checks if `gpio_is_valid(priv->config.reset_n_io)` \u2014 if valid, it calls `gpio_free(priv->config.reset_n_io)` to free the GPIO line used for reset. This is proper resource cleanup.\n\n7. After that, `nci_free_device(ndev)` is called to free the NCI device structure. This is correct and safe.\n\n8. Finally, `kfree(priv)` is called to free the private data structure.\n\nNow, consider potential issues:\n\n- Is there a risk of use-after-free? After `nci_free_device(ndev)`, the `ndev` pointer is no longer valid. However, the code does not use `ndev` after this call, so it's safe.\n\n- Is there a possibility of double-free? The `priv` structure is freed only once at the end with `kfree(priv)`, and no other part of the code references it after `nci_free_device` or `nfcmrvl_fw_dnld_deinit`.\n\n- Are any pointers used after being freed? No \u2014 the order of operations is correct: device is unregistered, firmware state is cleaned up, GPIO is freed, device structure is freed, and finally the private data is freed.\n\n- Is there any missing error checking? The function does not return a value, but it's a cleanup function. It's acceptable to proceed with cleanup even if some operations fail (e.g., `gpio_free` may fail, but it's not fatal). The code does not assume success of these calls, so it's safe.\n\n- No input validation is needed here since this is a cleanup function called during device removal, and the state is already known to be valid.\n\nOverall, the function performs cleanup in a correct and safe order, with no obvious memory safety issues, use-after-free, or double-free vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 457772, "project": "icecast-server", "commit_id": "03ea74c04a5966114c2fe66e4e6892d11a68181e", "project_url": "https://gitlab.xiph.org/xiph/icecast-server", "commit_url": "https://gitlab.xiph.org/xiph/icecast-server/commit/03ea74c04a5966114c2fe66e4e6892d11a68181e", "commit_message": "Fix: Worked around buffer overflows in URL auth's cURL interface\n\nThis is only a workaround that keeps compatibility with 2.4.x mainline.\nA real fix has been implemented in 2.5.x (master).", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2018-18820", "cve_desc": "A buffer overflow was discovered in the URL-authentication backend of the Icecast before 2.4.4. If the backend is enabled, then any malicious HTTP client can send a request for that specific resource including a crafted header, leading to denial of service and potentially remote code execution.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `handle_returned_header` is a callback used by libcurl to process HTTP response headers. It receives a pointer `ptr` to the header data, with `size * nmemb` being the total length of the header.\n\n2. The function extracts the `auth_client` context from `stream`, then accesses `client->auth->state`, which is an `auth_url` structure. This structure contains fields like `auth_header`, `timelimit_header`, and `errormsg`.\n\n3. The function checks for three types of headers:\n   - Authentication header (`auth_header`)\n   - Time limit header (`timelimit_header`)\n   - Error message header (`icecast-auth-message`)\n\n4. For the `auth_header` check:\n   - It uses `strncasecmp` to compare the header name case-insensitively.\n   - It checks that the length is at least `url->auth_header_len`, which prevents buffer over-read.\n   - No copying is done, only a comparison \u2014 safe.\n\n5. For the `timelimit_header`:\n   - It checks that `len > url->timelimit_header_len` (correctly avoids partial match).\n   - It verifies the trailing `\\r\\n` (correctly checks for CRLF).\n   - It uses `sscanf` to parse an unsigned integer from the remaining string.\n   - The parsed value is used to set `client->con->discon_time`.\n   - The `sscanf` format `%u\\r\\n` ensures that the input is a number followed by CRLF.\n   - No buffer overflow is possible here because `sscanf` reads from a known-length string and only parses one integer.\n\n6. For the `icecast-auth-message` header:\n   - It checks for the header name with `strncasecmp` and ensures `len > 24`.\n   - It calculates `copy_len = len - 24 + 1` to include the null terminator.\n   - It then checks if `copy_len > sizeof(url->errormsg)`, and if so, truncates it to fit.\n   - It verifies the trailing `\\r\\n` before copying.\n   - It uses `memcpy` to copy the message into `url->errormsg`, and explicitly null-terminates it with `url->errormsg[copy_len-1] = 0`.\n\n   This is a critical point: the `copy_len` is bounded by `sizeof(url->errormsg)`, and the copy is limited to that size. The null terminator is explicitly set. This prevents buffer overflow.\n\n7. All string comparisons use `strncasecmp` with known lengths, avoiding buffer over-reads.\n\n8. All copying operations are bounded by the size of the destination buffer (`url->errormsg`), and the code explicitly ensures null termination.\n\n9. The function returns `len`, which is correct for libcurl's callback.\n\nConclusion: The code performs proper bounds checking, uses safe string operations, and prevents buffer overflows through careful length validation and truncation. There are no exploitable vulnerabilities in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 221160, "project": "gpac", "commit_id": "a69b567b8c95c72f9560c873c5ab348be058f340", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/a69b567b8c95c72f9560c873c5ab348be058f340", "commit_message": "fixed #1895", "ground_truth": 0, "cwe": ["CWE-415"], "cve": "CVE-2021-40571", "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the ilst_box_read function in box_code_apple.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose and Input Validation**:\n   - The function `gf_odf_av1_cfg_read_bs_size` reads AV1 configuration data from a bitstream (`bs`) with a specified `size`.\n   - It first checks if `size` is zero, in which case it uses `gf_bs_available(bs)` to determine how many bytes are available. This is a reasonable fallback.\n   - If no bytes are available, it returns `NULL`, which is safe.\n\n2. **Memory Allocation and Initialization**:\n   - It allocates a new `GF_AV1Config` structure via `gf_odf_av1_cfg_new()`, which should be safe if properly implemented.\n   - It initializes an `AV1State` structure and sets `state.config = cfg`, which is used during parsing.\n\n3. **Reading Fixed-Size Fields**:\n   - The function reads several fixed-size fields (1, 3, 5, 7 bits) from the bitstream using `gf_bs_read_int()`. These are all bounded and validated.\n   - The `reserved` field is read (3 bits), and the code checks that it is zero, and that `marker == 1` and `version == 1`. If not, it logs a debug message and returns `NULL`. This is a good validation step to prevent malformed or malicious input from being processed.\n\n4. **Initial Presentation Delay Handling**:\n   - It reads `initial_presentation_delay_present` (1 bit). If set, it reads `initial_presentation_delay_minus_one` (4 bits). Otherwise, it skips 4 bits and sets the value to 0.\n   - The skipped bits are not used, but this is acceptable since they are reserved.\n\n5. **Loop for Parsing OBU (OBU = OBU Header)**:\n   - The loop processes OBU data until `size` is exhausted.\n   - It uses `gf_av1_parse_obu()` to parse the OBU type and size. This function is assumed to be safe and properly bounds-checking.\n   - It logs debug info about parsed OBU.\n   - It checks `av1_is_obu_header(obu_type)` \u2014 if not a header, it logs a debug message but continues. This is not a security issue since it's just forwarding.\n   - It allocates memory for `a` (`GF_AV1_OBUArrayEntry`) and `a->obu` using `gf_malloc` with `obu_size`.\n   - It seeks back to the original position and reads `obu_size` bytes into `a->obu`.\n   - It adds the entry to `cfg->obu_array`.\n\n6. **Critical Check: Size Validation Before Allocation**:\n   - Before reading the OBU data, it checks: `if (size < obu_size) { ... break; }`\n   - This is crucial: it ensures that the remaining `size` is sufficient to read the entire OBU. If not, it logs a warning and breaks.\n   - This prevents reading beyond the expected data length, which could otherwise lead to buffer over-reads or memory corruption.\n\n7. **Memory Safety**:\n   - `GF_SAFEALLOC` and `gf_malloc` are used, and error checks are in place. If allocation fails, it breaks out of the loop safely.\n   - The `obu_size` is obtained from `gf_av1_parse_obu()`, which should be trusted to return a valid size based on the bitstream.\n   - The function uses `gf_bs_seek()` and `gf_bs_read_data()` correctly, with bounds checked via `size < obu_size`.\n\n8. **Final Steps**:\n   - `gf_av1_reset_state()` is called with `GF_TRUE`, which likely resets internal state.\n   - `gf_bs_align(bs)` ensures alignment, which is safe.\n   - Returns `cfg` if successful.\n\n9. **Potential Risks**:\n   - Could `obu_size` be maliciously large? The function checks `size < obu_size` before reading, so if `obu_size` is larger than the remaining `size`, it breaks. This prevents reading beyond the provided data.\n   - The `obu_size` is derived from parsing the bitstream via `gf_av1_parse_obu()`. If that function is vulnerable to integer overflow or underflow, it could be a problem. However, the code assumes it returns a valid size, and the check `size < obu_size` acts as a safeguard.\n   - The `obu_size` is cast to `u32` before comparison, which is safe since `u32` is unsigned and `size` is `u32`.\n\n10. **Conclusion**:\n    - All critical memory operations are bounded.\n    - Input size is validated before any allocation or read.\n    - Malformed or oversized OBU data is rejected early.\n    - No buffer overflows, use-after-free, or memory corruption vulnerabilities are evident.\n    - The code follows safe practices: bounds checking, input validation, error handling, and proper cleanup.\n\n(2) NO: No security vulnerability."}
{"idx": 250692, "project": "drogon", "commit_id": "3c785326c63a34aa1799a639ae185bc9453cb447", "project_url": "https://github.com/drogonframework/drogon", "commit_url": "https://github.com/drogonframework/drogon/commit/3c785326c63a34aa1799a639ae185bc9453cb447", "commit_message": "Prevent malformed upload path causing arbitrary write (#1174)", "ground_truth": 0, "cwe": ["CWE-552"], "cve": "CVE-2022-25297", "cve_desc": "This affects the package drogonframework/drogon before 1.7.5. The unsafe handling of file names during upload using HttpFile::save() method may enable attackers to write files to arbitrary locations outside the designated target folder.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `saveAs` takes a `fileName` parameter of type `std::string` and is marked `const`, meaning it doesn't modify the object state.\n\n2. It first asserts that `fileName` is not empty \u2014 this is a basic input validation.\n\n3. It converts the `fileName` to a native filesystem path using `utils::toNativePath()`, which is likely a helper to normalize path separators (e.g., on Windows, convert `/` to `\\`).\n\n4. The key logic is in the path validation and normalization:\n   - It checks if the path is not absolute (`!fsFileName.is_absolute()`).\n   - Then it checks if the path has no parent path, or if it does, the first component (i.e., the first path element) is neither `\".\"` nor `\"..\"`.\n     - This is intended to prevent traversal into parent directories via `..` or `.` components.\n   - If the path is not absolute and doesn't start with `.` or `..`, it prepends the upload path from `HttpAppFrameworkImpl::instance().getUploadPath()`.\n\n5. Then, it checks if the parent path of the final `fsFileName` exists. If not, it creates the directory structure using `filesystem::create_directories`, with error handling via `drogon::error_code`.\n\n6. Finally, it calls `saveTo(fsFileName)` to actually save the file.\n\nNow, let's assess for security vulnerabilities:\n\n- The use of `fsFileName.begin()->string() != \".\" && ... != \"..\"` is a critical check. It prevents the path from starting with `.` or `..`, which would allow directory traversal attacks (e.g., `../../../etc/passwd`).\n- The path is only modified by prepending the upload directory if it's not absolute and doesn't start with `.` or `..`. This prevents attackers from specifying arbitrary absolute paths or relative paths that escape the upload directory.\n- The `create_directories` call is safe because it only creates missing directories in the path, and the path is already constrained by the above checks.\n- The `saveTo(fsFileName)` function is not shown, but assuming it's a safe file write operation (e.g., using `std::ofstream` with proper checks), and the path is already validated, no further injection is possible.\n\nHowever, one subtle point: the check `!fsFileName.has_parent_path() || ...` is a bit tricky. It says: if the path has no parent path, or if it does, then the first component must not be `.` or `..`. But this logic only checks the first component. What if the path is something like `a/..`? That would be allowed if `a` is not `.` or `..`, but `..` is a valid component later in the path.\n\nWait \u2014 the code checks `fsFileName.begin()->string()` \u2014 that is, the first path element. But `a/..` would have `a` as the first element, which is not `.` or `..`, so it would pass. Then the path becomes `upload_dir/a/..`, which resolves to `upload_dir` \u2014 so the file would be saved in the upload directory, not outside.\n\nBut what if the path is `../file`? Then `fsFileName.begin()->string()` is `\"..\"`, so it would be rejected by the condition:\n```cpp\nfsFileName.begin()->string() != \".\" && fsFileName.begin()->string() != \"..\"\n```\nSo `../file` is blocked.\n\nBut what about `a/../b`? The first component is `a`, which is allowed. Then the path becomes `upload_dir/a/../b`, which resolves to `upload_dir/b`. This is safe \u2014 it doesn't escape the upload directory.\n\nSo the only way to escape the upload directory is to have a `..` at the beginning, which is blocked.\n\nTherefore, the code prevents:\n- Absolute paths (via `!is_absolute()` check).\n- Paths starting with `.` or `..` (via the `begin()->string()` check).\n- Paths that would otherwise escape the upload directory via `..` components are resolved safely, but the initial check prevents `..` at the start.\n\nHowever, there is a potential issue: the `filesystem::path` class may normalize paths automatically. But the code does not explicitly normalize the path after construction. However, `filesystem::create_directories` and `saveTo` will likely resolve `..` components during path resolution.\n\nBut the key is: the only way to escape the upload directory is to have `..` at the beginning, which is blocked. Any `..` later in the path is resolved safely and does not escape the upload directory.\n\nTherefore, the code is secure against path traversal attacks.\n\nAdditionally, the use of `utils::toNativePath` is likely safe \u2014 it just normalizes separators, not content.\n\nNo input sanitization is missing, and the path is constrained to the upload directory.\n\n(2) NO: No security vulnerability."}
{"idx": 218852, "project": "tensorflow", "commit_id": "c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd", "commit_message": "Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2022-23578", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. If a graph node is invalid, TensorFlow can leak memory in the implementation of `ImmutableExecutorState::Initialize`. Here, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context**: The function `ImmutableExecutorState::Initialize` is part of a TensorFlow-like execution engine. It initializes internal state for a computational graph, including control flow information, frame management, kernel creation, and dependency tracking.\n\n2. **Input Validation and Error Handling**:\n   - The function uses `TF_RETURN_IF_ERROR` extensively, which is a TensorFlow macro that returns early on any non-OK status. This ensures that errors (e.g., from attribute retrieval or kernel creation) are caught and propagated.\n   - `GetNodeAttr` is used to extract attributes like `\"send_device\"`, `\"recv_device\"`, `\"frame_name\"`, `\"parallel_iterations\"`, etc. These are validated via `TF_RETURN_IF_ERROR`, so invalid or missing attributes result in early return with an error.\n   - All user-controlled input (e.g., node attributes, graph structure) is accessed through these safe APIs, which do not perform unsafe operations like string concatenation or buffer copying without bounds checks.\n\n3. **Memory Safety**:\n   - The code uses `absl::make_unique` for dynamic allocation, which is safe and exception-safe.\n   - `std::unique_ptr<bool[]> outputs_required` is used for dynamic array allocation, and it is properly managed with `std::move`.\n   - `const_tensors_.emplace_back(*const_tensor);` performs a shallow copy of a tensor. While this could be a concern if the tensor contains sensitive data, it is not a buffer overflow or memory corruption issue.\n   - `pending_ids_.resize(gview_.num_nodes());` is safe because `gview_.num_nodes()` is derived from the graph, which is validated during initialization.\n\n4. **Control Flow and Data Flow**:\n   - The code processes each node in the graph, and all operations are based on the graph structure and node attributes.\n   - There is no use of unsafe functions like `strcpy`, `strcat`, `sprintf`, or direct pointer arithmetic.\n   - All indexing is done via `n->id()` and `gview_.node(id)`, which are assumed to be valid and within bounds due to the graph's integrity and the use of `gview_.Initialize(&graph)` earlier.\n\n5. **Security-Sensitive Operations**:\n   - The code does not perform any file I/O, network operations, or dynamic code execution.\n   - It does not interpret user input as code or command (e.g., no `eval`, `exec`, or `system` calls).\n   - The only potential risk would be if a malicious graph could cause memory corruption or infinite loops, but:\n     - The graph is passed as a `const Graph&`, so it cannot be modified during processing.\n     - The `Initialize` function is idempotent and does not rely on external state.\n     - The use of `TF_RETURN_IF_ERROR` ensures that any failure (e.g., invalid attribute) halts execution safely.\n\n6. **No Obvious Vulnerabilities**:\n   - No buffer overflows, use-after-free, or integer overflows are present.\n   - All data structures are properly initialized and accessed within bounds.\n   - The code follows safe patterns: RAII, smart pointers, error propagation, and bounds-checked access.\n\nConclusion: The code is well-structured, uses safe APIs, performs proper error checking, and avoids any known security anti-patterns. There is no evidence of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 247290, "project": "tensorflow", "commit_id": "9e62869465573cb2d9b5053f1fa02a81fce21d69", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e62869465573cb2d9b5053f1fa02a81fce21d69", "commit_message": "Add more validation to `RequantizationRangePerChannel`.\n\nPiperOrigin-RevId: 387693946\nChange-Id: Ife8dcbdb021bec4787eef6a4361dd08f17c14bd6", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2021-37665", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions due to incomplete validation in MKL implementation of requantization, an attacker can trigger undefined behavior via binding a reference to a null pointer or can access data outside the bounds of heap allocated arrays. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantization_range_per_channel_op.cc) does not validate the dimensions of the `input` tensor. A similar issue occurs in `MklRequantizePerChannelOp`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/mkl/mkl_requantize_per_channel_op.cc) does not perform full validation for all the input arguments. We have patched the issue in GitHub commit 9e62869465573cb2d9b5053f1fa02a81fce21d69 and in the Github commit 203214568f5bc237603dbab6e1fd389f1572f5c9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Input Validation**:\n   - The function `Compute` takes an `OpKernelContext* ctx` and retrieves three inputs: `input`, `input_min`, and `input_max`.\n   - It checks that:\n     - `input_min.dim_size(0) == depth` (correct size).\n     - `input_max.dim_size(0) == depth` (correct size).\n     - `input_min.NumElements() == depth` (same number of elements as `input_max`).\n     - `input.NumElements() > 0` (input not empty).\n     - `input.dims() == 4` (input is 4D, expected NHWC format).\n     - `input.dim_size(3) == depth` (number of channels matches depth).\n   - These checks are performed using `OP_REQUIRES`, which ensures that if any condition fails, an error is returned and execution halts. This prevents invalid or malformed input from causing undefined behavior.\n\n2. **Memory Access and Buffer Safety**:\n   - The code uses `input_min.flat<float>().data()` and `input_max.flat<float>().data()` to access the underlying data. Since the size has already been validated (via `NumElements()` and `dim_size(0)`), and the data is accessed only within bounds (loop over `depth`), there is no out-of-bounds access.\n   - `transposed_input` is created via `input_matrix.shuffle(shuffling)`, which is a safe operation on Eigen tensors as long as the input is valid \u2014 and it is validated earlier.\n   - The loop iterates over `i` from `0` to `depth - 1`, and each `chip<0>(i)` accesses a single channel of the transposed tensor. Since `depth` is derived from `input_max.NumElements()`, and that has been validated, the loop is safe.\n\n3. **Parallelization and Thread Safety**:\n   - The code uses OpenMP with `#pragma omp parallel for reduction(max: out_min_max)` to compute the maximum range per channel in parallel.\n   - `out_min_max` is declared as a local variable and reduced via `max` operation \u2014 this is thread-safe due to the `reduction` clause.\n   - No shared state is modified without proper synchronization.\n\n4. **Floating-Point and Integer Arithmetic**:\n   - The computation of `scale`, `abs_max`, and `ranges[i]` uses safe arithmetic:\n     - `std::abs(min_per_channel)` and `std::abs(max_per_channel)` are safe for `int32_t`.\n     - `static_cast<float>(1L << 31)` is `2^31`, which is a large but representable float (though it's a bit of a red flag \u2014 `1L << 31` is `2147483648`, which is exactly `2^31`, and `float` can represent this exactly).\n     - The division and multiplication are done in float, so no integer overflow occurs.\n   - The final `out_min_max` is clamped to `clip_value_max_` \u2014 this is a safety guard against excessively large values.\n\n5. **Output Allocation and Assignment**:\n   - `ctx->allocate_output(kOutputMinIndex, {}, &output_min)` and similarly for `output_max` \u2014 the output tensors are allocated with size `0` (scalar), which is correct since the output is a single float value.\n   - The output values are assigned via `output_min->flat<float>()(0)` and `output_max->flat<float>()(0)` \u2014 safe because the tensor is scalar and the index `0` is valid.\n\n6. **Security Considerations**:\n   - No user-controlled data is directly used in unsafe operations (e.g., string formatting, memory copying, or system calls).\n   - All input sizes are validated before use.\n   - No buffer overflows, use-after-free, or integer overflows are present.\n   - The code is part of a TensorFlow kernel (likely for quantization calibration), and the logic is defensive and well-structured.\n\n7. **Potential Concerns**:\n   - The use of `1L << 31` for `int32_t` range: this is correct for the minimum value of a signed 32-bit integer (`-2^31`), but the code uses `abs_max` and `scale` in a way that is mathematically sound.\n   - The `clip_value_max_` clamping is a safety measure, but it's not a vulnerability \u2014 it's a design choice.\n   - The OpenMP directive is guarded by `ENABLE_ONEDNN_OPENMP`, so it's not always compiled \u2014 but that doesn't introduce a vulnerability.\n\nConclusion: The code performs thorough input validation, uses safe tensor operations, avoids buffer overflows, and handles parallelization safely. There are no exploitable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 417093, "project": "MilkyTracker", "commit_id": "7afd55c42ad80d01a339197a2d8b5461d214edaf", "project_url": "https://github.com/milkytracker/MilkyTracker", "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "commit_message": "Fix use-after-free in PlayerGeneric destructor", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2020-15569", "cve_desc": "PlayerGeneric.cpp in MilkyTracker through 1.02.00 has a use-after-free in the PlayerGeneric destructor.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The code is a destructor for a class `PlayerGeneric`, which is responsible for cleaning up resources.\n\n2. The destructor first checks if `player` is non-null:\n   - If so, it checks if `mixer` exists, and if the mixer is active and the player is not marked as removed from the device.\n   - If all conditions are true, it calls `mixer->removeDevice(player)`.\n   - Then it deletes `player`.\n\n3. After that, it checks if `mixer` is non-null and deletes it.\n\n4. Then it deletes `audioDriverName`, which is a dynamically allocated array (`delete[]` is used, which is correct for arrays).\n\n5. Finally, it deletes `listener`.\n\nNow, let's analyze for potential security vulnerabilities:\n\n- The use of `delete` and `delete[]` is appropriate: `player` is a single object, so `delete` is correct; `audioDriverName` is an array, so `delete[]` is correct.\n- The `mixer->removeDevice(player)` call is safe only if `mixer` is valid and the player is still registered. The checks `mixer && mixer->isActive() && !mixer->isDeviceRemoved(player)` prevent calling `removeDevice` on a null or already removed device.\n- There is no use of unsafe functions like `strcpy`, `sprintf`, or direct memory manipulation.\n- No buffer overflows, use-after-free, or memory leaks are evident in this code snippet.\n- The order of deletion is safe: `player` is deleted only after it's removed from the mixer, and `mixer` is deleted after `player` is gone.\n- No dangling pointers or double-free issues are apparent, as each pointer is deleted only once and only if non-null.\n\nThe code follows safe resource management practices, with proper null checks and correct deallocation syntax.\n\n(2) NO: No security vulnerability."}
{"idx": 220442, "project": "mruby", "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/27d1e0132a0804581dca28df042e7047fd27eaa8", "commit_message": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-4188", "cve_desc": "mruby is vulnerable to NULL Pointer Dereference", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `mrb_ary_shift_m` is a Ruby MRI (Matz's Ruby Interpreter) extension function that shifts elements from the beginning of an array. It takes an array `self` and an optional integer `n` indicating how many elements to shift.\n\n2) The function first checks for arguments using `mrb_get_args` with the format \"|i\", which means an optional integer. If no argument is provided, it calls `mrb_ary_shift` (which shifts one element).\n\n3) The function then retrieves the array pointer and its length. It performs several safety checks:\n   - `ary_modify_check` ensures the array is not frozen\n   - Checks if the array is empty or n is 0, returning a new empty array\n   - Checks for negative n and raises an error\n   - Ensures n doesn't exceed array length (clamps n to len)\n\n4) The function creates a new array `val` containing the first `n` elements using `mrb_ary_new_from_values`.\n\n5) The core logic handles two cases:\n   - If the array is shared (ARY_SHARED_P(a)), it simply advances the pointer and reduces the length\n   - If not shared, it either:\n     * Makes the array shared if it's large enough (ARY_SHIFT_SHARED_MIN)\n     * Or shifts elements in-place by copying elements from position n to the front\n\n6) The key safety aspects:\n   - Input validation for n (negative, too large)\n   - Proper bounds checking\n   - Use of `ary_modify_check` to prevent modification of frozen arrays\n   - Correct handling of shared arrays\n   - Proper memory management through MRI's garbage collector\n\n7) The function does not perform any unsafe operations like buffer overflows, use of untrusted input in unsafe ways, or memory corruption. All array operations are within bounds and properly managed by the MRI runtime.\n\n8) The function correctly handles edge cases (empty array, n=0, n>len) and uses the MRI's internal array management system properly.\n\n(2) NO: No security vulnerability."}
{"idx": 406206, "project": "util-linux", "commit_id": "5ebbc3865d1e53ef42e5f121c41faab23dd59075", "project_url": "https://github.com/karelzak/util-linux", "commit_url": "http://git.kernel.org/?p=utils/util-linux/util-linux.git;a=commit;h=5ebbc3865d1e53ef42e5f121c41faab23dd59075", "commit_message": "mount: sanitize paths from non-root users\n\n $ mount /root/.ssh/../../dev/sda2\n mount: only root can mount UUID=17bc65ec-4125-4e7c-8a7d-e2795064c736 on /boot\n\nthis is too promiscuous. It seems better to ignore on command line\nspecified paths which are not resolve-able for non-root users.\n\nFixed version:\n\n  $ mount /root/.ssh/../../dev/sda2\n  mount: /root/.ssh/../../dev/sda2: Permission denied\n\n  $ mount /dev/sda2\n  mount: only root can mount UUID=17bc65ec-4125-4e7c-8a7d-e2795064c736 on /boot\n\nNote that this bug has no relation to mount(2) permissions evaluation\nin suid mode. The way how non-root user specifies paths on command\nline is completely irrelevant for comparison with fstab entries.\n\nSigned-off-by: Karel Zak <kzak@redhat.com>", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2013-0157", "cve_desc": "(a) mount and (b) umount in util-linux 2.14.1, 2.17.2, and probably other versions allow local users to determine the existence of restricted directories by (1) using the --guess-fstype command-line option or (2) attempting to mount a non-existent device, which generates different error messages depending on whether the directory exists.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there is a security vulnerability.\n\n1. **Input Handling and Validation**:\n   - The code uses `getopt_long` to parse command-line arguments, which is a standard and safe way to handle CLI options.\n   - It checks for restricted (non-root) users and enforces access control via `mnt_context_is_restricted(cxt)` and `exit_non_root()`. This prevents non-root users from using certain dangerous options.\n   - For options like `-L` (label), `-U` (UUID), `--source`, and `--target`, the code uses `xasprintf` to construct strings like `\"LABEL=\\\"...\\\"\"` or `\"UUID=\\\"...\\\"\"`, and then sets them via `mnt_context_set_source(cxt, srcbuf)`. The `xasprintf` function is safe as it dynamically allocates memory and ensures null termination.\n\n2. **Use of `xasprintf` and `free`**:\n   - `xasprintf(&srcbuf, \"LABEL=\\\"%s\\\"\", optarg)` safely constructs a string with user input (optarg) enclosed in quotes. This is a common and safe pattern for handling labels/UUIDs.\n   - The allocated `srcbuf` is properly freed with `free(srcbuf)` after use, preventing memory leaks.\n\n3. **Mount Operation Context**:\n   - The code uses `libmnt_context` to manage mount operations. This library is designed to be secure and handles many edge cases.\n   - `mnt_context_set_source(cxt, ...)` and `mnt_context_set_target(cxt, ...)` are used to set source and target paths. These functions are part of a well-designed API that likely performs validation.\n   - The code checks for conflicting options using `err_exclusive_options`, which prevents unsafe combinations.\n\n4. **Path Sanitization**:\n   - If the context is restricted (non-root), the code calls `sanitize_paths(cxt)` before mounting. This function likely ensures that paths are safe and do not contain dangerous characters or sequences (e.g., `..`, symlinks, etc.), which is a strong security measure.\n\n5. **Mount Flags and Propagation**:\n   - The `oper` variable accumulates mount flags (e.g., `MS_BIND`, `MS_SHARED`, etc.) based on command-line options. These are standard kernel mount flags and are not user-controlled in a way that could lead to injection.\n   - The code sets `mnt_context_set_mflags(cxt, oper)` and `mnt_context_set_optsmode(cxt, MNT_OMODE_NOTAB)` to ensure proper behavior.\n\n6. **No Direct String Concatenation with User Input**:\n   - There is no use of unsafe functions like `strcpy`, `strcat`, or `sprintf` with user input.\n   - All user input is either passed through safe functions (`xasprintf`, `mnt_context_set_*`) or validated before use.\n\n7. **No Use of Shell or External Commands**:\n   - The code does not invoke shell commands or use `system()` or similar functions, so there is no risk of command injection.\n\n8. **Error Handling and Resource Management**:\n   - The code properly initializes and cleans up resources: `mnt_new_context()`, `mnt_free_context()`, `mnt_free_table()`.\n   - Errors are handled with `err()` and `usage()`, and the program exits cleanly.\n\n9. **No Known Vulnerabilities in libmnt**:\n   - The code uses `libmnt`, a well-maintained library for mount operations. While vulnerabilities in the library itself could exist, the code as written does not introduce new ones.\n\nConclusion: The code follows secure coding practices:\n- Input is validated and sanitized.\n- Memory is managed safely.\n- Privilege separation is enforced.\n- Dangerous operations are restricted for non-root users.\n- No unsafe string operations or command execution.\n\n(2) NO: No security vulnerability."}
{"idx": 225547, "project": "tensorflow", "commit_id": "a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a1e1511dde36b3f8aa27a6ec630838e7ea40e091", "commit_message": "[lite] Update TfLiteIntArrayCreate to return size_t\n\nPiperOrigin-RevId: 416439896\nChange-Id: I847f69b68d1ddaff4b1e925a09b8b69c1756653b", "ground_truth": 0, "cwe": ["CWE-190"], "cve": "CVE-2022-23558", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in `TfLiteIntArrayCreate`. The `TfLiteIntArrayGetSizeInBytes` returns an `int` instead of a `size_t. An attacker can control model inputs such that `computed_size` overflows the size of `int` datatype. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `TfLiteIntArrayGetSizeInBytes` calculates the size in bytes required to store a `TfLiteIntArray` structure with a given `size` (number of elements).\n\n2. The function uses a `static` `TfLiteIntArray dummy` to get the size of the structure's header (i.e., the part before the `data` array). This is a common idiom to avoid hardcoding the size of the struct.\n\n3. The computed size is:\n   - `sizeof(dummy)` \u2192 size of the struct header (including the `size` field and any other fixed members).\n   - Plus `sizeof(dummy.data[0]) * size` \u2192 size of the dynamic array part (assuming `data` is an array of `int` or similar).\n\n4. The `#if defined(_MSC_VER)` block adjusts the computed size by subtracting `sizeof(dummy.data[0])`. This is a platform-specific fix, and the comment references a bug report (http://b/189926408#comment21), which implies this adjustment is necessary due to a compiler-specific alignment or padding issue on MSVC.\n\n5. The key question: Is this adjustment safe and correct?\n\n   - The `dummy` is a `static` variable, so it's initialized once and reused. It's not used to store data, just to compute sizes.\n   - The subtraction of `sizeof(dummy.data[0])` on MSVC is likely due to a known issue where MSVC's struct padding or alignment causes the `data` field to be misaligned or the struct size to be miscalculated.\n   - The fix is applied only on MSVC, which suggests it's a workaround for a compiler-specific behavior, not a general logic error.\n   - The function returns `computed_size`, which is used to allocate memory for a `TfLiteIntArray` with `size` elements.\n\n6. Is there a security vulnerability?\n\n   - The function does not perform any input validation on `size`, but `size` is an `int`, and the function returns `size_t`. If `size` is negative, this would result in a large positive `size_t` value (due to unsigned wraparound), which could lead to a buffer overflow when allocating memory.\n   - However, the function itself does not allocate memory \u2014 it only computes the size. The actual allocation would be done elsewhere, and it's assumed that the caller validates `size` before calling this function.\n   - The function does not perform any unsafe operations like buffer copying, string manipulation, or direct memory access.\n   - The MSVC-specific fix is a known workaround for a compiler issue, not a security flaw.\n\n7. The only potential issue is that `size` is not validated for negative values. But this is a common pattern in C: if the caller passes a negative `size`, the resulting `computed_size` will be huge (due to unsigned wraparound), which could lead to a heap overflow if used to allocate memory. However, this is a logic error in the caller, not a vulnerability in this function per se \u2014 and the function itself is not the source of the vulnerability.\n\n8. But note: the function is used to compute memory size. If `size` is negative, `sizeof(dummy.data[0]) * size` becomes a large positive number due to unsigned arithmetic, leading to an oversized allocation. This could be exploited if an attacker controls `size` and the allocation is done based on this result.\n\n   Example: `size = -1` \u2192 `size_t` becomes `0xFFFFFFFF` (on 32-bit), so `computed_size` becomes huge \u2192 allocation fails or causes memory exhaustion, or worse, if the allocation is not checked, could lead to heap corruption.\n\n   However, this is a classic integer overflow/underflow issue, and the function does not validate the input. But is this a security vulnerability?\n\n   Yes \u2014 because if `size` is user-controlled and not validated, an attacker could pass a negative value to cause a large allocation, leading to denial of service (DoS) or potentially memory corruption if the allocation is not properly checked.\n\n   But wait: the function is `TfLiteIntArrayGetSizeInBytes`, and `size` is likely an internal API parameter. In practice, `size` is expected to be non-negative. However, the function does not validate this.\n\n   The lack of input validation on `size` (which is `int`) means that a negative value can be passed, leading to a large `size_t` value due to unsigned wraparound. This is a classic integer overflow vulnerability.\n\n   Therefore, this function is vulnerable to integer overflow if `size` is negative.\n\n   Example:\n   ```c\n   int size = -1;\n   size_t bytes = TfLiteIntArrayGetSizeInBytes(size); // becomes huge\n   ```\n\n   This could lead to a denial of service (DoS) via memory exhaustion, or if the allocation is not checked, memory corruption.\n\n   So, even though the function is not directly doing anything unsafe, the lack of input validation on a size parameter that is used to compute memory allocation size is a security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 246495, "project": "tensorflow", "commit_id": "1e206baedf8bef0334cca3eb92bab134ef525a28", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/1e206baedf8bef0334cca3eb92bab134ef525a28", "commit_message": "Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-37683", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of a TensorFlow Lite operator implementation for division (Div) operation. It handles different data types: FLOAT32, INT32, and UINT8.\n\n2) The key security concern is division by zero. The code explicitly checks for division by zero in the INT32 and UINT8 cases using the macro TF_LITE_CHECK_DIV_NON_ZERO, which iterates through all elements of input2 (the divisor) and ensures none are zero using TF_LITE_ENSURE(context, input2_data[i] != 0).\n\n3) For FLOAT32, the code intentionally does NOT check for division by zero, stating \"Div by zero seems ok in this case, just like in TF case infinities are returned.\" This is a deliberate design choice, as floating-point division by zero is well-defined in IEEE 754 standard (producing infinity or NaN), and TensorFlow's behavior is consistent with this.\n\n4) The INT32 and UINT8 cases have explicit checks that prevent division by zero, which is critical because integer division by zero is undefined behavior and can lead to crashes or security vulnerabilities.\n\n5) The code uses proper TensorFlow Lite error handling with TF_LITE_ENSURE_OK and context->ReportError for invalid types.\n\n6) The macro TF_LITE_CHECK_DIV_NON_ZERO is only used for integer types where division by zero is undefined behavior, and it performs a complete check of all elements in the input2 tensor.\n\n7) There are no buffer overflows, use-after-free, or other memory safety issues apparent in the code.\n\n8) The only potential concern is the lack of division-by-zero check for FLOAT32, but this is explicitly documented as intentional behavior consistent with TensorFlow's design.\n\n(2) NO: No security vulnerability."}
{"idx": 511472, "project": "server", "commit_id": "b3c3291f0b7c1623cb20663f7cf31b7f749768bc", "project_url": "https://github.com/MariaDB/server", "commit_url": "https://github.com/MariaDB/server/commit/b3c3291f0b7c1623cb20663f7cf31b7f749768bc", "commit_message": "MDEV-24176 fixup: GCC -Wmaybe-uninitialized", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-27376", "cve_desc": "MariaDB Server v10.6.5 and below was discovered to contain an use-after-free in the component Item_args::walk_arg, which is exploited via specially crafted SQL statements.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function and its purpose\nThe function `open_table` is part of a database system (likely MySQL) and is responsible for opening a database table. It handles:\n- Metadata locking (MDL)\n- Table definition cache (TDC) lookups\n- Table sharing and reuse\n- Error handling for missing or invalid tables\n- Support for views, temporary tables, partitioned tables, and sequences\n- Handling of read-only transactions, global read locks, and deadlock recovery\n\nIt uses various internal structures like `TABLE`, `TABLE_LIST`, `MDL_ticket`, `TABLE_SHARE`, and `Open_table_context`.\n\n---\n\n### Step 2: Look for potential security vulnerabilities\n\n#### A. **Input validation and sanitization**\n- The function checks for:\n  - Null pointers (`!table_list->table`, `!table_list->db.str`)\n  - Invalid table names or aliases\n  - Use of `get_table_def_key()` to generate a key for cache lookup\n  - Use of `my_strcasecmp` for case-insensitive comparison of aliases\n- These checks are appropriate and prevent some forms of injection or misuse.\n\n#### B. **Use of `tdc_acquire_share` and `tdc_release_share`**\n- The function uses `tdc_acquire_share` to get a shared table definition from the table definition cache (TDC).\n- If the share is not found, it returns an error.\n- The TDC is a central cache for table metadata, and its integrity is critical.\n- The code checks for stale or outdated shares via `share->tdc->flushed` and retries if necessary.\n- This is a **correct and secure** mechanism to handle metadata consistency and avoid using outdated table definitions.\n\n#### C. **Metadata Locking (MDL)**\n- The function acquires MDL locks using `thd->mdl_context.acquire_lock()` when needed.\n- It handles deadlock detection via `MDL_deadlock_handler`.\n- It ensures that write operations in read-only transactions are blocked (except for log tables).\n- This is a **secure and well-implemented** pattern to prevent race conditions and inconsistent state.\n\n#### D. **Use of `my_error()` and `thd->clear_error()`**\n- Errors are properly reported using `my_error()` with appropriate error codes.\n- When errors are suppressed (e.g., for views), the error is cleared and replaced with a more appropriate one.\n- This prevents information leakage and ensures consistent error handling.\n\n#### E. **Use of `goto` and `DBUG_RETURN`**\n- The function uses `goto` for error handling (e.g., `err_lock`, `reset`).\n- While `goto` can be risky in general, in this context it is used in a controlled way for cleanup and error propagation.\n- The `DBUG_RETURN(TRUE)` and `DBUG_RETURN(FALSE)` are used correctly to exit early on error.\n- No dangling pointers or memory leaks are evident in the cleanup paths.\n\n#### F. **View handling**\n- The function checks if a table is a view (`share->is_view`) and handles it appropriately.\n- It validates the view's metadata version and calls `mysql_make_view()` to open it.\n- It prevents opening views as merge tables or sequences incorrectly.\n- This is **secure** and prevents misuse of views.\n\n#### G. **Partitioning and sequence handling**\n- Checks for invalid partitioning usage (e.g., `PARTITION()` on non-partitioned tables).\n- Checks for invalid sequence usage.\n- These are **correct and secure** validations.\n\n#### H. **Memory management**\n- Uses `my_malloc` and `my_free` for memory allocation.\n- Proper cleanup via `tc_release_table`, `tdc_release_share`, `closefrm`, etc.\n- No obvious memory leaks or use-after-free.\n\n#### I. **No user input directly used in unsafe operations**\n- The function does not directly concatenate user input into strings, SQL queries, or system calls.\n- All table names and keys are validated and used through safe APIs (`get_table_def_key`, `tdc_acquire_share`, etc.).\n- No `strcpy`, `sprintf`, `strcat`, or similar unsafe functions are used.\n\n#### J. **No buffer overflows or integer overflows**\n- The function uses `uint`, `size_t`, and `const char*` appropriately.\n- `key_length` is derived from `get_table_def_key`, which is expected to be safe.\n- No arithmetic on pointers or sizes that could overflow.\n\n---\n\n### Step 3: Conclusion\nAfter a thorough analysis:\n- The function performs proper input validation.\n- It uses secure patterns for metadata locking, caching, and error handling.\n- It avoids unsafe string operations and memory management issues.\n- It correctly handles edge cases (views, sequences, partitions, stale metadata).\n- No exploitable vulnerabilities (e.g., buffer overflow, SQL injection, use-after-free, race conditions) are present.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 249510, "project": "libjxl", "commit_id": "7dfa400ded53919d986c5d3d23446a09e0cf481b", "project_url": "https://github.com/libjxl/libjxl", "commit_url": "https://github.com/libjxl/libjxl/commit/7dfa400ded53919d986c5d3d23446a09e0cf481b", "commit_message": "Fix handling of APNG with 0 delay_den (#313)", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-36692", "cve_desc": "libjxl v0.3.7 is affected by a Divide By Zero in issue in lib/extras/codec_apng.cc jxl::DecodeImageAPNG(). When encoding a malicous APNG file using cjxl, an attacker can trigger a denial of service.", "vuln": 1, "reasoning": "Let's analyze the provided code step-by-step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Parsing\n- The function `DecodeImageAPNG` takes a `Span<const uint8_t>` `bytes` as input, which represents the raw APNG data.\n- It starts by reading the first 8 bytes to verify the PNG signature (`{137, 80, 78, 71, 13, 10, 26, 10}`), which is standard for PNG files. If the signature doesn't match, it returns `false` immediately. This is a good practice to prevent processing malformed or non-PNG data.\n\n---\n\n### Step 2: Chunk Parsing and Memory Management\n- The code uses a `Reader` class (`r`) to read chunks from the input stream.\n- It reads the `IHDR` chunk and validates its size (`chunkIHDR.size == 25`). If not, it skips further processing.\n- The `IHDR` chunk contains image dimensions (`w`, `h`). The code checks if `w > cMaxPNGSize` or `h > cMaxPNGSize`, and returns `false` if so. This prevents integer overflow or excessive memory allocation due to large dimensions.\n\n---\n\n### Step 3: Dynamic Memory Allocation\n- The code dynamically allocates memory for `frameRaw.p` (pixel data) and `frameRaw.rows` (row pointers) using `new`.\n  ```cpp\n  frameRaw.p = new unsigned char[imagesize];\n  frameRaw.rows = new png_bytep[h * sizeof(png_bytep)];\n  for (j = 0; j < h; j++) frameRaw.rows[j] = frameRaw.p + j * rowbytes;\n  ```\n- This is correct and safe **as long as** `imagesize` and `rowbytes` are properly bounded.\n- `imagesize = h * rowbytes`, and `rowbytes = w * 4`. Since `w` and `h` are checked against `cMaxPNGSize`, and `cMaxPNGSize` is likely a reasonable limit (e.g., 65535), this prevents excessive memory allocation.\n\n---\n\n### Step 4: Chunk Processing Loop\n- The function processes chunks in a loop using `read_chunk(&r, &chunk)`.\n- For each chunk:\n  - It checks `id` and processes accordingly.\n  - It uses `delete[] chunk.p` after processing, which is correct to avoid memory leaks.\n  - It validates chunk types and content (e.g., `kId_acTL`, `kId_fcTL`, `kId_IDAT`, `kId_fdAT`).\n  - It checks for invalid values: `dop > 2`, `bop > 1`, `x0 + w0 > w`, etc. \u2014 all of which are bounds checks to prevent out-of-bounds access.\n\n---\n\n### Step 5: Potential Vulnerability: Integer Overflow in `imagesize`\n- The calculation:\n  ```cpp\n  rowbytes = w * 4;\n  imagesize = h * rowbytes;\n  ```\n  This could overflow if `w` and `h` are large, even if they are individually under `cMaxPNGSize`. For example, if `w = 100000` and `h = 100000`, even though each is under `cMaxPNGSize`, their product could overflow `size_t` or `int` (depending on type), leading to a small `imagesize` and subsequent buffer overflow.\n\n- However, the code **does** check:\n  ```cpp\n  if (w > cMaxPNGSize || h > cMaxPNGSize) {\n    return false;\n  }\n  ```\n  So if `cMaxPNGSize` is set to a value like 65535, then `w * 4` is at most `262140`, and `imagesize = h * rowbytes` is at most `65535 * 262140 \u2248 17.1 GB`, which is **not** safe for `int` or even `size_t` on 32-bit systems.\n\n- But wait: `imagesize` is used in `new unsigned char[imagesize]`. If `imagesize` overflows (e.g., becomes negative or small), then `new` will allocate a tiny buffer, but the code still tries to write `h * rowbytes` bytes into it \u2014 **this leads to a buffer overflow**.\n\n- **Critical issue**: The code does **not** check for integer overflow in `rowbytes` or `imagesize` before allocation. Even though `w` and `h` are bounded, the product `w * 4 * h` could still overflow `size_t` if `cMaxPNGSize` is too large or if `size_t` is 32-bit.\n\n- Example: On 32-bit systems, `size_t` is 32 bits. The maximum value is ~4.3 billion. If `w = 100000`, `h = 100000`, then `imagesize = 40000000000`, which overflows `size_t` \u2192 becomes a small number \u2192 `new` allocates a small buffer \u2192 later writes 40 billion bytes \u2192 **buffer overflow**.\n\n---\n\n### Step 6: Use of `png_get_uint_32` and `png_get_uint_16`\n- The code uses `png_get_uint_32` and `png_get_uint_16` to read values from chunks. These are safe as long as the input is valid, and the code checks that `chunk.size` is sufficient before reading.\n\n---\n\n### Step 7: Memory Leak and Double-Free?\n- The code deletes `chunk.p` after processing each chunk, and `chunkIHDR.p` at the end.\n- `chunksInfo` is a vector of `CHUNK`, and the code deletes each `chunk.p` in the loop and then clears the vector.\n- No memory leaks are apparent.\n\n---\n\n### Step 8: Use of `JXL_ASSERT(chunk.p != nullptr)` \u2014 Not a Vulnerability\n- This is an assertion, not a runtime check. It's fine for debugging, but not a security issue.\n\n---\n\n### Step 9: Final Check: `errorstate`\n- The function sets `errorstate = true` initially.\n- If the loop completes without breaking (i.e., `r.Eof()` and `id == kId_IEND`), it sets `errorstate = false`.\n- Only if `errorstate` remains `true` does it return `false`.\n\nThis is correct.\n\n---\n\n### Conclusion: Critical Security Vulnerability\n- The code **does not check for integer overflow** when computing `rowbytes = w * 4` and `imagesize = h * rowbytes`.\n- Even though `w` and `h` are bounded by `cMaxPNGSize`, the product `w * 4 * h` can still overflow `size_t` (especially on 32-bit systems), leading to:\n  - Allocation of a small buffer.\n  - Writing large amounts of data into it \u2192 **buffer overflow**.\n- This is a classic **integer overflow vulnerability** that can lead to memory corruption, crashes, or arbitrary code execution.\n\n---\n\n(1) YES: A security vulnerability detected."}
{"idx": 391627, "project": "linux", "commit_id": "cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "commit_message": "PCI: rpadlpar: Fix potential drc_name corruption in store functions\n\nBoth add_slot_store() and remove_slot_store() try to fix up the\ndrc_name copied from the store buffer by placing a NUL terminator at\nnbyte + 1 or in place of a '\\n' if present. However, the static buffer\nthat we copy the drc_name data into is not zeroed and can contain\nanything past the n-th byte.\n\nThis is problematic if a '\\n' byte appears in that buffer after nbytes\nand the string copied into the store buffer was not NUL terminated to\nstart with as the strchr() search for a '\\n' byte will mark this\nincorrectly as the end of the drc_name string resulting in a drc_name\nstring that contains garbage data after the n-th byte.\n\nAdditionally it will cause us to overwrite that '\\n' byte on the stack\nwith NUL, potentially corrupting data on the stack.\n\nThe following debugging shows an example of the drmgr utility writing\n\"PHB 4543\" to the add_slot sysfs attribute, but add_slot_store()\nlogging a corrupted string value.\n\n  drmgr: drmgr: -c phb -a -s PHB 4543 -d 1\n  add_slot_store: drc_name = PHB 4543\u00b0|<82>!, rc = -19\n\nFix this by using strscpy() instead of memcpy() to ensure the string\nis NUL terminated when copied into the static drc_name buffer.\nFurther, since the string is now NUL terminated the code only needs to\nchange '\\n' to '\\0' when present.\n\nCc: stable@vger.kernel.org\nSigned-off-by: Tyrel Datwyler <tyreld@linux.ibm.com>\n[mpe: Reformat change log and add mention of possible stack corruption]\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/r/20210315214821.452959-1-tyreld@linux.ibm.com", "ground_truth": 0, "cwe": ["CWE-120"], "cve": "CVE-2021-28972", "cve_desc": "In drivers/pci/hotplug/rpadlpar_sysfs.c in the Linux kernel through 5.11.8, the RPA PCI Hotplug driver has a user-tolerable buffer overflow when writing a new device name to the driver from userspace, allowing userspace to write data to the kernel stack frame directly. This occurs because add_slot_store and remove_slot_store mishandle drc_name '\\0' termination, aka CID-cc7a0bb058b8.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `remove_slot_store` is a sysfs attribute store function, typically called when writing to a sysfs file to perform some operation (in this case, removing a DRC slot).\n\n2. It declares a local buffer `drc_name` of size `MAX_DRC_NAME_LEN`, which is presumably a fixed maximum length for DRC (Dynamic Reconfiguration Connector) names.\n\n3. The function first checks if `nbytes >= MAX_DRC_NAME_LEN`. If so, it returns 0 immediately. This is a good defensive check to prevent buffer overflow.\n\n4. Then it uses `strscpy(drc_name, buf, nbytes + 1)`. The `strscpy` function is a safe string copy that copies at most `nbytes + 1` characters (including null terminator), and ensures the destination is null-terminated. This prevents buffer overflow because it limits the copy to `nbytes + 1`, and since `nbytes < MAX_DRC_NAME_LEN` (due to the earlier check), the copy will not exceed the buffer size.\n\n5. It then looks for a newline character (`\\n`) in the copied string and null-terminates it if found. This is a common practice to clean up input from sysfs (which may include a newline from the user's write).\n\n6. The resulting `drc_name` is passed to `dlpar_remove_slot(drc_name)`, which presumably performs the actual DRC slot removal.\n\n7. The function returns `nbytes` on success, or the error code from `dlpar_remove_slot` if it fails.\n\n8. Key security considerations:\n   - The input is bounded by `nbytes < MAX_DRC_NAME_LEN`, and `strscpy` ensures no overflow.\n   - The string is properly null-terminated.\n   - No unsafe string operations (like `strcpy`, `strcat`) are used.\n   - The function does not perform any dangerous operations on the string beyond sanitizing the newline and passing it to a system call.\n\n9. The only potential concern would be if `dlpar_remove_slot` itself performs unsafe operations or if `drc_name` is used in a way that could lead to path traversal or command injection. However, based on the code provided, `drc_name` is passed directly to a kernel function that likely validates the DRC name internally.\n\n10. Since the input is properly bounded and sanitized, and no unsafe operations are performed, there is no buffer overflow or injection vulnerability in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 443298, "project": "vim", "commit_id": "35d21c6830fc2d68aca838424a0e786821c5891c", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/35d21c6830fc2d68aca838424a0e786821c5891c", "commit_message": "patch 9.0.0360: crash when invalid line number on :for is ignored\n\nProblem:    Crash when invalid line number on :for is ignored.\nSolution:   Do not check breakpoint for non-existing line.", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-3099", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0360.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `do_cmdline` is part of the Vim editor's internal command execution system. It is responsible for:\n- Parsing and executing a sequence of Vim commands (e.g., from a script, function, or user input).\n- Handling control structures like `:if`, `:while`, `:for`, `:try`, `:finally`, etc.\n- Supporting debugging, error handling, recursion, and command repetition.\n- Managing command-line input via a callback function (`fgetline`) and cookie data.\n\nThis is a core, low-level function in Vim that processes user or script-provided commands. It is not directly exposed to untrusted input in the same way as a web server, but it does process command strings that may originate from user input or scripts.\n\n---\n\n### Step 2: Identify potential security concerns\n\nWe must look for:\n- Buffer overflows\n- Use of unsafe string operations\n- Improper input validation\n- Use of user-controlled data in dangerous contexts (e.g., command execution, memory access)\n- Memory safety issues (e.g., use-after-free, null pointer dereference)\n- Code injection or execution of arbitrary commands\n\nLet\u2019s examine key aspects:\n\n#### A. Input handling: `cmdline`, `fgetline`, `cookie`\n\n- `cmdline` is a `char_u*` (unsigned char pointer) representing the command line.\n- `fgetline` is a function pointer used to retrieve the next command line (e.g., from a file or script).\n- `cookie` is a void pointer passed to `fgetline` for context.\n\nThese are used to read and process command lines. The function uses `vim_strsave()` to copy strings, which is safe (allocates new memory and copies the string).\n\n#### B. String manipulation and copying\n\n- `vim_strsave()` is used to copy `next_cmdline` into `cmdline_copy`. This is safe and prevents buffer overflows.\n- `STRMOVE(cmdline_copy, next_cmdline)` is used to move the remainder of a command after a `|`. This is safe because `cmdline_copy` is allocated with sufficient space (via `vim_strsave`), and `STRMOVE` is a macro that copies bytes safely up to the null terminator.\n\nNo use of `strcpy`, `strcat`, `gets`, or other unsafe functions.\n\n#### C. Memory management\n\n- `vim_free()` is used to free `cmdline_copy` and other allocated buffers.\n- `ga_init2(&lines_ga, sizeof(wcmd_T), 10)` initializes a growable array (`garray_T`) safely.\n- `free_cmdlines(&lines_ga)` and `ga_clear(&lines_ga)` are used to clean up.\n- All memory allocations are done via Vim\u2019s safe wrappers (`vim_strsave`, `ga_init2`, etc.).\n\nNo memory leaks or use-after-free issues are apparent.\n\n#### D. Command execution\n\n- The function calls `do_one_cmd()` to execute individual commands.\n- `do_one_cmd()` is responsible for parsing and executing the command.\n- The command is not directly passed to `system()` or `exec()` \u2014 it is processed by Vim\u2019s internal command parser.\n\nThis means that **command injection is not possible** unless `do_one_cmd()` itself has vulnerabilities. But we are analyzing `do_cmdline`, not `do_one_cmd`.\n\n#### E. Recursive depth protection\n\n- The function checks `call_depth >= 200` (or `p_mfd`) to prevent infinite recursion.\n- This is a good defense against stack overflow via recursive command execution.\n\n#### F. Use of `fgetline` and `cookie`\n\n- The `fgetline` function is passed from the caller and used to read lines.\n- The `cookie` is used to maintain state (e.g., function/script context).\n- The code checks `getline_equal(fgetline, cookie, ...)` to determine context (e.g., function vs script).\n- This is safe as long as `fgetline` is not maliciously crafted.\n\nBut: **Is there any risk of arbitrary code execution via `fgetline`?**\n\nNo \u2014 `fgetline` is a callback that returns a string. The function `do_cmdline` only uses it to read command lines. It does not execute the returned string directly. The string is passed to `do_one_cmd`, which parses it.\n\nSo, even if `fgetline` returned a malicious string, it would be parsed as a Vim command, not executed as code.\n\n#### G. Debugging and exception handling\n\n- The code handles `:try`, `:catch`, `:finally`, `:breakpoint`, etc.\n- It uses `do_errthrow()` and `do_intthrow()` to handle exceptions.\n- These are internal mechanisms and do not expose unsafe behavior.\n\n#### H. No use of unsafe functions\n\n- No `sprintf`, `vsprintf`, `strcpy`, `strcat`, `gets`, `scanf`, etc.\n- All string operations use safe wrappers (`vim_strsave`, `STRMOVE`, `ga_*` functions).\n\n---\n\n### Step 3: Conclusion\n\nAfter a thorough analysis:\n\n- The function does not perform any unsafe string operations.\n- It uses safe memory allocation and deallocation.\n- It validates input and prevents infinite recursion.\n- It does not directly execute user input as code.\n- It processes commands through a safe internal parser (`do_one_cmd`).\n- There are no known buffer overflows, use-after-free, or code injection vectors.\n\nWhile the function is complex and handles many edge cases (e.g., nested loops, debugging), all operations are within safe bounds and use proper safety mechanisms.\n\n---\n\n### Final Answer:\n\n(2) NO: No security vulnerability."}
{"idx": 345131, "project": "linux", "commit_id": "a09d2d00af53b43c6f11e6ab3cb58443c2cac8a7", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/a09d2d00af53b43c6f11e6ab3cb58443c2cac8a7", "commit_message": "video: fbdev: pxa3xx-gcu: Fix integer overflow in pxa3xx_gcu_write\n\nIn pxa3xx_gcu_write, a count parameter of type size_t is passed to words of\ntype int.  Then, copy_from_user() may cause a heap overflow because it is used\nas the third argument of copy_from_user().\n\nSigned-off-by: Hyunwoo Kim <imv4bel@gmail.com>\nSigned-off-by: Helge Deller <deller@gmx.de>", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-39842", "cve_desc": "An issue was discovered in the Linux kernel before 5.19. In pxa3xx_gcu_write in drivers/video/fbdev/pxa3xx-gcu.c, the count parameter has a type conflict of size_t versus int, causing an integer overflow and bypassing the size check. After that, because it is used as the third argument to copy_from_user(), a heap overflow may occur. NOTE: the original discoverer disputes that the overflow can actually happen.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `pxa3xx_gcu_write` is a kernel-level write handler for a device driver, likely for a graphics processing unit (GCU) on an ARM-based PXA3xx processor.\n\n2. The function receives user data via `buff` (from user space), and copies it into a kernel buffer (`buffer->ptr`) using `copy_from_user()`. This is a standard pattern for kernel drivers handling user input.\n\n3. The size of the data is determined by `count`, and the number of 4-byte words is calculated as `words = count / 4`. This assumes that the input is aligned to 4-byte boundaries.\n\n4. The function checks if `words >= PXA3XX_GCU_BATCH_WORDS`, and returns `-E2BIG` if so. This prevents buffer overflow in the batch buffer by limiting the number of words.\n\n5. The function uses a free list of pre-allocated buffers (`priv->free`) to manage memory. It acquires a spinlock to safely remove a buffer from the free list.\n\n6. It then copies data from user space to the buffer using `copy_from_user()`, which is safe as long as the size is properly bounded. The size used is `words * 4`, which is derived from `count / 4`, so it's consistent.\n\n7. After copying, it sets `buffer->length = words`, and appends a batch end command (`0x01000000`) at index `words` (i.e., the next word after the data).\n\n8. The buffer is then added to the `ready` list, and if the hardware is not running, it triggers `run_ready(priv)`.\n\n9. Critical points to consider:\n   - The `words` calculation is based on `count / 4`, which truncates any remainder. This means if `count` is not a multiple of 4, the last partial word is ignored. This is acceptable if the protocol expects 4-byte alignment, but could be a logic issue if not handled properly.\n   - However, the function checks `words >= PXA3XX_GCU_BATCH_WORDS` before proceeding, so even if `count` is large, it's capped.\n   - The `copy_from_user` call uses `words * 4` as the size, which is safe because `words` is derived from `count / 4`, and the upper bound is enforced.\n   - The buffer is allocated in advance (presumably via `kmalloc` or similar), and the driver manages a pool of such buffers. The `priv->free` list ensures only valid buffers are used.\n   - The `BUG_ON(priv->ready_last == NULL)` check ensures the list is properly maintained, but only when `priv->ready` is non-null. This is safe because `priv->ready_last` is only updated when `priv->ready` is set.\n   - The `buffer->ptr[words] = 0x01000000` writes to the word immediately after the copied data. Since `words` is the number of 4-byte words copied, and the buffer is sized to hold `PXA3XX_GCU_BATCH_WORDS` words, this write is within bounds due to the earlier check.\n\n10. No buffer overflow occurs because:\n   - The maximum number of words is limited by `PXA3XX_GCU_BATCH_WORDS`.\n   - The `copy_from_user` size is `words * 4`, which is exactly the amount of data to copy.\n   - The end command is written at index `words`, which is one beyond the copied data, but still within the buffer since `words < PXA3XX_GCU_BATCH_WORDS`.\n\n11. The function does not perform any input validation on the content of `buff` beyond size, but since it's copying raw data (likely GPU commands), and the size is bounded, this is acceptable.\n\n12. No use of unsafe string functions, no format string vulnerabilities, no memory corruption via unchecked indexing.\n\nConclusion: The code correctly bounds the input size, safely copies user data using `copy_from_user`, and manages buffer lists with proper locking. All operations are within safe limits, and no buffer overflow or memory corruption is possible under normal operation.\n\n(2) NO: No security vulnerability."}
{"idx": 224153, "project": "tensorflow", "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b", "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1", "ground_truth": 0, "cwe": ["CWE-908"], "cve": "CVE-2022-23573", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of an OpKernel implementation (likely in TensorFlow) that performs an assignment operation (AssignOp), where the right-hand side tensor is assigned to the left-hand side tensor.\n\n2) The function starts by getting the right-hand side tensor and forwarding the reference input to the output (preserving the reference).\n\n3) It checks that the right-hand side tensor is initialized using OP_REQUIRES, which is a proper safety check.\n\n4) Memory allocation attributes are set conservatively unless relax_constraints_ is true, which is a reasonable design choice for safety.\n\n5) The code uses a mutex_lock on the input reference mutex to ensure thread safety when accessing the left-hand side tensor.\n\n6) It checks if the shapes match (with optional validation), and if not, returns an error. This prevents shape mismatches that could lead to memory corruption.\n\n7) The code implements two optimization strategies:\n   - Reusing the existing lhs buffer if it's initialized and has the same number of elements\n   - Reusing the rhs buffer if possible via forward_input\n\n8) When reusing the rhs buffer, it uses context->forward_input which is a safe mechanism for transferring ownership of tensor buffers.\n\n9) When creating a new tensor, it uses context->allocate_temp with proper attributes and then replaces the input reference.\n\n10) The code carefully handles memory management, including clearing recorded memory and using proper locking mechanisms.\n\n11) All operations are performed with proper error checking using OP_REQUIRES_OK and OP_REQUIRES.\n\n12) The only potential concern is the use of Copy() outside the lock in the final block, but this is explicitly documented as \"we have been told to do the copy outside the lock\" and is consistent with the design.\n\n13) There are no buffer overflows, use-after-free, null pointer dereferences, or other classic memory safety issues.\n\n14) The code follows TensorFlow's best practices for tensor assignment operations, including proper locking, shape validation, and memory management.\n\n(2) NO: No security vulnerability."}
{"idx": 252437, "project": "tinyexr", "commit_id": "a685e3332f61cd4e59324bf3f669d36973d64270", "project_url": "https://github.com/syoyo/tinyexr", "commit_url": "https://github.com/syoyo/tinyexr/commit/a685e3332f61cd4e59324bf3f669d36973d64270", "commit_message": "Make line_no with too large value(2**20) invalid. Fixes #124", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2020-19490", "cve_desc": "tinyexr 0.9.5 has a integer overflow over-write in tinyexr::DecodePixelData in tinyexr.h, related to OpenEXR code.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Bounds Checking\n\nThe function `DecodeChunk` processes EXR image data from a buffer (`head`) of size `size`, using offsets from a vector `offsets`. It decodes either tiled or scanline-based EXR data.\n\n- **Offset validation**: The code checks whether `offsets[tile_idx] + sizeof(int)*5 > size` before accessing data. This prevents reading beyond the buffer.\n- Similarly, in the scanline branch: `offsets[y_idx] + sizeof(int)*2 > size` is checked.\n- These checks are **correct and sufficient** to prevent out-of-bounds reads.\n\n---\n\n### Step 2: Data Length Validation\n\n- In the **tiled** case:\n  - `data_len` is read from the buffer and validated: `data_len < 4 || size_t(data_len) > data_size`.\n  - `data_size` is computed as `size - (offset + 20)`, so `data_len` must be within bounds.\n  - This prevents reading more data than available.\n\n- In the **scanline** case:\n  - `data_len` is similarly checked: `size_t(data_len) > data_size` \u2192 invalid.\n  - Also, `data_len == 0` triggers `invalid_data = true`, which is safe.\n  - `line_no` is checked for extreme values (`> 2^21` or `< -2^21`), which is a heuristic to catch malformed or malicious data.\n\nThese checks are **robust** against buffer over-reads.\n\n---\n\n### Step 3: Integer Overflow and Underflow Protection\n\n- `data_width` and `data_height` are computed from `data_window`, and checked for negative values.\n- A threshold (`1024 * 8192`) is used to prevent excessively large images.\n- In the scanline case, `total_data_len = data_width * data_height * num_channels` is computed, and:\n  - If `total_data_len == 0` \u2192 invalid.\n  - If `total_data_len_overflown` (based on `sizeof(void*) == 8`, i.e., 64-bit), and `total_data_len >= 0x4000000000` (~256 GB), it's rejected.\n\nThis is a **good mitigation** against integer overflow and denial-of-service via large image sizes.\n\nNote: The check `total_data_len_overflown` uses a heuristic based on 64-bit pointer size. While not perfect (e.g., could overflow even below 256GB on 64-bit), it's a reasonable defense-in-depth measure.\n\n---\n\n### Step 4: Memory Allocation and Use\n\n- `calloc` is used for `exr_image->tiles`, and `AllocateImage` is used for tile images.\n- `AllocateImage` is assumed to be safe (not shown, but typically bounds-checked).\n- No use of unsafe functions like `strcpy`, `sprintf`, or direct buffer copying without size checks.\n\n---\n\n### Step 5: Endianness and Data Parsing\n\n- `tinyexr::swap4` is used to handle byte order for `tile_coordinates` and `data_len`. This is correct and prevents issues with cross-platform data.\n\n---\n\n### Step 6: Parallel Processing (`#pragma omp`)\n\n- The scanline loop uses OpenMP for parallelization.\n- Each thread operates on a separate `y` index, and `offsets[y_idx]` is accessed safely.\n- No shared state is modified without synchronization (e.g., `invalid_data` is a boolean, but it's only set to `true` \u2014 not read or written in a race condition).\n- However, `invalid_data` is **not atomic**, and multiple threads may write to it simultaneously. This could lead to **race condition** in setting `invalid_data = true`.\n\nBut: The function only checks `invalid_data` at the end and returns an error. Even if multiple threads set it, the result is the same: error is returned. So **this race condition does not lead to a security vulnerability** (no memory corruption, no arbitrary code execution, no buffer overflow). It's a **race condition in error reporting**, not a security flaw.\n\n---\n\n### Step 7: Potential for Integer Overflow in `total_data_len`\n\n- `total_data_len = data_width * data_height * num_channels`\n- All are `int` or `size_t`. On 64-bit systems, `size_t` is 64-bit, so multiplication of large values could overflow `size_t` if not checked.\n\nBut: The code checks `total_data_len_overflown` using:\n```cpp\nconst bool total_data_len_overflown = sizeof(void*) == 8 ? (total_data_len >= 0x4000000000) : false;\n```\nThis is **not a full overflow check** \u2014 it only checks if the value exceeds 256 GB. However, `total_data_len` is computed as `size_t(data_width) * size_t(data_height) * size_t(num_channels)`, and `size_t` is unsigned. So **if the multiplication overflows, it wraps around**, and the check `>= 0x4000000000` may not catch it.\n\nFor example:\n- `data_width = 1000000`, `data_height = 1000000`, `num_channels = 1000` \u2192 `1e15`, which is > 256 GB \u2192 caught.\n- But if `data_width = 1000000`, `data_height = 1000000`, `num_channels = 1000000` \u2192 `1e18`, which overflows `size_t` on 64-bit (max ~1.8e19), so it might wrap to a small number \u2192 **not caught**.\n\nSo: **There is a potential integer overflow in `total_data_len` that could be exploited to bypass the size check**.\n\nThis is a **security vulnerability** because:\n- An attacker could craft an EXR file with extremely large `data_width`, `data_height`, or `num_channels` such that the multiplication overflows `size_t` and wraps to a small value.\n- The code would then proceed to allocate memory based on that small value, but later use the actual large value in `DecodePixelData`, leading to **buffer overflow or memory corruption**.\n\nEven though `AllocateImage` may do its own bounds checks, the `total_data_len` check is **not sufficient** to prevent overflow.\n\n---\n\n### Step 8: Final Check\n\n- The code does **not** use unsafe functions like `strcpy`, `gets`, or `memcpy` without size checks.\n- All buffer accesses are bounded by `offset + size` checks.\n- However, the **integer overflow in `total_data_len`** is a **critical flaw** that can be exploited to bypass size validation.\n\n---\n\n### Conclusion\n\nDespite strong input validation, the **lack of proper overflow detection in `total_data_len` computation** creates a **security vulnerability** that could allow an attacker to bypass size checks and cause memory corruption.\n\n(1) YES: A security vulnerability detected."}
{"idx": 231710, "project": "mvfst", "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0", "project_url": "https://github.com/facebookincubator/mvfst", "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0", "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2021-24029", "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `updateHandshakeState` is responsible for updating the cryptographic state of a QUIC server connection during the handshake process. It retrieves various ciphers (0-RTT, 1-RTT, handshake) from the `handshakeLayer` and assigns them to the connection's codec and state.\n\n2) The code checks for the existence of each cipher before using it:\n   - `if (zeroRttReadCipher)` - checks if 0-RTT read cipher exists\n   - `if (oneRttWriteCipher)` - checks if 1-RTT write cipher exists\n   - `if (oneRttReadCipher)` - checks if 1-RTT read cipher exists\n   - `if (handshakeReadCipher)` - checks if handshake read cipher exists\n\n3) For the 1-RTT write cipher, there's an additional safety check:\n   - `if (conn.oneRttWriteCipher)` - throws an exception if a 1-RTT write cipher already exists, preventing duplication.\n\n4) The code properly uses `std::move` when transferring cipher ownership, which is correct for move semantics.\n\n5) The function also handles logging and tracing via `conn.qLogger` and `QUIC_TRACE`, which is non-security related but useful for debugging.\n\n6) The code checks `handshakeLayer->isHandshakeDone()` and sends a HandshakeDone frame if appropriate, with a check to ensure the 1-RTT write cipher is available.\n\n7) All cipher assignments are protected by null checks, and the code uses `CHECK` assertions for internal consistency (e.g., `CHECK(handshakeReadHeaderCipher)`), which ensures that if the handshake read cipher exists, the header cipher must also exist.\n\n8) There are no obvious buffer overflows, use-after-free, or memory corruption issues.\n\n9) The code does not perform any untrusted input parsing that could lead to injection or overflow vulnerabilities.\n\n10) The cryptographic state transitions are properly sequenced and validated, with checks to prevent reuse of ciphers and ensure correct handshake progression.\n\n11) The use of `folly::none` for `writableBytesLimit` is appropriate and safe.\n\nAfter thorough analysis, there are no security vulnerabilities in the code. The cryptographic state updates are properly guarded, null checks are in place, and duplicate cipher assignment is prevented.\n\n(2) NO: No security vulnerability."}
{"idx": 232287, "project": "libjpeg", "commit_id": "4746b577931e926a49e50de9720a4946de3069a7", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7", "commit_message": "Fixed handling of empty JPEG-LS scans.", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-32978", "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `ParseMCU` processes data from a stream (`m_Stream.ByteStreamOf()`), which is likely derived from user-controlled input (e.g., a JPEG-like compressed image stream).\n   - The function uses `m_ulWidth[0]` and `m_ulRemaining[0]` to control loop iterations. These values are derived from the frame header (`m_pFrame->HeightOf()` and `m_ulRemaining[0]`), which are part of the input stream.\n   - There is no explicit validation of `m_ulWidth[0]` or `m_ulRemaining[0]` to ensure they are within safe bounds (e.g., not excessively large). However, the code does cap `lines` to 8, and `length` is derived from `m_ulWidth[0]`, which is used in a `do-while` loop: `do { ... } while(++lp, --length);`.\n   - The loop uses `lp` (a pointer to `line->m_pData`) and increments it with `*lp++ = ...`. If `length` is very large (e.g., due to malformed input), this could lead to a buffer overflow if `m_pData` is not large enough to hold `length` values.\n\n2. **Buffer Overflow Risk**:\n   - The `line->m_pData` buffer is assumed to be allocated based on `m_ulWidth[0]`, but there is no explicit check that `m_ulWidth[0]` is valid or that `m_pData` is large enough to hold `length` elements.\n   - The loop runs `length` times, and each iteration writes one value to `*lp++`. If `length` is larger than the actual allocated size of `m_pData`, this will result in a buffer overflow.\n   - Although `m_ulWidth[0]` is used to initialize `length`, there is no validation that this value is reasonable (e.g., not 0xFFFFFFFF or similar). This is a classic example of an integer overflow or underflow vulnerability if the input is crafted maliciously.\n\n3. **Error Handling and Recovery**:\n   - The function calls `BeginReadMCU(m_Stream.ByteStreamOf())` without any error handling. If the stream is malformed or ends prematurely, this could lead to undefined behavior.\n   - The `GolombDecode` and `InverseErrorMapping` functions are called with parameters derived from the stream, but there is no validation that the decoded values are within expected ranges.\n   - The `SkipStuffing()` call is made unconditionally, which may be safe, but if the stream is corrupted, it could lead to unexpected behavior.\n\n4. **Use of `assert`**:\n   - The code uses `assert(m_ucCount == 1);` and `assert(lines == 0);` \u2014 these are only active in debug builds and do not provide runtime protection. An attacker could exploit this by providing malformed input that bypasses these checks.\n\n5. **No Input Sanitization**:\n   - The function directly uses values from the stream (`m_ulWidth[0]`, `m_ulRemaining[0]`, etc.) without validating them against expected ranges or limits. This is a common source of vulnerabilities in parsers.\n\n6. **Conclusion**:\n   - The code lacks proper bounds checking on user-controlled data (`m_ulWidth[0]`, `m_ulRemaining[0]`), which could be manipulated to cause a buffer overflow when writing to `line->m_pData`.\n   - The loop `do { ... } while(++lp, --length);` will continue until `length` reaches zero, but if `length` is too large (due to invalid input), it will write beyond the allocated buffer.\n   - This is a classic case of a **buffer overflow vulnerability** due to improper input validation and lack of bounds checking.\n\n(1) YES: A security vulnerability detected."}
{"idx": 273407, "project": "tensorflow", "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a", "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-29200", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a kernel implementation (likely for a machine learning framework like TensorFlow) that computes an LSTM (Long Short-Term Memory) block cell forward pass.\n\n2) The function takes multiple input tensors: x (input), cs_prev (previous cell state), h_prev (previous hidden state), weight matrices (w, wci, wcf, wco), and bias (b).\n\n3) The code performs extensive input validation:\n   - Checks for null pointers using OP_REQUIRES_OK\n   - Validates tensor dimensions against expected shapes\n   - Ensures tensor ranks are correct (all tensors are validated to be rank 2 except wci, wcf, wco which are rank 1)\n   - Performs bounds checking on dimensions (e.g., w_tensor must have dim_size(0) == input_size + cell_size)\n   - Uses proper tensor allocation with size validation\n\n4) The code uses the framework's built-in safety mechanisms:\n   - OP_REQUIRES_OK and OP_REQUIRES macros handle error checking\n   - TensorShape is used to ensure proper allocation\n   - allocate_temp and allocate_output are used with validated shapes\n   - The functor is called with properly validated and typed data\n\n5) There are no direct memory operations like strcpy, memcpy, or manual buffer management that could lead to buffer overflows.\n\n6) The code does not perform any string manipulation, file I/O, or system calls that could be exploited.\n\n7) All tensor accesses are through safe wrapper methods (matrix<T>(), vec<T>()) that are part of the framework's tensor interface and include bounds checking.\n\n8) The input validation is comprehensive and covers all dimensions and ranks, preventing out-of-bounds access.\n\n9) The code follows the framework's best practices for kernel implementation with proper error handling and resource management.\n\n(2) NO: No security vulnerability."}
{"idx": 387149, "project": "ImageMagick", "commit_id": "c111ed9b035532c2c81ea569f2d22fded9517287", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/c111ed9b035532c2c81ea569f2d22fded9517287", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1540", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2019-11598", "cve_desc": "In ImageMagick 7.0.8-40 Q16, there is a heap-based buffer over-read in the function WritePNMImage of coders/pnm.c, which allows an attacker to cause a denial of service or possibly information disclosure via a crafted image file. This is related to SetGrayscaleImage in MagickCore/quantize.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Function Purpose and Context**:\n   - The function `SetGrayscaleImage` is part of the ImageMagick library, responsible for converting an image to grayscale.\n   - It handles both direct pixel data (TrueColor) and indexed color images (PseudoClass).\n   - It uses `AcquireQuantumMemory` and `RelinquishMagickMemory` for dynamic memory allocation and deallocation, which are safe if used correctly.\n\n2. **Memory Allocation and Bounds Checking**:\n   - The function allocates memory for `colormap_index` using `AcquireQuantumMemory` with size `MagickMax(image->colors+1, MaxMap)` or `MagickMax(MaxColormapSize+1, MaxMap)`. This ensures the array is large enough for the maximum possible colormap size.\n   - `MaxColormapSize` is a defined constant (typically 256 or 65536), and `MaxMap` is also a known safe limit.\n   - The use of `AcquireQuantumMemory` is safe because it checks for overflow and returns NULL on failure, which is properly handled with `ThrowBinaryException`.\n\n3. **Index Usage and Bounds**:\n   - The `colormap_index` array is indexed using `intensity = ScaleQuantumToMap(GetPixelRed(image,q))`.\n   - `ScaleQuantumToMap` maps a Quantum (typically 0\u201365535) to a map index (0\u2013MaxMap-1). This is a safe scaling operation, and the result is guaranteed to be within bounds because `MaxMap` is defined and `ScaleQuantumToMap` is designed to clamp values.\n   - Later, `colormap_index[(ssize_t) image->colormap[i].alpha]` is used, but `image->colormap[i].alpha` is a double that is set to `i` (an integer from 0 to `image->colors-1`), and `image->colors` is limited by `MaxColormapSize`. So the index is within bounds.\n\n4. **Race Condition and Thread Safety**:\n   - The code uses OpenMP with `#pragma omp critical (MagickCore_SetGrayscaleImage)` when updating `colormap_index[intensity]` and `image->colormap[image->colors]`.\n   - This critical section ensures that only one thread can update the colormap at a time, preventing race conditions during colormap construction.\n   - This is a correct use of OpenMP critical sections to protect shared state.\n\n5. **Memory Management**:\n   - All dynamically allocated memory (`colormap_index`, `colormap`) is properly freed using `RelinquishMagickMemory` when no longer needed.\n   - The function checks for NULL returns from memory allocation and throws appropriate exceptions, preventing use-after-free or memory leaks.\n\n6. **Image Type and Colorspace Conversion**:\n   - The function checks `image->type != GrayscaleType` and calls `TransformImageColorspace` if needed. This is safe and correct.\n   - The final `SetImageMonochrome` call is used to detect if the image is monochrome, which is a valid and safe operation.\n\n7. **No User Input Directly**:\n   - The function operates on internal image data structures, not on user-provided strings or raw input. There is no direct string concatenation, format string usage, or untrusted data injection.\n   - All data comes from the image itself, which is assumed to be validated earlier in the pipeline.\n\n8. **No Buffer Overflows or Integer Overflows**:\n   - All array accesses are bounded by `MaxColormapSize`, `MaxMap`, or `image->colors`, which are controlled and limited.\n   - The use of `ssize_t` and `size_t` is consistent with ImageMagick\u2019s safe practices.\n\nConclusion: The code uses safe memory allocation, proper bounds checking, thread-safe critical sections, and correct data handling. There are no known vulnerabilities such as buffer overflows, use-after-free, race conditions, or injection flaws.\n\n(2) NO: No security vulnerability."}
{"idx": 281662, "project": "LibRaw", "commit_id": "4606c28f494a750892c5c1ac7903e62dd1c6fdb5", "project_url": "https://github.com/LibRaw/LibRaw", "commit_url": "https://github.com/LibRaw/LibRaw/commit/4606c28f494a750892c5c1ac7903e62dd1c6fdb5", "commit_message": "0.16.1: fix for dcraw ljpeg_start() vulnerability", "ground_truth": 0, "cwe": ["CWE-189"], "cve": "CVE-2015-3885", "cve_desc": "Integer overflow in the ljpeg_start function in dcraw 7.00 and earlier allows remote attackers to cause a denial of service (crash) via a crafted image, which triggers a buffer overflow, related to the len variable.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `ljpeg_start` is designed to parse JPEG headers, specifically looking for markers like 0xFFC0 (SOF0), 0xFFC3 (SOF3), 0xFFC4 (DHT), 0xFFDA (SOS), and 0xFFDD (DRI).\n\n2. A fixed-size buffer `data[0x10000]` (65,536 bytes) is declared. This is large but within reasonable limits for a JPEG header parser, as JPEG headers are typically small. However, the size is not validated against the actual data being read.\n\n3. The code reads data from a file stream (`ifp`) using `fread`:\n   - First, it reads 2 bytes: `fread(data, 2, 1, ifp)` \u2014 this is likely to read the SOI marker (0xFFD8).\n   - Then, it reads 4 bytes: `fread(data, 2, 2, ifp)` \u2014 this reads the marker (2 bytes) and length (2 bytes).\n   - Then, it reads `len` bytes: `fread(data, 1, len, ifp)` \u2014 this reads the payload of the marker.\n\n4. The critical point is that `len` is read from the file as `data[2] << 8 | data[3] - 2`. This value is used to determine how many bytes to read next via `fread(data, 1, len, ifp)`.\n\n5. The vulnerability lies here: **There is no validation that `len` is within a safe range before using it to read data into the fixed-size buffer `data`**. The buffer is 65,536 bytes, but `len` is derived from user-controlled input (the JPEG file). If the length field in the JPEG marker is maliciously set to a very large value (e.g., 0xFFFF), then `len` could be up to 65,534 (since it's subtracted by 2), which is still within the buffer size. However, if the length field is corrupted or maliciously set to a value that causes integer overflow or underflow, or if the file is crafted to make `len` larger than the buffer, it could lead to a buffer overflow.\n\n6. But more importantly: **The code uses `fread(data, 1, len, ifp)` without checking if `len` is reasonable or if it exceeds the buffer size**. Even though the buffer is large (64KB), the `len` value is not validated against the buffer size. If `len` is greater than 0xFFFF (65,535), then `len` could be interpreted as a negative number due to signed integer overflow (since `len` is of type `ushort`, which is unsigned, but the subtraction `len = ... - 2` could still be problematic if the original length is 0x0000). However, `ushort` is unsigned, so `len` cannot be negative. But if the length field is 0xFFFF, then `len = 0xFFFF - 2 = 0xFFFD`, which is 65,533 \u2014 still within the 65,536 buffer.\n\n7. However, the real issue is that **the code does not validate the length field against the actual file size or a reasonable maximum**. A malicious JPEG file could have a marker with a length field set to a huge value (e.g., 0xFFFF), which would cause `fread` to attempt to read 65,534 bytes into a 65,536-byte buffer \u2014 which is safe in this case. But if the file is truncated or the length field is malformed, or if the `len` value is used in a way that causes integer overflow in other contexts, it could be dangerous.\n\n8. But here's the key: **The buffer `data` is 65,536 bytes, and `len` is read from the file and used as the number of bytes to read. Since `len` is derived from a 16-bit field (2 bytes), the maximum value is 65,535. Subtracting 2 gives a maximum of 65,533. This is less than the buffer size (65,536), so the read operation `fread(data, 1, len, ifp)` will not overflow the buffer.**\n\n9. However, there is a **critical flaw**: the code reads `len` bytes into `data`, but **does not check if the file has enough data**. If the file is truncated or maliciously crafted to be shorter than `len`, then `fread` will read fewer bytes than expected, but the code still proceeds to use `data` as if it contains `len` bytes. This could lead to **undefined behavior or use of uninitialized memory**, which is a security vulnerability.\n\n10. More importantly, **the code uses `data` as a pointer to access fields like `data[7]`, `data[0]`, etc., without validating that `len` is large enough to access those indices**. For example, in the `case 0xffc3` block:\n    ```c\n    jh->sraw = ((data[7] >> 4) * (data[7] & 15) - 1) & 3;\n    ```\n    This accesses `data[7]`, but if `len < 8`, this would be out of bounds. Similarly, in `case 0xffc0`, it accesses `data[0]` to `data[5]`, and `data[1]` to `data[4]` \u2014 so at least 6 bytes are needed. But `len` could be less than 8, especially if the file is truncated.\n\n11. The code does not check whether `len >= 8` before accessing `data[7]`, nor does it check `len >= 6` for `case 0xffc0`. This is a **classic buffer over-read (out-of-bounds read)** vulnerability.\n\n12. Even though the buffer is large, **the code assumes that `len` bytes are available and that the data is valid**, but it does not validate that `len` is sufficient to access the required indices. This can lead to reading uninitialized or arbitrary memory, which could be exploited in certain contexts (e.g., information disclosure, crash, or side-channel attacks).\n\n13. Additionally, the `fread` call for `len` bytes may not read all `len` bytes if the file is short. The code does not check the return value of `fread`, so it assumes the read succeeded completely. This is a **critical flaw** \u2014 if `fread` returns fewer bytes than requested, the `data` buffer is not fully populated, but the code proceeds to use it as if it were.\n\n14. Therefore, the code has two major issues:\n    - It does not validate that `len` is sufficient to access required indices (e.g., `data[7]`).\n    - It does not check the return value of `fread`, so it may use partially read or uninitialized data.\n\n15. These issues can lead to **undefined behavior, crashes, or information disclosure**, which are security vulnerabilities.\n\n(1) YES: A security vulnerability detected."}
{"idx": 462409, "project": "rsyslog", "commit_id": "0381a0de64a5a048c3d48b79055bd9848d0c7fc2", "project_url": "https://github.com/rsyslog/rsyslog", "commit_url": "https://github.com/rsyslog/rsyslog/commit/0381a0de64a5a048c3d48b79055bd9848d0c7fc2", "commit_message": "imptcp: fix Segmentation Fault when octet count is to high", "ground_truth": 0, "cwe": ["CWE-190"], "cve": "CVE-2018-16881", "cve_desc": "A denial of service vulnerability was found in rsyslog in the imptcp module. An attacker could send a specially crafted message to the imptcp socket, which would cause rsyslog to crash. Versions before 8.27.0 are vulnerable.", "vuln": 0, "reasoning": "Let's analyze the provided C code step-by-step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `processDataRcvd` processes incoming TCP data in a logging or message-processing system (likely part of rsyslog or similar). It handles two framing modes:\n- **Octet counting** (`TCP_FRAMING_OCTET_COUNTING`): A count of bytes is sent before the message.\n- **Octet stuffing** (`TCP_FRAMING_OCTET_STUFFING`): Messages are terminated by a newline or a custom delimiter.\n\nThe function manages state (`inputState`, `eFraming`, `iOctetsRemain`, `iMsg`, etc.) and processes incoming data buffer (`*buff`) of length `buffLen`.\n\n---\n\n### Step 2: Check for buffer overflows\n- The function uses `memcpy(pThis->pMsg + pThis->iMsg, *buff, octatesToCopy)` in the octet-counting mode.\n- It ensures `octatesToCopy` is limited by `iMaxLine - pThis->iMsg`, so the message buffer (`pThis->pMsg`) is not overflowed.\n- Also, `pThis->iMsg` is incremented only by `octatesToCopy`, which is capped at `iMaxLine - pThis->iMsg`, so the message buffer is safely bounded.\n\n\u2705 **No buffer overflow in message buffer**.\n\n---\n\n### Step 3: Check for integer overflow in octet count\nIn the `eInOctetCnt` state:\n```c\nif(pThis->iOctetsRemain <= 200000000) {\n    pThis->iOctetsRemain = pThis->iOctetsRemain * 10 + c - '0';\n} else {\n    // error log and switch to octet stuffing\n}\n```\n- The check `pThis->iOctetsRemain <= 200000000` prevents overflow when multiplying by 10.\n- The maximum value before overflow would be around 2147483647 (INT_MAX), so 200M is a safe threshold.\n- Even if the count is large, it's capped at 200M before further processing.\n\n\u2705 **No integer overflow in octet count parsing**.\n\n---\n\n### Step 4: Check for improper handling of input length\n- In octet-counting mode:\n  - `octatesToCopy = buffLen` if `buffLen < pThis->iOctetsRemain`.\n  - Then, `octatesToCopy` is further reduced if `pThis->iMsg + octatesToCopy > iMaxLine`.\n  - `*buff += (octatesToCopy + octatesToDiscard - 1)` \u2014 note: this is **not** `+1`, but `-1` \u2014 this is **critical**.\n\nWait: `*buff += (octatesToCopy + octatesToDiscard - 1);`\n\nThis line advances the buffer pointer by `octatesToCopy + octatesToDiscard - 1`, but:\n- `octatesToCopy` is the number of bytes copied.\n- `octatesToDiscard` is the number of bytes to skip (e.g., due to truncation).\n- So total bytes consumed = `octatesToCopy + octatesToDiscard`.\n\nBut the pointer is advanced by `octatesToCopy + octatesToDiscard - 1`, which means **one byte is not advanced**.\n\nThis is a **bug** \u2014 it causes the next iteration to reprocess the same byte.\n\nBut is this a **security vulnerability**?\n\nLet\u2019s analyze:\n- The function processes data in chunks (`buffLen`).\n- If the buffer pointer is not advanced correctly, it may reprocess the same data.\n- However, this is a **logic error**, not a direct security vulnerability like buffer overflow or injection.\n- It could lead to message corruption or infinite loops, but not arbitrary code execution or data leakage.\n\nStill, let\u2019s check if this affects message boundaries or framing.\n\nBut note: the function uses `*buff += ...` to advance the pointer. If it advances by one less than the actual bytes consumed, then the next call will start processing the same byte again.\n\nThis could lead to:\n- Infinite loop if the same byte is never consumed.\n- Message truncation or duplication.\n\nBut is this exploitable?\n\nOnly if an attacker can control the framing and buffer content to cause infinite processing or denial of service.\n\nHowever, the function has:\n- `pThis->iOctetsRemain` tracking how many bytes are left.\n- `iMaxLine` limiting message size.\n- `buffLen` limiting how much data is processed per call.\n\nSo even if one byte is not advanced, the next call will process the same data again, but the state (`iOctetsRemain`, `iMsg`) will be updated, and eventually the frame will be completed or truncated.\n\nThis is a **bug**, but not a **security vulnerability** in the traditional sense (like buffer overflow, injection, or memory corruption).\n\n---\n\n### Step 5: Check for improper input validation\n- The function checks for `isdigit(c)` before parsing the octet count.\n- It validates that the delimiter is a space (`' '`) after the count.\n- It logs errors for invalid framing.\n- It handles large messages by truncating and logging.\n\nAll input validation is appropriate.\n\n---\n\n### Step 6: Check for use of unsafe functions\n- `memcpy` is used with bounds checked via `octatesToCopy`.\n- `strncpy` is not used.\n- No `strcpy`, `sprintf`, etc.\n\n\u2705 Safe memory operations.\n\n---\n\n### Step 7: Check for race conditions or state issues\n- The function uses `pThis->inputState`, `eFraming`, `iOctetsRemain`, `iMsg`, etc.\n- These are updated based on input.\n- The state machine is well-defined.\n- `assert(pThis->inputState == eInMsg)` is used in the else block \u2014 this is good for debugging.\n\nNo obvious race conditions (assuming single-threaded or properly synchronized).\n\n---\n\n### Final Assessment:\n- The code has a **bug** in buffer pointer advancement: `*buff += (octatesToCopy + octatesToDiscard - 1)` should be `+ (octatesToCopy + octatesToDiscard)`.\n- This could lead to **infinite loop** or **infinite message processing** if not handled properly.\n- However, this is **not a direct security vulnerability** like buffer overflow, injection, or memory corruption.\n- It could be exploited for **denial of service (DoS)** if an attacker sends a malformed frame that causes repeated processing of the same data.\n- But the function has safeguards:\n  - `iMaxLine` limits message size.\n  - `pThis->iOctetsRemain` is decremented.\n  - `buffLen` limits per-call input.\n\nSo, while the bug is serious, it does not lead to **arbitrary code execution**, **memory corruption**, or **information disclosure**.\n\nTherefore, it is **not a security vulnerability** in the context of this analysis (which focuses on classic vulnerabilities like buffer overflows, injection, etc.).\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 220463, "project": "tensorflow", "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8", "commit_message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-23595", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When building an XLA compilation cache, if default settings are used, TensorFlow triggers a null pointer dereference. In the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `BuildXlaCompilationCache` is responsible for creating an XLA compilation cache for a given device and platform. It takes several parameters including device, function library runtime, platform info, and outputs a pointer to an XlaCompilationCache.\n\n2) The function first checks if `platform_info.xla_device_metadata()` is available. If so, it creates a cache using the client and JIT device type from that metadata. This is a valid path and does not involve user input.\n\n3) If no metadata is available, it attempts to get the platform using `MultiPlatformManager::PlatformWithId`. This is a system-level platform lookup and not based on user-controlled input.\n\n4) It then tries to get a compiler for the platform using `xla::Compiler::GetForPlatform`. If this fails with a NOT_FOUND error, it returns an Unimplemented error with a message that includes the platform name. This is a defensive check and does not expose any user input to unsafe operations.\n\n5) The function sets up `xla::LocalClientOptions` with platform and thread settings. The number of threads comes from `device->tensorflow_cpu_worker_threads()->num_threads`, which is a configuration parameter, not user input.\n\n6) It optionally sets allowed GPU devices based on `flr->config_proto()->gpu_options().visible_device_list()`. This is parsed using `ParseVisibleDeviceList`, which is a well-defined function that validates the device list format. The result is stored in an `absl::optional<std::set<int>>`, which is properly handled with `TF_ASSIGN_OR_RETURN`.\n\n7) It creates a local client using `ClientLibrary::GetOrCreateLocalClient`. This is a standard XLA client creation process and does not involve unsafe operations.\n\n8) It checks for a JIT device registration using `XlaOpRegistry::GetCompilationDevice`. If no registration is found, it returns an InvalidArgument error. This is a validation step, not a vulnerability.\n\n9) Finally, it creates the `XlaCompilationCache` using the client and compilation device name, and returns OK.\n\n10) Throughout the function, there are no instances of:\n- Direct string concatenation with user input\n- Unchecked buffer operations\n- Use of unsafe functions (like strcpy, sprintf, etc.)\n- Improper input validation\n- Memory corruption risks\n- Use of untrusted data in system calls or execution paths\n\n11) All inputs are either system-level configuration, platform metadata, or validated through proper error handling and type-safe operations. The function follows defensive programming practices with proper error checking and early returns.\n\n12) The function does not expose any attack surface that could be exploited through malicious input, as all data sources are either internal system state or properly validated configuration.\n\n(2) NO: No security vulnerability."}
{"idx": 449294, "project": "vim", "commit_id": "a062006b9de0b2947ab5fb376c6e67ef92a8cd69", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/a062006b9de0b2947ab5fb376c6e67ef92a8cd69", "commit_message": "patch 8.2.3610: crash when ModeChanged triggered too early\n\nProblem:    Crash when ModeChanged triggered too early.\nSolution:   Trigger ModeChanged after setting VIsual.", "ground_truth": 0, "cwe": ["CWE-122"], "cve": "CVE-2021-3968", "cve_desc": "vim is vulnerable to Heap-based Buffer Overflow", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `n_start_visual_mode(int c)` is responsible for initializing visual mode in a text editor (likely Vim or a derivative). It sets global visual mode state variables like `VIsual_mode`, `VIsual_active`, and `VIsual_reselect`.\n\n2. There is a conditional block that checks if the visual mode is `Ctrl_V` (block-wise visual mode), `VE_BLOCK` is enabled in `virtualedit`, and the current character at the cursor is a tab (`TAB`). In this case, it calls `validate_virtcol()` and `coladvance(curwin->w_virtcol)` to adjust the virtual column. This is a defensive measure to ensure correct cursor positioning when entering block visual mode, especially around tabs, which can have variable display width. This is a correct handling of a known edge case.\n\n3. The function sets `VIsual = curwin->w_cursor`, which stores the starting position of the visual selection. This is expected behavior.\n\n4. There are conditional checks for features like folding (`foldAdjustVisual()`), conceal (`conceal_check_cursor_line()`), mode change triggers (`trigger_modechanged()`), mouse updates (`setmouse()`), and clipboard state updates (`clip_star.vmode = NUL`). These are all standard operations for maintaining UI consistency and state across features.\n\n5. The code checks `p_smd` (show mode in status line) and sets `redraw_cmdline = TRUE` if needed, which is a UI update flag.\n\n6. The final block checks `curwin->w_redr_type < INVERTED`. If true, it updates the old cursor and visual line numbers. This is used to track changes for redrawing purposes, particularly when `lazyredraw` is in effect. This logic is safe and does not involve untrusted input.\n\n7. The function does not directly handle user input in a way that could lead to buffer overflows, format string vulnerabilities, or memory corruption. All operations are on internal state variables, cursor positions, and feature flags. The use of `gchar_cursor()` and `coladvance()` is well-contained and does not involve unbounded memory access.\n\n8. There are no calls to unsafe functions like `strcpy`, `sprintf`, or `strcat`. No dynamic memory allocation or pointer arithmetic that could lead to overflows is present.\n\n9. The code is part of a larger system (Vim-like editor) and uses feature guards (`#ifdef FEAT_...`) appropriately. The conditional compilation ensures that only relevant code is compiled, reducing attack surface.\n\n10. No user-controlled data is directly used in a way that could be exploited (e.g., no string formatting with user input, no unbounded loops, no direct memory manipulation).\n\nConclusion: The code performs proper initialization of visual mode state, handles edge cases (like tabs in block visual mode), and updates UI and state variables safely. There are no obvious security vulnerabilities such as buffer overflows, use-after-free, or injection issues.\n\n(2) NO: No security vulnerability."}
{"idx": 220841, "project": "tensorflow", "commit_id": "8c6f391a2282684a25cbfec7687bd5d35261a209", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209", "commit_message": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2022-23557", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Function Purpose**: The function `BiasAndClamp` applies a bias to elements in `array_data` using `bias_data`, then clamps the results between `clamp_min` and `clamp_max`. It is designed to process data in chunks of size `bias_size`, with the total array size being `array_size`.\n\n2. **Input Validation**:\n   - The function checks `if (bias_size == 0) return;` \u2014 this prevents division by zero or invalid operations.\n   - There is a `TFLITE_DCHECK_EQ((array_size % bias_size), 0);` \u2014 this ensures that `array_size` is divisible by `bias_size`. This is critical because the loop processes data in chunks of `bias_size`. If this condition fails, the function will abort via the `DCHECK`, which is a debug assertion. In release builds, this may be disabled, but in production, this check is essential to prevent out-of-bounds access.\n\n3. **NEON-optimized Path**:\n   - The code uses NEON intrinsics (`vld1q_f32`, `vaddq_f32`, `vmaxq_f32`, `vminq_f32`, `vst1q_f32`) to process 4 floats at a time (128-bit vectors).\n   - The outer loop iterates over `array_data` in steps of `bias_size`.\n   - The inner loops process `bias_data` and `array_data` in chunks of 16, then 4, then scalar.\n   - All memory accesses are bounded by `array_ptr + i` where `i` is within `[0, bias_size)`, and `array_ptr` is within `[array_data, array_data + array_size)`.\n   - The loop bounds are carefully constructed:\n     - First loop: `i <= bias_size - 16` \u2192 ensures `i + 12 < bias_size`\n     - Second loop: `i <= bias_size - 4` \u2192 ensures `i + 3 < bias_size`\n     - Third loop: `i < bias_size` \u2192 handles remaining elements\n   - All accesses to `bias_data` and `array_data` are within valid bounds due to the loop conditions and the `TFLITE_DCHECK_EQ` ensuring `array_size % bias_size == 0`.\n\n4. **Non-NEON Path**:\n   - Uses a straightforward loop: `for (int array_offset = 0; array_offset < array_size; array_offset += bias_size)`\n   - Inner loop: `for (int i = 0; i < bias_size; i++)`\n   - Accesses `array_data[array_offset + i]` and `bias_data[i]`\n   - Since `array_offset` increases by `bias_size` and `array_size` is divisible by `bias_size`, the total number of iterations is exactly `array_size / bias_size`, and each `array_offset + i` stays within bounds.\n\n5. **Potential Issues**:\n   - Could there be a buffer overflow? No \u2014 all array accesses are bounded by the loop conditions and the `TFLITE_DCHECK_EQ` ensures alignment.\n   - Could there be integer overflow in indices? Unlikely \u2014 `array_size` and `bias_size` are `int`, and the loop bounds are carefully constructed to avoid overflow.\n   - Is `ActivationFunctionWithMinMax` safe? The function is called with `array_ptr[i] + bias_data[i]`, and the values are clamped. Assuming `ActivationFunctionWithMinMax` is correctly implemented (not shown), it's not a vulnerability here.\n   - Are the NEON intrinsics used safely? Yes \u2014 all vector loads, operations, and stores are within the bounds of the `bias_size` chunk.\n\n6. **Conclusion**:\n   - The code includes proper bounds checking via `TFLITE_DCHECK_EQ`.\n   - All loops are bounded and use safe indexing.\n   - No out-of-bounds memory access is possible under valid input conditions.\n   - The function is designed to be safe and efficient, with fallback paths.\n\n(2) NO: No security vulnerability."}
{"idx": 274865, "project": "tensorflow", "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-29212", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ComparisonQuantized` is designed to perform a comparison operation between two quantized tensors (input1 and input2) and store the result in an output tensor. It supports quantized types (UInt8, Int8) and uses scaling and offset parameters for quantization.\n\n2) The function first checks if the input tensor types are UInt8 or Int8, which is appropriate for quantized operations.\n\n3) It calculates offsets based on zero_point values, which is standard for quantized arithmetic.\n\n4) It uses `QuantizeMultiplier` to compute scaling multipliers and shifts for both input tensors. This is a standard technique in quantized neural network operations to maintain precision during fixed-point arithmetic.\n\n5) The function sets up a `ComparisonParams` struct with all necessary parameters (left_shift, offsets, multipliers, shifts) for the comparison operation.\n\n6) It then calls either `BroadcastComparison4DSlowWithScaling` or `ComparisonWithScaling` depending on whether broadcasting is required. These are reference implementations that handle the actual comparison with proper scaling.\n\n7) The function uses `GetTensorShape` and `GetTensorData` to access tensor metadata and data, which are assumed to be safe wrappers around tensor access.\n\n8) The key security consideration here is whether there are any buffer overflows, out-of-bounds accesses, or improper input validation. However:\n   - The function validates the input tensor types (UInt8/Int8)\n   - It uses proper quantization parameters\n   - It uses reference implementations that are known to be safe\n   - There are no direct array accesses without bounds checking\n   - The tensor shape and data access functions are assumed to be properly implemented\n\n9) The function does not perform any unsafe operations like direct memory copying, pointer arithmetic, or unbounded loops. All operations are within the bounds of the tensor dimensions.\n\n10) The use of quantized arithmetic with proper scaling and offset handling is a standard and safe practice in machine learning inference.\n\n(2) NO: No security vulnerability."}
{"idx": 225383, "project": "v4l2loopback", "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd", "project_url": "https://github.com/umlaeute/v4l2loopback", "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd", "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134", "ground_truth": 0, "cwe": ["CWE-134"], "cve": "CVE-2022-2652", "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `vidioc_querycap` is a V4L2 (Video4Linux2) ioctl handler that fills a `v4l2_capability` structure with device information.\n\n2. The function retrieves the device context via `v4l2loopback_getdevice(file)`, which is a valid and safe operation assuming proper input validation upstream.\n\n3. The variable `labellen` is calculated as the minimum of `sizeof(cap->card)` and `sizeof(dev->card_label)`. This ensures that the copy into `cap->card` will not exceed the buffer size of `cap->card`, which is a good defensive practice.\n\n4. `strlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver))` is used to copy a fixed string into `cap->driver`. `strlcpy` is safe because it guarantees null termination and bounds checking.\n\n5. `snprintf(cap->card, labellen, \"%s\", dev->card_label)` copies `dev->card_label` into `cap->card` with a size limit (`labellen`). Since `labellen` is the smaller of the two buffer sizes, this prevents overflow.\n\n6. `snprintf(cap->bus_info, sizeof(cap->bus_info), \"platform:v4l2loopback-%03d\", device_nr)` safely formats a string into `bus_info` with a known buffer size. The format string is static and the variable `device_nr` is an integer, so no format string injection is possible.\n\n7. The version field is set conditionally based on kernel version, but it's a constant (`V4L2LOOPBACK_VERSION_CODE`), so no risk of overflow.\n\n8. The `capabilities` field is built from known flags and conditionally modified based on device state. No user input is involved in this logic.\n\n9. The assignment `cap->device_caps = cap->capabilities = capabilities` is safe because it's just copying a value.\n\n10. `memset(cap->reserved, 0, sizeof(cap->reserved))` clears the reserved field, which is good practice to avoid information leakage.\n\n11. All string operations use bounded functions (`strlcpy`, `snprintf`) with proper buffer size checks.\n\n12. There is no use of unsafe functions like `strcpy`, `sprintf`, or `strcat` that could lead to buffer overflows.\n\n13. The `dev->card_label` is assumed to be a string from the device configuration, but since it's copied using `snprintf` with a size limit, it cannot overflow.\n\n14. The `device_nr` is derived from the device private data and is used in a safe format string with a fixed width (`%03d`), so it cannot cause overflow.\n\nConclusion: All string operations are bounded and safe. No buffer overflows or injection vulnerabilities are present. The code follows secure coding practices.\n\n(2) NO: No security vulnerability."}
{"idx": 389760, "project": "jasper", "commit_id": "d99636fad60629785efd1ef72da772a8ef68f54c", "project_url": "https://github.com/mdadams/jasper", "commit_url": "https://github.com/jasper-software/jasper/commit/d99636fad60629785efd1ef72da772a8ef68f54c", "commit_message": "fix memory leaks in function cmdopts_parse", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-2963", "cve_desc": "A vulnerability found in jasper. This security vulnerability happens because of a memory leak bug in function cmdopts_parse that can cause a crash or segmentation fault.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - The function `cmdopts_parse` allocates memory for a `cmdopts_t` structure using `malloc`. If allocation fails, it prints an error and exits. This is safe and prevents use-after-free or null pointer dereference.\n   - All fields in the `cmdopts_t` structure are properly initialized to default values (e.g., `0`, `-1`, `\"\"`, etc.), which avoids uninitialized memory usage.\n\n2. **Command-Line Option Parsing**:\n   - The code uses `jas_getopt` to parse command-line arguments. This is a standard and safe way to handle options, especially when paired with a well-defined `jasp_opt_t` table.\n   - The `cmdoptions` array correctly maps short and long options to their respective enum values, with proper flags (`JAS_OPT_HASARG` for options requiring arguments).\n\n3. **String Handling and Buffer Management**:\n   - For options like `CMDOPT_INOPT` and `CMDOPT_OUTOPT`, the function calls `addopt(cmdopts->inoptsbuf, OPTSMAX, jas_optarg)` to append option strings to a fixed-size buffer (`inoptsbuf` and `outoptsbuf`).\n   - The `addopt` function is not shown, but the use of `OPTSMAX` suggests a maximum buffer size. If `addopt` properly bounds checks the input (e.g., ensures no buffer overflow), this is safe.\n   - However, if `addopt` does not properly check the length of `jas_optarg` or the remaining space in the buffer, it could lead to a buffer overflow. But since the function is not provided, we must assume it is implemented correctly, as this is a common utility in such parsing libraries.\n\n4. **Input Validation and Sanitization**:\n   - The code does not directly use user input in unsafe functions like `strcpy`, `strcat`, or `sprintf`. Instead, it assigns pointers (`jas_optarg`) to fields like `infile`, `infmt_str`, etc.\n   - The `jas_optarg` is a pointer to the argument string provided by `jas_getopt`, which is safe as long as `jas_getopt` does not return invalid or corrupted data.\n   - For numeric values (`debug`, `cmptno`, `max_mem`), the code uses `atoi` and `strtoull`. While `atoi` is not the most robust (it doesn't handle overflow or invalid input well), `strtoull` is used for `max_mem`, which is safer and includes error checking via the second parameter (though it's passed as `0`, which means no error pointer is captured \u2014 a minor issue, but not a critical vulnerability).\n   - However, `atoi` is used for `debug`, which could silently return 0 on invalid input (e.g., non-numeric string), but this is a logic issue, not a security vulnerability.\n\n5. **Error Handling and Exit Conditions**:\n   - The function calls `badusage()` and `cmdopts_destroy(cmdopts)` on invalid options, which is appropriate.\n   - It also warns about unused arguments and exits with an error if output format is not specified, which is good practice.\n\n6. **Potential Issues**:\n   - The use of `atoi` instead of `strtol` or `strtoll` for `debug` and `cmptno` is a minor concern, but not a direct security vulnerability unless the input is untrusted and can be manipulated to cause overflow or unexpected behavior. However, since these are command-line options, and `jas_getopt` ensures the argument is present and non-null, the risk is low.\n   - The `addopt` function is critical \u2014 if it does not check buffer bounds, it could lead to a buffer overflow. But since it's not shown, and the code uses `OPTSMAX`, we assume it's safe.\n\n7. **Overall Security**:\n   - There are no obvious buffer overflows, format string vulnerabilities, or unsafe string operations.\n   - All user input is either directly assigned (as pointers) or parsed with safe functions.\n   - The code follows standard practices for command-line argument parsing.\n\nConclusion: The code appears to be well-written and secure, with proper initialization, safe string handling (assuming `addopt` is safe), and appropriate error handling.\n\n(2) NO: No security vulnerability."}
{"idx": 477273, "project": "linux", "commit_id": "fa40d9734a57bcbfa79a280189799f76c88f7bb0", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/fa40d9734a57bcbfa79a280189799f76c88f7bb0", "commit_message": "tipc: fix size validations for the MSG_CRYPTO type\n\nThe function tipc_crypto_key_rcv is used to parse MSG_CRYPTO messages\nto receive keys from other nodes in the cluster in order to decrypt any\nfurther messages from them.\nThis patch verifies that any supplied sizes in the message body are\nvalid for the received message.\n\nFixes: 1ef6f7c9390f (\"tipc: add automatic session key exchange\")\nSigned-off-by: Max VA <maxv@sentinelone.com>\nAcked-by: Ying Xue <ying.xue@windriver.com>\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nAcked-by: Jon Maloy <jmaloy@redhat.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2021-43267", "cve_desc": "An issue was discovered in net/tipc/crypto.c in the Linux kernel before 5.14.16. The Transparent Inter-Process Communication (TIPC) functionality allows remote attackers to exploit insufficient validation of user-supplied sizes for the MSG_CRYPTO message type.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `tipc_crypto_key_rcv` handles receiving a cryptographic key over a TIPC (Transparent Inter-Process Communication) message.\n\n2. It first extracts the key generation number (`key_gen`) and data size (`size`) from the message header.\n\n3. It performs a size check:\n   - `if (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN))`\n   - This ensures the message data is large enough to contain at least the minimum required key data. This is a valid bounds check.\n\n4. It extracts the key length from the message data:\n   - `keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));`\n   - This reads a 32-bit big-endian value from the data, which is expected to be the length of the key.\n\n5. It performs two critical checks:\n   - `if (unlikely(size != keylen + sizeof(struct tipc_aead_key) || keylen > TIPC_AEAD_KEY_SIZE_MAX))`\n   - This checks that the total size matches the expected size (keylen + struct tipc_aead_key) and that the key length is within the maximum allowed limit.\n   - This prevents buffer overflows by ensuring the key length is reasonable and consistent with the message size.\n\n6. It acquires a spinlock to protect the critical section where it updates the `rx->skey` and `rx->key_gen` fields.\n\n7. It checks if a key already exists or if the key generation number matches an existing one:\n   - `if (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys)))`\n   - This prevents overwriting an existing key or accepting a key with the same generation number, which is a good security practice to prevent replay attacks.\n\n8. It allocates memory for the key using `kmalloc(size, GFP_ATOMIC)` \u2014 the size is validated earlier, so this is safe.\n\n9. It copies the algorithm name and key data into the allocated structure using `memcpy`, with bounds checked by the earlier size validation.\n\n10. It updates the key generation, mode, and sets the key pointer.\n\n11. Finally, it schedules a work item to process the key, using `queue_delayed_work`, which is safe as long as the work item is properly initialized.\n\nKey observations:\n- All memory allocations are based on validated size values.\n- The size checks prevent buffer overflows.\n- The key length is extracted from the message and validated against the total message size and maximum allowed size.\n- The use of `memcpy` is safe because the source size is bounded by the validated `size` and `keylen`.\n- The spinlock protects the state update, preventing race conditions.\n- No untrusted input is used in unsafe operations like string copying or format strings.\n\nThere are no obvious buffer overflows, use-after-free, or injection vulnerabilities. The code performs proper input validation and bounds checking.\n\n(2) NO: No security vulnerability."}
{"idx": 282984, "project": "LuaJIT", "commit_id": "53f82e6e2e858a0a62fd1a2ff47e9866693382e6", "project_url": "https://github.com/LuaJIT/LuaJIT", "commit_url": "https://github.com/LuaJIT/LuaJIT/commit/53f82e6e2e858a0a62fd1a2ff47e9866693382e6", "commit_message": "Fix frame traversal for __gc handler frames.\n\nReported by Changochen.", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2020-15890", "cve_desc": "LuaJit through 2.1.0-beta3 has an out-of-bounds read because __gc handler frame traversal is mishandled.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `finderrfunc` is part of the LuaJIT runtime, specifically designed to locate an error handler function in the call stack during error propagation.\n\n2) The function traverses both the Lua stack (`frame`) and the C frame chain (`cf`) to find an appropriate error handler. It checks various frame types (FRAME_LUA, FRAME_C, FRAME_CONT, FRAME_CP, etc.) and handles them accordingly.\n\n3) Key safety checks:\n   - The loop condition `frame > bot && cf` ensures we don't go below the stack bottom or beyond the C frame chain.\n   - The function uses `restorestack` to safely handle stack restoration when needed.\n   - All frame access is bounded by the stack limits and frame chain validity.\n   - The function returns 0 (no error handler found) or a valid stack pointer when an error handler is found.\n\n4) The function does not perform any unbounded memory access, buffer overflows, or unsafe pointer arithmetic. All pointer arithmetic is bounded by stack limits and frame chain validity checks.\n\n5) The function correctly handles edge cases:\n   - When `cframe_nres(cf) < 0`, it checks for valid frame state.\n   - It properly unwinds the C frame chain with `cframe_prev(cf)`.\n   - It returns 0 when no error handler is found, which is the expected behavior.\n\n6) There are no known vulnerabilities in this code pattern. The stack and frame traversal is bounded and safe, with proper validation at each step.\n\n(2) NO: No security vulnerability."}
{"idx": 437708, "project": "linux", "commit_id": "a7b2df76b42bdd026e3106cf2ba97db41345a177", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/a7b2df76b42bdd026e3106cf2ba97db41345a177", "commit_message": "media: rc: prevent memory leak in cx23888_ir_probe\n\nIn cx23888_ir_probe if kfifo_alloc fails the allocated memory for state\nshould be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Sean Young <sean@mess.org>\nSigned-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2019-19054", "cve_desc": "A memory leak in the cx23888_ir_probe() function in drivers/media/pci/cx23885/cx23888-ir.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering kfifo_alloc() failures, aka CID-a7b2df76b42b.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `cx23888_ir_probe` is a driver probe function for an IR (Infrared) controller device in a Linux kernel module. It initializes state structures, sets up a kernel FIFO (kfifo) for receiving IR data, registers a V4L2 subdevice, and configures IR parameters.\n\n2. Memory allocation:\n   - `kzalloc` is used to allocate memory for `struct cx23888_ir_state`. This is safe as long as the allocation succeeds.\n   - If allocation fails, the function returns `-ENOMEM`, which is correct behavior.\n\n3. kfifo allocation:\n   - `kfifo_alloc` is used to allocate a circular buffer for IR data reception.\n   - The size is `CX23888_IR_RX_KFIFO_SIZE`, which is a constant defined elsewhere.\n   - If `kfifo_alloc` fails, the code calls `kfree(state)` and returns `-ENOMEM`. This is correct cleanup.\n\n4. Device registration:\n   - The subdevice is registered via `v4l2_device_register_subdev`. If this fails, the code calls `kfifo_free(&state->rx_kfifo)` to free the kfifo, which is proper cleanup.\n\n5. Initialization of locks:\n   - `spin_lock_init` and `mutex_init` are used correctly for synchronization primitives.\n\n6. IR parameter setup:\n   - `default_params` is initialized from `default_rx_params` and `default_tx_params`, which are presumably predefined constants.\n   - `v4l2_subdev_call` is used to set IR receive and transmit parameters. This is a standard V4L2 mechanism and is safe as long as the parameters are valid.\n\n7. Security considerations:\n   - There is no user input being processed or copied into buffers without bounds checking.\n   - No string formatting with user-controlled data (e.g., no `sprintf` with untrusted input).\n   - No use of unsafe functions like `strcpy`, `strcat`, `gets`, etc.\n   - The `snprintf` call uses `dev->name` as a source, but `dev->name` is a kernel device name, typically set during device initialization and not user-controlled. It is used with a fixed buffer size and proper bounds checking.\n   - The `v4l2_subdev_call` mechanism is designed to be safe and type-checked by the V4L2 framework.\n\n8. Error handling:\n   - All error paths properly clean up allocated resources (kfifo, state).\n   - No resource leaks are apparent.\n\n9. No obvious vulnerabilities:\n   - No buffer overflows.\n   - No use-after-free.\n   - No race conditions (locks are properly initialized).\n   - No injection vectors (no user input in strings or parameters).\n\nConclusion: The code follows safe kernel programming practices, uses proper error handling, and does not exhibit any known security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 439495, "project": "squashfs-tools", "commit_id": "79b5a555058eef4e1e7ff220c344d39f8cd09646", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/79b5a555058eef4e1e7ff220c344d39f8cd09646", "commit_message": "Unsquashfs: fix write outside destination directory exploit\n\nAn issue on Github (https://github.com/plougher/squashfs-tools/issues/72)\nshows how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and ..) can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nThis commit fixes this exploit by checking all names for\nvalidity.\n\nIn doing so I have also added checks for '.' and for names that\nare shorter than they should be (names in the file system should\nnot have '\\0' terminators).\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 0, "cwe": ["CWE-22"], "cve": "CVE-2021-40153", "cve_desc": "squashfs_opendir in unsquash-1.c in Squashfs-Tools 4.5 stores the filename in the directory entry; this is then used by unsquashfs to create the new file during the unsquash. The filename is not validated for traversal outside of the destination directory, and thus allows writing to locations outside of the destination.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its directory entries, and populating a `struct dir` with metadata about the entries.\n\n2. A buffer `buffer` of size `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` is declared and aligned. This buffer is used to hold a single directory entry (`dire`) during processing.\n\n3. The function reads the directory header (`dirh`) and then iterates over each directory entry (`dire`) in the directory data.\n\n4. For each entry:\n   - It copies the entry from `directory_table` into `dire` using `memcpy`, with size `sizeof(*dire)`.\n   - It then copies the name from `directory_table + bytes` into `dire->name`, using `dire->size + 1` bytes (including null terminator).\n   - It checks that `dire->size < SQUASHFS_NAME_LEN` to prevent overly long filenames.\n   - It calls `check_name(dire->name, dire->size + 1)` to validate the name (e.g., no `/`, `.` or `..`).\n   - It then copies the name into `dir->dirs[dir->dir_count].name` using `strcpy`.\n\n5. The critical point is in the `strcpy(dir->dirs[dir->dir_count].name, dire->name)` call.\n\n   - `dire->name` is copied from `directory_table + bytes` using `memcpy(dire->name, ..., dire->size + 1)`, and then `dire->name[dire->size + 1] = '\\0'` is explicitly set. This ensures that `dire->name` is null-terminated and the length is at most `dire->size + 1`, which is \u2264 `SQUASHFS_NAME_LEN + 1`.\n\n   - However, `dir->dirs[dir->dir_count].name` is a field in a `struct dir_ent` that is presumably declared as a fixed-size character array (e.g., `char name[SQUASHFS_NAME_LEN + 1]`), which is the same size as the buffer used for `dire->name`.\n\n   - Since `dire->size < SQUASHFS_NAME_LEN` is enforced, the name length is strictly less than `SQUASHFS_NAME_LEN`, so `dire->name` is at most `SQUASHFS_NAME_LEN` characters plus null terminator.\n\n   - Therefore, `strcpy` will copy at most `SQUASHFS_NAME_LEN` characters, which fits in the destination buffer.\n\n6. The code also checks `dire->size >= SQUASHFS_NAME_LEN` and exits with an error if true \u2014 this prevents any name from being too long.\n\n7. The `check_name` function is called to prevent invalid characters (like `/`, `.` or `..`), which is a good security practice.\n\n8. The `memcpy` operations are bounded by known sizes (`sizeof(*dire)` and `dire->size + 1`), and the `directory_table` is assumed to be a valid, trusted filesystem image (since this is a filesystem driver).\n\n9. There is no user-controlled input directly used in a way that could overflow buffers \u2014 the input is from a filesystem image, which is validated at the filesystem level.\n\n10. The only potential issue is the `strcpy` call. However, because:\n    - `dire->size < SQUASHFS_NAME_LEN` is enforced,\n    - `dire->name` is null-terminated,\n    - and the destination buffer is at least `SQUASHFS_NAME_LEN + 1` in size,\n    the `strcpy` is safe.\n\n11. The `memcpy(dire->name, ..., dire->size + 1)` ensures that the name is copied safely, and the null terminator is explicitly set.\n\n12. No buffer overflow occurs because all sizes are bounded and validated.\n\n(2) NO: No security vulnerability."}
{"idx": 443152, "project": "linux", "commit_id": "a53046291020ec41e09181396c1e829287b48d47", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/a53046291020ec41e09181396c1e829287b48d47", "commit_message": "jfs: prevent NULL deref in diFree\n\nAdd validation check for JFS_IP(ipimap)->i_imap to prevent a NULL deref\nin diFree since diFree uses it without do any validations.\nWhen function jfs_mount calls diMount to initialize fileset inode\nallocation map, it can fail and JFS_IP(ipimap)->i_imap won't be\ninitialized. Then it calls diFreeSpecial to close fileset inode allocation\nmap inode and it will flow into jfs_evict_inode. Function jfs_evict_inode\njust validates JFS_SBI(inode->i_sb)->ipimap, then calls diFree. diFree use\nJFS_IP(ipimap)->i_imap directly, then it will cause a NULL deref.\n\nReported-by: TCS Robot <tcs_robot@tencent.com>\nSigned-off-by: Haimin Zhang <tcs_kernel@tencent.com>\nSigned-off-by: Dave Kleikamp <dave.kleikamp@oracle.com>", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-3202", "cve_desc": "A NULL pointer dereference flaw in diFree in fs/jfs/inode.c in Journaled File System (JFS)in the Linux kernel. This could allow a local attacker to crash the system or leak kernel internal information.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `jfs_evict_inode` is responsible for evicting an inode from memory in the JFS (Journaled File System) implementation. This is a kernel-level function, so any vulnerability here could lead to serious security issues like kernel crashes, data corruption, or privilege escalation.\n\n2. The function begins by retrieving the JFS-specific inode information (`ji = JFS_IP(inode)`), which is standard and safe.\n\n3. It logs the inode address using `jfs_info`, which is a debug/trace function and not a security concern.\n\n4. The main logic checks if the inode has no links (`!inode->i_nlink`) and is not a bad inode (`!is_bad_inode(inode)`). This is correct behavior for determining whether an inode should be fully cleaned up (i.e., deleted from disk metadata).\n\n5. Inside this block:\n   - `dquot_initialize(inode)` is called: This initializes disk quota accounting for the inode. Safe.\n   - If the inode belongs to the filesystem's special `FILESYSTEM_I` fileset, it proceeds to:\n     - Truncate the inode's page cache (`truncate_inode_pages_final(&inode->i_data)`): This is safe and correct.\n     - Checks if the `COMMIT_Freewmap` flag is set and calls `jfs_free_zero_link(inode)` if so: This is a cleanup operation for free block maps, safe.\n     - Checks if `ipimap` exists and if its `i_imap` is valid, then calls `diFree(inode)`: This frees the inode's metadata on disk. This is a critical operation, but the checks are in place to avoid null pointer dereferences.\n     - Calls `dquot_free_inode(inode)` to free quota resources: Safe.\n\n6. The `else` branch handles the case where the inode still has links (i.e., it's not being deleted), so it only truncates the page cache and proceeds to cleanup.\n\n7. Then, `clear_inode(inode)` is called: This clears the inode structure, which is standard and safe.\n\n8. `dquot_drop(inode)` is called: Drops the quota reference, safe.\n\n9. `BUG_ON(!list_empty(&ji->anon_inode_list))`: This is a kernel assertion that checks that the `anon_inode_list` is empty. If not, it triggers a kernel bug. This is a defensive check, not a vulnerability. It ensures that no anonymous inodes are left dangling, which could indicate a logic error elsewhere, but it's not a security flaw per se.\n\n10. The function then locks `ji->ag_lock` (a spinlock), checks if `ji->active_ag != -1`, and if so, decrements the active allocation group counter and resets `active_ag` to -1. This is a thread-safe operation using proper spinlock usage.\n\n11. All operations are within the bounds of kernel memory management and use proper locking mechanisms.\n\n12. There are no obvious buffer overflows, use-after-free, null pointer dereferences, or unchecked user input. The function operates on kernel data structures and uses proper checks and locking.\n\n13. The only potential concern is the `BUG_ON` macro: if the list is not empty, the kernel will panic. However, this is not a vulnerability\u2014it's a safety check to catch programming errors. It does not allow arbitrary code execution or data corruption from external input.\n\nConclusion: The code is well-structured, uses proper locking, performs necessary cleanup, and includes safety checks. No exploitable security vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 229337, "project": "tensorflow", "commit_id": "a5b89cd68c02329d793356bda85d079e9e69b4e7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a5b89cd68c02329d793356bda85d079e9e69b4e7", "commit_message": "Fix empty resource handle vulnerability.\n\nSome ops that attempt to extract a resource handle from user input\ncan lead to nullptr dereferences.  This returns an error in such\na case.\n\nPiperOrigin-RevId: 445571938", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-29207", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, multiple TensorFlow operations misbehave in eager mode when the resource handle provided to them is invalid. In graph mode, it would have been impossible to perform these API calls, but migration to TF 2.x eager mode opened up this vulnerability. If the resource handle is empty, then a reference is bound to a null pointer inside TensorFlow codebase (various codepaths). This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `GetDeviceForInput` determines which device (CPU, TPU, etc.) should be used for a tensor handle in an eager execution context.\n\n2) The function handles three main cases:\n   - Non-local tensor handles (remote tensors)\n   - Resource handles (special tensor type for resources)\n   - Regular tensor handles\n\n3) For non-local tensor handles:\n   - It gets the device from the tensor handle\n   - Falls back to CPU if device is null\n   - Uses the device name from the device or CPU if device is null\n\n4) For resource handles:\n   - It retrieves the actual tensor from the handle\n   - Checks if the tensor is empty (returns error if so)\n   - Gets the device name from the ResourceHandle\n   - Uses ctx.FindDeviceFromName to get the actual device\n   - This is safe because it uses the context's device lookup\n\n5) For regular tensor handles:\n   - Checks if it's a TPU device\n   - Determines whether to use host memory based on data type\n   - If use_host_memory is true, uses CPU device\n   - Otherwise, checks if the op is a function and uses the op's device if appropriate\n   - Falls back to the tensor's device or CPU\n\n6) Key security considerations:\n   - The function does not directly handle user input\n   - Device names are obtained from tensor handles or resource handles\n   - The function uses `ctx.FindDeviceFromName` which is a controlled lookup\n   - There is no string concatenation or untrusted input being used directly\n   - The device name is validated through the context's device lookup mechanism\n   - No buffer overflows, format string vulnerabilities, or injection attacks are present\n   - The function properly handles null pointers and edge cases\n\n7) The code follows proper error handling with TF_RETURN_IF_ERROR and validates inputs appropriately.\n\n8) There are no obvious security vulnerabilities such as buffer overflows, injection attacks, or improper access control.\n\n(2) NO: No security vulnerability."}
{"idx": 389676, "project": "vim", "commit_id": "1e56bda9048a9625bce6e660938c834c5c15b07d", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/1e56bda9048a9625bce6e660938c834c5c15b07d", "commit_message": "patch 9.0.0104: going beyond allocated memory when evaluating string constant\n\nProblem:    Going beyond allocated memory when evaluating string constant.\nSolution:   Properly skip over <Key> form.", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2022-2580", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 9.0.0102.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Function Purpose**: The function `eval_string` processes a string argument (`char_u **arg`) that may contain escape sequences (like `\\n`, `\\x12`, `\\u0023`, etc.), special key codes (`\\<C-W>`), and possibly string interpolation (`{...}`) if `interpolate` is true. It parses the string, handles backslash escapes, expands special keys, and stores the result in `rettv->vval.v_string`.\n\n2. **Input Validation and Bounds Checking**:\n   - The function first calculates the required length (`len`) for the output string based on the input length and the number of extra characters needed due to escape sequences (e.g., `\\<x>` expands to up to 9 characters, so `extra` is incremented by 5).\n   - It allocates memory using `alloc(len)` for the result string.\n   - The function then copies characters from the input to the output, processing escape sequences and special keys.\n\n3. **Potential Vulnerability: Buffer Overflow**:\n   - The key concern is whether the `extra` variable correctly accounts for all possible expansions, especially in the `case '<'` block where `trans_special()` is called.\n   - The function calls `trans_special(&p, end, flags, FALSE, NULL)` and assigns the return value to `extra`. This function is responsible for expanding special key sequences like `\\<C-W>`.\n   - The function then does: `end += extra;` and checks: `if (end >= rettv->vval.v_string + len) iemsg(\"eval_string() used more space than allocated\")`.\n   - This check is critical: it detects if the expansion exceeds the allocated buffer size. If it does, it prints an error and presumably fails.\n   - However, the function does **not** return `FAIL` in this case \u2014 it only issues a message. This is a serious issue: **the function continues execution even when the buffer is overflowed**, which could lead to memory corruption.\n\n4. **Critical Flaw**:\n   - The `extra` variable is used to estimate the buffer size, but `trans_special()` may return a value that is not properly bounded by the original `extra` calculation.\n   - The function does not re-check the total length after `trans_special` returns, nor does it validate that `end + extra` stays within bounds before writing.\n   - The `if (end >= rettv->vval.v_string + len)` check is **after** the write, and only issues a message \u2014 it does not prevent the overflow.\n   - This means that if `trans_special` returns a large `extra` value (e.g., due to malformed input or a bug), the function may write beyond the allocated buffer, leading to a **buffer overflow**.\n\n5. **Other Considerations**:\n   - The function uses `MB_COPY_CHAR` for multibyte characters, which is safe if used correctly.\n   - The `interpolate` logic for `{...}` is handled with care, and the `{{`/`}}` escaping is correctly reduced.\n   - The `eval_string` function is used in a context where user input is processed (e.g., in Vim's expression evaluation), so untrusted input is likely.\n\n6. **Conclusion**:\n   - The function fails to prevent buffer overflow when `trans_special()` expands a special key sequence beyond the allocated buffer size.\n   - The check for buffer overflow is present but **not enforced** \u2014 it only logs a message and continues.\n   - This is a classic **buffer overflow vulnerability** that can be exploited to corrupt memory or execute arbitrary code.\n\n(1) YES: A security vulnerability detected."}
{"idx": 349259, "project": "squashfs-tools", "commit_id": "e0485802ec72996c20026da320650d8362f555bd", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/e0485802ec72996c20026da320650d8362f555bd", "commit_message": "Unsquashfs: additional write outside destination directory exploit fix\n\nAn issue on github (https://github.com/plougher/squashfs-tools/issues/72)\nshowed how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and '..') can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nSince then it has been shown that specially crafted Squashfs filesystems\nthat contain a symbolic link pointing outside of the destination directory,\ncoupled with an identically named file within the same directory, can\ncause Unsquashfs to write files outside of the destination directory.\n\nSpecifically the symbolic link produces a pathname pointing outside\nof the destination directory, which is then followed when writing the\nduplicate identically named file within the directory.\n\nThis commit fixes this exploit by explictly checking for duplicate\nfilenames within a directory.  As directories in v2.1, v3.x, and v4.0\nfilesystems are sorted, this is achieved by checking for consecutively\nidentical filenames.  Additionally directories are checked to\nensure they are sorted, to avoid attempts to evade the duplicate\ncheck.\n\nVersion 1.x and 2.0 filesystems (where the directories were unsorted)\nare sorted and then the above duplicate filename check is applied.\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2021-41072", "cve_desc": "squashfs_opendir in unsquash-2.c in Squashfs-Tools 4.5 allows Directory Traversal, a different vulnerability than CVE-2021-40153. A squashfs filesystem that has been crafted to include a symbolic link and then contents under the same filename in a filesystem can cause unsquashfs to first create the symbolic link pointing outside the expected directory, and then the subsequent write operation will cause the unsquashfs process to write through the symbolic link elsewhere in the filesystem.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Buffer Handling**:\n   - The function `squashfs_opendir` reads directory data from a compressed filesystem (SquashFS) using `read_directory_data` to read headers and entries.\n   - A fixed-size buffer `buffer` is declared with size `sizeof(squashfs_dir_entry_3) + SQUASHFS_NAME_LEN + 1`, and it's aligned. This buffer is used to hold a directory entry.\n   - The `dire` pointer is cast to point into this buffer. The size of the buffer is sufficient to hold a directory entry (including the name) plus one extra byte for null termination.\n\n2. **Bounds Checking on Name Length**:\n   - After reading the `dire->size`, the code checks: `if(dire->size >= SQUASHFS_NAME_LEN) { ... }`.\n   - This is a critical check: if the name size is too large (equal to or greater than `SQUASHFS_NAME_LEN`), it reports corruption and exits.\n   - This prevents buffer overflow when copying the name into `dire->name`.\n\n3. **Name Copy and Null Termination**:\n   - The name is read using `read_directory_data(dire->name, &start, &offset, dire->size + 1)`.\n   - Then, `dire->name[dire->size + 1] = '\\0';` is executed.\n   - However, this line is **dangerous** because:\n     - `dire->name` is a field within the `buffer`, which is of size `sizeof(squashfs_dir_entry_3) + SQUASHFS_NAME_LEN + 1`.\n     - The `dire->size` is read from the directory entry, which comes from untrusted filesystem data.\n     - If `dire->size` is greater than or equal to `SQUASHFS_NAME_LEN`, the earlier check would have caught it and exited.\n     - But even if `dire->size` is less than `SQUASHFS_NAME_LEN`, the `dire->name` array is only `SQUASHFS_NAME_LEN + 1` bytes long.\n     - The code writes `dire->name[dire->size + 1] = '\\0'`, which is **one byte beyond the end of the name** if `dire->size + 1` is the last index.\n     - Wait: `dire->name` is an array of size `SQUASHFS_NAME_LEN + 1`, so valid indices are `0` to `SQUASHFS_NAME_LEN`.\n     - `dire->size + 1` could be up to `SQUASHFS_NAME_LEN` (if `dire->size == SQUASHFS_NAME_LEN - 1`), so `dire->name[dire->size + 1]` would be `dire->name[SQUASHFS_NAME_LEN]`, which is the last valid index (since array is 0-indexed and size is `SQUASHFS_NAME_LEN + 1`).\n     - So `dire->name[dire->size + 1] = '\\0'` is **safe** as long as `dire->size + 1 <= SQUASHFS_NAME_LEN`, which is ensured by the earlier check: `if(dire->size >= SQUASHFS_NAME_LEN)` \u2192 exit.\n     - Therefore, `dire->size < SQUASHFS_NAME_LEN`, so `dire->size + 1 <= SQUASHFS_NAME_LEN`, so `dire->name[dire->size + 1]` is within bounds.\n\n4. **Null Termination**:\n   - The code sets `dire->name[dire->size + 1] = '\\0'`, but the name was already read with `read_directory_data(dire->name, ..., dire->size + 1)`, which should have read `dire->size + 1` bytes.\n   - That means the name is already null-terminated by the read operation, so this line is redundant but not harmful.\n   - However, if `read_directory_data` does not null-terminate, this line ensures it does.\n\n5. **Memory Allocation and Copying**:\n   - `ent = malloc(sizeof(struct dir_ent))` \u2192 safe.\n   - `ent->name = strdup(dire->name)` \u2192 `strdup` copies the name, which is null-terminated and within bounds (due to earlier checks), so no overflow.\n\n6. **Directory Entry Processing Loop**:\n   - The loop reads `dir_count` entries, each with a size check (`dire->size < SQUASHFS_NAME_LEN`), and ensures the name is valid via `check_name`.\n   - The `check_name` function likely checks for invalid characters like `/`, `.`, `..`, which is good for security.\n\n7. **Final Directory Validation**:\n   - `check_directory(dir)` ensures no duplicate names and proper sorting \u2014 this is a good integrity check.\n\n8. **Potential Issues**:\n   - The `read_directory_data` function is assumed to be safe, but if it doesn't validate the size of data it reads, it could be a problem. However, the code uses `sizeof(dirh)` and `sizeof(*dire)` as the size to read, which are fixed and known.\n   - The `start` and `offset` are updated correctly in the loop.\n   - The `bytes` counter tracks how much data has been read, and it's compared to `size`, which is derived from `(*i)->data + bytes - 3`. This seems to be a calculation based on the inode data, but note: `bytes` is incremented inside the loop, and `size` is computed once at the beginning. This could be a problem if `(*i)->data` is corrupted or maliciously large.\n\n   However, `size = (*i)->data + bytes - 3` \u2014 but `bytes` is initialized to 0 and incremented in the loop. This means `size` is computed as `(*i)->data - 3` at the start, and then `bytes` increases. So the loop condition `bytes < size` is based on a fixed `size` value. This is **correct** because `(*i)->data` is the total size of the directory data, and `bytes` tracks how much has been read. The `-3` might be due to header overhead, but it's consistent.\n\n   But wait: `size = (*i)->data + bytes - 3` \u2014 this is **incorrect** because `bytes` is used in the computation of `size`, but `bytes` is being incremented in the loop. This creates a **circular dependency**.\n\n   Let's re-express:\n   - `size = (*i)->data + bytes - 3`\n   - But `bytes` starts at 0, so `size = (*i)->data - 3`\n   - Then, in the loop, `bytes` is incremented by `sizeof(dirh)` and then by `sizeof(*dire)` and `dire->size + 1` for each entry.\n   - So `size` is fixed at `(*i)->data - 3`, and the loop runs while `bytes < size`.\n\n   This is **correct** only if `(*i)->data` is the total size of the directory data, and the `-3` accounts for the header or something. But the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   This is **wrong** because `bytes` is not known at the time of computing `size`. It's initialized to 0, so `size = (*i)->data - 3`, which is fine. But then `bytes` is incremented, and the loop condition is `bytes < size`. This is acceptable only if `(*i)->data` is the total size of the directory data, and the `-3` is a fixed offset.\n\n   However, the comment says: `size = (*i)->data + bytes - 3;` \u2014 this is **incorrect** because `bytes` is not a constant. It's being used in the computation of `size`, but `bytes` is being updated in the loop. This is a **logic error**.\n\n   But wait: `bytes` is initialized to 0, and `size` is computed once at the start of the loop. So `size = (*i)->data - 3` (since `bytes = 0`). Then the loop runs while `bytes < size`. This is **correct** only if `(*i)->data` is the total size of the directory data, and the `-3` is a fixed offset (e.g., for header or metadata). But the code uses `(*i)->data` as the size of the directory data, and `bytes` is the amount read so far.\n\n   However, the `size` variable is used to control the loop, and it's computed as `(*i)->data + bytes - 3`. But `bytes` is 0 at the start, so `size = (*i)->data - 3`. Then, as `bytes` increases, the loop continues until `bytes >= size`.\n\n   But this means the loop will read `size` bytes, but `size` is `(*i)->data - 3`, so it reads `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes. So it's missing 3 bytes? Or the `-3` is intentional?\n\n   Actually, the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   But `bytes` is 0, so `size = (*i)->data - 3`. Then the loop runs while `bytes < size`. So it reads `size` bytes, i.e., `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes. So it's not reading the full data.\n\n   This is a **bug**, but is it a security vulnerability?\n\n   The `read_directory_data` function reads `sizeof(dirh)` or `sizeof(*dire)` or `dire->size + 1` bytes, which are all bounded by the `size` variable. But if `(*i)->data` is maliciously large, and `bytes` is 0, then `size = (*i)->data - 3` could be huge, leading to a potential infinite loop or memory exhaustion.\n\n   However, `(*i)->data` is read from the filesystem inode, which is part of the compressed filesystem. If the filesystem is corrupted or malicious, `(*i)->data` could be very large (e.g., 2^32 - 1). Then `size` becomes huge, and the loop runs many times, potentially consuming all memory.\n\n   But the code has a check: `if(dir_count > SQUASHFS_DIR_COUNT)` \u2192 exit. And `SQUASHFS_DIR_COUNT` is a small constant (e.g., 1024). So even if `(*i)->data` is large, the loop will only run `dir_count` times per header, and `dir_count` is limited.\n\n   However, the outer loop is `while(bytes < size)`, and `size` is `(*i)->data - 3`. But `(*i)->data` is the size of the directory data, so it should be the total size. But the code uses `(*i)->data + bytes - 3`, which is wrong because `bytes` is not constant.\n\n   This is a **critical bug**: the `size` variable is computed using `bytes`, which is being updated in the loop. But `size` is computed only once at the start of the loop. So if `(*i)->data` is large, `size` becomes large, and the loop runs many times, but each iteration reads a fixed amount of data (e.g., `sizeof(dirh)` or `sizeof(*dire)`), and `bytes` increases accordingly.\n\n   But the problem is: `size = (*i)->data + bytes - 3` \u2014 this is **incorrect** because `bytes` is not known at the time of computation. It should be `size = (*i)->data - 3` (if the `-3` is a fixed offset), or `size = (*i)->data` (if no offset). But the current code is `size = (*i)->data + bytes - 3`, which means `size` increases as `bytes` increases \u2014 this is **nonsensical**.\n\n   For example:\n   - Initially: `bytes = 0`, `size = (*i)->data - 3`\n   - After first header: `bytes += sizeof(dirh)`, so `bytes = sizeof(dirh)`\n   - Then `size` is still `(*i)->data - 3`, so the loop continues if `sizeof(dirh) < (*i)->data - 3`\n   - But the next iteration computes `size` again? No \u2014 the `size` variable is computed only once at the start of the loop.\n\n   Actually, the `size` variable is computed **once** at the beginning of the function, before the loop. So it's fixed.\n\n   But the code says:\n   ```c\n   size = (*i)->data + bytes - 3;\n   ```\n   And `bytes` is 0, so `size = (*i)->data - 3`.\n\n   Then the loop is:\n   ```c\n   while(bytes < size) {\n       ...\n   }\n   ```\n\n   So it's correct: it reads until `bytes >= (*i)->data - 3`.\n\n   But why `-3`? It might be a typo. It should be `size = (*i)->data` or `size = (*i)->data - 3` if the header is 3 bytes. But the code uses `(*i)->data + bytes - 3`, which is `(*i)->data - 3` when `bytes=0`.\n\n   So the `+ bytes` is a **bug** \u2014 it should not be there.\n\n   But even with the bug, the loop condition is `bytes < size`, and `size` is `(*i)->data - 3`, so it reads `(*i)->data - 3` bytes. But the total data is `(*i)->data` bytes, so it's missing 3 bytes. This is a **data corruption issue**, but not a security vulnerability per se.\n\n   However, the `read_directory_data` function reads data based on the size passed to it (e.g., `sizeof(dirh)`), which is fixed. So it won't read more than that. The `size` variable is only used to control the loop, not to limit the amount read per call.\n\n   Therefore, the loop will not read more than the actual data, because `read_directory_data` reads a fixed amount each time, and `bytes` is incremented accordingly.\n\n   But if `(*i)->data` is maliciously large (e.g., 2^32 - 1), then `size` becomes huge, and the loop runs many times, potentially causing a denial of service (DoS) by consuming excessive CPU or memory.\n\n   However, the `dir_count` is limited by `SQUASHFS_DIR_COUNT`, so the number of entries is bounded. But the loop is not bounded by `dir_count` \u2014 it's bounded by `size`.\n\n   But `dir_count` is read from the header, and the code checks `if(dir_count > SQUASHFS_DIR_COUNT)` \u2192 exit. So `dir_count` is at most `SQUASHFS_DIR_COUNT`, which is small.\n\n   So the loop runs at most `SQUASHFS_DIR_COUNT` times per header, and the number of headers is limited by the total data size.\n\n   But if `(*i)->data` is huge, and the directory has many headers, the loop could run many times.\n\n   However, the `dir_count` is read from each header, and it's limited. So the total number of entries is bounded.\n\n   But the `size` variable is `(*i)->data - 3`, which could be huge, but the loop condition is `bytes < size`, and `bytes` increases by `sizeof(dirh)` and then by `sizeof(*dire)` and `dire->size + 1` for each entry.\n\n   But the total number of entries is bounded by `dir_count` per header, and `dir_count` is bounded by `SQUASHFS_DIR_COUNT`.\n\n   So the loop will not run more than a few thousand times, even if `(*i)->data` is huge.\n\n   Therefore, it's not a DoS vulnerability.\n\n   But the `size` computation is still wrong: `size = (*i)->data + bytes - 3` \u2014 this is incorrect because `bytes` is not used in the computation. It should be `size = (*i)->data - 3` or `size = (*i)->data`.\n\n   However, this is a **logic bug**, not a security vulnerability.\n\n9. **Conclusion**:\n   - The code performs proper bounds checking on `dire->size` (prevents name overflow).\n   - The name is read with `read_directory_data` and null-terminated safely.\n   - The `strdup` call is safe because the name is within bounds.\n   - The `check_name` function prevents invalid characters.\n   - The `check_directory` function ensures integrity.\n   - The loop is bounded by the number of entries, which is limited by `SQUASHFS_DIR_COUNT`.\n   - The `size` computation has a bug (using `bytes` in the formula), but it doesn't lead to a security vulnerability because the actual data read is bounded by the fixed-size reads and the entry count.\n\nTherefore, there is no exploitable security vulnerability in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 220909, "project": "tensorflow", "commit_id": "92dba16749fae36c246bec3f9ba474d9ddeb7662", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662", "commit_message": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43", "ground_truth": 0, "cwe": ["CWE-617"], "cve": "CVE-2022-23579", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step-by-step to determine if there is a security vulnerability.\n\n1. The function `SafeToRemoveIdentity` is part of a dependency optimization system, likely in a machine learning framework (e.g., TensorFlow), and determines whether an Identity node (or IdentityN node) can be safely removed during graph optimization.\n\n2. The function first checks if the node is not an Identity or IdentityN node \u2014 if so, it returns `true`, meaning it's safe to remove. This is logical because only Identity nodes are considered for removal.\n\n3. It checks if the node is in `nodes_to_preserve_` \u2014 if so, it returns `false`, preventing removal. This is a safety mechanism to preserve user-specified nodes.\n\n4. It checks `fetch_nodes_known_` \u2014 if not known, it returns `false`. This ensures that if the output values of the node are not yet known (e.g., during graph construction), the node is not removed, preventing potential data loss.\n\n5. It checks if the node has no inputs (`node.input_size() < 1`) \u2014 if so, it returns `false`. This is valid because an Identity node without input is invalid and cannot be safely removed.\n\n6. It retrieves the input node via `node_map_->GetNode(node.input(0))`. If the input node is `nullptr`, it logs a warning and returns `false`. This prevents dereferencing invalid pointers and ensures input validity.\n\n7. It checks if the input node is a Variable or Recv node \u2014 if so, it returns `false`. This is a correct safety check because removing Identity nodes that wrap Variable reads or Recv operations could break data flow or cause incorrect execution.\n\n8. It iterates over consumers of the node. For each consumer:\n   - If the consumer is a Retval or Merge and the node has more than one input, it returns `false`. This prevents removal in cases where multiple inputs are involved and the consumer depends on the control flow or multiple data paths.\n   - If the input node is a Switch, it checks if the current node is a control dependency of the consumer. If so, it returns `false`. This prevents breaking control dependencies in conditional execution (e.g., in Switch/Case logic).\n\n9. Only if all checks pass does the function return `true`, indicating the Identity node can be safely removed.\n\nNow, evaluating for security vulnerabilities:\n\n- There are no buffer overflows, use-after-free, or memory corruption issues.\n- No user input is directly processed or exposed in a way that could lead to code injection or arbitrary execution.\n- The function operates on a well-defined graph structure (NodeDef, node_map_), and all accesses are bounded and validated (e.g., checking for null pointers, valid input size).\n- The logic is defensive: it errs on the side of caution (returns `false` when in doubt), which is good for correctness and safety.\n- There are no unsafe string operations, pointer arithmetic, or unchecked array accesses.\n\nThe function is part of a static graph optimization pass and does not involve untrusted input in a way that could lead to exploitation.\n\n(2) NO: No security vulnerability."}
{"idx": 400743, "project": "linux", "commit_id": "9d2231c5d74e13b2a0546fee6737ee4446017903", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/9d2231c5d74e13b2a0546fee6737ee4446017903", "commit_message": "lib/iov_iter: initialize \"flags\" in new pipe_buffer\n\nThe functions copy_page_to_iter_pipe() and push_pipe() can both\nallocate a new pipe_buffer, but the \"flags\" member initializer is\nmissing.\n\nFixes: 241699cd72a8 (\"new iov_iter flavour: pipe-backed\")\nTo: Alexander Viro <viro@zeniv.linux.org.uk>\nTo: linux-fsdevel@vger.kernel.org\nTo: linux-kernel@vger.kernel.org\nCc: stable@vger.kernel.org\nSigned-off-by: Max Kellermann <max.kellermann@ionos.com>\nSigned-off-by: Al Viro <viro@zeniv.linux.org.uk>", "ground_truth": 0, "cwe": ["CWE-284"], "cve": "CVE-2022-0847", "cve_desc": "A flaw was found in the way the \"flags\" member of the new pipe buffer structure was lacking proper initialization in copy_page_to_iter_pipe and push_pipe functions in the Linux kernel and could thus contain stale values. An unprivileged local user could use this flaw to write to pages in the page cache backed by read only files and as such escalate their privileges on the system.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `push_pipe` is responsible for pushing data into a pipe buffer, managing the ring buffer structure of a pipe inode (`pipe_inode_info`).\n\n2. The function takes parameters:\n   - `iov_iter *i`: an iterator for the data to be pushed.\n   - `size`: the amount of data to push.\n   - `iter_headp`, `offp`: output parameters for the starting buffer index and offset.\n\n3. The function first checks if `size` exceeds `i->count` (the total available data), and caps it accordingly. This prevents over-reading from the input.\n\n4. It then calls `data_start(i, &iter_head, &off)` to determine the starting buffer index and offset within the first buffer. This is correct and safe.\n\n5. The function handles a partial buffer (if `off` is non-zero) by:\n   - Subtracting the remaining space in the first page (`PAGE_SIZE - off`) from `left`.\n   - If `left` becomes non-positive, it updates the length of the first buffer and returns.\n   - Otherwise, it fully fills the first buffer and proceeds to the next.\n\n6. The main loop uses `pipe_full()` to check if the pipe is full. The condition `!pipe_full(iter_head, p_tail, pipe->max_usage)` ensures that we don\u2019t overflow the pipe.\n\n7. Inside the loop:\n   - A new page is allocated with `alloc_page(GFP_USER)`.\n   - If allocation fails (`!page`), the loop breaks, and the function returns the amount of data successfully pushed (`size - left`).\n   - The new buffer is initialized with `default_pipe_buf_ops`, zero flags, the allocated page, offset 0, and length set to `min(left, PAGE_SIZE)`.\n   - `left` is decremented by the amount written.\n   - `iter_head` is incremented, and `pipe->head` is updated.\n\n8. The function returns `size - left`, which is the total amount of data successfully pushed.\n\nNow, let\u2019s look for potential security vulnerabilities:\n\n- Buffer overflow: The code uses `iter_head & p_mask` to index into `pipe->bufs`, which is safe because `p_mask = pipe->ring_size - 1` (a power-of-2 minus one), so the bitwise AND ensures wrapping within bounds. This is a standard ring buffer idiom and is safe.\n\n- Use-after-free or dangling pointer: No such issues \u2014 pages are allocated and managed properly, and `pipe->bufs` are updated only with valid pointers.\n\n- Integer overflow: The `size` is capped at `i->count`, and `left` is decremented safely. The use of `min_t(ssize_t, left, PAGE_SIZE)` prevents negative values.\n\n- Memory allocation failure: The code checks `if (!page)` and breaks the loop, which is correct. It does not proceed with invalid memory, so no use of uninitialized or freed memory.\n\n- Off-by-one or boundary issues: The `pipe_full()` check ensures we don\u2019t exceed the maximum usage. The `iter_head` is only incremented when a buffer is successfully added, and `pipe->head` is updated accordingly.\n\n- No direct user input manipulation: The function operates on kernel data structures, and the input is validated via `i->count` and `data_start`.\n\nOverall, the code correctly manages the pipe buffer, handles edge cases (partial buffer, allocation failure), and avoids buffer overflows, use-after-free, or integer overflows.\n\n(2) NO: No security vulnerability."}
{"idx": 489215, "project": "linux-2.6", "commit_id": "efc7ffcb4237f8cb9938909041c4ed38f6e1bf40", "project_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6", "commit_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=efc7ffcb4237f8cb9938909041c4ed38f6e1bf40", "commit_message": "hfsplus: fix Buffer overflow with a corrupted image\n\nWhen an hfsplus image gets corrupted it might happen that the catalog\nnamelength field gets b0rked.  If we mount such an image the memcpy() in\nhfsplus_cat_build_key_uni() writes more than the 255 that fit in the name\nfield.  Depending on the size of the overwritten data, we either only get\nmemory corruption or also trigger an oops like this:\n\n[  221.628020] BUG: unable to handle kernel paging request at c82b0000\n[  221.629066] IP: [<c022d4b1>] hfsplus_find_cat+0x10d/0x151\n[  221.629066] *pde = 0ea29163 *pte = 082b0160\n[  221.629066] Oops: 0002 [#1] PREEMPT DEBUG_PAGEALLOC\n[  221.629066] Modules linked in:\n[  221.629066]\n[  221.629066] Pid: 4845, comm: mount Not tainted (2.6.27-rc4-00123-gd3ee1b4-dirty #28)\n[  221.629066] EIP: 0060:[<c022d4b1>] EFLAGS: 00010206 CPU: 0\n[  221.629066] EIP is at hfsplus_find_cat+0x10d/0x151\n[  221.629066] EAX: 00000029 EBX: 00016210 ECX: 000042c2 EDX: 00000002\n[  221.629066] ESI: c82d70ca EDI: c82b0000 EBP: c82d1bcc ESP: c82d199c\n[  221.629066]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 0068\n[  221.629066] Process mount (pid: 4845, ti=c82d1000 task=c8224060 task.ti=c82d1000)\n[  221.629066] Stack: c080b3c4 c82aa8f8 c82d19c2 00016210 c080b3be c82d1bd4 c82aa8f0 00000300\n[  221.629066]        01000000 750008b1 74006e00 74006900 65006c00 c82d6400 c013bd35 c8224060\n[  221.629066]        00000036 00000046 c82d19f0 00000082 c8224548 c8224060 00000036 c0d653cc\n[  221.629066] Call Trace:\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c0107aa3>] ? native_sched_clock+0x82/0x96\n[  221.629066]  [<c01302d2>] ? __kernel_text_address+0x1b/0x27\n[  221.629066]  [<c010487a>] ? dump_trace+0xca/0xd6\n[  221.629066]  [<c0109e32>] ? save_stack_address+0x0/0x2c\n[  221.629066]  [<c0109eaf>] ? save_stack_trace+0x1c/0x3a\n[  221.629066]  [<c013b571>] ? save_trace+0x37/0x8d\n[  221.629066]  [<c013b62e>] ? add_lock_to_list+0x67/0x8d\n[  221.629066]  [<c013ea1c>] ? validate_chain+0x8a4/0x9f4\n[  221.629066]  [<c013553d>] ? down+0xc/0x2f\n[  221.629066]  [<c013f1f6>] ? __lock_acquire+0x68a/0x6e0\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c0107aa3>] ? native_sched_clock+0x82/0x96\n[  221.629066]  [<c013da5d>] ? mark_held_locks+0x43/0x5a\n[  221.629066]  [<c013dc3a>] ? trace_hardirqs_on+0xb/0xd\n[  221.629066]  [<c013dbf4>] ? trace_hardirqs_on_caller+0xf4/0x12f\n[  221.629066]  [<c06abec8>] ? _spin_unlock_irqrestore+0x42/0x58\n[  221.629066]  [<c013555c>] ? down+0x2b/0x2f\n[  221.629066]  [<c022aa68>] ? hfsplus_iget+0xa0/0x154\n[  221.629066]  [<c022b0b9>] ? hfsplus_fill_super+0x280/0x447\n[  221.629066]  [<c0107aa3>] ? native_sched_clock+0x82/0x96\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013f1f6>] ? __lock_acquire+0x68a/0x6e0\n[  221.629066]  [<c041c9e4>] ? string+0x2b/0x74\n[  221.629066]  [<c041cd16>] ? vsnprintf+0x2e9/0x512\n[  221.629066]  [<c010487a>] ? dump_trace+0xca/0xd6\n[  221.629066]  [<c0109eaf>] ? save_stack_trace+0x1c/0x3a\n[  221.629066]  [<c0109eaf>] ? save_stack_trace+0x1c/0x3a\n[  221.629066]  [<c013b571>] ? save_trace+0x37/0x8d\n[  221.629066]  [<c013b62e>] ? add_lock_to_list+0x67/0x8d\n[  221.629066]  [<c013ea1c>] ? validate_chain+0x8a4/0x9f4\n[  221.629066]  [<c01354d3>] ? up+0xc/0x2f\n[  221.629066]  [<c013f1f6>] ? __lock_acquire+0x68a/0x6e0\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c013bca3>] ? trace_hardirqs_off_caller+0x14/0x9b\n[  221.629066]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[  221.629066]  [<c0107aa3>] ? native_sched_clock+0x82/0x96\n[  221.629066]  [<c041cfb7>] ? snprintf+0x1b/0x1d\n[  221.629066]  [<c01ba466>] ? disk_name+0x25/0x67\n[  221.629066]  [<c0183960>] ? get_sb_bdev+0xcd/0x10b\n[  221.629066]  [<c016ad92>] ? kstrdup+0x2a/0x4c\n[  221.629066]  [<c022a7b3>] ? hfsplus_get_sb+0x13/0x15\n[  221.629066]  [<c022ae39>] ? hfsplus_fill_super+0x0/0x447\n[  221.629066]  [<c0183583>] ? vfs_kern_mount+0x3b/0x76\n[  221.629066]  [<c0183602>] ? do_kern_mount+0x32/0xba\n[  221.629066]  [<c01960d4>] ? do_new_mount+0x46/0x74\n[  221.629066]  [<c0196277>] ? do_mount+0x175/0x193\n[  221.629066]  [<c013dbf4>] ? trace_hardirqs_on_caller+0xf4/0x12f\n[  221.629066]  [<c01663b2>] ? __get_free_pages+0x1e/0x24\n[  221.629066]  [<c06ac07b>] ? lock_kernel+0x19/0x8c\n[  221.629066]  [<c01962e6>] ? sys_mount+0x51/0x9b\n[  221.629066]  [<c01962f9>] ? sys_mount+0x64/0x9b\n[  221.629066]  [<c01038bd>] ? sysenter_do_call+0x12/0x31\n[  221.629066]  =======================\n[  221.629066] Code: 89 c2 c1 e2 08 c1 e8 08 09 c2 8b 85 e8 fd ff ff 66 89 50 06 89 c7 53 83 c7 08 56 57 68 c4 b3 80 c0 e8 8c 5c ef ff 89 d9 c1 e9 02 <f3> a5 89 d9 83 e1 03 74 02 f3 a4 83 c3 06 8b 95 e8 fd ff ff 0f\n[  221.629066] EIP: [<c022d4b1>] hfsplus_find_cat+0x10d/0x151 SS:ESP 0068:c82d199c\n[  221.629066] ---[ end trace e417a1d67f0d0066 ]---\n\nSince hfsplus_cat_build_key_uni() returns void and only has one callsite,\nthe check is performed at the callsite.\n\nSigned-off-by: Eric Sesterhenn <snakebyte@gmx.de>\nReviewed-by: Pekka Enberg <penberg@cs.helsinki.fi>\nCc: Roman Zippel <zippel@linux-m68k.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2008-4933", "cve_desc": "Buffer overflow in the hfsplus_find_cat function in fs/hfsplus/catalog.c in the Linux kernel before 2.6.28-rc1 allows attackers to cause a denial of service (memory corruption or system crash) via an hfsplus filesystem image with an invalid catalog namelength field, related to the hfsplus_cat_build_key_uni function.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `hfsplus_find_cat` is part of the HFS+ filesystem driver in the Linux kernel and is responsible for finding a catalog entry (file or folder) by its CNID (Catalog Node ID).\n\n2. The function first builds a search key using `hfsplus_cat_build_key` based on the CNID and prepares the `fd` structure for a catalog search.\n\n3. It then reads a catalog entry from the disk using `hfs_brec_read`, storing the result in `tmp` of type `hfsplus_cat_entry`. The size of the read is `sizeof(hfsplus_cat_entry)`, which is correct for the structure.\n\n4. The function checks the `type` field of the catalog entry. It ensures that the entry is either a folder thread (`HFSPLUS_FOLDER_THREAD`) or a file thread (`HFSPLUS_FILE_THREAD`). If not, it logs an error and returns `-EIO`. This is a valid sanity check to prevent processing malformed or unexpected entries.\n\n5. Next, it checks the `length` of the `nodeName` field: `if (be16_to_cpu(tmp.thread.nodeName.length) > 255)`. This is a critical check because the name length is stored in a 16-bit field (be16), and the maximum allowed length is 255 (typical for filename length limits in many filesystems). If the length exceeds 255, it logs an error and returns `-EIO`. This prevents potential buffer overflows when handling the name.\n\n6. The function then builds a new search key using `hfsplus_cat_build_key_uni`, based on the parent ID and the node name from the entry. This is used for a subsequent `hfs_brec_find` call.\n\n7. The key observation: The `nodeName` field is read from the disk via `hfs_brec_read`, and its length is validated before being used. The `hfsplus_cat_build_key_uni` function likely uses this length to safely copy the name into a key buffer. Since the length is checked and capped at 255, and the function uses proper endianness conversion (`be16_to_cpu`), there is no indication of unbounded copying or buffer overflow.\n\n8. The code does not perform any direct string copying without bounds checking. All access to the `nodeName` is preceded by a length check, and the use of `hfsplus_cat_build_key_uni` is assumed to be safe (as it's part of the kernel's HFS+ implementation and used consistently).\n\n9. There is no evidence of integer overflow, use-after-free, or improper memory access. The validation of the name length is sufficient to prevent buffer overflows.\n\n10. The function returns early on error conditions, which is good practice.\n\nConclusion: The code includes proper bounds checking on the `nodeName.length` field, and all subsequent operations are based on validated data. There is no indication of a buffer overflow, memory corruption, or other exploitable vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 232839, "project": "tensorflow", "commit_id": "8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992", "commit_message": "Ensure num_streams >= 0 in tf.raw_ops.BoostedTreesCreateQuantileStreamResource\n\nPiperOrigin-RevId: 387452765\nChange-Id: I9990c760e177fabca6a3b9b4612ceeaeeba51495", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2021-37661", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause a denial of service in `boosted_trees_create_quantile_stream_resource` by using negative arguments. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantile_ops.cc#L96) does not validate that `num_streams` only contains non-negative numbers. In turn, [this results in using this value to allocate memory](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h#L31-L40). However, `reserve` receives an unsigned integer so there is an implicit conversion from a negative value to a large positive unsigned. This results in a crash from the standard library. We have patched the issue in GitHub commit 8a84f7a2b5a2b27ecf88d25bad9ac777cd2f7992. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The code is part of a TensorFlow OpKernel implementation, specifically the `Compute` method, which processes input tensors and creates a resource (QuantileStreamResource).\n\n2. The function first retrieves an input tensor `epsilon_t` and extracts its scalar value as a float. It then checks that `epsilon > 0`, rejecting zero or negative values. This is a valid safety check to prevent potential performance issues or undefined behavior.\n\n3. Next, it retrieves `num_streams_t`, extracts its scalar value as `int64_t`, and ensures it is non-negative. This prevents negative stream counts, which would be invalid.\n\n4. It then creates a new `QuantileStreamResource` using the validated `epsilon`, `max_elements_` (assumed to be a member variable), and `num_streams`.\n\n5. The resource is registered using `CreateResource`, which associates it with a handle from input 0. The code checks the status of `CreateResource`:\n   - If the status is not OK and is not `ALREADY_EXISTS`, it triggers an error via `OP_REQUIRES(context, false, status)`.\n   - This means that if the resource already exists (i.e., a resource with the same handle is present), it is not treated as an error \u2014 which is expected behavior for idempotent resource creation.\n\n6. The key point: The code does not perform any input validation on the handle from `HandleFromInput(context, 0)` itself. However, `HandleFromInput` is a TensorFlow utility that safely extracts a handle from an input tensor, and `CreateResource` is designed to handle concurrent or duplicate creation attempts gracefully.\n\n7. The `OP_REQUIRES` with `false` in the error case is safe because it only triggers when the resource creation fails for reasons other than already existing. This is a standard pattern in TensorFlow to avoid overwriting existing resources while still reporting unexpected errors.\n\n8. There is no use of unsafe memory operations, buffer overflows, format string vulnerabilities, or direct user input injection into system calls or dynamic code execution.\n\n9. The input validation for `epsilon` and `num_streams` is sufficient and appropriate.\n\n10. The only potential concern could be if `max_elements_` is unbounded or could be set to an extremely large value, but that is not shown in the code snippet. However, since `max_elements_` is a member variable and not derived from user input, and no bounds checking is shown, this would only be a concern if it leads to uncontrolled memory allocation. But the code does not show such behavior, and the `QuantileStreamResource` constructor is assumed to handle its own internal limits.\n\n11. Overall, the code follows TensorFlow's best practices: input validation, safe resource creation, and proper error handling.\n\n(2) NO: No security vulnerability."}
{"idx": 384677, "project": "nbdkit", "commit_id": "6c5faac6a37077cf2366388a80862bb00616d0d8", "project_url": "https://github.com/libguestfs/nbdkit", "commit_url": "https://gitlab.com/nbdkit/nbdkit/-/commit/6c5faac6a37077cf2366388a80862bb00616d0d8", "commit_message": "server: reset meta context replies on starttls\n\nRelated to CVE-2021-3716, but not as severe.  No compliant client will\nsend NBD_CMD_BLOCK_STATUS unless it first negotiates\nNBD_OPT_SET_META_CONTEXT.  If an attacker injects a premature\nSET_META_CONTEXT, either the client will never notice (because it\nnever uses BLOCK_STATUS), or the client will overwrite the attacker's\nattempt with the client's own SET_META_CONTEXT request after\nencryption is enabled.  So I don't class this as having the potential\nto trigger denial-of-service due to any protocol mismatch between\ncompliant client and server (I don't care what happens with\nnon-compliant clients).\n\nFixes: 26455d45 (server: protocol: Implement Block Status \"base:allocation\".)", "ground_truth": 0, "cwe": ["CWE-924"], "cve": "CVE-2021-3716", "cve_desc": "A flaw was found in nbdkit due to to improperly caching plaintext state across the STARTTLS encryption boundary. A MitM attacker could use this flaw to inject a plaintext NBD_OPT_STRUCTURED_REPLY before proxying everything else a client sends to the server, potentially leading the client to terminate the NBD session. The highest threat from this vulnerability is to system availability.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there are any security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Buffer Handling\n\nThe function `negotiate_handshake_newstyle_options` handles incoming NBD (Network Block Device) protocol options from a client. It reads data via `conn_recv_full`, which is used to read a fixed-size header (`new_option`) and then variable-length data based on `optlen`.\n\n- `optlen` is read from the network and validated:\n  ```c\n  optlen = be32toh (new_option.optlen);\n  if (optlen > MAX_REQUEST_SIZE) {\n    nbdkit_error (\"client option data too long (%\" PRIu32 \")\", optlen);\n    return -1;\n  }\n  ```\n  This is a critical check: it limits the maximum allowed option length to `MAX_REQUEST_SIZE`, preventing unbounded memory allocation.\n\n- A buffer `data` is allocated with:\n  ```c\n  data = malloc (optlen + 1);\n  ```\n  This ensures space for the data and a trailing NUL byte (for safety in string handling), and is only done after validating `optlen` is within bounds.\n\n- The code uses `conn_recv_full` to read the full `optlen` bytes into `data`. This function is assumed to be safe and perform full reads (no partial reads), which is important for preventing under-reads.\n\n---\n\n### Step 2: Use of `memcpy` and Index Bounds Checking\n\nIn several cases, the code uses `memcpy` to extract fields from `data`:\n\n- Example:\n  ```c\n  memcpy (&exportnamelen, &data[0], 4);\n  exportnamelen = be32toh (exportnamelen);\n  if (exportnamelen > optlen - 6) { ... }\n  ```\n\n  This checks that `exportnamelen` does not exceed the available data length (`optlen - 6`), preventing buffer over-reads.\n\n- Similarly, when reading `nrinfos`, it checks:\n  ```c\n  if (optlen != 4 + exportnamelen + 2 + 2*nrinfos)\n  ```\n  This ensures the total length matches expected structure, preventing malformed data from causing out-of-bounds access.\n\n- In the `NBD_OPT_LIST_META_CONTEXT`/`NBD_OPT_SET_META_CONTEXT` section:\n  ```c\n  if (opt_index + 4 > optlen) goto opt_meta_invalid_option_len;\n  ```\n  This checks bounds before reading `querylen`, preventing buffer over-reads.\n\n- The `check_string` and `check_export_name` functions are used to validate strings. These are likely implemented to ensure null-termination and proper length, and are called before any use of the data.\n\n---\n\n### Step 3: Use of `strndup` and Memory Management\n\n- `strndup` is used to copy the export name:\n  ```c\n  conn->exportname_from_set_meta_context = strndup (&data[4], exportnamelen);\n  ```\n  This is safe because `exportnamelen` is validated earlier and `strndup` copies at most `exportnamelen` bytes, null-terminating safely.\n\n- `free` is used appropriately on `conn->exportname_from_set_meta_context` when reassigning or closing, preventing memory leaks.\n\n---\n\n### Step 4: Protocol-Level Security Checks\n\n- The code enforces strict protocol order:\n  - `NBD_OPT_EXPORT_NAME` or `NBD_OPT_GO` must be the last option.\n  - It breaks the loop when either is received, preventing further processing.\n\n- It enforces TLS requirements:\n  ```c\n  if (tls == 2 && !conn->using_tls) {\n    nbdkit_error (\"non-TLS client tried to connect in --tls=require mode\");\n    return -1;\n  }\n  ```\n  This ensures that in `--tls=require` mode, TLS is actually negotiated, preventing downgrade attacks.\n\n- It checks for duplicate `NBD_OPT_LIST`:\n  ```c\n  if (list_seen) { ... send NBD_REP_ERR_INVALID; continue; }\n  ```\n  Prevents replay or malformed sequences.\n\n- It validates that `NBD_OPT_STARTTLS` is not sent twice, and only allowed in appropriate modes.\n\n---\n\n### Step 5: Use of `send_newstyle_option_reply` and Error Handling\n\n- All replies are sent via `send_newstyle_option_reply`, which is assumed to be a safe wrapper that handles errors and returns `-1` on failure.\n\n- The code checks return values of all `send` and `recv` operations, and returns early on failure, preventing further processing of potentially invalid data.\n\n- The use of `CLEANUP_FREE` macro (implied) ensures that `data` is freed on exit, even in error paths.\n\n---\n\n### Step 6: No Use of Dangerous Functions\n\n- No use of `strcpy`, `strcat`, `sprintf`, `gets`, or other unsafe string functions.\n- No direct use of `memcpy` without bounds checks \u2014 all accesses are validated.\n- No format string vulnerabilities (no `printf` with user input).\n- No use of `eval`, `system`, or dynamic code execution.\n\n---\n\n### Step 7: Overall Security Controls\n\n- **Input validation**: All lengths are checked before use.\n- **Bounds checking**: All array accesses are validated.\n- **Memory safety**: No buffer overflows or underflows.\n- **Protocol enforcement**: Enforces correct order and state transitions.\n- **Error handling**: All errors are handled gracefully, with appropriate rejection and cleanup.\n- **TLS enforcement**: Prevents insecure connections in required modes.\n\n---\n\n### Conclusion\n\nThe code demonstrates strong defensive programming practices:\n- Input validation at every step.\n- Bounds checking before memory access.\n- Safe memory allocation and deallocation.\n- Protocol correctness enforcement.\n- Proper error handling and cleanup.\n\nThere are no detectable security vulnerabilities such as buffer overflows, use-after-free, integer overflows, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 445881, "project": "file-roller", "commit_id": "b147281293a8307808475e102a14857055f81631", "project_url": "https://git.gnome.org/browse/file-roller", "commit_url": "https://git.gnome.org/browse/file-roller/commit/?id=b147281293a8307808475e102a14857055f81631", "commit_message": "libarchive: sanitize filenames before extracting", "ground_truth": 0, "cwe": ["CWE-22"], "cve": "CVE-2013-4668", "cve_desc": "Directory traversal vulnerability in File Roller 3.6.x before 3.6.4, 3.8.x before 3.8.3, and 3.9.x before 3.9.3, when libarchive is used, allows remote attackers to create arbitrary files via a crafted archive that is not properly handled in a \"Keep directory structure\" action, related to fr-archive-libarchive.c and fr-window.c.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `_fr_window_ask_overwrite_dialog` is responsible for handling overwrite dialogs during file extraction in a GUI application (likely a file archiver).\n\n2) The function checks if:\n   - The overwrite mode is set to \"ask\" (FR_OVERWRITE_ASK)\n   - A current file is being processed (odata->current_file != NULL)\n\n3) If both conditions are true, it:\n   - Gets the relative basename of the current file using `_g_path_get_relative_basename_safe`\n   - Creates a GFile for the destination path\n   - Asynchronously queries file info using `g_file_query_info_async`\n   - Passes the callback `query_info_ready_for_overwrite_dialog_cb` with the odata context\n   - Unrefs the destination GFile\n\n4) The key security consideration is input validation and path handling:\n   - The function uses `_g_path_get_relative_basename_safe` which is designed to safely extract the basename from a path relative to a base directory, preventing path traversal attacks.\n   - The destination path is constructed using `g_file_get_child`, which properly handles path components and prevents directory traversal.\n   - The function does not directly use user input in string concatenation or system calls.\n   - The asynchronous file query is properly managed with cancellation and callback context.\n\n5) The function does not perform any dangerous operations like:\n   - Direct string concatenation of user input into paths\n   - Shell command execution\n   - Unvalidated file operations\n   - Buffer overflows\n\n6) The only potential concern is the use of `g_file_query_info_async` with user-controlled paths, but this is properly handled through the GFile abstraction which sanitizes paths and prevents traversal attacks.\n\n7) The function properly handles error cases and does not expose sensitive information.\n\n(2) NO: No security vulnerability."}
{"idx": 289293, "project": "linux", "commit_id": "8423f0b6d513b259fdab9c9bf4aaa6188d054c2d", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8423f0b6d513b259fdab9c9bf4aaa6188d054c2d", "commit_message": "ALSA: pcm: oss: Fix race at SNDCTL_DSP_SYNC\n\nThere is a small race window at snd_pcm_oss_sync() that is called from\nOSS PCM SNDCTL_DSP_SYNC ioctl; namely the function calls\nsnd_pcm_oss_make_ready() at first, then takes the params_lock mutex\nfor the rest.  When the stream is set up again by another thread\nbetween them, it leads to inconsistency, and may result in unexpected\nresults such as NULL dereference of OSS buffer as a fuzzer spotted\nrecently.\n\nThe fix is simply to cover snd_pcm_oss_make_ready() call into the same\nparams_lock mutex with snd_pcm_oss_make_ready_locked() variant.\n\nReported-and-tested-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Jaroslav Kysela <perex@perex.cz>\nCc: <stable@vger.kernel.org>\nLink: https://lore.kernel.org/r/CAFcO6XN7JDM4xSXGhtusQfS2mSBcx50VJKwQpCq=WeLt57aaZA@mail.gmail.com\nLink: https://lore.kernel.org/r/20220905060714.22549-1-tiwai@suse.de\nSigned-off-by: Takashi Iwai <tiwai@suse.de>", "ground_truth": 0, "cwe": ["CWE-362"], "cve": "CVE-2022-3303", "cve_desc": "A race condition flaw was found in the Linux kernel sound subsystem due to improper locking. It could lead to a NULL pointer dereference while handling the SNDCTL_DSP_SYNC ioctl. A privileged local user (root or member of the audio group) could use this flaw to crash the system, resulting in a denial of service condition", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - The function `snd_pcm_oss_sync` is part of an ALSA (Advanced Linux Sound Architecture) OSS (Open Sound System) compatibility layer.\n   - It synchronizes playback and capture streams by handling buffer management, silence filling, draining, and resetting state.\n   - It operates on PCM (Pulse Code Modulation) substreams and uses various ALSA internal structures.\n\n2. **Input Validation and Control Flow**:\n   - The function takes a single parameter: `pcm_oss_file`, which is a pointer to a structure containing PCM stream data.\n   - It checks for `NULL` substreams before accessing them (e.g., `if (substream != NULL)`), which prevents null pointer dereferences.\n   - It uses atomic operations (`atomic_read`, `atomic_inc`, `atomic_dec`) to manage reference counts safely, which is appropriate for concurrent access.\n\n3. **Mutex Usage**:\n   - The function uses `mutex_lock_interruptible` and `mutex_unlock` around critical sections (e.g., `runtime->oss.params_lock`), which prevents race conditions and ensures thread safety.\n   - The mutex is properly unlocked even in error paths (via `goto unlock`), so no deadlock or resource leak is apparent.\n\n4. **Buffer Handling and Memory Safety**:\n   - The function uses `snd_pcm_format_set_silence` to fill portions of the buffer with silence. This function is assumed to be safe and bounds-checked, as it operates on known buffer sizes (`runtime->oss.buffer_used`, `runtime->oss.period_bytes`, etc.).\n   - The size calculations use `runtime->period_size`, `runtime->oss.period_bytes`, and `runtime->oss.buffer_used`, all of which are controlled by the runtime configuration and validated earlier in the ALSA stack.\n   - The use of `size_t` and `unsigned long` for sizes is appropriate, and no arithmetic overflow is evident in the expressions (e.g., `(8 * (runtime->oss.period_bytes - runtime->oss.buffer_used) + 7) / width`), as `width` is derived from `snd_pcm_format_physical_width`, which is bounded.\n\n5. **Use of `snd_pcm_lib_write` and `snd_pcm_lib_writev`**:\n   - These functions are used to write silence into the buffer. They are part of the ALSA library and are designed to handle buffer boundaries safely.\n   - The `size` passed is derived from `runtime->period_size - size`, which is bounded by the period size, a known runtime parameter.\n\n6. **IOCTL Calls**:\n   - `snd_pcm_kernel_ioctl(substream, SNDRV_PCM_IOCTL_DRAIN, NULL)` and `SNDRV_PCM_IOCTL_DROP` are standard ALSA kernel interface calls.\n   - These are safe when called with valid substream pointers and are used to drain or drop data, which is a standard operation in audio stream management.\n\n7. **No User Input or External Data**:\n   - The function does not directly process user input or external data. All data comes from internal PCM runtime structures, which are managed by the kernel and validated by the ALSA core.\n   - There is no string formatting, memory copying with unbounded sizes, or direct user data injection.\n\n8. **Error Handling**:\n   - The function uses proper error propagation with `goto` labels (`unlock`, `__direct`) and ensures cleanup (mutex unlock, atomic decrement) even on error.\n   - No memory leaks or resource leaks are apparent.\n\n9. **Potential Concerns**:\n   - One might worry about integer overflow in size calculations (e.g., `8 * (runtime->oss.period_bytes - runtime->oss.buffer_used)`), but:\n     - `runtime->oss.period_bytes` is typically limited by the hardware buffer size (e.g., a few MB).\n     - `width` is at least 8 bits (1 byte), so division by `width` reduces the value.\n     - The expression `(8 * X + 7) / width` is safe as long as `X` is not excessively large, which is enforced by the ALSA runtime.\n   - No buffer overflows or out-of-bounds memory access is evident.\n\n10. **Conclusion**:\n   - The code is well-structured, uses proper synchronization, validates pointers, handles errors correctly, and operates on trusted internal data.\n   - There are no obvious security vulnerabilities such as buffer overflows, use-after-free, race conditions, or injection flaws.\n\n(2) NO: No security vulnerability."}
{"idx": 222737, "project": "pjproject", "commit_id": "f74c1fc22b760d2a24369aa72c74c4a9ab985859", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/f74c1fc22b760d2a24369aa72c74c4a9ab985859", "commit_message": "Merge pull request from GHSA-r374-qrwv-86hh", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2021-43845", "cve_desc": "PJSIP is a free and open source multimedia communication library. In version 2.11.1 and prior, if incoming RTCP XR message contain block, the data field is not checked against the received packet size, potentially resulting in an out-of-bound read access. This affects all users that use PJMEDIA and RTCP XR. A malicious actor can send a RTCP XR message with an invalid packet size.", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Input validation and bounds checking\n\nThe function `pjmedia_rtcp_xr_rx_rtcp_xr` processes a received RTCP XR packet (`pkt`) of size `size`. The function begins by casting the packet to a `pjmedia_rtcp_xr_pkt` structure and extracting the common header.\n\n- `rtcp_xr->common.pt != RTCP_XR` \u2192 early return if not a valid RTCP XR packet. This is good.\n- `pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);` \u2192 extracts the length field from the header, which is in network byte order.\n- The check `(pkt_len + 1) > (size / 4)` \u2192 this is intended to prevent parsing beyond the packet boundary. However, note:\n  - `size / 4` is integer division, so it truncates.\n  - The condition checks if `pkt_len + 1` exceeds `size / 4`. But `pkt_len` is in 32-bit words (as per RTCP spec), so the total length in bytes is `pkt_len * 4`.\n  - Therefore, the correct check should be: `pkt_len * 4 > size` or `pkt_len > size / 4`.\n  - But here, it's checking `(pkt_len + 1) > (size / 4)`, which is **incorrect** and **too lenient**.\n\nFor example:\n- If `size = 100`, then `size / 4 = 25`.\n- If `pkt_len = 26`, then `pkt_len + 1 = 27 > 25`, so it returns.\n- But `26 * 4 = 104 > 100`, so the packet is actually too long \u2014 but this check would **not** catch it because `26 + 1 = 27 > 25` \u2192 returns, which is correct in this case.\n\nWait \u2014 actually, `pkt_len` is the length in 32-bit words (as per RTCP spec), so the total length in bytes is `pkt_len * 4`. So the correct check should be:\n```c\nif (pkt_len * 4 > size) return;\n```\nBut the code does:\n```c\nif ((pkt_len + 1) > (size / 4)) return;\n```\n\nLet\u2019s test with `size = 100`:\n- `size / 4 = 25`\n- `pkt_len = 25` \u2192 `pkt_len + 1 = 26 > 25` \u2192 returns \u2192 but `25 * 4 = 100`, which is exactly the size \u2192 should be allowed.\n- So this condition **rejects valid packets**.\n\nBut more importantly, consider `pkt_len = 26`, `size = 100`:\n- `pkt_len * 4 = 104 > 100` \u2192 invalid.\n- `pkt_len + 1 = 27`, `size / 4 = 25` \u2192 27 > 25 \u2192 returns \u2192 correct.\n\nBut what if `size = 103`?\n- `size / 4 = 25`\n- `pkt_len = 26` \u2192 `26 + 1 = 27 > 25` \u2192 returns \u2192 but `26 * 4 = 104 > 103` \u2192 invalid \u2192 so it's safe.\n\nWait \u2014 actually, the condition `(pkt_len + 1) > (size / 4)` is **not equivalent** to `pkt_len * 4 > size`.\n\nLet\u2019s solve:\n- We want: `pkt_len * 4 > size` \u2192 `pkt_len > size / 4`\n- But the code checks: `pkt_len + 1 > size / 4` \u2192 `pkt_len > size / 4 - 1`\n\nSo the code allows `pkt_len = floor(size / 4)` even if `pkt_len * 4 > size`, because:\n- If `size = 100`, `size / 4 = 25`, so `pkt_len = 25` \u2192 `25 + 1 = 26 > 25` \u2192 returns \u2192 but `25 * 4 = 100` \u2192 valid.\n- But if `size = 101`, `size / 4 = 25`, `pkt_len = 25` \u2192 `26 > 25` \u2192 returns \u2192 but `25 * 4 = 100 \u2264 101` \u2192 valid \u2192 so it **rejects a valid packet**.\n\nThis is a **false positive** \u2014 it rejects valid packets. But is it a security vulnerability?\n\nNo \u2014 it's a **bug**, but not a security vulnerability per se, because it only causes packet rejection, not memory corruption.\n\nBut more importantly: **the code does not validate that the packet length is within bounds before parsing**. The `pkt_len` is used to control the loop, but the loop uses:\n```c\nwhile ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n```\nThis is **correct** \u2014 it ensures we don\u2019t read beyond `pkt_len` words.\n\nBut the **real issue** is in the **block parsing**.\n\n---\n\n### Step 2: Block parsing and buffer overflow risk\n\nInside the loop:\n```c\nrb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);\n```\nThen:\n```c\nif ((char*)rb_hdr + sizeof(*rb_rr_time) <= (char*)pkt + size)\n```\nThis checks if the entire `rb_rr_time` structure fits within the packet.\n\nBut note: `rb_len` is the length of the block in 32-bit words. So the total size of the block is `rb_len * 4`.\n\nBut the code only checks:\n```c\n(char*)rb_hdr + sizeof(*rb_rr_time) <= (char*)pkt + size\n```\nThis only checks if the **first structure** fits \u2014 but the block may be longer than `sizeof(*rb_rr_time)`.\n\nFor example:\n- `rb_hdr->length = 10` \u2192 block is 40 bytes.\n- But `sizeof(*rb_rr_time) = 16` \u2192 so the check passes.\n- But if the actual packet is only 20 bytes long, then `rb_hdr + 16` is still within bounds, but `rb_hdr + 40` is not.\n\nSo the check is **insufficient** \u2014 it only checks the size of the header, not the full block.\n\nThis is a **critical flaw**.\n\nThe correct check should be:\n```c\nif ((char*)rb_hdr + (rb_len * 4) <= (char*)pkt + size)\n```\nBut the code only checks:\n```c\nif ((char*)rb_hdr + sizeof(*rb_rr_time) <= (char*)pkt + size)\n```\nThis means:\n- If `rb_len` is large (e.g., 1000), but the packet is only 100 bytes, the check may pass (if `sizeof(*rb_rr_time) = 16` and `pkt + size` is 100, and `rb_hdr + 16` is within bounds), but then the code proceeds to read `rb_hdr` as `rb_rr_time`, which may access memory beyond the packet.\n\nBut wait \u2014 the code does:\n```c\nrb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*)rb_hdr;\n```\nThis is a **type cast**, not a read. But later, it uses:\n```c\nsess->rx_lrr = ((pj_ntohl(rb_rr_time->ntp_sec) & 0x0000FFFF) << 16) | \n               ((pj_ntohl(rb_rr_time->ntp_frac) >> 16) & 0xFFFF);\n```\nThis **reads** from `rb_rr_time->ntp_sec` and `rb_rr_time->ntp_frac`.\n\nIf the block is longer than the packet, but the first few bytes are within bounds, this **could** read past the end of the packet.\n\nBut the **real problem** is that the code **does not validate the full block size**.\n\nEven worse: the loop advances:\n```c\nrb_hdr = (pjmedia_rtcp_xr_rb_header*)\n         ((pj_int32_t*)rb_hdr + rb_len + 1);\n```\nThis assumes that the block is `rb_len` words long, and adds `rb_len + 1` to the pointer.\n\nBut if `rb_len` is maliciously large (e.g., 0xFFFF), and the packet is small, this could cause:\n- `rb_hdr + rb_len + 1` to point far beyond the packet.\n- But the loop condition is:\n  ```c\n  (pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len\n  ```\n  So it will stop if `rb_hdr` exceeds `pkt + pkt_len`.\n\nBut `pkt_len` is derived from the packet header \u2014 so if the packet is forged to have a large `pkt_len`, then the loop may run longer than intended.\n\nBut the **first check** is:\n```c\nif ((pkt_len + 1) > (size / 4)) return;\n```\nThis is **weak** \u2014 as we saw, it doesn't prevent `pkt_len` from being too large.\n\nFor example:\n- `size = 100` \u2192 `size / 4 = 25`\n- `pkt_len = 100` \u2192 `100 + 1 = 101 > 25` \u2192 returns \u2192 so it's safe.\n\nBut if `size = 1000`, `size / 4 = 250`, `pkt_len = 251` \u2192 `252 > 250` \u2192 returns.\n\nSo the check **does** prevent `pkt_len` from being too large relative to `size`.\n\nBut what if `pkt_len` is 1000, `size = 4000` \u2192 `size / 4 = 1000`, `pkt_len + 1 = 1001 > 1000` \u2192 returns.\n\nSo the check is actually **correct** in preventing `pkt_len` from being too large.\n\nBut the **block-level check** is still **inadequate**.\n\nThe code checks:\n```c\nif ((char*)rb_hdr + sizeof(*rb_rr_time) <= (char*)pkt + size)\n```\nBut the block may be longer than `sizeof(*rb_rr_time)`.\n\nFor example:\n- `rb_hdr->length = 10` \u2192 block is 40 bytes.\n- `sizeof(*rb_rr_time) = 16` \u2192 so `rb_hdr + 16` is within the packet (if packet is 100 bytes), but `rb_hdr + 40` may be beyond.\n\nBut the code **does not check** that the full block fits.\n\nSo if the packet is only 30 bytes long, and `rb_hdr` points to a block with `length = 10`, the code will:\n- Check `rb_hdr + 16 <= pkt + 30` \u2192 true (if `rb_hdr` is at offset 0, then `16 <= 30` \u2192 true).\n- Then cast `rb_hdr` to `rb_rr_time` and read `ntp_sec` and `ntp_frac` \u2014 which are at offset 0 and 4 \u2014 both within 30 bytes.\n- But the block is 40 bytes long \u2014 so the next block may be corrupted, but the code doesn't read beyond the first 16 bytes.\n\nWait \u2014 the code only reads the first few fields of the block. It does not read the entire block.\n\nSo even if the block is longer than the packet, as long as the **first few fields** are within bounds, it may not crash.\n\nBut the **real danger** is that `rb_len` is used to advance the pointer:\n```c\nrb_hdr = (pjmedia_rtcp_xr_rb_header*)\n         ((pj_int32_t*)rb_hdr + rb_len + 1);\n```\nThis adds `rb_len + 1` to the pointer.\n\nIf `rb_len` is very large (e.g., 0xFFFF), and the packet is small, this could cause:\n- `rb_hdr` to point far beyond the packet.\n- But the loop condition is:\n  ```c\n  (pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len\n  ```\n  So if `pkt_len` is large, the loop may continue.\n\nBut `pkt_len` is limited by the earlier check: `(pkt_len + 1) > (size / 4)` \u2192 so `pkt_len` cannot be larger than `size / 4`.\n\nBut `size` is the actual packet size \u2014 so `pkt_len` is bounded.\n\nSo the loop will not run forever.\n\nBut the **critical issue** is: **the code does not validate that the block size (rb_len) is reasonable**.\n\nFor example, if `rb_len` is 1000, and the packet is only 100 bytes, then:\n- The check `rb_hdr + sizeof(*rb_rr_time) <= pkt + size` may pass (if `rb_hdr` is near the start).\n- But then the code reads `rb_rr_time->ntp_sec` \u2014 which is at offset 0 \u2014 so it's safe.\n- But the pointer is advanced by `rb_len + 1 = 1001` words \u2192 4004 bytes \u2192 which may be far beyond the packet.\n\nBut the loop condition is:\n```c\n(pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len\n```\nSo if `pkt_len` is 100, then `pkt + pkt_len` is at offset 400 bytes (since `pkt_len` is in 32-bit words).\n\nSo if `rb_hdr` is at offset 0, and we add 1001 words (4004 bytes), it will be far beyond `pkt + pkt_len`, so the loop will stop.\n\nSo no infinite loop.\n\nBut the **real problem** is that the code **does not validate the block size against the packet size**.\n\nIt only checks if the **first structure** fits \u2014 but the block may be longer than the packet.\n\nHowever, since the code only reads a few fields from the block (e.g., `ntp_sec`, `ntp_frac`), and those are at the beginning, it may not cause a buffer overflow.\n\nBut what if the block is malformed and `rb_len` is huge? The pointer arithmetic may cause a **wraparound** or **underflow**?\n\nFor example, if `rb_hdr` is near the end of the packet, and `rb_len` is large, then `rb_hdr + rb_len + 1` may wrap around to a small address.\n\nBut `rb_hdr` is a pointer to `pjmedia_rtcp_xr_rb_header`, and `rb_len` is from `rb_hdr->length`, which is a 16-bit field.\n\nSo `rb_len` is at most 0xFFFF = 65535.\n\nSo `rb_hdr + rb_len + 1` is at most `rb_hdr + 65536` \u2192 which is safe in 32-bit systems.\n\nBut if `rb_hdr` is near the end of the packet, and `rb_len` is large, it may point to invalid memory.\n\nBut the loop condition prevents infinite iteration.\n\nSo no buffer overflow in the loop.\n\nBut the **real vulnerability** is in the **block size validation**.\n\nThe code should check:\n```c\nif ((char*)rb_hdr + (rb_len * 4) > (char*)pkt + size)\n    continue; // skip invalid block\n```\nBut it doesn't.\n\nSo if a block is longer than the packet, the code may still process it, but only read the first few fields.\n\nBut since it only reads `ntp_sec` and `ntp_frac`, which are at the start, it's safe.\n\nBut what if the block is shorter than expected? That's not a problem.\n\nThe **main issue** is that the code **does not validate the block size against the packet size**, which could allow an attacker to craft a packet where a block appears valid but is actually longer than the packet, leading to **undefined behavior**.\n\nBut in this case, since the code only reads the first few fields, and the pointer arithmetic is bounded by `pkt_len`, it may not cause a crash.\n\nHowever, **this is a classic example of a missing bounds check**.\n\nMoreover, the `rb_len` is used to advance the pointer, and if `rb_len` is very large, it could cause a **denial of service** by making the loop run many times, but the loop is bounded by `pkt_len`.\n\nBut `pkt_len` is limited by the earlier check.\n\nSo the **most serious issue** is that the code **does not validate that the block size (in bytes) is less than or equal to the remaining packet size**.\n\nThis is a **security vulnerability** because:\n- An attacker can send a packet with a large `rb_len` and a small block size.\n- The code may read past the end of the packet if it tries to access fields beyond the first few.\n- But in this code, it only reads `ntp_sec` and `ntp_frac`, which are at the beginning.\n\nBut what if the structure is not `rb_rr_time` but `rb_dlrr`? The code checks:\n```c\nif ((char*)rb_hdr + sizeof(*rb_dlrr) <= (char*)pkt + size)\n```\nSame issue.\n\nBut the code only reads `lrr` and `dlrr`, which are at the beginning.\n\nSo it's **safe**.\n\nBut the **real vulnerability** is that the code **does not validate the block size against the packet size**, which could lead to **memory corruption** if the code ever reads beyond the first few fields.\n\nBut in this code, it doesn't.\n\nHowever, the **lack of proper bounds checking** is a **security anti-pattern**.\n\nMoreover, the **initial check** `(pkt_len + 1) > (size / 4)` is **incorrect** \u2014 it should be `pkt_len > size / 4`.\n\nBut it's not a direct vulnerability.\n\nAfter careful analysis, the code:\n- Validates the packet type.\n- Uses `pkt_len` to bound the loop.\n- Checks that the block header fits in the packet.\n- But does **not** check that the full block fits in the packet.\n\nThis is a **missing bounds check** and could lead to **undefined behavior** if the code ever reads beyond the first few fields.\n\nBut in this specific code, it only reads the first few fields.\n\nSo **no buffer overflow** occurs.\n\nBut the **design is flawed**.\n\nHowever, since no actual memory corruption or information disclosure occurs, and the code is defensive in other ways, it may not be a **security vulnerability**.\n\nBut let's consider: if an attacker sends a packet with a block that has `rb_len = 1000`, but the packet is only 100 bytes, the code will:\n- Check `rb_hdr + sizeof(*rb_rr_time) <= pkt + size` \u2192 may pass.\n- Read `ntp_sec` and `ntp_frac` \u2192 safe.\n- Advance pointer by `rb_len + 1` \u2192 may go beyond the packet, but the loop condition prevents infinite iteration.\n\nSo no crash.\n\nTherefore, **no security vulnerability** is present.\n\n---\n\n### Final Decision\n\nAfter careful analysis, the code has **no buffer overflow**, **no memory corruption**, and **no information disclosure**. The bounds checks, while not perfect, are sufficient to prevent exploitation in this context.\n\n(2) NO: No security vulnerability."}
{"idx": 453109, "project": "libexpat", "commit_id": "a2fe525e660badd64b6c557c2b1ec26ddc07f6e4", "project_url": "https://github.com/libexpat/libexpat", "commit_url": "https://github.com/libexpat/libexpat/commit/a2fe525e660badd64b6c557c2b1ec26ddc07f6e4", "commit_message": "lib: Protect against malicious namespace declarations (CVE-2022-25236)", "ground_truth": 0, "cwe": ["CWE-668"], "cve": "CVE-2022-25236", "cve_desc": "xmlparse.c in Expat (aka libexpat) before 2.4.5 allows attackers to insert namespace-separator characters into namespace URIs.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `addBinding` is part of the Expat XML parser and is responsible for:\n- Adding a namespace binding (URI to prefix mapping) during XML parsing.\n- Validating namespace URIs against known reserved prefixes (like `xml` and `xmlns`).\n- Allocating memory for the URI string in a `BINDING` structure.\n- Handling namespace separator characters to prevent ambiguity.\n\nIt takes parameters:\n- `parser`: the XML parser context.\n- `prefix`: the namespace prefix being bound.\n- `attId`: attribute ID (if this binding is from an attribute).\n- `uri`: the namespace URI string.\n- `bindingsPtr`: pointer to a list of bindings (linked list).\n\n---\n\n### Step 2: Check for buffer overflows or memory corruption\nThe function dynamically allocates memory for `b->uri` using `MALLOC` or `REALLOC`, based on the length of `uri` plus `EXPAND_SPARE`.\n\nKey points:\n- `len` is computed as the length of `uri` (via `for` loop).\n- Memory allocation is done with: `sizeof(XML_Char) * (len + EXPAND_SPARE)`.\n- There are **two integer overflow checks**:\n  - `if (len > INT_MAX - EXPAND_SPARE)` \u2192 prevents overflow in `len + EXPAND_SPARE`.\n  - A second check using `#if UINT_MAX >= SIZE_MAX` to ensure `(unsigned)(len + EXPAND_SPARE) <= (size_t)(-1) / sizeof(XML_Char)` \u2192 prevents overflow in the multiplication.\n\nThese checks are **robust** and prevent integer overflow during memory allocation, which is a common source of buffer overflows.\n\nAlso, `memcpy(b->uri, uri, len * sizeof(XML_Char))` copies exactly `len` characters \u2014 no overflow here because `len` is the actual length of `uri`.\n\n---\n\n### Step 3: Check for improper input validation\nThe function performs several validations:\n- Rejects binding `xmlns` prefix (reserved).\n- Rejects `xml` prefix if not exactly `xml` (must be exactly `xml`).\n- Checks that `uri` matches known namespace URIs (`xmlNamespace` and `xmlnsNamespace`) for reserved prefixes.\n- Rejects any `uri` containing the `parser->m_namespaceSeparator` character (e.g., `:`), which prevents ambiguity in parsing namespace-qualified names.\n\nThis is **critical** for preventing:\n- Namespace injection attacks.\n- Ambiguity in tag name parsing (e.g., `prefix:local` vs `prefix:local:other`).\n\nThe check `if (parser->m_ns && (uri[len] == parser->m_namespaceSeparator))` is **correct** and prevents attackers from injecting a namespace separator into the URI, which could otherwise be exploited to confuse the parser.\n\n---\n\n### Step 4: Check for use-after-free or dangling pointers\nThe function manages a free list (`parser->m_freeBindingList`) and reuses memory when possible. It correctly updates `b->nextTagBinding` and `*bindingsPtr` to maintain the linked list. No dangling pointer issues are evident.\n\n---\n\n### Step 5: Check for improper null termination\n- `b->uriLen = len;` \u2192 correct length.\n- `memcpy` copies `len` characters, and then:\n  - If `parser->m_namespaceSeparator` is set, it overwrites the last character of `uri` with the separator.\n  - But note: `b->uri` is allocated with `len + EXPAND_SPARE`, so there is room for the separator and null termination.\n\nHowever, **there is no explicit null termination** after the `memcpy` or after the separator assignment.\n\nWait \u2014 this is **critical**.\n\nAfter:\n```c\nmemcpy(b->uri, uri, len * sizeof(XML_Char));\nif (parser->m_namespaceSeparator)\n  b->uri[len - 1] = parser->m_namespaceSeparator;\n```\n\nThe code **does not null-terminate** `b->uri`. But `b->uriLen` is set to `len`, and the `parser` uses `b->uriLen` to know the length. So if the parser uses `b->uriLen` to read the string, it's safe.\n\nBut: **Is `b->uri` used in a context that expects null-termination?**\n\nLooking at the code:\n- The `uri` is later passed to `parser->m_startNamespaceDeclHandler` as `uri` or `0`.\n- The handler receives `uri` only if `prefix->binding` is non-NULL.\n- The `uri` is not passed to any function that assumes null-termination (e.g., `strcpy`, `strlen`).\n\nMoreover, the `uri` is used in comparisons like:\n```c\nif (len > xmlLen || uri[len] != xmlNamespace[len])\n```\nThis uses `len` as a length, not relying on null termination.\n\nSo **even though `b->uri` is not null-terminated, it is not used in a way that requires null termination**.\n\nThus, this is **not a vulnerability** \u2014 it's a design choice to avoid null termination when length is tracked separately.\n\n---\n\n### Step 6: Check for other vulnerabilities\n- No use of unsafe string functions (like `strcpy`, `strcat`).\n- No format string vulnerabilities.\n- No use of `eval`, `system`, or dynamic code execution.\n- All memory allocations are bounded and checked for overflow.\n\n---\n\n### Conclusion\nThe code:\n- Properly validates namespace URIs.\n- Prevents reserved prefix binding.\n- Prevents injection of namespace separators.\n- Performs robust integer overflow checks.\n- Uses length-based string handling instead of null-terminated strings where appropriate.\n- Avoids buffer overflows and memory corruption.\n\nNo security vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 221413, "project": "linux", "commit_id": "c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc", "commit_message": "KVM: nSVM: always intercept VMLOAD/VMSAVE when nested (CVE-2021-3656)\n\nIf L1 disables VMLOAD/VMSAVE intercepts, and doesn't enable\nVirtual VMLOAD/VMSAVE (currently not supported for the nested hypervisor),\nthen VMLOAD/VMSAVE must operate on the L1 physical memory, which is only\npossible by making L0 intercept these instructions.\n\nFailure to do so allowed the nested guest to run VMLOAD/VMSAVE unintercepted,\nand thus read/write portions of the host physical memory.\n\nFixes: 89c8a4984fc9 (\"KVM: SVM: Enable Virtual VMLOAD VMSAVE feature\")\n\nSuggested-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Maxim Levitsky <mlevitsk@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>", "ground_truth": 0, "cwe": ["CWE-862"], "cve": "CVE-2021-3656", "cve_desc": "A flaw was found in the KVM's AMD code for supporting SVM nested virtualization. The flaw occurs when processing the VMCB (virtual machine control block) provided by the L1 guest to spawn/handle a nested guest (L2). Due to improper validation of the \"virt_ext\" field, this issue could allow a malicious L1 to disable both VMLOAD/VMSAVE intercepts and VLS (Virtual VMLOAD/VMSAVE) for the L2 guest. As a result, the L2 guest would be allowed to read/write physical pages of the host, resulting in a crash of the entire system, leak of sensitive data or potential guest-to-host escape.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `recalc_intercepts` is responsible for recalculating intercepts in a nested virtualization environment (SVM - Secure Virtual Machine) for AMD processors.\n\n2) The function first marks the VMCB (Virtual Machine Control Block) as dirty for intercepts, which is a standard practice to ensure changes are reflected in the hardware.\n\n3) It checks if the current mode is guest mode using `is_guest_mode(&svm->vcpu)`. If not in guest mode, it returns early. This is a valid safety check.\n\n4) The function then copies intercepts from the L1 (host) VMCB (`h->intercepts`) to the L2 (nested guest) VMCB (`c->intercepts`). This is correct for nested virtualization.\n\n5) It then conditionally clears certain intercepts based on the nested guest's control settings:\n   - Clears CR8 read/write intercepts if the nested guest has interrupt masking enabled.\n   - Clears VINTR (virtual interrupt) intercept if the nested guest has HF_VINTR_MASK set.\n   - Clears VMMCALL intercept to prevent nested guest from making VMMCALLs.\n\n6) After clearing, it ORs in the nested guest's intercepts (`g->intercepts[i]`) into the final intercepts.\n\n7) It conditionally clears SMI intercept if `intercept_smi` is false.\n\n8) Finally, it explicitly sets intercepts for VMLOAD and VMSAVE.\n\n9) Key security considerations:\n   - The function correctly handles nested virtualization by combining L1 and L2 intercepts.\n   - It properly clears intercepts that should not be passed through to the nested guest (e.g., VMMCALL).\n   - The use of `vmcb_clr_intercept` and `vmcb_set_intercept` functions suggests they are properly implemented to avoid overflow or invalid operations.\n   - There is no direct buffer overflow, out-of-bounds access, or untrusted input manipulation.\n   - The loop over `MAX_INTERCEPT` is bounded and safe.\n   - All operations are on well-defined control structures with proper validation.\n\n10) The function appears to be correctly implementing the security policy for nested virtualization: only allowing intercepts that are explicitly permitted, and blocking potentially dangerous ones (like VMMCALL) from reaching the nested guest.\n\n(2) NO: No security vulnerability."}
{"idx": 346415, "project": "vim", "commit_id": "4748c4bd64610cf943a431d215bb1aad51f8d0b4", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/4748c4bd64610cf943a431d215bb1aad51f8d0b4", "commit_message": "patch 8.2.4974: \":so\" command may read after end of buffer\n\nProblem:    \":so\" command may read after end of buffer.\nSolution:   Compute length of text properly.", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-1769", "cve_desc": "Buffer Over-read in GitHub repository vim/vim prior to 8.2.4974.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Function Purpose**: The function `get_one_sourceline` reads a line from a source file or buffer (used in Vim for sourcing scripts). It uses a growable array (`garray_T`) to accumulate the line content.\n\n2. **Buffer Management**:\n   - `ga_init2(&ga, 1, 250);` initializes a growable array with initial size 1 and maximum growth step 250.\n   - `ga_grow(&ga, 120)` is used to ensure space for at least 120 more characters before reading.\n   - The buffer is managed via `ga.ga_data`, `ga.ga_len`, and `ga.ga_maxlen`.\n\n3. **Input Source**:\n   - The input comes from either a file (`sp->fp`) via `fgets`, or from a buffer (`sp->buflines`) via direct concatenation.\n   - In the file case: `fgets((char *)buf + ga.ga_len, ga.ga_maxlen - ga.ga_len, sp->fp)` is used. This ensures that `fgets` does not write beyond the allocated buffer size, as it limits the number of characters read to `ga.ga_maxlen - ga.ga_len`.\n\n4. **Null Termination**:\n   - After `fgets`, the code sets `buf[ga.ga_len] = NUL` only after ensuring space (via `ga_grow`), and then updates `len = ga.ga_len + STRLEN(buf + ga.ga_len)`.\n   - Later, when a newline is found, `buf[len - 1] = NUL` is used to null-terminate the line.\n   - The code carefully ensures null termination at the end of the line, and only after checking that the buffer has space.\n\n5. **Line Length Handling**:\n   - If the line is longer than the buffer and doesn't end with a newline, the loop continues to read more (via `continue`).\n   - This is safe because `ga_grow` is called before each read, and `fgets` is bounded by the available space.\n\n6. **Escape Handling**:\n   - The code handles escaped newlines (e.g., `^V` before `\\n`) by checking the parity of the number of `^V` characters before the newline.\n   - This is a correct and safe way to handle escaped newlines without buffer overflow.\n\n7. **Security Considerations**:\n   - No direct string concatenation with untrusted input without bounds checking.\n   - All input is read via `fgets` with proper size limits.\n   - The growable array (`garray_T`) is used correctly with `ga_grow` to prevent overflow.\n   - The code explicitly checks for buffer overflow conditions (e.g., `ga_grow` returns `FAIL`).\n   - The `buf` pointer is always within the bounds of `ga.ga_data`, and `ga.ga_len` is updated safely.\n\n8. **Potential Risks**:\n   - Could there be a buffer overflow if `ga_grow` fails? No \u2014 the code checks `ga_grow` return value and breaks if it fails, preventing further use of the buffer.\n   - Could `STRLEN(buf + ga.ga_len)` cause overflow? No \u2014 `buf + ga.ga_len` points to the start of the newly read data, and `STRLEN` is safe as long as the data is null-terminated. But `fgets` ensures null termination if the buffer is large enough, and the code checks `ga_grow` before `fgets`, so the buffer has space for the null terminator.\n\n9. **Conclusion**:\n   - The code uses safe practices: bounded reads (`fgets` with size limit), growable arrays with bounds checking, proper null termination, and careful handling of line endings and escape sequences.\n   - There is no evidence of buffer overflow, format string vulnerability, or unsafe string manipulation.\n   - The function correctly handles edge cases like long lines, escaped newlines, and file format detection.\n\n(2) NO: No security vulnerability."}
{"idx": 472123, "project": "linux", "commit_id": "3b0462726e7ef281c35a7a4ae33e93ee2bc9975b", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/3b0462726e7ef281c35a7a4ae33e93ee2bc9975b", "commit_message": "cgroup: verify that source is a string\n\nThe following sequence can be used to trigger a UAF:\n\n    int fscontext_fd = fsopen(\"cgroup\");\n    int fd_null = open(\"/dev/null, O_RDONLY);\n    int fsconfig(fscontext_fd, FSCONFIG_SET_FD, \"source\", fd_null);\n    close_range(3, ~0U, 0);\n\nThe cgroup v1 specific fs parser expects a string for the \"source\"\nparameter.  However, it is perfectly legitimate to e.g.  specify a file\ndescriptor for the \"source\" parameter.  The fs parser doesn't know what\na filesystem allows there.  So it's a bug to assume that \"source\" is\nalways of type fs_value_is_string when it can reasonably also be\nfs_value_is_file.\n\nThis assumption in the cgroup code causes a UAF because struct\nfs_parameter uses a union for the actual value.  Access to that union is\nguarded by the param->type member.  Since the cgroup paramter parser\ndidn't check param->type but unconditionally moved param->string into\nfc->source a close on the fscontext_fd would trigger a UAF during\nput_fs_context() which frees fc->source thereby freeing the file stashed\nin param->file causing a UAF during a close of the fd_null.\n\nFix this by verifying that param->type is actually a string and report\nan error if not.\n\nIn follow up patches I'll add a new generic helper that can be used here\nand by other filesystems instead of this error-prone copy-pasta fix.\nBut fixing it in here first makes backporting a it to stable a lot\neasier.\n\nFixes: 8d2451f4994f (\"cgroup1: switch to option-by-option parsing\")\nReported-by: syzbot+283ce5a46486d6acdbaf@syzkaller.appspotmail.com\nCc: Christoph Hellwig <hch@lst.de>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Dmitry Vyukov <dvyukov@google.com>\nCc: <stable@kernel.org>\nCc: syzkaller-bugs <syzkaller-bugs@googlegroups.com>\nSigned-off-by: Christian Brauner <christian.brauner@ubuntu.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2021-4154", "cve_desc": "A use-after-free flaw was found in cgroup1_parse_param in kernel/cgroup/cgroup-v1.c in the Linux kernel's cgroup v1 parser. A local attacker with a user privilege could cause a privilege escalation by exploiting the fsconfig syscall parameter leading to a container breakout and a denial of service on the system.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `cgroup1_parse_param` is responsible for parsing filesystem parameters for the cgroup v1 filesystem context.\n\n2. The function first attempts to parse the parameter using `fs_parse`, which returns an option code. If `opt == -ENOPARAM`, it means the parameter is not a known option, so the code handles it as a special case.\n\n3. In the `opt == -ENOPARAM` block:\n   - It checks if the parameter key is \"source\". If so, it validates that the value is a string, ensures only one source is specified (no duplicate sources), and assigns the string to `fc->source`. It then nulls out `param->string` to prevent double-free or use-after-free.\n   - Then it iterates over all cgroup subsystems using `for_each_subsys(ss, i)` to check if the parameter key matches any subsystem's legacy name.\n   - If a match is found, it checks if the subsystem is enabled and not disabled via `cgroup1_ssid_disabled(i)`. If valid, it sets the corresponding bit in `ctx->subsys_mask`.\n   - If no match is found, it returns an error for unknown subsystem name.\n\n4. The code then handles known options via a switch statement:\n   - `Opt_none`: sets `ctx->none = true` \u2014 this disables all subsystems.\n   - `Opt_all`: sets `ctx->all_ss = true` \u2014 enables all subsystems.\n   - `Opt_noprefix`, `Opt_clone_children`, `Opt_cpuset_v2_mode`, `Opt_xattr`: set corresponding flags.\n   - `Opt_release_agent`: checks if a release agent is already set; if so, rejects duplicate. Otherwise, assigns the string and nulls `param->string`.\n   - `Opt_name`: performs several validations:\n     - Checks if named cgroups are disabled (`cgroup_no_v1_named`), returns `-ENOENT` if so.\n     - Ensures the name is not empty (`!param->size`).\n     - Ensures the name is not too long (`param->size > MAX_CGROUP_ROOT_NAMELEN - 1`).\n     - Validates the name characters: only alphanumeric, '.', '-', '_' are allowed via `isalnum` and explicit checks.\n     - Ensures the name is not respecified (only one name allowed).\n     - Assigns the name to `ctx->name` and nulls `param->string`.\n\n5. Key security considerations:\n   - All string inputs are validated before being stored.\n   - The `Opt_name` validation uses a loop to check each character against allowed set \u2014 this prevents injection of invalid or dangerous characters.\n   - The `source` and `release_agent` parameters are checked for duplicates and nullified after assignment to prevent use-after-free.\n   - The `subsys_mask` is set only for enabled and non-disabled subsystems.\n   - No direct string copying without bounds checking \u2014 all string assignments are done with proper validation and nulling of `param->string`.\n\n6. No buffer overflows, no format string vulnerabilities, no unsafe string operations, no use of unsafe functions like `strcpy`, `strcat`, etc. All string handling is bounded and validated.\n\n7. The code properly handles memory ownership: `param->string` is set to NULL after assignment, preventing double-free or dangling pointer issues.\n\n8. The validation for `Opt_name` is strict and prevents injection of malicious characters.\n\nConclusion: The code performs proper input validation, avoids unsafe operations, and manages memory safely. There are no obvious security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 430380, "project": "linux", "commit_id": "cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/cefa91b2332d7009bc0be5d951d6cbbf349f90f8", "commit_message": "openvswitch: fix OOB access in reserve_sfa_size()\n\nGiven a sufficiently large number of actions, while copying and\nreserving memory for a new action of a new flow, if next_offset is\ngreater than MAX_ACTIONS_BUFSIZE, the function reserve_sfa_size() does\nnot return -EMSGSIZE as expected, but it allocates MAX_ACTIONS_BUFSIZE\nbytes increasing actions_len by req_size. This can then lead to an OOB\nwrite access, especially when further actions need to be copied.\n\nFix it by rearranging the flow action size check.\n\nKASAN splat below:\n\n==================================================================\nBUG: KASAN: slab-out-of-bounds in reserve_sfa_size+0x1ba/0x380 [openvswitch]\nWrite of size 65360 at addr ffff888147e4001c by task handler15/836\n\nCPU: 1 PID: 836 Comm: handler15 Not tainted 5.18.0-rc1+ #27\n...\nCall Trace:\n <TASK>\n dump_stack_lvl+0x45/0x5a\n print_report.cold+0x5e/0x5db\n ? __lock_text_start+0x8/0x8\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_report+0xb5/0x130\n ? reserve_sfa_size+0x1ba/0x380 [openvswitch]\n kasan_check_range+0xf5/0x1d0\n memcpy+0x39/0x60\n reserve_sfa_size+0x1ba/0x380 [openvswitch]\n __add_action+0x24/0x120 [openvswitch]\n ovs_nla_add_action+0xe/0x20 [openvswitch]\n ovs_ct_copy_action+0x29d/0x1130 [openvswitch]\n ? __kernel_text_address+0xe/0x30\n ? unwind_get_return_address+0x56/0xa0\n ? create_prof_cpu_mask+0x20/0x20\n ? ovs_ct_verify+0xf0/0xf0 [openvswitch]\n ? prep_compound_page+0x198/0x2a0\n ? __kasan_check_byte+0x10/0x40\n ? kasan_unpoison+0x40/0x70\n ? ksize+0x44/0x60\n ? reserve_sfa_size+0x75/0x380 [openvswitch]\n __ovs_nla_copy_actions+0xc26/0x2070 [openvswitch]\n ? __zone_watermark_ok+0x420/0x420\n ? validate_set.constprop.0+0xc90/0xc90 [openvswitch]\n ? __alloc_pages+0x1a9/0x3e0\n ? __alloc_pages_slowpath.constprop.0+0x1da0/0x1da0\n ? unwind_next_frame+0x991/0x1e40\n ? __mod_node_page_state+0x99/0x120\n ? __mod_lruvec_page_state+0x2e3/0x470\n ? __kasan_kmalloc_large+0x90/0xe0\n ovs_nla_copy_actions+0x1b4/0x2c0 [openvswitch]\n ovs_flow_cmd_new+0x3cd/0xb10 [openvswitch]\n ...\n\nCc: stable@vger.kernel.org\nFixes: f28cd2af22a0 (\"openvswitch: fix flow actions reallocation\")\nSigned-off-by: Paolo Valerio <pvalerio@redhat.com>\nAcked-by: Eelco Chaudron <echaudro@redhat.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 0, "cwe": ["CWE-362"], "cve": "CVE-2022-2639", "cve_desc": "An integer coercion error was found in the openvswitch kernel module. Given a sufficiently large number of actions, while copying and reserving memory for a new action of a new flow, the reserve_sfa_size() function does not return -EMSGSIZE as expected, potentially leading to an out-of-bounds write access. This flaw allows a local user to crash or potentially escalate their privileges on the system.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `reserve_sfa_size` is responsible for reserving space in a flow actions structure (`struct sw_flow_actions`) for a new attribute of size `attr_len`.\n\n2) The function calculates `req_size = NLA_ALIGN(attr_len)`, which aligns the requested size to a natural boundary (typically 4 or 8 bytes depending on architecture). This is a standard practice to ensure proper memory alignment.\n\n3) It checks if the required space fits in the current buffer: `if (req_size <= (ksize(*sfa) - next_offset))`. If it does, it skips allocation and goes to `out`.\n\n4) If not, it calculates a new buffer size: `new_acts_size = max(next_offset + req_size, ksize(*sfa) * 2)`. This ensures the new buffer is at least double the current size (for growth) or large enough to fit the new data.\n\n5) It then checks if the new size exceeds `MAX_ACTIONS_BUFSIZE`. If the required space alone exceeds this limit, it returns an error. Otherwise, it caps the new size at `MAX_ACTIONS_BUFSIZE`.\n\n6) It allocates a new buffer with `nla_alloc_flow_actions(new_acts_size)`, copies the old data, frees the old buffer, and updates the pointer.\n\n7) Finally, it returns a pointer to the newly reserved space: `return (struct nlattr *) ((unsigned char *)(*sfa) + next_offset)`.\n\n8) Key security considerations:\n   - The function uses `ksize(*sfa)` to get the actual allocated size of the buffer, which is correct for `kmalloc`-allocated memory.\n   - It properly checks bounds against `MAX_ACTIONS_BUFSIZE` to prevent unbounded memory allocation.\n   - It uses `memcpy` with a known length (`(*sfa)->actions_len`) and does not copy beyond the allocated buffer.\n   - The `NLA_ALIGN` ensures proper alignment.\n   - The function does not perform any unchecked arithmetic that could lead to integer overflow or underflow.\n   - The `max()` function ensures the new size is at least the required space or double the current size, preventing under-allocation.\n\n9) There is no evidence of buffer overflow, integer overflow, or memory corruption. The bounds checks are comprehensive and the memory management is sound.\n\n(2) NO: No security vulnerability."}
{"idx": 343175, "project": "linux", "commit_id": "ebe48d368e97d007bfeb76fcb065d6cfc4c96645", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/ebe48d368e97d007bfeb76fcb065d6cfc4c96645", "commit_message": "esp: Fix possible buffer overflow in ESP transformation\n\nThe maximum message size that can be send is bigger than\nthe  maximum site that skb_page_frag_refill can allocate.\nSo it is possible to write beyond the allocated buffer.\n\nFix this by doing a fallback to COW in that case.\n\nv2:\n\nAvoid get get_order() costs as suggested by Linus Torvalds.\n\nFixes: cac2661c53f3 (\"esp4: Avoid skb_cow_data whenever possible\")\nFixes: 03e2a30f6a27 (\"esp6: Avoid skb_cow_data whenever possible\")\nReported-by: valis <sec@valis.email>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-27666", "cve_desc": "A heap buffer overflow flaw was found in IPsec ESP transformation code in net/ipv4/esp4.c and net/ipv6/esp6.c. This flaw allows a local attacker with a normal user privilege to overwrite kernel heap objects and may cause a local privilege escalation threat.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there is a security vulnerability.\n\n1. **Function Overview**:\n   - The function `esp_output_head` is part of the IPsec ESP (Encapsulating Security Payload) implementation in the Linux kernel.\n   - It handles the preparation of the ESP header and trailer for an outgoing packet (`skb`), including handling of tail data (padding, integrity check, etc.).\n   - It manages memory allocation for additional data (trailer) either in-place (if space is available) or via `skb_cow_data` (copy-on-write).\n\n2. **Key Operations**:\n   - The function checks if the packet is encapsulated (e.g., UDP encapsulation) and handles it via `esp_output_encap`.\n   - It calculates `allocsz` for aligned memory allocation based on `skb->data_len + tailen`, and checks if it exceeds `ESP_SKB_FRAG_MAXSIZE`. If so, it jumps to `cow` (copy-on-write).\n   - If the skb is not cloned and there is enough tailroom, it uses the existing space (`skb_tailroom`) to append the trailer.\n   - Otherwise, it attempts to use a page fragment (`page_frag`) to allocate memory for the trailer, using `skb_page_frag_refill` and `__skb_fill_page_desc` to attach a new page fragment.\n   - If none of the above work, it falls back to `skb_cow_data`, which ensures the skb is writable and allocates space for the trailer.\n   - Finally, it calls `esp_output_fill_trailer` to fill the trailer data (TFCLen, PLEN, proto), and `pskb_put` to update the skb length.\n\n3. **Potential Security Concerns**:\n   - **Buffer Overflow / Memory Corruption**:\n     - The function uses `skb_tailroom(skb)` to check available space. This is safe as long as the `tailen` is not maliciously large.\n     - However, `tailen` comes from `esp->tailen`, which is derived from the ESP policy (e.g., padding length, ICV size). These values are controlled by the security policy and are validated earlier in the ESP processing chain (e.g., during `xfrm_state` setup).\n     - The kernel ensures that `esp->tailen` is within reasonable bounds (e.g., not larger than the maximum allowed padding or ICV size) before this function is called.\n   - **Use of `skb_cow_data`**:\n     - `skb_cow_data` is a safe function used to ensure the skb is writable and has enough space. It returns a new skb (or the same one) and updates the tail pointer. It handles fragmentation and memory allocation safely.\n   - **Page Fragment Usage**:\n     - The code uses `page_frag` for efficient allocation. It checks `skb_page_frag_refill` and uses `GFP_ATOMIC`, which is appropriate in softirq context.\n     - The `page` is properly referenced (`get_page`) and the offset is updated safely.\n   - **Trailer Filling**:\n     - `esp_output_fill_trailer` is responsible for writing the trailer data. This function is assumed to be safe and only writes the expected number of bytes (`esp->tfclen`, `esp->plen`, `esp->proto`), which are validated earlier.\n   - **No Direct User Input**:\n     - The function operates on kernel data structures (`struct xfrm_state`, `struct sk_buff`) that are validated and managed by the kernel. There is no direct user input being processed here.\n   - **Bounds Checking**:\n     - The code checks `skb_shinfo(skb)->nr_frags < MAX_SKB_FRAGS` and `!skb_has_frag_list(skb)` before adding a new fragment \u2014 this prevents overflow.\n     - `ALIGN` is used for cache alignment, which is safe.\n     - `pskb_put` is used to update the skb length and tail pointer \u2014 this is safe as long as the `tail` pointer is valid and within bounds.\n\n4. **No Obvious Vulnerabilities**:\n   - There is no use of unsafe string functions, no direct memory copying without bounds checks, no integer overflows (the `allocsz` check against `ESP_SKB_FRAG_MAXSIZE` prevents excessive allocation).\n   - All memory operations are mediated through kernel-safe functions (`skb_cow_data`, `__skb_fill_page_desc`, `skb_page_frag_refill`).\n   - The `tailen` value is not user-controlled directly \u2014 it is derived from the ESP policy, which is validated during setup.\n\n5. **Conclusion**:\n   - The code follows kernel security best practices: input validation, safe memory allocation, use of kernel-safe functions, and proper reference counting.\n   - There is no evidence of buffer overflow, use-after-free, integer overflow, or other common vulnerabilities.\n   - The function is part of a well-established, secure IPsec implementation.\n\n(2) NO: No security vulnerability."}
{"idx": 427707, "project": "file", "commit_id": "46a8443f76cec4b41ec736eca396984c74664f84", "project_url": "https://github.com/file/file", "commit_url": "https://github.com/file/file/commit/46a8443f76cec4b41ec736eca396984c74664f84", "commit_message": "Limit the number of elements in a vector (found by oss-fuzz)", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2019-18218", "cve_desc": "cdf_read_property_info in cdf.c in file through 5.37 does not restrict the number of CDF_VECTOR elements, which allows a heap-based buffer overflow (4-byte out-of-bounds write).", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Bounds Checking\n\nThe function `cdf_read_property_info` reads data from a structured stream (likely a Compound File Binary Format, or CFBF) and parses property information.\n\n- The function starts by checking:\n  ```c\n  if (offs > UINT32_MAX / 4) {\n      errno = EFTYPE;\n      goto out;\n  }\n  ```\n  This prevents `offs` from being so large that `offs * 4` would overflow. This is a good defensive check.\n\n- It then uses `cdf_offset(sst->sst_tab, offs)` to get a pointer to the section header. This is a safe offset calculation assuming `cdf_offset` performs bounds checks.\n\n- The function calls:\n  ```c\n  if (cdf_check_stream_offset(sst, h, shp, sizeof(*shp), __LINE__) == -1)\n      goto out;\n  ```\n  This checks that the section header is within the valid stream bounds. This is a critical safety check.\n\n- Then it reads `sh.sh_len` and checks:\n  ```c\n  if (sh.sh_len > CDF_SHLEN_LIMIT) {\n      errno = EFTYPE;\n      goto out;\n  }\n  ```\n  This limits the length of the section, preventing excessively large allocations.\n\n- It then checks:\n  ```c\n  if (cdf_check_stream_offset(sst, h, shp, sh.sh_len, __LINE__) == -1)\n      goto out;\n  ```\n  Ensures the full section is within bounds.\n\n- It reads `sh.sh_properties` and checks:\n  ```c\n  if (sh.sh_properties > CDF_PROP_LIMIT)\n      goto out;\n  ```\n  Limits the number of properties to prevent excessive memory allocation.\n\n---\n\n### Step 2: Memory Allocation and Growth\n\n- The function uses:\n  ```c\n  inp = cdf_grow_info(info, maxcount, sh.sh_properties);\n  if (inp == NULL)\n      goto out;\n  ```\n  This grows the `*info` array to accommodate the new properties. The `cdf_grow_info` function should handle bounds and overflow checks.\n\n- Then it updates:\n  ```c\n  inp += *count;\n  *count += sh.sh_properties;\n  ```\n  This is safe as long as `*count` and `sh.sh_properties` are within limits, which are already checked.\n\n---\n\n### Step 3: Parsing Loop and Buffer Access\n\nThe main loop iterates over `sh.sh_properties` and uses:\n```c\nif ((q = cdf_get_property_info_pos(sst, h, p, e, i)) == NULL)\n    goto out;\n```\nThis function returns the position of the i-th property within the section. It should validate that the offset is within bounds.\n\nThen:\n```c\ninp[i].pi_id = CDF_GETUINT32(p, i << 1);\n```\nThis reads the property ID. The offset `i << 1` is `2*i`, so it's accessing a 2-byte-aligned field. This is safe if `p` is properly aligned and the buffer is large enough.\n\nThen:\n```c\nleft = CAST(size_t, e - q);\nif (left < sizeof(uint32_t)) {\n    DPRINTF((\"short info (no type)_\\n\"));\n    goto out;\n}\n```\nThis checks that at least one `uint32_t` remains after `q`, which is necessary to read the type.\n\nNext:\n```c\ninp[i].pi_type = CDF_GETUINT32(q, 0);\n```\nThis reads the type field.\n\nThen:\n```c\nif (inp[i].pi_type & CDF_VECTOR) {\n    if (left < sizeof(uint32_t) * 2) {\n        DPRINTF((\"missing CDF_VECTOR length\\n\"));\n        goto out;\n    }\n    nelements = CDF_GETUINT32(q, 1);\n    if (nelements > CDF_ELEMENT_LIMIT || nelements == 0) {\n        DPRINTF((\"CDF_VECTOR with nelements == %\" SIZE_T_FORMAT \"u\\n\", nelements));\n        goto out;\n    }\n    slen = 2;\n} else {\n    nelements = 1;\n    slen = 1;\n}\n```\nThis checks for valid vector length and limits it to `CDF_ELEMENT_LIMIT`. This prevents integer overflow or excessive memory allocation.\n\nThen:\n```c\no4 = slen * sizeof(uint32_t);\n```\nThis computes the offset to the actual data.\n\n---\n\n### Step 4: String Handling (Critical Section)\n\nThe most complex part is handling `CDF_LENGTH32_STRING` and `CDF_LENGTH32_WSTRING`:\n\n```c\ncase CDF_LENGTH32_STRING:\ncase CDF_LENGTH32_WSTRING:\n    if (nelements > 1) {\n        size_t nelem = inp - *info;\n        inp = cdf_grow_info(info, maxcount, nelements);\n        if (inp == NULL)\n            goto out;\n        inp += nelem;\n    }\n    for (j = 0; j < nelements && i < sh.sh_properties; j++, i++)\n    {\n        uint32_t l;\n\n        if (o4 + sizeof(uint32_t) > left)\n            goto out;\n\n        l = CDF_GETUINT32(q, slen);\n        o4 += sizeof(uint32_t);\n        if (o4 + l > left)\n            goto out;\n\n        inp[i].pi_str.s_len = l;\n        inp[i].pi_str.s_buf = CAST(const char *, CAST(const void *, &q[o4]));\n\n        DPRINTF((\"o=%\" SIZE_T_FORMAT \"u l=%d(%\" SIZE_T_FORMAT \"u), t=%\" SIZE_T_FORMAT\n            \"u s=%s\\n\", o4, l, CDF_ROUND(l, sizeof(l)), left, inp[i].pi_str.s_buf));\n\n        if (l & 1)\n            l++;\n\n        slen += l >> 1;\n        o4 = slen * sizeof(uint32_t);\n    }\n    i--;\n    break;\n```\n\nLet\u2019s analyze this carefully:\n\n- `l = CDF_GETUINT32(q, slen)` reads the length of the string.\n- Then it checks:\n  ```c\n  if (o4 + l > left)\n      goto out;\n  ```\n  This ensures that the string data (`l` bytes) fits in the remaining buffer (`left` bytes). This is a **critical bounds check**.\n\n- Then it sets:\n  ```c\n  inp[i].pi_str.s_len = l;\n  inp[i].pi_str.s_buf = &q[o4];\n  ```\n  This stores a pointer into the original stream buffer (`q`), which is valid as long as `o4 + l <= left`.\n\n- Then:\n  ```c\n  if (l & 1)\n      l++;\n  ```\n  This rounds up `l` to the next even number (for alignment). But note: this is only used to update `slen` and `o4`, not to modify the actual data.\n\n- Then:\n  ```c\n  slen += l >> 1;\n  o4 = slen * sizeof(uint32_t);\n  ```\n  This updates the offset for the next field.\n\nThe key point: **all access to the string data is validated by `o4 + l > left` check**, which ensures that the string data does not overflow the buffer.\n\nAlso, `l` is read from the stream and checked against `left`, so it cannot be larger than the available data.\n\n---\n\n### Step 5: Other Types and Default Case\n\n- For other types (e.g., `CDF_SIGNED16`, `CDF_SIGNED32`, etc.), the code uses `cdf_copy_info` with a size check:\n  ```c\n  if (!cdf_copy_info(&inp[i], &q[o4], e, sizeof(int16_t)))\n      goto unknown;\n  ```\n  This function should validate that the data fits in the buffer.\n\n- The `CDF_CLIPBOARD` type is checked for `CDF_VECTOR`, and if present, it goes to `unknown` \u2014 this is safe.\n\n- The `default` case sets `pi_val` to zero and logs a warning \u2014 no memory corruption.\n\n---\n\n### Step 6: Final Checks and Error Handling\n\n- The function uses `goto out` on any error, and in `out`:\n  ```c\n  free(*info);\n  *info = NULL;\n  *count = 0;\n  *maxcount = 0;\n  errno = EFTYPE;\n  return -1;\n  ```\n  This cleans up allocated memory and resets state \u2014 prevents memory leaks.\n\n---\n\n### Conclusion\n\n- All buffer accesses are bounded by checks on `left` (remaining buffer size).\n- All lengths are validated against limits (`CDF_PROP_LIMIT`, `CDF_ELEMENT_LIMIT`, etc.).\n- No unchecked `strcpy`, `memcpy`, or direct pointer arithmetic without bounds.\n- The code uses `cdf_check_stream_offset` and `cdf_get_property_info_pos` to validate offsets.\n- The string parsing includes a check `o4 + l > left` to prevent reading beyond the buffer.\n- No integer overflows in critical calculations (e.g., `o4 = slen * sizeof(uint32_t)` is safe because `slen` is derived from `l`, which is bounded).\n\n---\n\n### Final Answer:\n\n(2) NO: No security vulnerability."}
{"idx": 256947, "project": "tensorflow", "commit_id": "f09caa532b6e1ac8d2aa61b7832c78c5b79300c6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6", "commit_message": "Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.\n\nEinsumHelper::ParseEquation is supposed to return true or false in\ninput_has_ellipsis and output_has_ellipsis to indicate whether there is\nellipsis in the inputs and output. Previously, when there is no ellipsis in the\ninputs or output, the routine doesn't assign false to the variables. This\nchange initializes the two variables with false to fix the problem.\nPiperOrigin-RevId: 391772004\nChange-Id: I17b6c88aadef4131470378e48cced054bf252e86", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2021-41201", "cve_desc": "TensorFlow is an open source platform for machine learning. In affeced versions during execution, `EinsumHelper::ParseEquation()` is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output. However, the code only changes these flags to `true` and never assigns `false`. This results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ParseEquation` takes a string `equation` and parses it into input and output labels using `ParseEinsumEquation`, which populates `input_str` (a vector of strings) and `output_str` (a string).\n\n2) The function then creates a mapping from single-character labels (from the equation) to integer labels using `absl::flat_hash_map<char, int> label_mapping`. This map is used to assign unique integer IDs to each distinct label.\n\n3) The function processes each input string in `input_str` and maps its characters to integer labels via `MapToLabels`. Similarly, it maps the `output_str` to integer labels.\n\n4) The function computes label counts for inputs and outputs, tracking how many times each label appears in each input and the output. It also tracks whether ellipsis (`kEllipsisLabel`) is present in each input and output.\n\n5) Finally, it assigns a `DimensionType` to each label based on whether it's removed (not in output) and whether it's unique (appears in only one input or not at all).\n\nNow, let's look for potential security vulnerabilities:\n\n- The input is a string (`equation`) that is parsed by `ParseEinsumEquation`. We must assume this function is trusted and properly bounds-checked, as it's a standard parsing function in the codebase.\n\n- The `input_str` and `output_str` are populated from the equation. The code uses `gtl::InlinedVector<string, 2>` and `string`, which are safe containers with bounds checking.\n\n- The `label_mapping` is an `absl::flat_hash_map` that maps characters (like 'a', 'b') to integers. Since the keys are single characters (from the equation), the number of possible keys is limited to 256 (ASCII), so the map cannot grow unbounded.\n\n- The function uses `input_labels->resize(num_inputs)` and similar operations, but `num_inputs` comes from `input_str.size()`, which is derived from the parsed equation. There is no indication that the input equation can be crafted to cause excessive memory allocation or infinite loops.\n\n- The loops over `input_labels->at(i)` and `*output_labels` are bounded by the number of labels, which is at most the number of distinct characters in the equation (again, limited by ASCII).\n\n- The function does not perform any dynamic memory allocation based on untrusted input in a way that could lead to resource exhaustion or buffer overflow.\n\n- There is no use of unsafe string functions (like `strcpy`, `strcat`, etc.), no direct memory manipulation, and no format string vulnerabilities.\n\n- The use of `absl::flat_hash_map` and `gtl::InlinedVector` are safe and do not introduce buffer overflows.\n\n- The function does not expose any sensitive data or perform any system calls that could be exploited.\n\nConclusion: The code performs input validation through parsing, uses safe containers, and processes input in a bounded and predictable way. There is no evidence of buffer overflows, use-after-free, integer overflows, or any other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 255807, "project": "tensorflow", "commit_id": "537bc7c723439b9194a358f64d871dd326c18887", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887", "commit_message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f", "ground_truth": 0, "cwe": ["CWE-908"], "cve": "CVE-2021-37682", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `Prepare` is part of a TensorFlow Lite (TFLite) operator implementation.\n   - It uses `TF_LITE_ENSURE_EQ` and `TF_LITE_ENSURE_OK` macros to validate:\n     - The number of inputs and outputs (5 inputs, 1 output).\n     - The types of input tensors (only float32 or int8).\n     - Tensor dimensions and their consistency (e.g., matching dimensions between input and weights_feature, correct rank, etc.).\n     - The shape of the state tensor (must be 2D with specific dimensions).\n   - These checks are robust and prevent out-of-bounds access or invalid tensor configurations.\n\n2. **Tensor Resizing and Memory Management**:\n   - The output tensor is resized using `context->ResizeTensor` with a correctly computed size array (`batch_size` \u00d7 `num_units`).\n   - Scratch tensors are allocated via `GetTemporarySafe` and resized using `context->ResizeTensor`.\n   - The code carefully manages temporary tensor indices and ensures that:\n     - Temporary tensors are properly sized.\n     - Their types are set based on the operation mode (e.g., float32 for hybrid, int32 for full integer).\n     - Allocation types are set to `kTfLiteArenaRw` or `kTfLiteArenaRwPersistent`, which are safe for temporary use in TFLite.\n\n3. **Use of Safe APIs**:\n   - The code uses `GetInputSafe`, `GetOutputSafe`, and `GetTemporarySafe` \u2014 these are TFLite-safe APIs that perform null checks and ensure valid tensor access.\n   - All tensor accesses are guarded by `TF_LITE_ENSURE_OK`, which ensures that any failure in tensor retrieval or resizing is caught early.\n\n4. **No Buffer Overflows or Unsafe Memory Access**:\n   - There are no calls to unsafe functions like `strcpy`, `strcat`, `memcpy` with unbounded sizes.\n   - All array indexing is derived from tensor dimensions that are validated before use.\n   - The use of `TfLiteIntArray` and `TfLiteIntArrayCreate`/`Copy`/`Free` is safe and consistent with TFLite\u2019s memory management model.\n\n5. **Quantization and Scaling Calculations**:\n   - The code computes effective scales for quantized operations and uses `QuantizeMultiplier` to safely quantize floating-point multipliers.\n   - All quantization parameters are validated to exist (not `kTfLiteNoQuantization`) before use.\n\n6. **No User Input Directly Manipulating Memory**:\n   - The input tensors come from the TFLite model and are validated at runtime.\n   - There is no direct string concatenation, dynamic memory allocation without bounds, or unsafe casting that could lead to memory corruption.\n\n7. **No Known Vulnerability Patterns**:\n   - No off-by-one errors, use-after-free, null pointer dereferences, or integer overflows are present.\n   - All indices are derived from validated tensor dimensions.\n   - The code is written in a defensive style typical of TFLite kernel implementations.\n\nConclusion: The code performs comprehensive input validation, uses safe APIs for tensor access and resizing, and carefully manages temporary memory. There are no exploitable security vulnerabilities such as buffer overflows, use-after-free, or improper input sanitization.\n\n(2) NO: No security vulnerability."}
{"idx": 308163, "project": "linux", "commit_id": "fc739a058d99c9297ef6bfd923b809d85855b9a9", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9", "commit_message": "misc: fastrpc: prevent memory leak in fastrpc_dma_buf_attach\n\nIn fastrpc_dma_buf_attach if dma_get_sgtable fails the allocated memory\nfor a should be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nLink: https://lore.kernel.org/r/20190925152742.16258-1-navid.emamdoost@gmail.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2019-19069", "cve_desc": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `fastrpc_dma_buf_attach` is responsible for attaching a DMA buffer to a device, creating a new attachment structure (`a`) and linking it to the buffer's list of attachments.\n\n2) The code allocates memory for the attachment structure using `kzalloc` with `GFP_KERNEL`, which is appropriate for kernel space allocations. If allocation fails, it returns `-ENOMEM`, which is correct behavior.\n\n3) It calls `dma_get_sgtable` to get a scatterlist table for the buffer's physical memory. This is a standard operation for DMA buffer handling. If this fails, it logs an error, frees the allocated attachment structure, and returns `-EINVAL`.\n\n4) The attachment structure is initialized with:\n   - `a->dev = attachment->dev` (the device being attached to)\n   - `INIT_LIST_HEAD(&a->node)` (initializes the list node)\n   - `attachment->priv = a` (stores the private data in the attachment)\n\n5) The code then acquires a mutex (`buffer->lock`) before adding the new attachment to the list (`list_add(&a->node, &buffer->attachments)`), and releases it afterward. This ensures thread safety when modifying the list of attachments.\n\n6) The function does not perform any input validation on `dmabuf` or `attachment` pointers before dereferencing them. However, in the Linux kernel, `dma_buf` and `dma_buf_attachment` are typically validated by the higher-level API before this function is called. The `dmabuf->priv` is assumed to be valid, and `buffer->dev` is expected to be valid.\n\n7) There is no buffer overflow, use-after-free, or memory corruption issue apparent in the code. The `kzalloc` ensures zero-initialization, and the `list_add` is protected by a mutex.\n\n8) The `dma_get_sgtable` call is standard and safe when used correctly. The parameters passed are derived from the buffer's metadata, which is assumed to be valid.\n\n9) No user-controlled data is directly manipulated in a way that could lead to memory corruption or privilege escalation.\n\n10) The code follows kernel DMA buffer attachment patterns correctly and includes proper error handling and cleanup.\n\n(2) NO: No security vulnerability."}
{"idx": 227022, "project": "weechat", "commit_id": "9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a", "project_url": "https://github.com/weechat/weechat", "commit_url": "https://github.com/weechat/weechat/commit/9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a", "commit_message": "irc: fix crash when receiving a malformed message 352 (who)\n\nThanks to Stuart Nevans Locke for reporting the issue.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2020-9759", "cve_desc": "A Vulnerability of LG Electronic web OS TV Emulator could allow an attacker to escalate privileges and overwrite certain files. This vulnerability is due to wrong environment setting. An attacker could exploit this vulnerability through crafted configuration files and executable files.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Argument Count Check**:\n   - The function begins with `IRC_PROTOCOL_MIN_ARGS(5)`, which ensures at least 5 arguments are provided.\n   - It then checks `if (argc < 8)` and returns `WEECHAT_RC_OK` silently if fewer than 8 arguments are present. This is a defensive check to avoid processing malformed messages.\n   - This prevents out-of-bounds access to `argv` and `argv_eol` arrays.\n\n2. **Argument Parsing and Indexing**:\n   - The code uses `argv[8]` and `argv_eol[arg_start + 1]`, etc., but carefully checks `argc > arg_start` and `argc > arg_start + 1` before accessing them.\n   - The `arg_start` is set conditionally based on whether `argv[8]` is `\"*\"`, and only if `argc > 9` and `argv[8] == \"*\"` is `arg_start` set to 9. Otherwise, it's 8.\n   - This ensures that array bounds are not violated when accessing `argv` and `argv_eol`.\n\n3. **Memory Allocation and String Formatting**:\n   - The code allocates memory for `str_host` using `malloc(length)` where `length = strlen(argv[4]) + 1 + strlen(argv[5]) + 1`.\n   - It then uses `snprintf(str_host, length, \"%s@%s\", argv[4], argv[5])`.\n   - The `length` is calculated to include space for both strings and the `@` symbol, plus null terminator. This ensures that `snprintf` will not overflow the buffer because the buffer size is exactly sufficient.\n   - After use, `str_host` is freed with `free(str_host)`, so no memory leak occurs.\n\n4. **String Copying and Null Termination**:\n   - The code uses `strdup(pos_realname)` only when `weechat_hashtable_has_key(..., \"extended-join\")` is true, and only if `pos_realname` is non-null.\n   - `strdup` is safe here because it allocates memory and copies the string safely.\n   - The code checks for `ptr_nick->realname` and frees it before reassigning, preventing memory leaks.\n\n5. **Use of `argv` and `argv_eol` in `weechat_printf_date_tags`**:\n   - The final `weechat_printf_date_tags` call uses `argv[3]`, `argv[4]`, `argv[5]`, `argv[7]`, `pos_attr`, `pos_hopcount`, `pos_realname`, etc.\n   - These are all validated via `argc` checks and conditional access.\n   - The format string uses `%s` for these values, but since they are all derived from `argv` or `argv_eol` and are properly null-terminated (as per IRC protocol), and the code ensures they are only accessed when valid, there is no risk of buffer overflow or format string vulnerability.\n   - The `weechat_printf_date_tags` function is a safe wrapper that handles formatting and output safely.\n\n6. **No Use of Dangerous Functions**:\n   - No `strcpy`, `strcat`, `sprintf`, or similar unsafe functions are used.\n   - `snprintf` is used correctly with proper buffer size.\n   - `strdup` is used safely.\n\n7. **No Injection or Code Execution Risks**:\n   - The code does not execute user input as code.\n   - It does not use `eval`, `system`, or dynamic code execution.\n   - The output is formatted for display, not execution.\n\n8. **Error Handling and Resource Management**:\n   - Memory is allocated and freed appropriately.\n   - Null checks are performed before dereferencing pointers.\n   - The function returns `WEECHAT_RC_OK` on success or early return on malformed input.\n\nConclusion: The code performs proper bounds checking, uses safe string functions with correct buffer sizes, manages memory correctly, and avoids dangerous operations. There are no exploitable vulnerabilities such as buffer overflows, format string vulnerabilities, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 453265, "project": "jasper", "commit_id": "839b1bcf0450ff036c28e8db40a7abf886e02891", "project_url": "https://github.com/mdadams/jasper", "commit_url": "https://github.com/jasper-software/jasper/commit/839b1bcf0450ff036c28e8db40a7abf886e02891", "commit_message": "jp2_dec: fix `numchans` mixup\n\nWhen iterating over `dec->cdef->data.cdef.ents`, we need to use its\n`numchans` variable, not the one in `jp2_dec_t`.\n\nFixes CVE-2018-19543\nFixes CVE-2017-9782\n\nCloses https://github.com/jasper-maint/jasper/issues/13\nCloses https://github.com/jasper-maint/jasper/issues/18\nCloses https://github.com/mdadams/jasper/issues/140\nCloses https://github.com/mdadams/jasper/issues/182", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2017-9782", "cve_desc": "JasPer 2.0.12 allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) via a crafted image, related to the jp2_decode function in libjasper/jp2/jp2_dec.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Stream Processing**:\n   - The function `jp2_decode` takes a `jas_stream_t *in` (input stream) and a `const char *optstr` (options string).\n   - The input stream is used to read JP2 (JPEG 2000) boxes via `jp2_box_get(in)`. This function is responsible for parsing structured boxes in the JP2 file format.\n   - The code checks for the presence of required boxes (JP, FTYP, IHDR, JP2C, etc.) and validates their types and contents.\n\n2. **Buffer and Memory Management**:\n   - The code uses `jas_alloc2` to allocate memory for `dec->chantocmptlut` and `lutents`. These are used for internal data structures.\n   - `jas_alloc2` is a safe allocation function (presumably from the JasPer library) that checks for overflow and returns NULL on failure.\n   - All allocated memory is properly freed in the `error` label via `jas_free` or `jp2_dec_destroy`, and `jp2_box_destroy` is used for box structures.\n\n3. **Bounds Checking and Index Validation**:\n   - The code performs several bounds checks:\n     - When accessing `dec->cmap->data.cmap.ents[i].cmptno`, it checks `cmptno >= jas_image_numcmpts(dec->image)` \u2014 this prevents out-of-bounds access.\n     - Similarly, `pcol >= dec->pclr->data.pclr.numchans` is checked before using it as an index.\n     - The `CDEF` box validation checks `channo >= dec->numchans`, which is safe.\n   - These checks prevent buffer overflows and out-of-bounds memory access.\n\n4. **Use of User-Controlled Data**:\n   - The input stream `in` is user-controlled (e.g., a JP2 file), so the data inside it is untrusted.\n   - However, the code does not directly copy untrusted data into fixed-size buffers without bounds checking.\n   - All data from the stream is parsed through structured box parsing (`jp2_box_get`), which validates sizes and types before use.\n   - The `jpc_decode` function is called to decode the actual image data \u2014 this is a well-established decoder that should handle malformed input safely.\n\n5. **Potential for Integer Overflow or Underflow**:\n   - The code uses `JAS_CAST(jas_uint, ...)` to cast from signed to unsigned types. This is safe as long as the original value is non-negative.\n   - The `jas_image_numcmpts` and similar functions return `jas_uint`, which is unsigned, so comparisons like `i < JAS_CAST(jas_uint, jas_image_numcmpts(...))` are safe.\n   - No arithmetic operations are performed on user-controlled values that could lead to integer overflow (e.g., no `size + offset` without checks).\n\n6. **Use of `goto error` and Resource Cleanup**:\n   - The code uses a `goto error` pattern with proper cleanup of allocated resources (`dec`, `box`, etc.).\n   - This ensures that memory leaks are avoided even in error paths.\n\n7. **No Direct String or Memory Copy Vulnerabilities**:\n   - There are no calls to `strcpy`, `strcat`, `memcpy`, or similar unsafe functions.\n   - All data is parsed through structured, validated box parsing.\n\n8. **Security Best Practices**:\n   - The code validates magic numbers (`JP2_JP_MAGIC`), box types, and required boxes.\n   - It checks for consistency between metadata (IHDR, BPCC, CMAP, etc.) and decoded image data.\n   - It performs sanity checks on component counts, data types, and indices.\n\n9. **No Evidence of Known Vulnerabilities**:\n   - The code does not exhibit classic vulnerabilities like buffer overflows, use-after-free, integer overflows, or improper input validation.\n   - The use of `jas_image_setclrspc`, `jas_image_depalettize`, and similar functions is done safely with validated inputs.\n\nConclusion: The code is well-structured, uses safe memory allocation and bounds checking, validates all user-controlled input, and properly handles errors. There are no detectable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 270922, "project": "tensorflow", "commit_id": "a2b743f6017d7b97af1fe49087ae15f0ac634373", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a2b743f6017d7b97af1fe49087ae15f0ac634373", "commit_message": "Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-37641", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions if the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors. We have patched the issue in GitHub commit a2b743f6017d7b97af1fe49087ae15f0ac634373. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of an OpKernelContext in a TensorFlow-like framework, handling nested splits and indices for tensor operations.\n\n2) Input validation is performed:\n   - `params_nested_splits_in` is checked to be non-empty\n   - The first split tensor is checked to not be a scalar (dims > 0)\n   - `indices_in` is validated using `ValidateIndices()`\n   - `params_dense_values_in` is checked to have non-zero rank\n\n3) The function `MakeSplits()` is called with:\n   - `indices_in` (user-provided indices)\n   - `params_nested_splits_in` (user-provided splits)\n   - `num_params_dense_values` (derived from input tensor size)\n\n4) The `MakeSplits()` function is responsible for:\n   - Processing the indices and splits to compute output splits\n   - Determining which value slices to copy\n   - Calculating the total number of values\n\n5) The output is written using:\n   - `WriteSplits()` - writes the computed splits\n   - `WriteValues()` - writes the selected value slices\n\n6) Key security considerations:\n   - All inputs are validated before use\n   - The `ValidateIndices()` function likely checks that indices are within bounds\n   - The `MakeSplits()` function appears to be responsible for proper bounds checking\n   - The `WriteValues()` function uses the computed `value_slices` and `out_splits` which are derived from validated inputs\n   - There is no direct memory copying without bounds checking\n   - The use of `OP_REQUIRES_OK` ensures that any error in the process will terminate execution safely\n\n7) The code follows a defensive programming pattern:\n   - Input validation at multiple points\n   - Use of safe operations (no direct buffer copying without bounds)\n   - Error propagation through the context system\n\n8) No evidence of:\n   - Buffer overflows\n   - Out-of-bounds memory access\n   - Unchecked array indexing\n   - Direct memory manipulation without bounds checking\n\n9) The function appears to be properly handling the nested structure of splits and indices with proper validation at each step.\n\n(2) NO: No security vulnerability."}
{"idx": 247337, "project": "rpm", "commit_id": "bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8", "project_url": "https://github.com/rpm-software-management/rpm", "commit_url": "https://github.com/rpm-software-management/rpm/commit/bd36c5dc9fb6d90c46fbfed8c2d67516fc571ec8", "commit_message": "Validate and require subkey binding signatures on PGP public keys\n\nAll subkeys must be followed by a binding signature by the primary key\nas per the OpenPGP RFC, enforce the presence and validity in the parser.\n\nThe implementation is as kludgey as they come to work around our\nsimple-minded parser structure without touching API, to maximise\nbackportability. Store all the raw packets internally as we decode them\nto be able to access previous elements at will, needed to validate ordering\nand access the actual data. Add testcases for manipulated keys whose\nimport previously would succeed.\n\nDepends on the two previous commits:\n7b399fcb8f52566e6f3b4327197a85facd08db91 and\n236b802a4aa48711823a191d1b7f753c82a89ec5\n\nFixes CVE-2021-3521.", "ground_truth": 0, "cwe": ["CWE-284"], "cve": "CVE-2021-3521", "cve_desc": "There is a flaw in RPM's signature functionality. OpenPGP subkeys are associated with a primary key via a \"binding signature.\" RPM does not check the binding signature of subkeys prior to importing them. If an attacker is able to add or socially engineer another party to add a malicious subkey to a legitimate public key, RPM could wrongly trust a malicious signature. The greatest impact of this flaw is to data integrity. To exploit this flaw, an attacker must either compromise an RPM repository or convince an administrator to install an untrusted RPM or public key. It is strongly recommended to only use RPMs and public keys from trusted sources.", "vuln": 0, "reasoning": "No response from agent"}
{"idx": 432351, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `vhost_user_set_inflight_fd` is responsible for setting up shared memory for inflight descriptor tracking in a vhost-user virtio network device.\n\n2. Input validation:\n   - `validate_msg_fds(dev, ctx, 1)` checks that exactly one file descriptor is provided. This is a good practice.\n   - The code checks `ctx->msg.size == sizeof(ctx->msg.payload.inflight)` to ensure the message size matches expected structure size. This prevents buffer over-reads.\n   - It checks `fd < 0` and returns error if invalid. This prevents use of invalid file descriptors.\n\n3. Memory mapping:\n   - `mmap(0, mmap_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, mmap_offset)` maps the shared memory region.\n   - The `mmap_size` and `mmap_offset` come from the message payload, which is validated by size check above.\n   - The `mmap` call is properly checked for `MAP_FAILED`, and error is returned if mapping fails.\n\n4. Memory management:\n   - The function checks if `dev->inflight_info->addr` is already set and unmaps it before remapping.\n   - It properly closes the previous file descriptor (`dev->inflight_info->fd`) before assigning the new one.\n   - The new file descriptor is stored in `dev->inflight_info->fd`.\n\n5. Pointer arithmetic:\n   - The code uses `addr = (void *)((char *)addr + pervq_inflight_size)` to advance the pointer to the next queue's inflight area.\n   - `pervq_inflight_size` is computed from `queue_size` via `get_pervq_shm_size_packed` or `get_pervq_shm_size_split`, which are presumably well-defined functions that return a fixed size based on queue size.\n   - The total memory mapped (`mmap_size`) must be at least `num_queues * pervq_inflight_size` for this to work correctly.\n\n6. Critical check:\n   - The code does **not** validate that `mmap_size` is sufficient to hold `num_queues * pervq_inflight_size`.\n   - If an attacker sends a large `num_queues` or a small `mmap_size`, this could lead to a buffer overflow when accessing `vq->inflight_packed` or `vq->inflight_split` beyond the mapped region.\n   - The `mmap_size` is taken from the message payload without checking if it's large enough for the number of queues and the size per queue.\n\n7. Potential vulnerability:\n   - The function assumes that `mmap_size` is sufficient for `num_queues * pervq_inflight_size`, but this is not validated.\n   - If `mmap_size < num_queues * pervq_inflight_size`, then the pointer arithmetic will access memory beyond the mapped region, leading to undefined behavior, potential crashes, or information disclosure.\n   - This is a classic case of a missing bounds check on a size parameter derived from untrusted input.\n\n8. Additional concerns:\n   - The `num_queues` value is taken from the message payload and used in a loop without bounds checking against `dev->max_queues` or any reasonable limit.\n   - If `num_queues` is extremely large (e.g., 2^32), the loop could run for a very long time or cause integer overflow.\n\nConclusion: The code fails to validate that the mapped memory size (`mmap_size`) is sufficient to accommodate the number of queues and the per-queue inflight data size. This can lead to out-of-bounds memory access when setting up the virtqueues, which is a serious security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 498160, "project": "nettle", "commit_id": "c71d2c9d20eeebb985e3872e4550137209e3ce4d", "project_url": "https://git.lysator.liu.se/nettle/nettle", "commit_url": "https://git.lysator.liu.se/nettle/nettle/commit/c71d2c9d20eeebb985e3872e4550137209e3ce4d", "commit_message": "Fixed miscomputation bugs in secp-256r1 modulo functions.", "ground_truth": 0, "cwe": ["CWE-310"], "cve": "CVE-2015-8803", "cve_desc": "The ecc_256_modp function in ecc-256.c in Nettle before 3.2 does not properly handle carry propagation and produces incorrect output in its implementation of the P-256 NIST elliptic curve, which allows attackers to have unspecified impact via unknown vectors, a different vulnerability than CVE-2015-8805.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `ecc_256_modp` performs modular reduction of a 512-bit number (represented as `rp`, a 4-limb array) modulo a 256-bit prime `p`, using a Montgomery-style reduction technique. The input `rp` is expected to be a 512-bit value (4 limbs of `mp_limb_t`, typically 64-bit), and the function reduces it modulo `p` in-place.\n\n2. The algorithm uses a series of operations involving:\n   - Bitwise shifts and arithmetic on limbs.\n   - Conditional operations using `cnd_add_n` and `cnd_sub_n` (conditional add/subtract based on flags).\n   - Use of `mpn_submul_1` to subtract `q1 * p->m` from the lower part of `rp`.\n   - Proper handling of carry and borrow using `t = (u0 < t)` and similar constructs.\n\n3. The key aspects of security in modular arithmetic implementations (especially in cryptographic contexts) include:\n   - Resistance to side-channel attacks (timing, power, etc.).\n   - Correctness of modular reduction (no overflow, no underflow).\n   - Use of constant-time operations to prevent leakage via timing.\n\n4. Looking at the code:\n   - The loop iterates from `n = 2*p->size` down to `p->size`, processing high limbs of `rp`.\n   - The operations use conditional expressions (`t = -(mp_limb_t)(u1 > q0)`, `cnd_add_n`, `cnd_sub_n`) that are designed to be branch-free and constant-time.\n   - The use of `cnd_add_n` and `cnd_sub_n` suggests that the implementation is intended to be constant-time, avoiding data-dependent branches.\n   - The `assert(q2 < 2)` ensures that `q2` is either 0 or 1, which is expected in this algorithm.\n   - The final assignment `rp[2] = u0; rp[3] = u1;` stores the reduced result.\n\n5. There is no use of `memcpy`, `strcpy`, or any unbounded memory access.\n   - All array accesses are bounded by `p->size` and `n`, which are derived from the input `p` (a struct containing the modulus).\n   - The function does not perform any dynamic memory allocation or user input parsing.\n   - The input `p` is assumed to be valid (as per cryptographic context), and `rp` is assumed to be a valid 4-limb buffer.\n\n6. The code appears to be a carefully crafted, low-level modular reduction algorithm, likely from a cryptographic library (e.g., GnuPG or libgcrypt). The use of conditional moves and avoidance of branches indicates an intent to prevent timing side-channel attacks.\n\n7. No buffer overflows, use-after-free, null pointer dereferences, or other classic vulnerabilities are present.\n\n8. The only potential concern would be if `p->size` is corrupted or maliciously set, but that would be a precondition violation. The function assumes `p` is valid and `rp` is large enough (4 limbs). If the caller provides invalid input, that's a separate issue, but the function itself does not introduce a vulnerability.\n\nConclusion: The code is well-written, uses constant-time operations, avoids buffer overflows, and performs modular reduction correctly. No security vulnerabilities are present in the logic or memory handling.\n\n(2) NO: No security vulnerability."}
{"idx": 309831, "project": "ncurses", "commit_id": "790a85dbd4a81d5f5d8dd02a44d84f01512ef443", "project_url": "https://github.com/mirror/ncurses", "commit_url": "https://github.com/mirror/ncurses/commit/790a85dbd4a81d5f5d8dd02a44d84f01512ef443#diff-7e95c7bc5f213e9be438e69a9d5d0f261a14952bcbd692f7b9014217b8047340", "commit_message": "ncurses 6.2 - patch 20200531\n\n+ correct configure version-check/warnng for g++ to allow for 10.x\n+ re-enable \"bel\" in konsole-base (report by Nia Huang)\n+ add linux-s entry (patch by Alexandre Montaron).\n+ drop long-obsolete convert_configure.pl\n+ add test/test_parm.c, for checking tparm changes.\n+ improve parameter-checking for tparm, adding function _nc_tiparm() to\n  handle the most-used case, which accepts only numeric parameters\n  (report/testcase by \"puppet-meteor\").\n+ use a more conservative estimate of the buffer-size in lib_tparm.c's\n  save_text() and save_number(), in case the sprintf() function\n  passes-through unexpected characters from a format specifier\n  (report/testcase by \"puppet-meteor\").\n+ add a check for end-of-string in cvtchar to handle a malformed\n  string in infotocap (report/testcase by \"puppet-meteor\").", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-39537", "cve_desc": "An issue was discovered in ncurses through v6.2-1. _nc_captoinfo in captoinfo.c has a heap-based buffer overflow.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `cvtchar` takes a pointer to a constant character string (`sp`) and converts a character (possibly escaped) into a terminfo format string, writing the result to a buffer via `dp` (which is presumably a global or external pointer to a buffer being built).\n\n2. The function handles several escape sequences:\n   - Backslash (`\\`) followed by certain characters (like `'`, `$`, `\\`, `%`, or digits) is processed.\n   - Backslash followed by `\\0` is treated as a literal backslash.\n   - Backslash followed by digits (0\u20133) is interpreted as an octal escape, where up to three digits are read and converted to a byte value.\n   - Caret (`^`) is used to represent control characters (e.g., `^A` \u2192 ASCII 1), with special handling for `^?` \u2192 127.\n   - Default case: normal character.\n\n3. The key part of the function is the handling of the `switch (*sp)` and nested `switch (*++sp)` for escape sequences.\n\n4. Let's focus on the **octal escape handling**:\n   ```c\n   case '0':\n   case '1':\n   case '2':\n   case '3':\n       len = 1;\n       while (isdigit(UChar(*sp))) {\n           c = UChar(8 * c + (*sp++ - '0'));\n           len++;\n       }\n       break;\n   ```\n   - This loop reads digits after the initial `0`, `1`, `2`, or `3`, interpreting them as octal digits.\n   - The variable `c` is initialized to 0 and accumulates the octal value.\n   - The loop continues while `isdigit(*sp)` is true.\n   - However, **there is no limit on how many digits are read**. The loop only stops when a non-digit is encountered.\n\n5. **Critical issue**: The function does not validate the number of digits in the octal sequence. In octal, only digits 0\u20137 are valid. But the code uses `isdigit()` which includes digits 8 and 9. If the input contains `08` or `09`, then `*sp - '0'` will be 8 or 9, and the expression `8 * c + (*sp++ - '0')` will produce a value that exceeds 255 (since `c` is unsigned char, but the arithmetic is done in int, and overflow is possible).\n\n6. However, more importantly: **the loop does not check for buffer overflow or maximum octal length**. In standard C, octal escape sequences are limited to 1\u20133 digits (e.g., `\\377` is valid, but `\\3777` is not). But here, the code allows **arbitrary length** of digits after the initial `0`, `1`, `2`, or `3`. This could lead to:\n   - **Integer overflow** in `c` (since `c` is `unsigned char`, it wraps around modulo 256).\n   - **Unbounded loop** if the input contains many digits (e.g., `\\01234567890123456789`), which could lead to **infinite loop or buffer overflow** if `sp` is not properly null-terminated.\n\n7. But more critically: **the function does not validate that the octal digits are only 0\u20137**. It uses `isdigit()` which includes 8 and 9. So if the input is `\\08`, then `*sp - '0'` is 8, and `8 * c + 8` will be computed. This is **invalid octal**, but the code does not reject it. This leads to **undefined behavior** or **incorrect character values**.\n\n8. However, the real vulnerability is not just incorrect parsing \u2014 it's that **the function does not validate the input length or the validity of the octal digits**, and **the loop can read beyond the intended bounds** if the input is malformed or malicious.\n\n9. Furthermore, the function uses `UChar(*sp)` \u2014 which is likely a macro to cast to `unsigned char`. This is safe, but the real danger is in the **unbounded loop** and **lack of input validation**.\n\n10. The function returns `len`, which is the number of characters consumed from `sp`. If the input is crafted to have many digits (e.g., `\\01234567890123456789`), the loop will read many characters, potentially leading to:\n    - **Buffer overflow** if `sp` is not null-terminated or if the buffer is not large enough.\n    - **Denial of service** via infinite loop (if `isdigit()` returns true for non-digit characters, but that's unlikely).\n\n11. But the most serious issue: **the function does not validate that octal digits are only 0\u20137**. This is a **critical flaw** because it allows invalid octal sequences to be processed, leading to **incorrect or unexpected character values**, which could be exploited in certain contexts (e.g., if the output is used in a configuration or command injection).\n\n12. However, the function does not directly write to a fixed-size buffer without bounds checking \u2014 it uses `save_string` and `save_char`, which are presumably safe functions that manage the `dp` buffer. But if `dp` is a fixed-size buffer and `save_string`/`save_char` do not check bounds, then **buffer overflow** could occur.\n\n13. But the code does not show the implementation of `save_string` and `save_char`. However, the function is designed to write to `dp`, which is likely a pointer to a buffer being built. If `dp` is not properly bounded, or if the output grows too large, this could lead to **buffer overflow**.\n\n14. The **most critical vulnerability** is the **lack of validation of octal digits (0\u20137 only)** and **unbounded digit reading**. This can lead to:\n    - **Incorrect character interpretation**.\n    - **Potential buffer overflow** if the output grows too large.\n    - **Undefined behavior** due to integer overflow.\n\n15. In security terms, this is a **classic example of improper input validation** and **lack of bounds checking** in parsing escape sequences. This can be exploited to cause crashes, memory corruption, or even code execution if the output is used in a sensitive context.\n\nTherefore, this code contains a **security vulnerability** due to:\n- Unbounded reading of digits in octal escape sequences.\n- No validation that octal digits are only 0\u20137.\n- Potential for buffer overflow in the output buffer if `save_string`/`save_char` do not check bounds.\n\n(1) YES: A security vulnerability detected."}
{"idx": 442587, "project": "spice", "commit_id": "a4a16ac42d2f19a17e36556546aa94d5cd83745f", "project_url": "https://gitlab.freedesktop.org/spice/spice", "commit_url": "https://gitlab.freedesktop.org/spice/spice/commit/a4a16ac42d2f19a17e36556546aa94d5cd83745f", "commit_message": "memslot: Fix off-by-one error in group/slot boundary check\n\nRedMemSlotInfo keeps an array of groups, and each group contains an\narray of slots. Unfortunately, these checks are off by 1, they check\nthat the index is greater or equal to the number of elements in the\narray, while these arrays are 0 based. The check should only check for\nstrictly greater than the number of elements.\n\nFor the group array, this is not a big issue, as these memslot groups\nare created by spice-server users (eg QEMU), and the group ids used to\nindex that array are also generated by the spice-server user, so it\nshould not be possible for the guest to set them to arbitrary values.\n\nThe slot id is more problematic, as it's calculated from a QXLPHYSICAL\naddress, and such addresses are usually set by the guest QXL driver, so\nthe guest can set these to arbitrary values, including malicious values,\nwhich are probably easy to build from the guest PCI configuration.\n\nThis patch fixes the arrays bound check, and adds a test case for this.\nThis fixes CVE-2019-3813.\n\nSigned-off-by: Christophe Fergeau <cfergeau@redhat.com>\nAcked-by: Frediano Ziglio <fziglio@redhat.com>", "ground_truth": 0, "cwe": ["CWE-193"], "cve": "CVE-2019-3813", "cve_desc": "Spice, versions 0.5.2 through 0.14.1, are vulnerable to an out-of-bounds read due to an off-by-one error in memslot_get_virt. This may lead to a denial of service, or, in the worst case, code-execution by unauthenticated attackers.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `memslot_get_virt` is responsible for translating a physical address (`addr`) to a virtual address (`h_virt`) within a memory slot, based on group_id and slot_id.\n\n2) The function performs several validation checks:\n   - It checks if `group_id` is within bounds (`group_id >= info->num_memslots_groups`)\n   - It computes `slot_id` using `memslot_get_id(info, addr)` and checks if it's valid\n   - It retrieves the `generation` of the address and compares it with the slot's generation\n   - It calls `__get_clean_virt(info, addr)` to get the base virtual address\n   - It adds `slot->address_delta` to get the final virtual address\n   - It validates the resulting virtual address using `memslot_validate_virt`\n\n3) The key security consideration is whether there's a risk of buffer overflow, out-of-bounds access, or memory corruption.\n\n4) The function uses `addr` (a QXLPHYSICAL, which is likely a 64-bit integer) to compute `slot_id` and `generation`. The `memslot_get_id` and `memslot_get_generation` functions are assumed to be properly implemented and bounds-checked.\n\n5) The `__get_clean_virt` function is called with `addr`, and the result is added to `slot->address_delta`. This could potentially lead to an overflow if `h_virt + slot->address_delta` exceeds the maximum representable value of `unsigned long`, but this is not a direct buffer overflow or memory corruption issue.\n\n6) The function then calls `memslot_validate_virt` with the computed `h_virt`, `slot_id`, `add_size`, and `group_id`. This validation function is expected to check that the virtual address range is valid and within bounds.\n\n7) The function returns `NULL` if any validation fails, which prevents use of invalid or out-of-bounds addresses.\n\n8) There is no direct use of unsafe string functions, no direct memory copying without bounds checking, and no use of user-controlled data in arithmetic without validation.\n\n9) The validation chain (group_id check, slot_id check, generation check, and final validation) appears to be comprehensive and prevents access to invalid or unauthorized memory regions.\n\n10) The function does not perform any unchecked arithmetic that could lead to integer overflow or underflow that would result in memory corruption.\n\nConclusion: The function implements multiple layers of validation and bounds checking, and returns NULL on any failure, preventing access to invalid memory. There is no evidence of a security vulnerability such as buffer overflow, use-after-free, or out-of-bounds access.\n\n(2) NO: No security vulnerability."}
{"idx": 508874, "project": "server", "commit_id": "3a52569499e2f0c4d1f25db1e81617a9d9755400", "project_url": "https://github.com/MariaDB/server", "commit_url": "https://github.com/MariaDB/server/commit/3a52569499e2f0c4d1f25db1e81617a9d9755400", "commit_message": "MDEV-25636: Bug report: abortion in sql/sql_parse.cc:6294\n\nThe asserion failure was caused by this query\n\n  select /*id=1*/ from t1\n  where\n   col= ( select /*id=2*/ from ... where corr_cond1\n          union\n          select /*id=4*/ from ... where corr_cond2)\n\nHere,\n- select with id=2 was correlated due to corr_cond1.\n- select with id=4 was initially correlated due to corr_cond2, but then\n  the optimizer optimized away the correlation, making the select with id=4\n  uncorrelated.\n\nHowever, since select with id=2 remained correlated, the execution had to\nre-compute the whole UNION. When it tried to execute select with id=4, it\nhit an assertion  (join buffer already free'd).\n\nThis is because select with id=4 has freed its execution structures after\nit has been executed once. The select is uncorrelated, so it did not expect\nit would need to be executed for the second time.\n\nFixed this by adding this logic in\nst_select_lex::optimize_unflattened_subqueries():\n\n  If a member of a UNION is correlated, mark all its members as\n  correlated, so that they are prepared to be executed multiple times.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-46664", "cve_desc": "MariaDB through 10.5.9 allows an application crash in sub_select_postjoin_aggr for a NULL value of aggr.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `st_select_lex::optimize_unflattened_subqueries` is part of a SQL query optimizer in a database system (likely MySQL).\n   - It processes subqueries, particularly unflattened ones (i.e., subqueries that are not merged into the outer query), and optimizes them.\n   - It handles various types of subqueries, including those with `IN`, `EXISTS`, and `UNION` constructs.\n   - The function iterates over `SELECT_LEX_UNIT`s (representing subquery units) and their constituent `SELECT_LEX` (individual select statements), optimizing each.\n\n2. **Input and Data Flow**:\n   - The function takes a boolean `const_only` and operates on internal data structures (`SELECT_LEX_UNIT`, `Item_subselect`, `JOIN`, etc.).\n   - The input is not user-controlled directly; it's part of the query execution plan built during parsing.\n   - The function does not read user input directly (e.g., via `scanf`, `getenv`, `strcpy`, etc.), nor does it perform string formatting, memory copying, or dynamic memory allocation without bounds checking.\n\n3. **Potential Vulnerability Areas**:\n   - **Buffer Overflows**: No array indexing or string copying is visible. All operations are on pointers and internal structures. No `strcpy`, `strcat`, `memcpy`, or similar unsafe functions are used.\n   - **Use-After-Free or Dangling Pointers**: The code uses `next_unit` and `un->next_unit()` carefully, and `un->exclude_level()` is called only when appropriate. The loop logic appears sound, and `next_unit` is reset appropriately. No evidence of invalid pointer dereference.\n   - **Integer Overflows/Underflows**: No arithmetic on user-controlled values is present. All loop counters and conditions are based on internal data structures.\n   - **SQL Injection**: This is not a code path that constructs SQL strings from user input. The function operates on already-parsed query trees. The `Item_subselect` objects are part of the internal query plan, not user input strings.\n   - **Logic Errors vs. Security Vulnerabilities**: The code checks for `subquery_predicate->fixed`, `const_item()`, `empty_result()`, and `is_correlated`. These are correct logical checks for query optimization. The handling of `UNCACHEABLE_DEPENDENT` and `union_plan_saved` is appropriate for query execution semantics.\n   - **Memory Safety**: The function uses `save_options`, `save_select`, and restores state after optimization. This is a standard pattern to avoid side effects and is safe.\n\n4. **Security Implications**:\n   - The function is part of the query optimizer, which is a trusted component of the database engine.\n   - It does not expose any external interface or handle untrusted input directly.\n   - There is no evidence of unsafe memory access, improper bounds checking, or injection vectors.\n   - The code is defensive: it checks for null pointers (`if (subquery_predicate)`), validates state (`if (!subquery_predicate->fixed)`), and restores context (`save_options`, `save_select`).\n\n5. **Conclusion**:\n   - The code is well-structured, uses safe patterns for traversal and state management, and operates on internal query plan data.\n   - No exploitable vulnerabilities (buffer overflow, use-after-free, injection, etc.) are present.\n   - The function correctly handles subquery optimization, including correlated and union subqueries, without introducing security risks.\n\n(2) NO: No security vulnerability."}
{"idx": 400779, "project": "php-src", "commit_id": "095cbc48a8f0090f3b0abc6155f2b61943c9eafb", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commitdiff;h=095cbc48a8f0090f3b0abc6155f2b61943c9eafb", "commit_message": "Fix segfault in older versions of OpenSSL (before 0.9.8i)", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2012-6113", "cve_desc": "The openssl_encrypt function in ext/openssl/openssl.c in PHP 5.3.9 through 5.3.13 does not initialize a certain variable, which allows remote attackers to obtain sensitive information from process memory by providing zero bytes of input data.", "vuln": 1, "reasoning": "Let's analyze the provided PHP code for `openssl_decrypt` function step by step, focusing on potential security vulnerabilities.\n\n1. **Input Validation and Parsing**:\n   - The function uses `zend_parse_parameters` to parse arguments: `data`, `method`, `password`, and optional `raw_input` and `iv`.\n   - It checks for empty `method` and returns an error if so. This prevents using an invalid cipher algorithm.\n   - It uses `EVP_get_cipherbyname(method)` to get the cipher type. If the cipher is unknown, it returns an error. This is good practice.\n\n2. **Base64 Decoding**:\n   - If `raw_input` is false, it decodes the `data` from base64 using `php_base64_decode`. The decoded data is stored in `base64_str`, and `data` is updated to point to the decoded data.\n   - This is safe as long as `php_base64_decode` properly handles malformed input (which it does by returning NULL on error, and the code checks `base64_str_len` after decoding).\n\n3. **Key Handling**:\n   - The function determines the required key length via `EVP_CIPHER_key_length(cipher_type)`.\n   - If the provided `password` is shorter than the required key length, it allocates a new buffer (`key`) of the correct size, zero-fills it, and copies the password into it.\n   - If the password is longer than the key length, it uses the password directly (but note: `EVP_CIPHER_CTX_set_key_length` is called only if `password_len > keylen`, which is correct).\n   - However, this is a **critical issue**: the code uses the password directly as the key even if it's longer than the key length. This is **not safe** because:\n     - For many ciphers, the key must be exactly the length specified by `EVP_CIPHER_key_length`. Using a longer key may result in undefined behavior or truncation, but more importantly, **the OpenSSL EVP interface does not automatically truncate or hash the key**.\n     - The `EVP_CIPHER_CTX_set_key_length` call is used to set the key length, but **this only affects the key length used in the cipher context, not the actual key material**. If the password is longer than the key length, the extra bytes are ignored, but the function does not hash or derive the key properly.\n     - This can lead to **weak key derivation** and potential vulnerabilities, especially if the password is longer than the key length but not properly processed (e.g., via PBKDF2, HKDF, etc.).\n\n4. **IV Handling**:\n   - The function calls `php_openssl_validate_iv` to validate and possibly allocate a new IV if needed.\n   - It ensures the IV length matches the expected block size for the cipher.\n   - This is handled correctly and safely.\n\n5. **Decryption Process**:\n   - The function initializes the cipher context with `EVP_DecryptInit`, then sets the key and IV with `EVP_DecryptInit_ex`.\n   - It performs `EVP_DecryptUpdate` and `EVP_DecryptFinal` to decrypt the data.\n   - The output buffer is allocated with `outlen = data_len + EVP_CIPHER_block_size(cipher_type)`, which is sufficient for the decrypted data (including padding).\n   - The result is null-terminated and returned via `RETVAL_STRINGL`.\n\n6. **Memory Management**:\n   - The function properly frees:\n     - `key` if it was allocated (not the same as `password`).\n     - `iv` if it was allocated by `php_openssl_validate_iv`.\n     - `base64_str` if it was allocated.\n     - The output buffer on failure.\n   - `EVP_CIPHER_CTX_cleanup` is called at the end.\n\n7. **Critical Security Issue**:\n   - The most serious issue is **key handling**: when the password is longer than the required key length, the function uses the full password as the key without any key derivation or hashing.\n   - This is **not secure** because:\n     - It assumes the password is already the correct key length, which is not typical.\n     - It does not use a key derivation function (KDF) like PBKDF2, which is standard for password-based encryption.\n     - This can lead to **predictable or weak keys**, especially if the password is long but not properly processed.\n   - This is a **known vulnerability pattern** in cryptographic implementations: using raw passwords as keys without proper key derivation.\n\n8. **Conclusion**:\n   - While the code handles buffer overflows, memory leaks, and input validation reasonably well, the **lack of proper key derivation** when the password is longer than the key length is a **critical security flaw**.\n   - This violates best practices in cryptography and can lead to weak encryption.\n\n(1) YES: A security vulnerability detected."}
{"idx": 401034, "project": "radare2", "commit_id": "2b77b277d67ce061ee6ef839e7139ebc2103c1e3", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/2b77b277d67ce061ee6ef839e7139ebc2103c1e3", "commit_message": "Fix oobread in dyldcache ##crash\n\n* Reported by @hdthky via huntr.dev\n* Reproducers: poc1\n* BountyID: 8ae2c61a-2220-47a5-bfe8-fe6d41ab1f82", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-1244", "cve_desc": "heap-buffer-overflow in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of inducing denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - `RList *bins = r_list_newf ((RListFree)free_bin);` \u2013 This creates a new list with a proper free function. Safe.\n   - `ut16 *depArray = NULL;` and `cache_imgxtr_t *extras = NULL;` \u2013 These are initialized to NULL, which is safe.\n   - `target_libs = r_sys_getenv(\"R_DYLDCACHE_FILTER\");` \u2013 Retrieves an environment variable. This is user-controlled input, so it must be handled carefully.\n\n2. **Input Validation and Parsing**:\n   - `target_lib_names = r_str_split_list(target_libs, \":\", 0);` \u2013 Splits the environment variable by `:`. This is safe as long as the input is properly handled.\n   - `deps = R_NEWS0(int, cache->hdr->imagesCount);` \u2013 Allocates memory for dependency tracking. The size is based on `imagesCount`, which comes from the cache header. This is a trusted source (parsed from the dyld cache), so no immediate buffer overflow risk here.\n\n3. **Use of User-Controlled Input**:\n   - The environment variable `R_DYLDCACHE_FILTER` is used to filter libraries. This input is used in:\n     - `r_list_find(target_lib_names, lib_name, string_contains)` \u2013 This checks if a library name is in the filtered list. The `string_contains` function is used as a comparator. This is safe as long as `string_contains` is implemented correctly (i.e., it doesn't cause buffer overflows).\n     - `strstr(lib_name, \"libobjc.A.dylib\")` \u2013 This checks for a specific library name. Safe.\n   - The `lib_name` is obtained via `get_lib_name(cache->buf, &img[j])`, which reads from the dyld cache. This is a trusted source (the cache is parsed and validated earlier), so no arbitrary data is read from untrusted input.\n\n4. **Buffer Handling and String Operations**:\n   - `char file[256];` \u2013 Fixed-size buffer. This is safe as long as the input is not longer than 255 characters.\n   - `r_buf_read_at(cache->buf, img[j].pathFileOffset, (ut8*) &file, sizeof(file))` \u2013 Reads up to 256 bytes into `file`. This is safe because the buffer size is explicitly checked.\n   - `file[255] = 0;` \u2013 Ensures null termination.\n   - `strrchr(file, '/')` and subsequent string manipulation \u2013 These operations are bounded by the `file` buffer size and use standard string functions safely.\n   - `bin->file = strdup(scan + 1);` \u2013 `strdup` is used on a substring that is guaranteed to be within the `file` buffer. Since `file` is 256 bytes and the input is read from a trusted source (dyld cache), this is safe.\n\n5. **Loop and Index Handling**:\n   - The loop over `i` and `j` uses `hdr->imagesCount`, which is part of the parsed cache header. This is trusted.\n   - `depArray` is allocated with `cache->accel->depListCount`, which is also from the cache header. This is trusted.\n   - `depArray[k] != 0xffff` \u2013 This is a known sentinel value used in dyld caches. Safe.\n   - `ut16 dep_index = depArray[k] & 0x7fff;` \u2013 Masking to remove the high bit. This is safe and prevents out-of-bounds access.\n\n6. **Error Handling and Resource Management**:\n   - The code uses `goto next;` to jump to cleanup on error, and `R_FREE` macros are used for cleanup. This ensures that memory is freed even on error paths.\n   - `R_FREE (depArray); R_FREE (extras); R_FREE (img);` \u2013 These are called in `next:` and at the end, preventing memory leaks.\n\n7. **Potential Issues**:\n   - The only user-controlled input is `R_DYLDCACHE_FILTER`, which is used to filter libraries. However, this input is only used in string comparisons (`strstr`, `r_list_find`) and does not affect memory layout or control flow in a dangerous way.\n   - The `string_contains` function is used as a comparator. If this function were poorly implemented (e.g., buffer overflow), it could be a problem. But since it's part of the R2 library and used in a standard way, it's assumed to be safe.\n   - The `get_lib_name` function reads from the cache buffer. If the cache is malformed, it could lead to out-of-bounds reads. However, this is a general issue with parsing untrusted binary formats, and the code already checks for `get_lib_name` returning `NULL`, which is handled.\n\n8. **Conclusion**:\n   - All memory operations are bounded.\n   - User input is used only in safe string operations.\n   - No buffer overflows, use-after-free, or arbitrary memory writes are present.\n   - The code follows safe practices: input validation, bounded reads, proper cleanup, and error handling.\n\n(2) NO: No security vulnerability."}
{"idx": 333503, "project": "php-src", "commit_id": "8fa9d1ce28f3a894b104979df30d0b65e0f21107", "project_url": "https://github.com/php/php-src", "commit_url": "https://git.php.net/?p=php-src.git;a=commit;h=8fa9d1ce28f3a894b104979df30d0b65e0f21107", "commit_message": "improve fix #72558, while (u>=0) with unsigned int will always be true", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2016-6207", "cve_desc": "Integer overflow in the _gdContributionsAlloc function in gd_interpolation.c in GD Graphics Library (aka libgd) before 2.2.3 allows remote attackers to cause a denial of service (out-of-bounds memory write or memory consumption) via unspecified vectors.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `_gdContributionsAlloc` allocates memory for a `LineContribType` structure and its nested components:\n   - First, it allocates the main structure (`LineContribType`)\n   - Then allocates an array of `ContributionType` elements (`ContribRow`) of size `line_length`\n   - For each element in `ContribRow`, it allocates an array of `double` values (`Weights`) of size `windows_size`\n\n2) The function checks for overflow using `overflow2(line_length, sizeof(ContributionType))` before allocating the `ContribRow` array. This is a good practice to prevent integer overflow when calculating the size of the allocation.\n\n3) The function also checks for overflow using `overflow2(windows_size, sizeof(double))` before allocating each `Weights` array. This is also a good practice.\n\n4) The function properly handles allocation failures:\n   - If any `gdMalloc` call fails, it frees previously allocated memory\n   - It uses a loop to free all previously allocated `Weights` arrays before freeing the main structure\n   - It returns NULL in case of any failure\n\n5) The function uses a flag `overflow_error` to track overflow conditions, and if either overflow occurs or allocation fails, it cleans up all allocated memory before returning NULL.\n\n6) The cleanup logic is correct: it decrements `u` (to avoid accessing an invalid index) and frees all previously allocated `Weights` arrays, then frees the main structure.\n\n7) The function properly handles all error cases and performs memory cleanup, preventing memory leaks.\n\n8) The use of `overflow2` function suggests that the code is designed to detect integer overflow conditions that could lead to buffer overflows or other memory corruption issues.\n\n9) All memory allocations are properly validated, and the function ensures that no memory is leaked in case of failure.\n\n(2) NO: No security vulnerability."}
{"idx": 504608, "project": "libtiff", "commit_id": "dc02f9050311a90b3c0655147cee09bfa7081cfc", "project_url": "https://github.com/vadz/libtiff", "commit_url": "https://github.com/vadz/libtiff/commit/dc02f9050311a90b3c0655147cee09bfa7081cfc", "commit_message": "* libtiff/tif_read.c: add protection against excessive memory\nallocation attempts in TIFFReadDirEntryArray() on short files.\nEffective for mmap'ed case. And non-mmap'ed case, but restricted\nto 64bit builds.\nFixes http://bugzilla.maptools.org/show_bug.cgi?id=2675", "ground_truth": 0, "cwe": ["CWE-770"], "cve": "CVE-2017-12944", "cve_desc": "The TIFFReadDirEntryArray function in tif_read.c in LibTIFF 4.0.8 mishandles memory allocation for short files, which allows remote attackers to cause a denial of service (allocation failure and application crash) in the TIFFFetchStripThing function in tif_dirread.c during a tiff2pdf invocation.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `TIFFReadDirEntryArrayWithLimit` reads a TIFF directory entry into a buffer, with a limit on the number of elements (`maxcount`) and proper handling of data types and sizes.\n\n2. The function starts by determining the size of the data type using `TIFFDataWidth(direntry->tdir_type)`, which returns the size in bytes for a given TIFF data type (e.g., 1 for TIFF_BYTE, 2 for TIFF_SHORT, etc.).\n\n3. It computes `target_count64` as the minimum of `direntry->tdir_count` and `maxcount`, which ensures that the number of elements read does not exceed the specified limit. This is a good safety measure to prevent excessive memory allocation.\n\n4. The function checks for zero `target_count64` or zero `typesize`, and returns early if so. This avoids invalid operations.\n\n5. It performs a sanity check to prevent overflow in size calculations:\n   - `(uint64)(2147483647/typesize) < target_count64` \u2192 if true, returns error.\n   - Same check for `desttypesize`.\n\n   This is a critical check: it ensures that `target_count64 * typesize` would not exceed 2GB (2147483647 bytes), which prevents integer overflow when computing `datasize`. This is a well-known mitigation for overflow vulnerabilities in size calculations.\n\n6. The `datasize` is computed as `(*count) * typesize`, and an assertion ensures that `datasize > 0`. This is safe because `*count` is derived from `target_count64`, which is bounded by `maxcount` and `direntry->tdir_count`, and `typesize` is non-zero.\n\n7. The function checks if the data size exceeds the file size when the file is memory-mapped (`isMapped(tif)`), preventing reading beyond the file bounds.\n\n8. For non-mapped files, it checks whether the data size exceeds 4 bytes (for classic TIFF) or 8 bytes (for BigTIFF). If so, it allocates memory via `_TIFFCheckMalloc`, which is a safe wrapper that checks for allocation failures.\n\n9. The data is then read either from the file (via `TIFFReadDirEntryData` or `TIFFReadDirEntryDataAndRealloc`) or copied directly from the offset if small enough.\n\n10. Memory is properly freed on error via `_TIFFfree(data)`.\n\n11. The function uses `uint64` for `target_count64` and `offset` calculations, which helps prevent overflow in large file handling.\n\n12. The use of `TIFFSwabLong` and `TIFFSwabLong8` for byte-swapping is correct and safe.\n\n13. The function properly bounds the number of elements via `maxcount`, and validates sizes to prevent overflow.\n\n14. All memory allocations are checked, and errors are handled gracefully.\n\n15. The function does not perform any unsafe operations like `strcpy`, `memcpy` without bounds checking, or direct user input interpretation.\n\nConclusion: The code includes multiple safeguards against integer overflow, buffer overflows, and out-of-bounds memory access. It properly validates input sizes, limits the number of elements, checks for overflow in size calculations, and handles memory allocation safely.\n\n(2) NO: No security vulnerability."}
{"idx": 224277, "project": "flatpak", "commit_id": "462fca2c666e0cd2b60d6d2593a7216a83047aaf", "project_url": "https://github.com/flatpak/flatpak", "commit_url": "https://github.com/flatpak/flatpak/commit/462fca2c666e0cd2b60d6d2593a7216a83047aaf", "commit_message": "run: Don't allow chroot()\n\nIf we don't allow pivot_root() then there seems no reason why we should\nallow chroot().\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2021-41133", "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\nStep 1: Understand the purpose of the code.\nThis function `setup_seccomp` is part of Flatpak's bubblewrap (bwrap) sandboxing mechanism. It sets up seccomp filters to restrict system calls (syscalls) that a sandboxed process can make. The goal is to enhance security by blocking dangerous or unnecessary syscalls.\n\nStep 2: Examine the syscall blocklist.\nThe code defines a list of syscalls to be blocked using `seccomp_rule_add`. Each entry specifies:\n- A syscall (e.g., `syslog`, `mount`, `clone`, `ptrace`)\n- An error code to return (`EPERM` or `ENOSYS`)\n- Optional argument matching (e.g., `SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)` to block `clone` only when `CLONE_NEWUSER` is set)\n\nThis is a well-known and standard approach in sandboxing: block dangerous syscalls that could escape the sandbox or compromise system integrity.\n\nStep 3: Check for missing or weak restrictions.\n- `clone` is blocked with a condition on `CLONE_NEWUSER`, which is correct because `CLONE_NEWUSER` allows creating new user namespaces \u2014 a privilege escalation vector.\n- `mount`, `umount`, `pivot_root`, `chroot`, `unshare`, `setns` are all blocked \u2014 essential for preventing namespace manipulation and filesystem escape.\n- `ptrace` is blocked \u2014 prevents debugging and process inspection.\n- `perf_event_open` is blocked \u2014 avoids performance monitoring that could be abused.\n- `personality` is blocked with a condition on `allowed_personality` \u2014 prevents changing execution environment.\n- `socket` filtering is done carefully: only specific families (AF_LOCAL, AF_INET, etc.) are allowed, and all others are blocked via `SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1)` and intermediate blocking.\n\nStep 4: Check for potential bypasses or logic flaws.\n- The `socket` family allowlist is processed in numerical order, and all non-allowed families are blocked via `seccomp_rule_add_exact`. This is correct and prevents bypasses.\n- The use of `seccomp_rule_add_exact` for socket filtering is intentional to avoid libseccomp's default behavior (which could interfere with the rule).\n- The `clone` syscall is blocked conditionally based on architecture (s390 vs. others), which is correct due to differing `clone` argument order.\n- `clone3` is blocked with `ENOSYS` to force fallback to `clone`, which is a known mitigation for seccomp limitations (as noted in the comment).\n- `open_tree`, `move_mount`, `mount_setattr`, etc., are blocked \u2014 these are modern mount APIs that could bypass traditional mount restrictions.\n\nStep 5: Check for input validation and error handling.\n- The function validates `arch` and maps it to `SCMP_ARCH_*` values.\n- It uses `seccomp_arch_add` to add target architecture, with a check for `EEXIST` \u2014 safe.\n- It uses `g_return_val_if_fail` to ensure `errnum` is `EPERM` or `ENOSYS` \u2014 prevents invalid error codes.\n- Error handling is robust: returns `FALSE` or `flatpak_fail_error` on failure, with descriptive messages.\n\nStep 6: Consider known vulnerabilities and best practices.\n- The code references multiple secure sandboxing projects (Sandstorm, systemd, Docker) and aligns with their blocklists.\n- It avoids common pitfalls: no use of `strcpy`, `strcat`, or unsafe memory operations.\n- No direct user input is used in a way that could lead to buffer overflow or injection.\n- The seccomp filter is exported to BPF and loaded via `--seccomp` argument \u2014 standard and secure.\n\nStep 7: Final assessment.\nThe code implements a comprehensive, well-structured, and secure seccomp filter. It blocks dangerous syscalls, uses proper argument matching, handles architecture differences correctly, and avoids known bypasses. The error handling is robust, and the design follows established security best practices.\n\n(2) NO: No security vulnerability."}
{"idx": 421378, "project": "mujs", "commit_id": "f5b3c703e18725e380b83427004632e744f85a6f", "project_url": "https://github.com/ccxvii/mujs", "commit_url": "https://github.com/ccxvii/mujs/commit/f5b3c703e18725e380b83427004632e744f85a6f", "commit_message": "Issue #161: Cope with empty programs in mujs-pp.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-30975", "cve_desc": "In Artifex MuJS through 1.2.0, jsP_dumpsyntax in jsdump.c has a NULL pointer dereference, as demonstrated by mujs-pp.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `jsP_dumpsyntax` takes three parameters:\n   - `js_State *J`: a pointer to the JavaScript interpreter state (likely used for context, but not directly used in this function).\n   - `js_Ast *prog`: a pointer to an abstract syntax tree (AST) representing a program.\n   - `int dominify`: an integer flag that controls formatting behavior (minification).\n\n2. The function sets a global variable `minify` to the value of `dominify`. This suggests that `minify` is a global or static variable used elsewhere in the code to control output formatting.\n\n3. The function checks if `prog` is non-null. If so, it checks the type of the AST node:\n   - If `prog->type == AST_LIST`, it calls `pstmlist(-1, prog)`.\n   - Otherwise, it calls `pstm(0, prog)` followed by `nl()` (which likely outputs a newline).\n\n4. After processing the AST, if `minify > 1`, it calls `putchar('\\n')` to output a newline.\n\n5. Key observations:\n   - There is no user input directly processed or manipulated in this function.\n   - The function only traverses and outputs an AST structure that was presumably generated from parsed JavaScript code.\n   - The AST is not user-controlled in this context \u2014 it's internal to the interpreter and constructed during parsing.\n   - The function does not perform any string formatting, memory copying, or dynamic memory allocation that could lead to buffer overflows, format string vulnerabilities, or other classic issues.\n   - The use of `putchar('\\n')` is safe and does not depend on user input.\n   - The variable `minify` is used as a control flag, and its value is not used in a way that could lead to out-of-bounds access or memory corruption.\n\n6. No evidence of:\n   - Buffer overflows (no fixed-size buffers being written to without bounds checking).\n   - Format string vulnerabilities (no `printf`-style functions with user-controlled format strings).\n   - Memory corruption (no unsafe pointer arithmetic or use-after-free).\n   - Injection attacks (no dynamic code generation or interpretation of user input).\n\n7. The function is essentially a pretty-printer or minifier for an AST, and its behavior is deterministic based on the AST structure and the `dominify` flag.\n\nConclusion: The code does not contain any obvious security vulnerabilities. It operates on internal data structures (AST) that are not directly influenced by untrusted input in this function, and it does not perform any unsafe operations.\n\n(2) NO: No security vulnerability."}
{"idx": 376350, "project": "evolution-data-server", "commit_id": "5d8b92c622f6927b253762ff9310479dd3ac627d", "project_url": "https://git.gnome.org/browse/evolution-data-server", "commit_url": "https://git.gnome.org/browse/evolution-data-server/commit/?id=5d8b92c622f6927b253762ff9310479dd3ac627d", "commit_message": "CamelGpgContext: Enclose email addresses in brackets.\n\nThe recipient list for encrypting can be specified by either key ID or\nemail address.  Enclose email addresses in brackets to ensure an exact\nmatch, as per the gpg man page:\n\nHOW TO SPECIFY A USER ID\n\n       ...\n\n       By exact match on an email address.\n              This is indicated by enclosing the email address in the\n              usual way with left and right angles.\n\n         <heinrichh@uni-duesseldorf.de>\n\nWithout the brackets gpg uses a substring match, which risks selecting\nthe wrong recipient.", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2013-4166", "cve_desc": "The gpg_ctx_add_recipient function in camel/camel-gpg-context.c in GNOME Evolution 3.8.4 and earlier and Evolution Data Server 3.9.5 and earlier does not properly select the GPG key to use for email encryption, which might cause the email to be encrypted with the wrong key and allow remote attackers to obtain sensitive information.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `gpg_ctx_add_recipient` is designed to add a recipient key ID to a GPG context's list of recipients.\n\n2. The function first checks if the mode is either GPG_CTX_MODE_ENCRYPT or GPG_CTX_MODE_EXPORT. If not, it returns early. This is a valid safety check to ensure the function is only used in appropriate contexts.\n\n3. It initializes the `gpg->recipients` array if it is NULL using `g_ptr_array_new()`. This is safe and proper.\n\n4. It uses `g_return_if_fail(keyid != NULL)` to ensure the keyid is not NULL. This is a standard assertion to prevent null pointer dereference.\n\n5. The function checks if the keyid contains an '@' character. If so, it wraps the keyid in angle brackets using `g_strdup_printf(\"<%s>\", keyid)`. This is done to ensure an exact match when GPG processes the key ID, especially for email addresses.\n\n6. If there is no '@', it simply duplicates the keyid using `g_strdup()`.\n\n7. Finally, it adds the resulting `safe_keyid` string to the `gpg->recipients` array using `g_ptr_array_add()`.\n\nNow, consider potential security issues:\n\n- The function does not perform any validation on the format of the keyid beyond checking for '@'. However, this is not necessarily a vulnerability because GPG itself handles the parsing and validation of key IDs during encryption/export operations. The wrapping in `<...>` is a known convention to force exact matching, which is a legitimate and safe practice.\n\n- The use of `g_strdup_printf` and `g_strdup` is safe because they allocate memory correctly and the string is properly null-terminated.\n\n- There is no risk of buffer overflow because `g_strdup_printf` and `g_strdup` are safe string duplication functions that handle memory allocation correctly.\n\n- The function does not perform any dangerous operations like direct string concatenation into fixed buffers, or use of unsafe functions.\n\n- The only potential concern might be if an attacker could inject malicious content via the keyid, but GPG's key handling is designed to be secure even with user-provided identifiers. The use of angle brackets for email-like identifiers is a standard and safe practice.\n\nConclusion: The code is well-structured, uses safe string handling functions, performs necessary checks, and applies a known secure pattern (wrapping email addresses in brackets) to prevent ambiguity in key matching. No exploitable vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 497809, "project": "grep", "commit_id": "83a95bd8c8561875b948cadd417c653dbe7ef2e2", "project_url": "http://git.savannah.gnu.org/cgit/grep", "commit_url": "http://git.sv.gnu.org/cgit/grep.git/commit/?id=83a95bd8c8561875b948cadd417c653dbe7ef2e2", "commit_message": "grep -F: fix a heap buffer (read) overrun\n\ngrep's read buffer is often filled to its full size, except when\nreading the final buffer of a file.  In that case, the number of\nbytes read may be far less than the size of the buffer.  However, for\ncertain unusual pattern/text combinations, grep -F would mistakenly\nexamine bytes in that uninitialized region of memory when searching\nfor a match.  With carefully chosen inputs, one can cause grep -F to\nread beyond the end of that buffer altogether.  This problem arose via\ncommit v2.18-90-g73893ff with the introduction of a more efficient\nheuristic using what is now the memchr_kwset function. The use of\nthat function in bmexec_trans could leave TP much larger than EP,\nand the subsequent call to bm_delta2_search would mistakenly access\nbeyond end of the main input read buffer.\n\n* src/kwset.c (bmexec_trans): When TP reaches or exceeds EP,\ndo not call bm_delta2_search.\n* tests/kwset-abuse: New file.\n* tests/Makefile.am (TESTS): Add it.\n* THANKS.in: Update.\n* NEWS (Bug fixes): Mention it.\n\nPrior to this patch, this command would trigger a UMR:\n\n  printf %0360db 0 | valgrind src/grep -F $(printf %019dXb 0)\n\n  Use of uninitialised value of size 8\n     at 0x4142BE: bmexec_trans (kwset.c:657)\n     by 0x4143CA: bmexec (kwset.c:678)\n     by 0x414973: kwsexec (kwset.c:848)\n     by 0x414DC4: Fexecute (kwsearch.c:128)\n     by 0x404E2E: grepbuf (grep.c:1238)\n     by 0x4054BF: grep (grep.c:1417)\n     by 0x405CEB: grepdesc (grep.c:1645)\n     by 0x405EC1: grep_command_line_arg (grep.c:1692)\n     by 0x4077D4: main (grep.c:2570)\n\nSee the accompanying test for how to trigger the heap buffer overrun.\n\nThanks to Nima Aghdaii for testing and finding numerous\nways to break early iterations of this patch.", "ground_truth": 0, "cwe": ["CWE-119"], "cve": "CVE-2015-1345", "cve_desc": "The bmexec_trans function in kwset.c in grep 2.19 through 2.21 allows local users to cause a denial of service (out-of-bounds heap read and crash) via crafted input when using the -F option.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `bmexec_trans` is a part of a string matching engine, likely implementing a variant of the Boyer-Moore algorithm with additional optimizations (e.g., delta1 and delta2 tables, character translation, etc.). It searches for a pattern (stored in `kwset`) within a given text.\n\n2. The function takes:\n   - `kwset_t kwset`: a structure containing the pattern, delta tables, translation table, and other metadata.\n   - `char const *text`: the input text to search in.\n   - `size_t size`: the length of the text.\n\n3. Key checks:\n   - `if (len == 0)` \u2192 returns 0 (no pattern to match).\n   - `if (len > size)` \u2192 returns -1 (pattern longer than text).\n   - `if (len == 1)` \u2192 uses `memchr_kwset`, which is safe for single-character search.\n\n4. The main loop uses `d1[U(tp[-1])]` to compute the next jump in the search. The `U()` macro is likely a safe cast to `unsigned char` to avoid negative indexing issues (common in Boyer-Moore).\n\n5. The loop condition: `tp <= ep`, where `ep = text + size - 11 * len`. This ensures that the loop only runs when there are enough characters left to perform the 11-step delta jumps.\n\n6. The code uses `tp = memchr_kwset (tp, text + size - tp, kwset)` as a fallback when the heuristic detects small advances. This function is likely designed to search for a character that matches the last character of the pattern, which is safe as long as the bounds are respected.\n\n7. The `bm_delta2_search` function is called with `&tp`, `ep`, `sp`, `len`, etc. This function is responsible for the actual pattern matching and is expected to be safe if properly implemented.\n\n8. The final fallback loop:\n   ```c\n   while (d <= ep - tp)\n   {\n     d = d1[U((tp += d)[-1])];\n     if (d != 0) continue;\n     if (bm_delta2_search (&tp, ep, sp, len, trans, gc1, gc2, NULL, kwset))\n       return tp - text;\n   }\n   ```\n   Here, `tp` is incremented by `d`, and the loop continues as long as `d <= ep - tp`. This ensures that `tp` does not exceed `ep`, preventing out-of-bounds access.\n\n9. The function carefully bounds all pointer arithmetic:\n   - `ep` is set to `text + size` in the final loop.\n   - `tp` starts at `text + len`, and is advanced only by `d`, which is derived from `d1[U(...)]`, a table indexed by character values (0\u2013255).\n   - The condition `d <= ep - tp` ensures that `tp + d` does not exceed `ep`, so `tp` never goes beyond `ep`.\n\n10. The use of `U()` macro (likely `unsigned char`) prevents signed overflow issues when indexing into `d1`.\n\n11. The `memchr_kwset` function is used in a bounded way: `text + size - tp` ensures the search range is valid.\n\n12. No buffer overflows, no use of unsafe string functions (like `strcpy`, `strcat`, etc.), no direct user input manipulation without bounds checking.\n\n13. All pointer arithmetic is bounded by `size` and `ep`, and the loop conditions prevent out-of-bounds access.\n\n14. The function is part of a well-known library (likely GNU `gawk` or `grep`'s `kwset` implementation), and this code is known to be safe when used correctly.\n\nConclusion: The code performs careful bounds checking, uses safe pointer arithmetic, and avoids buffer overflows or out-of-bounds memory access. The logic is sound and does not introduce any exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 359206, "project": "bpf", "commit_id": "4b81ccebaeee885ab1aa1438133f2991e3a2b6ea", "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf.git/commit/?id=4b81ccebaeee885ab1aa1438133f2991e3a2b6ea", "commit_message": "bpf, ringbuf: Deny reserve of buffers larger than ringbuf\n\nA BPF program might try to reserve a buffer larger than the ringbuf size.\nIf the consumer pointer is way ahead of the producer, that would be\nsuccessfully reserved, allowing the BPF program to read or write out of\nthe ringbuf allocated area.\n\nReported-by: Ryota Shiga (Flatt Security)\nFixes: 457f44363a88 (\"bpf: Implement BPF ring buffer and verifier support for it\")\nSigned-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nAcked-by: Andrii Nakryiko <andrii@kernel.org>\nAcked-by: Alexei Starovoitov <ast@kernel.org>", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-3489", "cve_desc": "The eBPF RINGBUF bpf_ringbuf_reserve() function in the Linux kernel did not check that the allocated size was smaller than the ringbuf size, allowing an attacker to perform out-of-bounds writes within the kernel and therefore, arbitrary code execution. This issue was fixed via commit 4b81ccebaeee (\"bpf, ringbuf: Deny reserve of buffers larger than ringbuf\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. It was introduced via 457f44363a88 (\"bpf: Implement BPF ring buffer and verifier support for it\") (v5.8-rc1).", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `__bpf_ringbuf_reserve` is responsible for reserving space in a BPF ring buffer for a record of a given size.\n\n2. First, it checks if the requested size exceeds `RINGBUF_MAX_RECORD_SZ`. If so, it returns NULL. This prevents excessively large allocations and is a good safety check.\n\n3. It calculates the required length (`len`) as `round_up(size + BPF_RINGBUF_HDR_SZ, 8)`, ensuring alignment to 8 bytes. This is a standard practice to avoid misalignment issues.\n\n4. It then checks if `len > rb->mask + 1`. Since `rb->mask` is typically `ring_buffer_size - 1` (assuming a power-of-2 size), this ensures that the requested record size does not exceed the available ring buffer space. This is a correct bounds check.\n\n5. The function reads the current consumer position (`cons_pos`) using `smp_load_acquire`, which ensures visibility of updates from the consumer side.\n\n6. It acquires a spinlock using `spin_lock_irqsave` (or `spin_trylock_irqsave` in NMI context), which protects the producer's access to the ring buffer. This is necessary to prevent race conditions between producer and consumer.\n\n7. It computes the new producer position (`new_prod_pos = prod_pos + len`) and checks whether this would advance the producer position more than `rb->mask` ahead of the consumer position. This is a critical check: if `new_prod_pos - cons_pos > rb->mask`, it means the producer would wrap around and overwrite data that the consumer hasn't yet read. This is a correct and necessary check to prevent data corruption and buffer overflow.\n\n8. The function then writes the header (`hdr`) at the current producer position, setting the `len` field with the size and the `BPF_RINGBUF_BUSY_BIT` to mark the record as in use. It also sets `pg_off` based on the page offset.\n\n9. It uses `smp_store_release` to update the `producer_pos`, which ensures that the update is visible to the consumer after the header is written.\n\n10. Finally, it unlocks the spinlock and returns a pointer to the data portion of the record (after the header).\n\nKey observations:\n- The ring buffer size is bounded by `rb->mask + 1`, and the check `new_prod_pos - cons_pos > rb->mask` ensures that the producer does not overtake the consumer by more than the buffer size.\n- The use of `smp_load_acquire` and `smp_store_release` ensures proper memory ordering between producer and consumer.\n- The `spinlock` protects the critical section, and the function handles both normal and NMI contexts correctly.\n- The `len` calculation includes the header and is aligned, preventing misalignment issues.\n- The function returns NULL if the buffer is full or the size is invalid, which is safe behavior.\n\nThere are no buffer overflows, use-after-free, race conditions, or memory corruption issues. The logic correctly enforces ring buffer semantics and prevents overwriting unread data.\n\n(2) NO: No security vulnerability."}
{"idx": 276921, "project": "u-boot", "commit_id": "8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409", "project_url": "https://github.com/u-boot/u-boot", "commit_url": "https://github.com/u-boot/u-boot/commit/8f8c04bf1ebbd2f72f1643e7ad9617dafa6e5409", "commit_message": "i2c: fix stack buffer overflow vulnerability in i2c md command\n\nWhen running \"i2c md 0 0 80000100\", the function do_i2c_md parses the\nlength into an unsigned int variable named length. The value is then\nmoved to a signed variable:\n\n    int nbytes = length;\n    #define DISP_LINE_LEN 16\n    int linebytes = (nbytes > DISP_LINE_LEN) ? DISP_LINE_LEN : nbytes;\n    ret = dm_i2c_read(dev, addr, linebuf, linebytes);\n\nOn systems where integers are 32 bits wide, 0x80000100 is a negative\nvalue to \"nbytes > DISP_LINE_LEN\" is false and linebytes gets assigned\n0x80000100 instead of 16.\n\nThe consequence is that the function which reads from the i2c device\n(dm_i2c_read or i2c_read) is called with a 16-byte stack buffer to fill\nbut with a size parameter which is too large. In some cases, this could\ntrigger a crash. But with some i2c drivers, such as drivers/i2c/nx_i2c.c\n(used with \"nexell,s5pxx18-i2c\" bus), the size is actually truncated to\na 16-bit integer. This is because function i2c_transfer expects an\nunsigned short length. In such a case, an attacker who can control the\nresponse of an i2c device can overwrite the return address of a function\nand execute arbitrary code through Return-Oriented Programming.\n\nFix this issue by using unsigned integers types in do_i2c_md. While at\nit, make also alen unsigned, as signed sizes can cause vulnerabilities\nwhen people forgot to check that they can be negative.\n\nSigned-off-by: Nicolas Iooss <nicolas.iooss+uboot@ledger.fr>\nReviewed-by: Heiko Schocher <hs@denx.de>", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-34835", "cve_desc": "In Das U-Boot through 2022.07-rc5, an integer signedness error and resultant stack-based buffer overflow in the \"i2c md\" command enables the corruption of the return address pointer of the do_i2c_md function.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `do_i2c_md` is responsible for reading data from an I2C device and displaying it in a formatted way (hex and ASCII).\n\n2) The function takes command-line arguments via `argv` and processes them:\n   - `argv[1]`: I2C chip address (converted with hextoul)\n   - `argv[2]`: I2C data address (converted with hextoul, length determined by get_alen)\n   - `argv[3]`: Optional length parameter (number of objects to read)\n\n3) Input validation:\n   - Checks `argc < 3` \u2192 returns usage error if not enough arguments\n   - Validates `alen > 3` \u2192 returns usage error if address length exceeds 3 bytes\n   - Uses `hextoul` which safely converts hex strings to unsigned long, with proper bounds checking\n\n4) Buffer handling:\n   - Uses a fixed-size buffer `linebuf[DISP_LINE_LEN]` to store data read from I2C\n   - The size of `linebytes` is limited to `DISP_LINE_LEN` (which is a constant, likely small, e.g., 16 or 32)\n   - The loop reads data in chunks of `linebytes`, which is bounded by `DISP_LINE_LEN`\n\n5) I2C read operations:\n   - Uses `dm_i2c_read` or `i2c_read` with the `linebytes` parameter, which is bounded by `DISP_LINE_LEN`\n   - The `linebytes` value is never larger than `DISP_LINE_LEN`, so the buffer cannot be overflowed\n\n6) No user-controlled input is used to determine buffer size or loop bounds in a way that could lead to overflow.\n\n7) The function properly updates the last-used parameters (`i2c_dp_last_*`) for repeat usage, but this does not introduce a vulnerability.\n\n8) The function does not perform any string formatting with user input that could lead to format string vulnerabilities.\n\n9) All input is validated and bounded:\n   - `alen` is capped at 3\n   - `length` is converted via `hextoul` but used only to control loop iterations\n   - `linebytes` is capped by `DISP_LINE_LEN`\n   - Buffer size is fixed and sufficient for the bounded read\n\n10) The function does not use any unsafe functions like `strcpy`, `sprintf`, or `gets`. All operations are bounded by known constants.\n\nConclusion: The code properly validates and bounds all inputs, uses fixed-size buffers with safe read operations, and does not expose any known vulnerabilities such as buffer overflows, format string issues, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 264715, "project": "tensorflow", "commit_id": "7731e8dfbe4a56773be5dc94d631611211156659", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/7731e8dfbe4a56773be5dc94d631611211156659", "commit_message": "Don't constant-fold DT_RESOURCE constants.\n\nPiperOrigin-RevId: 391803952\nChange-Id: I0ea3ec31d3e7dfda0f03b4027a237f08d00a3091", "ground_truth": 0, "cwe": ["CWE-824"], "cve": "CVE-2021-41204", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `IsConstantFoldable` is part of a graph optimization system (likely TensorFlow), determining whether a node in a computational graph can be constant-folded (i.e., evaluated at compile time rather than runtime).\n\n2) The function performs multiple checks to determine if constant folding is safe or feasible:\n   - It skips nodes that are constants of type DT_RESOURCE (which cannot be deep copied).\n   - It handles shape replacement via `MaybeReplaceShapeOp`.\n   - It rejects stateful operations (`is_stateful()`).\n   - It respects a user-provided `consider` function to filter nodes.\n   - It checks output sizes against `max_constant_size_in_bytes` to prevent excessive memory usage.\n   - It rejects control flow nodes, send/recv, session handle operations, source/sink nodes, fake parameters, and nodes without CPU kernels.\n   - It also skips nodes that use scoped allocators.\n\n3) All checks are defensive and designed to prevent:\n   - Memory exhaustion (via size limit check)\n   - Invalid operations (e.g., on resources, stateful ops)\n   - Unsafe or unsupported node types\n   - Memory safety issues (e.g., by avoiding nodes that require special allocators)\n\n4) The function does not:\n   - Accept untrusted input directly\n   - Perform string concatenation or dynamic code execution\n   - Use unsafe memory operations\n   - Have any obvious buffer overflows, use-after-free, or injection vectors\n\n5) The checks are comprehensive and follow security best practices for graph optimization: they limit resource usage, prevent unsafe operations, and avoid executing untrusted or dangerous node types.\n\n6) There is no evidence of a security vulnerability such as buffer overflow, memory corruption, code injection, or privilege escalation.\n\n(2) NO: No security vulnerability."}
{"idx": 230302, "project": "njs", "commit_id": "2e00e95473861846aa8538be87db07699d9f676d", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/2e00e95473861846aa8538be87db07699d9f676d", "commit_message": "Fixed Array.prototype.slice() with slow \"this\" argument.\n\nPreviously, when \"this\" argument was not a fast array, but the \"deleted\" array\nwas a fast array, the \"deleted\" array may be left in uninitialized state if\n\"this\" argument had gaps.\n\nThis fix is to ensure that \"deleted\" is properly initialized.\n\nThis fixes #485 issue on Github.", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-29779", "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_value_own_enumerate at src/njs_value.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - This is a JavaScript engine function `njs_array_prototype_splice` implementing the `Array.prototype.splice` method.\n   - It modifies an array by removing elements and/or adding new ones at a specified index.\n   - The function takes arguments: `args`, `nargs`, and `unused`. It processes the array object (`this`), the `start` index, the number of elements to delete (`delete`), and optional new elements to insert (`items`).\n\n2. **Input Validation and Bounds Checking**:\n   - The function first checks if `this` is a valid object using `njs_value_to_object`.\n   - It retrieves the array length using `njs_object_length`.\n   - The `start` index is converted to an integer and normalized: if negative, it's adjusted relative to the array length (`start = length + start`), but clamped to `max(0, length + start)` to prevent underflow.\n   - The `delete` count is computed based on `nargs`:\n     - If `nargs == 2`, `delete = length - start` (remove all from `start` to end).\n     - If `nargs > 2`, `delete` is taken from the third argument, but clamped to `max(0, min(delete, length - start))` to prevent over-deletion.\n   - This ensures `delete` is within valid bounds: `0 <= delete <= length - start`.\n\n3. **Length Overflow Protection**:\n   - The function computes `delta = items - delete` (net change in array length).\n   - It checks: `if (length + delta > NJS_MAX_LENGTH)` \u2192 returns error.\n   - This prevents integer overflow or excessive array growth, which could lead to memory exhaustion or heap corruption.\n\n4. **Memory Allocation and Buffer Handling**:\n   - `deleted` array is allocated with size `delete` using `njs_array_alloc`. This is safe because `delete` is bounded.\n   - The function then copies the deleted elements into `deleted`:\n     - For fast arrays: uses direct memory copy (`array->start[n]`).\n     - For non-fast arrays: uses `njs_value_property_i64` to read each property and `njs_value_property_i64_set` to write to `deleted`.\n   - These operations are safe because:\n     - The loop runs `i < delete`, and `delete` is bounded.\n     - The `njs_value_property_i64` and `njs_value_property_i64_set` functions are designed to handle array indices safely.\n\n5. **Array Modification (Insert/Remove)**:\n   - For fast arrays:\n     - If `delta > 0`, it expands the array using `njs_array_expand` (safe, with bounds check).\n     - Then uses `njs_array_copy_within` to shift elements \u2014 this function is assumed to be safe as it's part of the engine.\n     - Finally, inserts new elements via `memcpy` from `args[3]` to `args[3 + items - 1]`.\n     - The `memcpy` size is `items * sizeof(njs_value_t)`, and `items` is derived from `nargs - 3`, which is bounded by the number of arguments.\n   - For non-fast arrays:\n     - Uses `njs_array_copy_within` with proper delta handling.\n     - Deletes excess properties via `njs_value_property_i64_delete` in reverse order.\n     - Inserts new elements via `njs_value_property_i64_set` in a loop.\n     - Finally sets the new length with `njs_object_length_set`.\n\n6. **Argument Bounds and Index Safety**:\n   - The `args` array is accessed starting from index 3 (`args[3]`), but only if `nargs > 3`.\n   - The loop for inserting new items runs `items` times, where `items = nargs - 3`, so it accesses exactly `items` arguments.\n   - No out-of-bounds access occurs because `items` is derived from `nargs` and validated.\n\n7. **No Use of Unsafe Functions**:\n   - No `strcpy`, `strcat`, `memcpy` with untrusted size, or similar functions that could overflow.\n   - All memory operations are bounded by validated counts (`delete`, `items`, `length`).\n   - All array indices are normalized and clamped.\n\n8. **No Injection or Code Execution Risks**:\n   - This is not a string or input parsing function; it's a core array manipulation function.\n   - No dynamic code evaluation, no string concatenation with user input, no external data interpretation.\n   - The only data being manipulated is structured JavaScript values (njs_value_t), which are type-safe and managed by the VM.\n\n9. **Conclusion**:\n   - All input parameters are validated and bounded.\n   - All array indices are normalized and clamped.\n   - All memory operations are size-checked and bounded.\n   - No known vulnerabilities such as buffer overflows, integer overflows, or use-after-free.\n   - The code follows safe practices for array manipulation in a VM context.\n\n(2) NO: No security vulnerability."}
{"idx": 225125, "project": "tensorflow", "commit_id": "f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/f68fdab93fb7f4ddb4eb438c8fe052753c9413e8", "commit_message": "Add a check for pad width to be a positive value.\n\nPiperOrigin-RevId: 413275853\nChange-Id: I261a8db9dabf5ce48a806a9e58129080c9fac619", "ground_truth": 0, "cwe": ["CWE-190"], "cve": "CVE-2022-21733", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `StringNGrams` can be used to trigger a denial of service attack by causing an out of memory condition after an integer overflow. We are missing a validation on `pad_witdh` and that result in computing a negative value for `ngram_width` which is later used to allocate parts of the output. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation for ngram_widths_**:\n   - The code iterates over `ngram_widths_` and checks that each value is greater than 0 using `OP_REQUIRES(context, ngram_width > 0, ...)`.\n   - This prevents invalid (non-positive) ngram widths, which could lead to incorrect or unsafe behavior. This is a good defensive check.\n\n2. **Input Tensor Validation**:\n   - The code retrieves two inputs: `\"data\"` (of type `tstring`) and `\"data_splits\"` (of type `SPLITS_TYPE`).\n   - It uses `OP_REQUIRES_OK(context, context->input(...))` to ensure the inputs are valid and non-null.\n   - This prevents null pointer dereferences and ensures that required inputs are present.\n\n3. **Splits Validation**:\n   - The code validates that `splits_vec` is non-empty and that:\n     - The first split is 0.\n     - Each subsequent split is \u2265 the previous one and \u2264 `input_data_size`.\n     - The last split equals `input_data_size`.\n   - These checks ensure that the splits form a valid partition of the input data, preventing out-of-bounds access when indexing into `input_data`.\n\n4. **Memory Allocation and Buffer Bounds**:\n   - The code allocates output tensors using `context->allocate_output(...)`, with sizes derived from validated inputs.\n   - The output `ngrams_splits` is allocated with shape matching `splits->shape()`, which is consistent with the input splits.\n   - The `ngrams` tensor is allocated with size `ngrams_splits_data[num_batch_items]`, which is computed based on the number of ngrams derived from valid splits and ngram widths.\n   - All indexing into `input_data`, `ngrams_data`, and `ngrams_splits_data` is bounded by the validated sizes and loop conditions.\n\n5. **Indexing and Loop Bounds**:\n   - All loops use valid indices derived from `splits_vec.size()`, `input_data_size`, and `num_batch_items`, which are validated earlier.\n   - The `CreateNgrams` function is called with `num_ngrams` computed from `get_num_ngrams`, which is assumed to be safe (not shown, but typically bounds-checked).\n   - The `output_start_idx` is updated only within the bounds of the allocated `ngrams_data` array, and the final `ngrams` tensor is allocated with exactly the required size.\n\n6. **Special Case for preserve_short_**:\n   - When `preserve_short_` is true and no ngrams are generated, the code adds a single ngram with a dynamically computed `ngram_width` based on `pad_width_`.\n   - It checks `pad_width_ >= 0`, which is a valid defensive check.\n   - The `CreateNgrams` call is again within bounds because `num_ngrams = 1` and the output buffer is large enough (since `ngrams_splits_data` was already allocated with sufficient size).\n\n7. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `memcpy`, or other unsafe C-style string/memory functions.\n   - All data access is through `flat<T>()` and `data()`, which are safe when bounds are validated.\n\n8. **No Buffer Overflows or Underflows**:\n   - All array accesses are within the bounds of the allocated tensors.\n   - The use of `OP_REQUIRES` ensures that invalid inputs are rejected early.\n   - The `splits` validation ensures that indices into `input_data` are valid.\n\n9. **No Injection or Code Execution Risks**:\n   - The code processes string data and splits, but does not interpret or execute any user-controlled strings as code.\n   - No dynamic evaluation, command execution, or unsafe parsing is involved.\n\nConclusion: The code performs comprehensive input validation, bounds checking, and safe memory management. All array accesses are within valid ranges, and no unsafe operations are used. There are no indications of buffer overflows, out-of-bounds memory access, or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 379334, "project": "vim", "commit_id": "c6fdb15d423df22e1776844811d082322475e48a", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/c6fdb15d423df22e1776844811d082322475e48a", "commit_message": "patch 9.0.0025: accessing beyond allocated memory with the cmdline window\n\nProblem:    Accessing beyond allocated memory when using the cmdline window in\n            Ex mode.\nSolution:   Use \"*\" instead of \"'<,'>\" for Visual mode.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-2288", "cve_desc": "Out-of-bounds Write in GitHub repository vim/vim prior to 9.0.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Function Purpose**: The function `parse_command_modifiers` is responsible for parsing command modifiers in Vim (e.g., `:silent`, `:silent!`, `:tab`, `:verbose 2`, etc.) from an input command string (`eap->cmd`). It modifies the `cmdmod_T` structure (`cmod`) to reflect which modifiers were present and adjusts the command pointer (`eap->cmd`) to point to the actual command to be executed.\n\n2. **Input Handling**: The function processes the command string (`eap->cmd`) by:\n   - Skipping whitespace, tabs, and colons.\n   - Handling special cases like visual range (`'<,'>`).\n   - Parsing modifiers one by one using a `switch` statement based on the first character of a command modifier (e.g., 's' for silent, 'v' for verbose, etc.).\n   - Using helper functions like `checkforcmd_noparen`, `skip_range`, `skipwhite`, `skip_vimgrep_pat_ext`, etc., which are designed to safely parse command syntax.\n\n3. **Memory Safety**:\n   - The function uses `mch_memmove` and `STRCPY` to manipulate strings, but only after ensuring that the source and destination are within valid bounds.\n   - The `skip_vimgrep_pat_ext` function is used to parse patterns (e.g., in `:filter`), and it properly handles the `reg_pat` and `nulp` (null pointer) to restore overwritten characters.\n   - The `vim_regcomp` call is used to compile a regular expression, but it is only called after `skip_vimgrep_pat_ext` returns a valid pattern, and the function checks for `NULL` return from `vim_regcomp` before proceeding.\n   - The `get_address` function is used to parse tab numbers, and it includes bounds checking (`tabnr < 0 || tabnr > LAST_TAB_NR`), which prevents out-of-bounds access.\n\n4. **Buffer Overflows and String Manipulation**:\n   - The function uses `mch_memmove` to shift parts of the command string (e.g., moving `'<,'>` to after modifiers). However, it does so only when `has_visual_range` is true and `eap->cmd > cmd_start`, ensuring that the move is safe.\n   - The `STRCPY` and `mch_memmove` operations are used with known lengths (`STRLEN(cmd_start)`, `len`, etc.), and the code ensures that the destination buffer is large enough (since `orig_cmd` is the original input and the manipulation is within the same buffer).\n   - There is no use of unsafe functions like `strcpy`, `strcat`, or `gets`.\n\n5. **Input Validation**:\n   - The function checks for null pointers and invalid input early (e.g., `if (!dest || !src || dest_size == 0)` is not present here, but the code uses `skipwhite`, `checkforcmd_noparen`, etc., which are designed to be safe).\n   - The `checkforcmd_noparen` function ensures that the command modifier is matched exactly and that the next character is not part of a longer word (e.g., `silent!` vs `silent`).\n   - The `ends_excmd` function is used to detect the end of a command, preventing parsing beyond the intended scope.\n\n6. **Vim9 Script Specific Logic**:\n   - The code includes special handling for Vim9 script syntax (e.g., `vim9script` flag), such as preventing variable names from being interpreted as modifiers. This is done by checking for `.` or `=` after an identifier, which prevents ambiguity.\n   - The `skip_vimgrep_pat_ext` function includes a check `if (vim9script && !VIM_ISWHITE(p[-1]))` to prevent `filter(arg)` from being parsed as a modifier, which is a correct safeguard.\n\n7. **Error Handling**:\n   - The function returns `FAIL` on invalid input (e.g., `:verbose` without a command, `:legacy` without a command), and sets `*errormsg` appropriately.\n   - It checks for `NULL` return from `vim_regcomp` and breaks out of the loop, preventing use of invalid regex.\n\n8. **No Obvious Vulnerabilities**:\n   - There are no buffer overflows, use-after-free, or format string vulnerabilities.\n   - No user-controlled data is directly used in unsafe string operations without bounds checking.\n   - All string manipulations are bounded and validated.\n\nConclusion: The code is carefully written with proper input validation, bounds checking, and safe string handling. It uses safe memory operations and avoids known dangerous functions. The logic for parsing command modifiers is robust and secure.\n\n(2) NO: No security vulnerability."}
{"idx": 253515, "project": "mruby", "commit_id": "f72315575f78a9a773adbce0ee7d3ec33434cb76", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/f72315575f78a9a773adbce0ee7d3ec33434cb76", "commit_message": "codegen.c: fix a argument generation bug in array assignment.", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2022-0717", "cve_desc": "Out-of-bounds Read in GitHub repository mruby/mruby prior to 3.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - This function `gen_assignment` is part of a Ruby interpreter's code generation (codegen) system, likely part of a compiler or interpreter for a Ruby-like language (e.g., mruby).\n   - It handles assignment operations to various types of variables (global, local, instance, class, constants, etc.) and expressions (method calls, etc.).\n   - The function takes a `codegen_scope *s`, a syntax tree node `tree`, a right-hand side expression `rhs`, and stack pointer (`sp`) and value flag (`val`) parameters.\n\n2. **Input Validation and Control Flow**:\n   - The function uses `switch (type)` on `nint(tree->car)` to determine the type of left-hand side (LHS) expression.\n   - For each case, it performs appropriate code generation:\n     - For `NODE_GVAR`, `NODE_LVAR`, `NODE_IVAR`, etc., it generates appropriate opcodes (`OP_SETGV`, `OP_SETIV`, etc.) to store values.\n     - For `NODE_CALL` and `NODE_SCALL`, it generates method call code with proper handling of receivers, arguments, and return values.\n     - For `NODE_COLON2`, it handles constant assignment via `OP_SETMCNST`.\n     - For `NODE_MASGN`, it calls `gen_vmassignment`, which is likely for multiple assignments.\n   - The function uses `codegen(s, rhs, VAL)` to generate code for the right-hand side, and `pop()` to clean up the stack after evaluation.\n\n3. **Stack and Memory Safety**:\n   - The function uses `cursp()` to get the current stack pointer and `push()`/`pop()`/`pop_n()` to manage the stack.\n   - It carefully manages stack operations: `push()` before method calls, `pop()` after evaluation, and `pop_n(2)` in some cases.\n   - The use of `cursp()` and `sp` tracking suggests that stack management is done with care to avoid stack overflows or underflows.\n   - There is no direct use of unsafe functions like `strcpy`, `sprintf`, or manual buffer manipulation.\n\n4. **Potential Vulnerabilities**:\n   - **No buffer overflows**: There are no arrays or buffers being copied into without bounds checking. All operations are on the stack or via opcodes.\n   - **No user input directly manipulated**: The code is part of a compiler/interpreter and processes abstract syntax trees (ASTs), not raw user input. The input is already parsed and validated at a higher level.\n   - **No injection vectors**: The code does not construct strings or execute code based on untrusted input directly. It generates opcodes based on AST nodes, which are already validated during parsing.\n   - **No unsafe memory access**: All accesses are through well-defined structures (`node`, `codegen_scope`, etc.), and there is no pointer arithmetic or raw memory access.\n   - **Error handling**: The function calls `codegen_error` for unknown types, which is a safe way to handle invalid input.\n\n5. **Security Considerations**:\n   - The function is part of a trusted code generation pipeline. It assumes the AST is valid and correctly structured.\n   - If the AST is malformed or crafted maliciously, that would be a vulnerability in the parser, not in this function.\n   - However, this function itself does not introduce new vulnerabilities. It correctly handles stack management and opcode generation.\n\n6. **Conclusion**:\n   - The code is well-structured, uses proper stack management, and does not perform any unsafe operations.\n   - There are no obvious buffer overflows, use-after-free, or injection vulnerabilities.\n   - The function operates on a parsed AST, not raw input, so it is not directly exposed to injection attacks.\n   - No evidence of unsafe memory access, improper bounds checking, or insecure coding practices.\n\n(2) NO: No security vulnerability."}
{"idx": 477946, "project": "clamav-devel", "commit_id": "224fee54dd6cd8933d7007331ec2bfca0398d4b4", "project_url": "https://github.com/vrtadmin/clamav-devel", "commit_url": "http://git.clamav.net/gitweb?p=clamav-devel.git;a=commit;h=224fee54dd6cd8933d7007331ec2bfca0398d4b4", "commit_message": "libclamav/mspack.c: fix Quantum decompressor (bb#1771)", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2010-1311", "cve_desc": "The qtm_decompress function in libclamav/mspack.c in ClamAV before 0.96 allows remote attackers to cause a denial of service (memory corruption and application crash) via a crafted CAB archive that uses the Quantum (aka .Q) compression format.  NOTE: some of these details are obtained from third party information.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function starts with checks for null pointer (`qtm`) and negative `out_bytes`. This is good practice to prevent null pointer dereferences and invalid operations.\n   - `if (!qtm || (out_bytes < 0)) return CL_ENULLARG;` \u2014 This prevents invalid inputs.\n\n2. **Buffer Management and Bounds Checking**:\n   - The function uses a sliding window (`window`) of size `qtm->window_size` to store decompressed data.\n   - The code carefully checks whether a match operation would go beyond the window bounds:\n     ```c\n     if (window_posn + match_length > qtm->window_size) {\n       cli_dbgmsg(\"qtm_decompress: match ran over window wrap\\n\");\n       return qtm->error = CL_EFORMAT;\n     }\n     ```\n     This prevents buffer overflow during copy operations.\n\n   - The code also checks for invalid match offsets:\n     ```c\n     if (match_offset > window_posn) {\n       j = match_offset - window_posn;\n       if (j > (int) qtm->window_size) {\n         cli_dbgmsg(\"qtm_decompress: match offset beyond window boundaries\\n\");\n         return qtm->error = CL_EFORMAT;\n       }\n     }\n     ```\n     This ensures that the match offset does not point outside the valid window range.\n\n   - The copy logic handles wrap-around correctly:\n     - If the match offset wraps around the window, it copies from the end of the window to the beginning.\n     - It uses `runsrc = &window[qtm->window_size - j];` and handles partial copies correctly.\n     - The code ensures that `i` (the number of bytes to copy) does not exceed the available space in the window:\n       ```c\n       if(i > (int) (qtm->window_size - window_posn))\n         i = qtm->window_size - window_posn;\n       ```\n       This prevents reading beyond the window.\n\n3. **Use of `qtm->window_size`**:\n   - The window size is assumed to be a fixed, trusted value (likely set during initialization).\n   - There is no evidence that `qtm->window_size` is user-controlled or modifiable without proper validation. It is used consistently in bounds checks.\n\n4. **Bitstream and Symbol Decoding**:\n   - The code uses `QTM_GET_SYMBOL` and `QTM_READ_BITS` macros to decode symbols and bits from the input stream.\n   - These macros are assumed to be safe and properly validate input (e.g., not reading past the input buffer).\n   - The code does not perform any unchecked arithmetic on bit positions or buffer indices.\n\n5. **Output Handling**:\n   - The function writes output to `qtm->ofd` via `mspack_write`, but only after ensuring that the number of bytes to write is within bounds.\n   - It uses `out_bytes` to limit how much data is written, and checks `i = (int) out_bytes` only after ensuring it's valid.\n\n6. **State Management**:\n   - The function saves and restores bit state (`QTM_STORE_BITS`, `QTM_RESTORE_BITS`) \u2014 this is safe as long as the bit buffer is properly managed.\n   - No unbounded loops or unchecked memory access is present.\n\n7. **Error Handling**:\n   - The function returns `CL_EFORMAT` on invalid format (e.g., invalid selector, out-of-bounds match), which is appropriate.\n   - All critical operations are guarded by checks.\n\n8. **No Use of Dangerous Functions**:\n   - No `strcpy`, `strcat`, `memcpy`, `sprintf`, etc., are used in a way that could lead to buffer overflows.\n   - All memory access is bounded by `window_posn`, `window_size`, and `match_length`.\n\n9. **Potential Concerns**:\n   - The only potential risk is if `qtm->window_size` is user-controlled and not validated. However, in the context of this decompression function, `window_size` is typically a fixed value (e.g., 64KB) set during initialization and not modifiable by the input stream.\n   - The code does not expose `window_size` to user input directly, and all access is bounded by it.\n\n10. **Conclusion**:\n    - All buffer accesses are bounded.\n    - All offsets and lengths are validated before use.\n    - No integer overflows or underflows are evident (e.g., `window_posn + match_length` is checked).\n    - The code handles wrap-around correctly and safely.\n\n(2) NO: No security vulnerability."}
{"idx": 463051, "project": "qemu", "commit_id": "8c92060d3c0248bd4d515719a35922cd2391b9b4", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://git.qemu.org/?p=qemu.git;a=commit;h=8c92060d3c0248bd4d515719a35922cd2391b9b4", "commit_message": "sungem: switch to use qemu_receive_packet() for loopback\n\nThis patch switches to use qemu_receive_packet() which can detect\nreentrancy and return early.\n\nThis is intended to address CVE-2021-3416.\n\nCc: Prasad J Pandit <ppandit@redhat.com>\nCc: qemu-stable@nongnu.org\nReviewed-by: Mark Cave-Ayland <mark.cave-ayland@ilande.co.uk>\nReviewed-by: Philippe Mathieu-Daud\u00e9 <philmd@redhat.com>\nReviewed-by: Alistair Francis <alistair.francis@wdc.com>\nSigned-off-by: Jason Wang <jasowang@redhat.com>", "ground_truth": 0, "cwe": ["CWE-835"], "cve": "CVE-2021-3416", "cve_desc": "A potential stack overflow via infinite loop issue was found in various NIC emulators of QEMU in versions up to and including 5.2.0. The issue occurs in loopback mode of a NIC wherein reentrant DMA checks get bypassed. A guest user/process may use this flaw to consume CPU cycles or crash the QEMU process on the host resulting in DoS scenario.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `sungem_send_packet` is responsible for sending a network packet in a QEMU emulated SunGEM network device.\n2. It takes three parameters: a pointer to the device state `s`, a buffer `buf` containing the packet data, and the `size` of the packet.\n3. It retrieves the NetClientState `nc` associated with the network interface using `qemu_get_queue(s->nic)`.\n4. The function checks the `MAC_XIFCFG_LBCK` bit in the `macregs[MAC_XIFCFG >> 2]` register. If this bit is set, it means loopback mode is enabled.\n5. In loopback mode, the packet is sent back to the network stack using `qemu_receive_packet(nc, buf, size)`.\n6. Otherwise, the packet is sent out via the network interface using `qemu_send_packet(nc, buf, size)`.\n\nNow, consider security implications:\n\n- `qemu_receive_packet` is used to inject a packet back into the network stack, typically for loopback testing or internal processing.\n- `qemu_send_packet` sends the packet out to the network.\n- Both functions are part of QEMU's networking stack and are designed to handle packet data safely.\n- The input `buf` and `size` are passed directly to these functions without any validation or sanitization.\n- However, in the context of QEMU's network emulation, `qemu_receive_packet` and `qemu_send_packet` are trusted functions that are expected to handle the data safely, especially since the data comes from the emulated device (SunGEM) and not from an untrusted external source.\n- The loopback check is a legitimate feature and does not introduce a vulnerability by itself.\n- There is no evidence of buffer overflows, memory corruption, or injection attacks in this code.\n- The code does not perform any unsafe operations like direct memory copying without bounds checking, nor does it use unsafe string functions.\n\nTherefore, this code is correctly handling packet transmission based on the device's configuration, and there is no indication of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 484063, "project": "open62541", "commit_id": "b79db1ac78146fc06b0b8435773d3967de2d659c", "project_url": "https://github.com/open62541/open62541", "commit_url": "https://github.com/open62541/open62541/commit/b79db1ac78146fc06b0b8435773d3967de2d659c", "commit_message": "fix(plugin): Add default limits for chunks and message size\n\nBased on a reported DoS vulnerability reported by Team82 (Claroty\nResearch).", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-25761", "cve_desc": "The package open62541/open62541 before 1.2.5, from 1.3-rc1 and before 1.3.1 are vulnerable to Denial of Service (DoS) due to a missing limitation on the number of received chunks - per single session or in total for all concurrent sessions. An attacker can exploit this vulnerability by sending an unlimited number of huge chunks (e.g. 2GB each) without sending the Final closing chunk.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `setup_secureChannel` is setting up a secure channel in what appears to be an OPC UA (Open Platform Communications Unified Architecture) implementation, given the use of `UA_SecureChannel_init`, `UA_SecureChannel_setSecurityPolicy`, and `UA_Connection_attachSecureChannel`.\n\n2. The function initializes a secure channel (`testChannel`) using the default connection configuration (`UA_ConnectionConfig_default`), which is generally safe if the default configuration is secure by default.\n\n3. It sets the security policy using `TestingPolicy(&dummyPolicy, dummyCertificate, &fCalled, &keySizes)`. The use of `dummyPolicy` and `dummyCertificate` suggests this is for testing purposes. However, the key concern is whether this dummy policy is actually secure or if it allows weak or no security. Since it's a test policy, it may not enforce strong cryptographic standards (e.g., weak key sizes, no authentication, or no encryption), but this is acceptable in a test context.\n\n4. The function then creates a dummy connection (`createDummyConnection`) with the default send buffer size and attaches it to the secure channel via `UA_Connection_attachSecureChannel`. This is a standard setup pattern.\n\n5. The `testChannel.connection` is set to point to the dummy connection, and the channel state is set to `UA_SECURECHANNELSTATE_OPEN`. This is a valid state transition for a secure channel in a test environment.\n\n6. The critical point: the code is part of a test setup. The use of `dummyPolicy`, `dummyCertificate`, and `createDummyConnection` indicates this is not a production configuration. Therefore, the absence of real security enforcement is expected and acceptable in a testing context.\n\n7. There is no evidence of buffer overflows, memory corruption, improper input validation, or insecure state transitions. The functions called are part of a well-designed secure channel framework, and the setup follows correct usage patterns.\n\n8. Since this is a test function and the dummy components are intended for testing, no actual security vulnerability exists in the code as written \u2014 it's not exposing a real system to risk.\n\n(2) NO: No security vulnerability."}
{"idx": 231048, "project": "FreeRTOS-Kernel", "commit_id": "47338393f1f79558f6144213409f09f81d7c4837", "project_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel", "commit_url": "https://github.com/FreeRTOS/FreeRTOS-Kernel/commit/47338393f1f79558f6144213409f09f81d7c4837", "commit_message": "add assert for addition overflow on queue creation (#225)", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2021-31571", "cve_desc": "The kernel in Amazon Web Services FreeRTOS before 10.4.3 has an integer overflow in queue.c for queue creation.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `xQueueGenericCreate` is responsible for creating a queue in a real-time operating system (likely FreeRTOS), allocating memory for both the queue structure and its storage area.\n\n2) The function first validates that `uxQueueLength > 0` using `configASSERT`, which is a compile-time check. This prevents creation of empty queues.\n\n3) It calculates `xQueueSizeInBytes = uxQueueLength * uxItemSize`. This is a critical calculation because if `uxQueueLength` and `uxItemSize` are large, this multiplication could overflow.\n\n4) The code includes a check: `configASSERT( ( uxItemSize == 0 ) || ( uxQueueLength == ( xQueueSizeInBytes / uxItemSize ) ) )`. This is a standard way to detect integer overflow in multiplication. If the multiplication overflowed, then `xQueueSizeInBytes / uxItemSize` would not equal the original `uxQueueLength`. This check is correct and prevents the use of an incorrect size due to overflow.\n\n5) Another check: `configASSERT( ( sizeof( Queue_t ) + xQueueSizeInBytes ) > xQueueSizeInBytes )`. This checks for addition overflow when adding the queue structure size to the storage size. If the sum overflows, the condition would fail. This is a valid overflow check.\n\n6) The memory allocation uses `pvPortMalloc(sizeof(Queue_t) + xQueueSizeInBytes)`. The size is calculated correctly, and the overflow checks ensure that the size is valid before allocation.\n\n7) The code then correctly sets up the queue storage pointer by advancing past the `Queue_t` structure.\n\n8) The function uses `prvInitialiseNewQueue` to initialize the queue, which is a private function that sets up internal state.\n\n9) All memory operations are bounded by the calculated size, and the overflow checks are in place to prevent buffer overflows or incorrect memory allocation.\n\n10) There are no direct uses of unsafe string functions, no input validation bypasses, no format string vulnerabilities, and no improper memory access patterns.\n\n11) The use of `configASSERT` ensures that overflow conditions are caught at compile time or during development, preventing runtime issues.\n\nConclusion: The code includes proper overflow checks for both multiplication and addition, uses safe memory allocation, and correctly manages the queue storage. These are all good security practices that prevent buffer overflows and memory corruption.\n\n(2) NO: No security vulnerability."}
{"idx": 314536, "project": "pjproject", "commit_id": "560a1346f87aabe126509bb24930106dea292b00", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/560a1346f87aabe126509bb24930106dea292b00", "commit_message": "Merge pull request from GHSA-f5qg-pqcg-765m", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-24764", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. Versions 2.12 and prior contain a stack buffer overflow vulnerability that affects PJSUA2 users or users that call the API `pjmedia_sdp_print(), pjmedia_sdp_media_print()`. Applications that do not use PJSUA2 and do not directly call `pjmedia_sdp_print()` or `pjmedia_sdp_media_print()` should not be affected. A patch is available on the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `print_media_desc` is responsible for formatting an SDP (Session Description Protocol) media description into a character buffer `buf` of size `len`.\n\n2) The function first checks if the provided buffer size `len` is sufficient to hold the \"m=\" line (media description), which includes:\n   - media type (m->desc.media.slen)\n   - transport protocol (m->desc.transport.slen)\n   - port number and optional port count\n   - format list\n   - CRLF at the end\n   - The check: `if (len < (pj_size_t)m->desc.media.slen + m->desc.transport.slen + 12 + 24)` ensures there's enough space for the \"m=\" line and some extra room.\n\n3) The function then proceeds to copy data into the buffer using:\n   - `pj_memcpy` for media type, transport, and format values\n   - `pj_utoa` for converting integers to strings (port, port_count)\n   - Manual character-by-character writing for spaces, CRLF, etc.\n\n4) Critical safety checks:\n   - Before copying each format string: `if (end-p > m->desc.fmt[i].slen)` ensures there's enough space.\n   - Before writing CRLF: `if (end-p >= 2)` ensures at least 2 bytes remain.\n   - Each sub-function call (print_connection_info, print_bandw, print_attr) returns a negative value on error, and the function checks this.\n\n5) The function uses `end = buf + len` to track the end of the buffer, and all writes are bounded by `p < end`. This prevents buffer overflow in the main loop.\n\n6) The function does not use unsafe string functions like `strcpy`, `strcat`, or `sprintf`. Instead, it uses bounded memory operations (`pj_memcpy`) and checks buffer space before each write.\n\n7) The `print_connection_info`, `print_bandw`, and `print_attr` functions are assumed to be similarly safe (as they are called with `end-p` as the available size), and their return values are checked.\n\n8) The function returns the number of bytes written, or -1 on error (insufficient buffer size).\n\nConclusion: The function performs proper bounds checking before every write operation, uses safe memory copy functions, and validates buffer space at every step. There is no risk of buffer overflow or other memory corruption.\n\n(2) NO: No security vulnerability."}
{"idx": 513202, "project": "server", "commit_id": "c05fd700970ad45735caed3a6f9930d4ce19a3bd", "project_url": "https://github.com/MariaDB/server", "commit_url": "https://github.com/MariaDB/server/commit/c05fd700970ad45735caed3a6f9930d4ce19a3bd", "commit_message": "MDEV-26323 use-after-poison issue of MariaDB server", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-27383", "cve_desc": "MariaDB Server v10.6 and below was discovered to contain an use-after-free in the component my_strcasecmp_8bit, which is exploited via specially crafted SQL statements.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `fix_dl_name` is designed to ensure that a dynamic library name (stored in `LEX_STRING *dl`) ends with the shared object extension (SO_EXT), typically \".so\" on Unix-like systems.\n\n2. The function first checks if:\n   - The length of the string (`dl->length`) is less than the length of the SO_EXT string (i.e., if the extension is already present).\n   - Or if the last part of the string (of length `so_ext_len`) does not match `SO_EXT` (case-insensitively, using `my_strcasecmp`).\n\n   If either condition is true, the function appends the SO_EXT to the string.\n\n3. The function allocates memory using `alloc_root(root, dl->length + so_ext_len + 1)`, which is sufficient to hold the original string, the extension, and a null terminator.\n\n4. It then copies the original string into the new buffer, appends the SO_EXT using `strcpy`, and updates `dl->str` and `dl->length` to point to the new buffer and its new length.\n\n5. Key points:\n   - The `alloc_root` function is assumed to be a safe memory allocator within a memory root context, which is typically used in MySQL and is designed to avoid memory leaks and handle allocation safely.\n   - The buffer size is calculated as `dl->length + so_ext_len + 1`, which accounts for the original string, the extension, and the null terminator.\n   - `memcpy` is used to copy the original string safely (within bounds).\n   - `strcpy` is used to append the extension, but only after ensuring that the destination buffer has enough space (since `alloc_root` allocated `dl->length + so_ext_len + 1` bytes).\n   - The `SO_EXT` is a constant string (e.g., \".so\"), so it's not user-controlled in this context.\n   - The input `dl->str` is assumed to be a user-provided or external string, but the function only appends a fixed extension if missing.\n\n6. Potential concerns:\n   - Could `dl->str` be null? The function does not check for `dl->str == NULL`, but `dl->length` is used in the condition. If `dl->length` is non-zero but `dl->str` is null, this would be a problem. However, in practice, `LEX_STRING` is typically used with valid strings, and the `dl->length` is expected to be valid.\n   - However, the function does not validate that `dl->str` is non-null before accessing `dl->str + dl->length - so_ext_len`. If `dl->length` is 0 or `dl->str` is null, this would lead to undefined behavior.\n\n7. Critical flaw:\n   - The function uses `dl->str + dl->length - so_ext_len` without checking if `dl->length >= so_ext_len`. If `dl->length < so_ext_len`, then `dl->length - so_ext_len` is negative, and `dl->str + negative_offset` is undefined behavior (buffer underflow).\n   - However, the first condition in the if-statement is `dl->length < so_ext_len`, so if this is true, the function enters the block and appends the extension. But the `my_strcasecmp` call is only executed if the first condition is false (i.e., `dl->length >= so_ext_len`). So the `my_strcasecmp` call is safe because it only runs when `dl->length >= so_ext_len`.\n\n8. Therefore, the `my_strcasecmp` call is safe because it is only executed when `dl->length >= so_ext_len`, so `dl->str + dl->length - so_ext_len` is a valid pointer within the string.\n\n9. The `strcpy` call is also safe because the allocated buffer has size `dl->length + so_ext_len + 1`, and the string being copied (`SO_EXT`) is `so_ext_len` characters long, so there is enough space.\n\n10. No buffer overflow, no use-after-free, no null pointer dereference, and no injection vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 449321, "project": "clamav-devel", "commit_id": "c6870a6c857dd722dffaf6d37ae52ec259d12492", "project_url": "https://github.com/vrtadmin/clamav-devel", "commit_url": "https://github.com/vrtadmin/clamav-devel/commit/c6870a6c857dd722dffaf6d37ae52ec259d12492", "commit_message": "bb #6808", "ground_truth": 0, "cwe": ["CWE-189"], "cve": "CVE-2013-2020", "cve_desc": "Integer underflow in the cli_scanpe function in pe.c in ClamAV before 0.97.8 allows remote attackers to cause a denial of service (crash) via a skewed offset larger than the size of the PE section in a UPX packed executable, which triggers an out-of-bounds read.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `getsistring` reads a string from a file at a given offset `ptr` with length `len`.\n\n2) The function first checks if `len` is zero, returning NULL if so.\n\n3) It then limits `len` to a maximum of 400 bytes, which is a reasonable bound to prevent excessive memory allocation.\n\n4) It allocates memory for `len + 1` bytes (for the string + null terminator) using `cli_malloc`.\n\n5) It seeks to the specified file position with `fseek(f, ptr, SEEK_SET)`.\n\n6) It attempts to read `len` bytes into the allocated buffer with `fread(name, len, 1, f)`. The check `fread(...) != 1` ensures the full block was read.\n\n7) The critical part is the loop: `for (i = 0 ; i < len; i+=2) name[i/2] = name[i];`\n\n   - This loop copies every other byte from the input buffer to a new position, effectively skipping every second byte.\n   - The destination index is `i/2`, so for i=0,2,4,... it writes to positions 0,1,2,...\n   - The loop runs while i < len, so it processes all even indices up to len-1.\n   - The final null terminator is set at `name[i/2] = '\\0'`, where i is the final value after the loop (i = len).\n\n8) However, there's a critical issue: the loop only processes even indices (i = 0,2,4,...), so it only copies half of the input data. The destination buffer size is `len+1`, but the actual data copied is only `len/2` bytes (rounded down).\n\n9) The null terminator is placed at `name[i/2]` where `i = len`, so the null terminator is placed at `name[len/2]`.\n\n10) This means the function returns a string that is at most `len/2` characters long, but the allocated buffer is `len+1` bytes. This is not a buffer overflow in the traditional sense, but it's a logic error.\n\n11) More importantly, the function does not ensure that the data read from the file is null-terminated or that the data being copied contains valid string data. The loop assumes that the data is structured in a way that every other byte contains meaningful data, but this is not guaranteed.\n\n12) The function could return a string that contains uninitialized memory if the input data doesn't have valid content at the even indices, but since it's copying from the read data, this is not the case.\n\n13) The real vulnerability is that the function is designed to extract a string from a binary format where every other byte contains the actual string data. However, if the input data is not properly formatted, this could lead to unexpected behavior, but this is not a direct security vulnerability.\n\n14) The function properly bounds the length, checks for allocation failures, and handles read errors. The memory management is correct.\n\n15) The loop that copies every other byte is a deliberate design choice for a specific binary format, not a vulnerability in itself.\n\nAfter careful analysis, this function does not contain a buffer overflow, use-after-free, or other classic security vulnerabilities. The logic is sound for its intended purpose of extracting strings from a specific binary format.\n\n(2) NO: No security vulnerability."}
{"idx": 242926, "project": "tensorflow", "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730", "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2022-29206", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `ValidateInputs` is designed to validate input tensors for a sparse tensor operation, likely in a machine learning framework like TensorFlow. It checks the shapes and values of several tensors: `a_indices`, `a_values`, `a_shape`, and `b`.\n\n2. The function performs multiple validity checks:\n   - Ensures `a_indices` is a matrix (2D tensor).\n   - Ensures `a_values` and `a_shape` are vectors (1D tensors).\n   - Verifies that the number of non-zero elements (`nnz`) in `a_indices` matches the size of `a_values`.\n   - Verifies that the number of dimensions (`ndims`) in `a_indices` matches the size of `a_shape`.\n   - Checks that the total number of elements in `a_shape` matches the number of dimensions in `b` (i.e., no broadcasting is allowed).\n   - Compares each dimension of `a_shape` with the corresponding dimension of `b` to ensure they are equal.\n   - Validates that all indices in `a_indices` are within bounds (i.e., `0 <= idx < a_shape_flat(didx)` for each dimension).\n\n3. The validation of indices is particularly important: the loop iterates over each non-zero element (`zidx`) and each dimension (`didx`), and checks that the index value is non-negative and strictly less than the corresponding dimension size in `a_shape`. This prevents out-of-bounds access and ensures the sparse tensor is well-formed.\n\n4. All input parameters are checked for nullity implicitly via the `Tensor` object access (e.g., `a_indices->shape()`), and the function returns early with an error if any condition fails. This prevents further processing of malformed inputs.\n\n5. There are no calls to unsafe functions (like `strcpy`, `strcat`, `memcpy`, etc.), no dynamic memory allocation without bounds checking, no use of untrusted input in format strings, no direct execution of user-controlled code, and no use of unsafe casting or pointer arithmetic.\n\n6. The function is defensive in nature: it validates all inputs before proceeding, and it explicitly checks for index bounds, which is a critical security measure in tensor operations to prevent memory corruption or invalid memory access.\n\n7. Since the function only performs validation and returns early on invalid input, and all checks are properly bounded and safe, there is no indication of a buffer overflow, integer overflow, use-after-free, or any other exploitable vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 391628, "project": "linux", "commit_id": "cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "commit_message": "PCI: rpadlpar: Fix potential drc_name corruption in store functions\n\nBoth add_slot_store() and remove_slot_store() try to fix up the\ndrc_name copied from the store buffer by placing a NUL terminator at\nnbyte + 1 or in place of a '\\n' if present. However, the static buffer\nthat we copy the drc_name data into is not zeroed and can contain\nanything past the n-th byte.\n\nThis is problematic if a '\\n' byte appears in that buffer after nbytes\nand the string copied into the store buffer was not NUL terminated to\nstart with as the strchr() search for a '\\n' byte will mark this\nincorrectly as the end of the drc_name string resulting in a drc_name\nstring that contains garbage data after the n-th byte.\n\nAdditionally it will cause us to overwrite that '\\n' byte on the stack\nwith NUL, potentially corrupting data on the stack.\n\nThe following debugging shows an example of the drmgr utility writing\n\"PHB 4543\" to the add_slot sysfs attribute, but add_slot_store()\nlogging a corrupted string value.\n\n  drmgr: drmgr: -c phb -a -s PHB 4543 -d 1\n  add_slot_store: drc_name = PHB 4543\u00b0|<82>!, rc = -19\n\nFix this by using strscpy() instead of memcpy() to ensure the string\nis NUL terminated when copied into the static drc_name buffer.\nFurther, since the string is now NUL terminated the code only needs to\nchange '\\n' to '\\0' when present.\n\nCc: stable@vger.kernel.org\nSigned-off-by: Tyrel Datwyler <tyreld@linux.ibm.com>\n[mpe: Reformat change log and add mention of possible stack corruption]\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/r/20210315214821.452959-1-tyreld@linux.ibm.com", "ground_truth": 0, "cwe": ["CWE-120"], "cve": "CVE-2021-28972", "cve_desc": "In drivers/pci/hotplug/rpadlpar_sysfs.c in the Linux kernel through 5.11.8, the RPA PCI Hotplug driver has a user-tolerable buffer overflow when writing a new device name to the driver from userspace, allowing userspace to write data to the kernel stack frame directly. This occurs because add_slot_store and remove_slot_store mishandle drc_name '\\0' termination, aka CID-cc7a0bb058b8.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `add_slot_store` is a kernel object attribute store function, likely part of a sysfs interface, which handles writing data to a kernel-controlled attribute.\n\n2. The input `buf` is a user-provided string (from sysfs), and `nbytes` is the number of bytes written.\n\n3. The function first checks if `nbytes >= MAX_DRC_NAME_LEN`. If so, it returns 0 immediately. This prevents the buffer `drc_name` from being overflowed by a large input.\n\n4. It then uses `strscpy(drc_name, buf, nbytes + 1)` to copy the input into `drc_name`. The `strscpy` function is a safe string copy that ensures null termination and bounds checking. It copies at most `nbytes + 1` characters, which is safe because `nbytes < MAX_DRC_NAME_LEN` (due to the earlier check), so `drc_name` will not overflow.\n\n5. The function then looks for a newline character (`\\n`) in `drc_name` and null-terminates it if found. This is a common practice to clean up input from sysfs, which often includes a newline.\n\n6. The resulting `drc_name` is passed to `dlpar_add_slot(drc_name)`, which presumably performs some hardware slot addition operation.\n\n7. The function returns `nbytes` on success, or an error code if `dlpar_add_slot` fails.\n\n8. Key security considerations:\n   - Input length is validated upfront (`nbytes >= MAX_DRC_NAME_LEN` \u2192 return 0).\n   - `strscpy` ensures no buffer overflow.\n   - The string is properly null-terminated.\n   - No unsafe string operations are used.\n   - The input is not directly used in a format string or command execution without validation.\n\n9. The only potential concern is whether `dlpar_add_slot` performs proper validation of `drc_name` (e.g., checking for valid DRC names, preventing injection of malicious values). However, that is outside the scope of this function. The function itself does not introduce a vulnerability.\n\n10. Therefore, the code correctly handles input bounds, null termination, and avoids unsafe operations.\n\n(2) NO: No security vulnerability."}
{"idx": 509510, "project": "server", "commit_id": "9e39d0ae44595dbd1570805d97c9c874778a6be8", "project_url": "https://github.com/MariaDB/server", "commit_url": "https://github.com/MariaDB/server/commit/9e39d0ae44595dbd1570805d97c9c874778a6be8", "commit_message": "MDEV-25787 Bug report: crash on SELECT DISTINCT thousands_blob_fields\n\nfix a debug assert to account for not opened temp tables", "ground_truth": 0, "cwe": ["CWE-400"], "cve": "CVE-2021-46668", "cve_desc": "MariaDB through 10.5.9 allows an application crash via certain long SELECT DISTINCT statements that improperly interact with storage-engine resource limitations for temporary data structures.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `ha_maria::drop_table` takes a `const char *name` parameter, which represents the name of the table to be dropped.\n\n2. The function begins with a `DBUG_ASSERT` that checks whether `file` is null or if `file->s->temporary` is true. This assertion ensures that the table being dropped is either not open (file is null) or is a temporary table. This is a debugging check and does not affect runtime behavior, but it implies that the function is intended to handle temporary tables safely.\n\n3. The function then calls `ha_close()`, which closes the current table handler. The result is cast to `void`, indicating that the return value is ignored. This is a standard pattern when the function is expected to clean up resources regardless of the success or failure of the close operation.\n\n4. The function then calls `maria_delete_table_files(name, 1, MY_WME)`. This function is responsible for deleting the actual table files on disk. The parameters are:\n   - `name`: the name of the table to delete.\n   - `1`: likely indicates that the table is being dropped (as opposed to being renamed or moved).\n   - `MY_WME`: a flag that may indicate \"my error\" or \"with error message\", suggesting that the function will report errors if something goes wrong.\n\n5. The key security concern here is whether the `name` parameter is properly validated before being passed to `maria_delete_table_files`. If the `name` is not validated, an attacker could potentially supply a malicious table name (e.g., with path traversal sequences like `../` or `../../`) to delete unintended files outside the intended database directory.\n\n6. However, in the MariaDB/MySQL codebase, `maria_delete_table_files` is typically called only after proper validation of the table name within the storage engine layer. The `ha_maria` class is part of the storage engine interface, and table names are usually validated earlier in the call chain (e.g., in the SQL layer) before reaching this function.\n\n7. Additionally, the `DBUG_ASSERT` suggests that the function is only called in contexts where the table is temporary or not open, which further restricts the scope of the operation.\n\n8. Given that the function is part of a well-established database system and that the table name is likely validated upstream (in the SQL parser or metadata layer), and that `maria_delete_table_files` is designed to operate only on valid table files within the database directory, there is no evidence of a direct security vulnerability in this code snippet.\n\n9. The code does not perform any string manipulation or path construction that could be exploited via path traversal or injection. The `name` is passed directly to a function that is expected to handle it safely.\n\nTherefore, based on the analysis, no security vulnerability is present in this code snippet.\n\n(2) NO: No security vulnerability."}
{"idx": 454759, "project": "linux", "commit_id": "690b2549b19563ec5ad53e5c82f6a944d910086e", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/690b2549b19563ec5ad53e5c82f6a944d910086e", "commit_message": "i2c: ismt: prevent memory corruption in ismt_access()\n\nThe \"data->block[0]\" variable comes from the user and is a number\nbetween 0-255.  It needs to be capped to prevent writing beyond the end\nof dma_buffer[].\n\nFixes: 5e9a97b1f449 (\"i2c: ismt: Adding support for I2C_SMBUS_BLOCK_PROC_CALL\")\nReported-and-tested-by: Zheyu Ma <zheyuma97@gmail.com>\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nReviewed-by: Mika Westerberg <mika.westerberg@linux.intel.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-3077", "cve_desc": "A buffer overflow vulnerability was found in the Linux kernel Intel\u2019s iSMT SMBus host controller driver in the way it handled the I2C_SMBUS_BLOCK_PROC_CALL case (via the ioctl I2C_SMBUS) with malicious input data. This flaw could allow a local user to crash the system.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `ismt_access` handles I2C/SMBus transactions with various sizes (e.g., I2C_SMBUS_BYTE, I2C_SMBUS_BLOCK_DATA, etc.).\n   - For `I2C_SMBUS_BLOCK_DATA` and `I2C_SMBUS_BLOCK_PROC_CALL`, the code checks the block length:\n     - In `I2C_SMBUS_BLOCK_DATA` (read case), `dma_size = I2C_SMBUS_BLOCK_MAX` is used, which is a fixed maximum size. The code does not validate the user-provided `data->block[0]` against this limit in the read case, but it does set a hard cap via `I2C_SMBUS_BLOCK_MAX`.\n     - In `I2C_SMBUS_BLOCK_PROC_CALL`, it explicitly checks: `if (data->block[0] > I2C_SMBUS_BLOCK_MAX) return -EINVAL;` \u2014 this is good.\n     - In `I2C_SMBUS_I2C_BLOCK_DATA`, the code enforces bounds:\n       ```c\n       if (data->block[0] < 1)\n           data->block[0] = 1;\n       if (data->block[0] > I2C_SMBUS_BLOCK_MAX)\n           data->block[0] = I2C_SMBUS_BLOCK_MAX;\n       ```\n       This ensures the block size is within safe limits (1 to I2C_SMBUS_BLOCK_MAX), preventing buffer overflows.\n\n2. **Buffer Usage and DMA Mapping**:\n   - The code uses a fixed-size buffer: `u8 *dma_buffer = PTR_ALIGN(&priv->buffer[0], 16);` \u2014 this buffer is pre-allocated and has a known size (`sizeof(priv->buffer)`).\n   - The `dma_size` is derived from `data->block[0]` or other size parameters, but it is always bounded by `I2C_SMBUS_BLOCK_MAX` (or similar limits).\n   - The `memcpy` calls are used to copy data into `dma_buffer`:\n     - `memcpy(&dma_buffer[1], &data->block[1], dma_size - 1);` \u2014 here, `dma_size - 1` is the number of bytes to copy.\n     - Since `dma_size` is bounded by `I2C_SMBUS_BLOCK_MAX`, and `data->block[0]` is clamped to that value, the copy is safe.\n   - The `dma_map_single` and `dma_unmap_single` are used correctly with the same `dma_size`, and the buffer is properly unmapped.\n\n3. **Use of `data` from User Input**:\n   - The `union i2c_smbus_data *data` is passed from user space (via I2C ioctl or similar).\n   - However, the code validates and sanitizes the `data->block[0]` field before using it to determine buffer sizes.\n   - The `data->word` and `data->byte` fields are used directly, but they are small (1 or 2 bytes), so no overflow risk.\n\n4. **No Direct String or Memory Copy Without Bounds**:\n   - There are no calls to `strcpy`, `strcat`, `memcpy` without size checks \u2014 all `memcpy` calls are with size parameters derived from validated input.\n   - The `dma_buffer` is not exposed to user input directly; it's used as a staging buffer for DMA.\n\n5. **Race Conditions or State Management**:\n   - The function uses `priv->head` to manage a ring buffer of descriptors. It increments and wraps it modulo `ISMT_DESC_ENTRIES`. This is safe as long as `ISMT_DESC_ENTRIES` is a power of two (common in ring buffers), and the code does not access out-of-bounds descriptors.\n   - The `desc` pointer is taken from `priv->hw[priv->head]`, which is a fixed-size array. The `head` is properly wrapped, so no out-of-bounds access.\n\n6. **Error Handling and Safety**:\n   - The code checks for DMA mapping errors and returns `-EIO` if mapping fails.\n   - It uses `wait_for_completion_timeout` with a 1-second timeout, preventing indefinite blocking.\n   - The `desc` is processed only after successful submission and completion.\n\n7. **No Known Vulnerabilities (e.g., Buffer Overflow, Use-After-Free, etc.)**:\n   - All buffer accesses are bounded by validated input.\n   - No unsafe memory operations.\n   - No direct user input used in format strings or command execution.\n   - No integer overflows or underflows are evident in the size calculations.\n\nConclusion: The code performs proper input validation, bounds checking, and safe use of DMA buffers. All potentially dangerous operations (like `memcpy`, DMA mapping) are protected by size limits derived from validated input. There are no exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 233867, "project": "php-src", "commit_id": "0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f", "project_url": "https://github.com/php/php-src", "commit_url": "https://github.com/php/php-src/commit/0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f", "commit_message": "Fix for bug #72790 and bug #72799\n\n(cherry picked from commit a14fdb9746262549bbbb96abb87338bacd147e1b)\n\nConflicts:\n\text/wddx/wddx.c", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2016-7132", "cve_desc": "ext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid wddxPacket XML document that is mishandled in a wddx_deserialize call, as demonstrated by a stray element inside a boolean element, leading to incorrect pop processing.", "vuln": 1, "reasoning": "Let's analyze the provided C code step by step, focusing on potential security vulnerabilities.\n\n---\n\n### Step 1: Understanding the context\nThis function `php_wddx_pop_element` is part of a PHP extension handling WDDX (Web Distributed Data eXchange) parsing. It is called when an XML element is closed (i.e., the end tag is encountered). The function manages a stack (`wddx_stack`) of parsed data elements, and when an element ends, it processes the corresponding data.\n\nThe function handles various WDDX types: string, number, boolean, null, array, struct, recordset, binary, datetime, and variable/field elements.\n\n---\n\n### Step 2: Key operations and potential risks\n\n#### A. Stack management and bounds checking\n- The function checks `if (stack->top == 0)` at the beginning and returns early. This prevents accessing an empty stack.\n- It uses `wddx_stack_top(stack, (void**)&ent1)` to get the top element. This is safe as long as `stack->top > 0`, which is ensured by the initial check.\n\n\u2705 No buffer overflow or out-of-bounds access here.\n\n#### B. Memory management and use-after-free\n- `efree(ent1)` is called in several places (e.g., when `Z_TYPE(ent1->data) == IS_UNDEF`, or when `stack->top > 1` and `ent1` is processed).\n- `zval_ptr_dtor(&ent1->data)` is used to destroy the zval data before reassigning it (e.g., after base64 decoding).\n- `efree(ent1->varname)` is called when `ent1->varname` is not NULL.\n\n\u26a0\ufe0f **Potential issue**: The function calls `efree(ent1)` at the end of the `stack->top > 1` block, but `ent1` was obtained via `wddx_stack_top`, which likely returns a pointer to a stack-allocated or heap-allocated `st_entry`. If `efree(ent1)` is called **after** `ent1` has already been freed elsewhere (e.g., in `zval_ptr_dtor` or `efree(ent1->varname)`), this could lead to a use-after-free.\n\nHowever, in this code:\n- `ent1` is only freed once via `efree(ent1)` at the end of the block.\n- `zval_ptr_dtor(&ent1->data)` is called before `efree(ent1)`, which is correct.\n- `efree(ent1->varname)` is called before `efree(ent1)`, so `ent1` is not accessed after being freed.\n\n\u2705 So, **no use-after-free** occurs here \u2014 the order is correct.\n\n#### C. Base64 decoding and memory handling\n- `php_base64_decode` is used for `EL_BINARY` elements.\n- It returns a `zend_string *`, which is assigned to `ent1->data` after `zval_ptr_dtor` is called on the old value.\n\n\u26a0\ufe0f **Potential risk**: If `php_base64_decode` fails (e.g., invalid input), it may return `NULL`. But the code does not check for `NULL` before assigning to `ZVAL_STR(&ent1->data, new_str)`.\n\nIf `php_base64_decode` returns `NULL`, then `ZVAL_STR` will set `ent1->data` to `NULL`, and later `Z_TYPE(ent1->data)` will be `IS_NULL`, which is handled correctly.\n\nBut: `ZVAL_STR` with `NULL` is **not valid** \u2014 it will cause undefined behavior or crashes.\n\n\ud83d\udd0d **Critical flaw**: The code does **not check** the return value of `php_base64_decode`. If the input is invalid (e.g., non-base64 string), `php_base64_decode` returns `NULL`, and `ZVAL_STR` is called with `NULL`, which is **undefined behavior** and can lead to crashes or memory corruption.\n\nThis is a **serious security vulnerability** because:\n- An attacker can craft a WDDX document with malformed base64 data in a `<binary>` element.\n- This triggers `php_base64_decode` to return `NULL`.\n- The code proceeds to assign `NULL` to a `zval` via `ZVAL_STR`, which is **not safe** and can cause crashes or memory corruption (potential for exploitation).\n\n\u2705 This is a **clear security vulnerability**.\n\n#### D. Object creation and `__wakeup()` call\n- The code calls `call_user_function_ex` to invoke `__wakeup()` on deserialized objects.\n- This is **intentional** in PHP's `unserialize()` mechanism, but it's **dangerous** if untrusted data is used.\n\n\u26a0\ufe0f **Security concern**: Calling `__wakeup()` on untrusted data is a known vector for **object injection attacks** (e.g., in PHP, this can lead to RCE if the class has a vulnerable `__wakeup()` method).\n\nHowever, this is **not a bug in the code itself** \u2014 it's a **design decision** of the WDDX deserialization mechanism. The code correctly calls `__wakeup()` when appropriate.\n\nBut: The code **does not validate** whether the object being deserialized is safe. This is a **known risk** in PHP's `unserialize()` and similar functions.\n\nStill, this is **not a vulnerability in this function** per se \u2014 it's a **feature** of the deserialization process. The function is doing what it should.\n\nSo, while this is a **security risk**, it's not a **code-level vulnerability** in this function \u2014 it's a **design-level risk**.\n\n#### E. Field and variable handling\n- `EL_FIELD` and `EL_VAR` are handled with `efree(ent)` and `efree(stack->varname)`.\n- These are safe as long as the pointers are valid and not double-freed.\n\nNo evidence of double-free or use-after-free.\n\n---\n\n### Step 3: Summary of findings\n\n- \u2705 Stack bounds checking is correct.\n- \u2705 Memory management (zval and efrees) is mostly correct.\n- \u274c **Critical flaw**: `php_base64_decode` return value is **not checked** before being passed to `ZVAL_STR`. If the input is invalid, `NULL` is passed, leading to **undefined behavior** (crash or memory corruption).\n- \u26a0\ufe0f `__wakeup()` call on untrusted data is a known risk, but not a code bug.\n\n---\n\n### Final Decision\n\nThe **unchecked return value of `php_base64_decode`** is a **clear security vulnerability** because it can lead to memory corruption or crashes when processing malformed input.\n\n(1) YES: A security vulnerability detected."}
{"idx": 220804, "project": "tensorflow", "commit_id": "2b7100d6cdff36aa21010a82269bc05a6d1cc74a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/2b7100d6cdff36aa21010a82269bc05a6d1cc74a", "commit_message": "Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-21740", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of a TensorFlow OpKernel implementation that processes input tensors: splits, values, and weights.\n\n2) The function first validates inputs:\n   - Checks that weights and values have the same shape when weights are used\n   - Ensures splits has at least 2 elements (num_batches > 0)\n   - Verifies splits starts with 0 and ends with the total number of values\n   - These checks are proper input validation to prevent out-of-bounds access\n\n3) The core logic processes each value in the values tensor and assigns it to a batch based on the splits tensor. The batch index is determined by finding the first splits value that is greater than or equal to the current index.\n\n4) The code uses:\n   - flat<T>() and flat<W>() to access tensor data directly\n   - Bounds checking via OP_REQUIRES for critical conditions\n   - Proper array indexing with batch_idx - 1 (after incrementing)\n\n5) The critical part is the loop where batch_idx is incremented while idx >= splits_values(batch_idx). This is a standard pattern for processing split-based data. The loop condition ensures batch_idx stays within bounds because:\n   - splits_values(0) == 0 (verified)\n   - splits_values(num_batches) == num_values (verified)\n   - batch_idx starts at 0 and increments at most num_batches times\n   - The loop condition idx >= splits_values(batch_idx) will eventually terminate when batch_idx reaches num_batches\n\n6) The access per_batch_counts[batch_idx - 1] is safe because:\n   - batch_idx starts at 0\n   - batch_idx is incremented only when idx >= splits_values(batch_idx)\n   - batch_idx will be at most num_batches (since splits_values(num_batches) == num_values)\n   - Therefore batch_idx - 1 will be at most num_batches - 1, which is valid for per_batch_counts of size num_batches\n\n7) The code properly validates all inputs and uses safe indexing patterns. There are no buffer overflows, out-of-bounds accesses, or other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 506428, "project": "core", "commit_id": "69ad3c902ea4bbf9f21ab1857d8923f975dc6145", "project_url": "https://github.com/LibreOffice/core", "commit_url": "https://github.com/dovecot/core/commit/69ad3c902ea4bbf9f21ab1857d8923f975dc6145", "commit_message": "auth: mech-rpa - Fail on zero len buffer", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2020-12674", "cve_desc": "In Dovecot before 2.3.11.3, sending a specially formatted RPA request will crash the auth service because a length of zero is mishandled.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `rpa_read_buffer` is designed to read a length-prefixed buffer from a data stream. It takes:\n   - `pool_t pool`: memory pool for allocation\n   - `const unsigned char **data`: pointer to current position in input data\n   - `const unsigned char *end`: pointer to the end of the input data\n   - `unsigned char **buffer`: output buffer to store the extracted data\n\n2. The function first checks if `p > end`, which would mean the current pointer is beyond the end of the data. This is a valid bounds check to prevent reading past the input buffer.\n\n3. It reads the length `len` from the first byte (`len = *p++`), which is the length of the data to follow.\n\n4. Then it checks:\n   - `p + len > end`: ensures that the data of length `len` fits within the remaining input buffer\n   - `len == 0`: checks for zero-length data\n\n   If either condition is true, it returns 0 (failure). This prevents reading past the buffer and avoids allocating zero-sized memory.\n\n5. It allocates memory using `p_malloc(pool, len)` \u2014 this is safe as long as `len` is valid and within bounds.\n\n6. It copies `len` bytes from `p` to `*buffer` using `memcpy`, which is safe because the bounds have already been checked.\n\n7. Finally, it updates `*data` to point past the length byte and the data: `*data += 1 + len`.\n\n8. The key security consideration is whether `len` can be manipulated to cause a buffer overflow or memory corruption.\n\n   - The function checks `p + len > end`, which ensures that the data to be copied does not exceed the input buffer.\n   - It also checks `len == 0`, which prevents zero-length allocation (though not strictly necessary for security, it's harmless).\n   - The `len` value is read from the input, but the bounds check `p + len > end` prevents reading beyond the input buffer.\n\n9. There is no integer overflow vulnerability here because:\n   - `len` is read from a single byte (`unsigned char`), so it's at most 255.\n   - The check `p + len > end` uses pointer arithmetic, and since `len` is small (\u2264255), and `p` is within bounds, this check is safe against overflow in practice (though in theory, if `p` is near the end, `p + len` could wrap around, but that would still be caught by `p + len > end`).\n\n10. The function does not perform any unsafe operations like `strcpy`, `strcat`, or unbounded `memcpy`. All memory operations are bounded by the `len` value, which is validated before use.\n\nConclusion: The function correctly validates the length and ensures that no more data is read than available in the input buffer. It safely allocates memory and copies data only within bounds.\n\n(2) NO: No security vulnerability."}
{"idx": 300731, "project": "linux", "commit_id": "d6d86830705f173fca6087a3e67ceaf68db80523", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/d6d86830705f173fca6087a3e67ceaf68db80523", "commit_message": "net ticp:fix a kernel-infoleak in __tipc_sendmsg()\n\nstruct tipc_socket_addr.ref has a 4-byte hole,and __tipc_getname() currently\ncopying it to user space,causing kernel-infoleak.\n\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline]\nBUG: KMSAN: kernel-infoleak in instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\nBUG: KMSAN: kernel-infoleak in _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n instrument_copy_to_user include/linux/instrumented.h:121 [inline]\n instrument_copy_to_user include/linux/instrumented.h:121 [inline] lib/usercopy.c:33\n _copy_to_user+0x1c9/0x270 lib/usercopy.c:33 lib/usercopy.c:33\n copy_to_user include/linux/uaccess.h:209 [inline]\n copy_to_user include/linux/uaccess.h:209 [inline] net/socket.c:287\n move_addr_to_user+0x3f6/0x600 net/socket.c:287 net/socket.c:287\n __sys_getpeername+0x470/0x6b0 net/socket.c:1987 net/socket.c:1987\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n tipc_getname+0x575/0x5e0 net/tipc/socket.c:757 net/tipc/socket.c:757\n __sys_getpeername+0x3b3/0x6b0 net/socket.c:1984 net/socket.c:1984\n __do_sys_getpeername net/socket.c:1997 [inline]\n __se_sys_getpeername net/socket.c:1994 [inline]\n __do_sys_getpeername net/socket.c:1997 [inline] net/socket.c:1994\n __se_sys_getpeername net/socket.c:1994 [inline] net/socket.c:1994\n __x64_sys_getpeername+0xda/0x120 net/socket.c:1994 net/socket.c:1994\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nUninit was stored to memory at:\n msg_set_word net/tipc/msg.h:212 [inline]\n msg_set_destport net/tipc/msg.h:619 [inline]\n msg_set_word net/tipc/msg.h:212 [inline] net/tipc/socket.c:1486\n msg_set_destport net/tipc/msg.h:619 [inline] net/tipc/socket.c:1486\n __tipc_sendmsg+0x44fa/0x5890 net/tipc/socket.c:1486 net/tipc/socket.c:1486\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n sock_sendmsg_nosec net/socket.c:704 [inline]\n sock_sendmsg net/socket.c:724 [inline]\n sock_sendmsg_nosec net/socket.c:704 [inline] net/socket.c:2409\n sock_sendmsg net/socket.c:724 [inline] net/socket.c:2409\n ____sys_sendmsg+0xe11/0x12c0 net/socket.c:2409 net/socket.c:2409\n ___sys_sendmsg net/socket.c:2463 [inline]\n ___sys_sendmsg net/socket.c:2463 [inline] net/socket.c:2492\n __sys_sendmsg+0x704/0x840 net/socket.c:2492 net/socket.c:2492\n __do_sys_sendmsg net/socket.c:2501 [inline]\n __se_sys_sendmsg net/socket.c:2499 [inline]\n __do_sys_sendmsg net/socket.c:2501 [inline] net/socket.c:2499\n __se_sys_sendmsg net/socket.c:2499 [inline] net/socket.c:2499\n __x64_sys_sendmsg+0xe2/0x120 net/socket.c:2499 net/socket.c:2499\n do_syscall_x64 arch/x86/entry/common.c:51 [inline]\n do_syscall_x64 arch/x86/entry/common.c:51 [inline] arch/x86/entry/common.c:82\n do_syscall_64+0x54/0xd0 arch/x86/entry/common.c:82 arch/x86/entry/common.c:82\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nLocal variable skaddr created at:\n __tipc_sendmsg+0x2d0/0x5890 net/tipc/socket.c:1419 net/tipc/socket.c:1419\n tipc_sendmsg+0xeb/0x140 net/tipc/socket.c:1402 net/tipc/socket.c:1402\n\nBytes 4-7 of 16 are uninitialized\nMemory access of size 16 starts at ffff888113753e00\nData copied to user address 0000000020000280\n\nReported-by: syzbot+cdbd40e0c3ca02cae3b7@syzkaller.appspotmail.com\nSigned-off-by: Haimin Zhang <tcs_kernel@tencent.com>\nAcked-by: Jon Maloy <jmaloy@redhat.com>\nLink: https://lore.kernel.org/r/1640918123-14547-1-git-send-email-tcs.kernel@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2022-0382", "cve_desc": "An information leak flaw was found due to uninitialized memory in the Linux kernel's TIPC protocol subsystem, in the way a user sends a TIPC datagram to one or more destinations. This flaw allows a local user to read some kernel memory. This issue is limited to no more than 7 bytes, and the user cannot control what is read. This flaw affects the Linux kernel versions prior to 5.17-rc1.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Input Validation and Bounds Checking**:\n   - The function starts by checking if `dlen > TIPC_MAX_USER_MSG_SIZE`, returning `-EMSGSIZE` if so. This prevents excessively large messages, which is a good defensive measure.\n   - It checks `ua` (the destination address) for validity using `tipc_uaddr_valid(ua, m->msg_namelen)`. This ensures the address structure is properly formed and within the expected size.\n   - The `msg_namelen` is used in the validation, which is critical to prevent buffer overflows when accessing `ua`.\n\n2. **Address Type Handling**:\n   - The code handles different address types (`TIPC_SERVICE_ADDR`, `TIPC_SOCKET_ADDR`, `TIPC_SERVICE_RANGE`) and validates them appropriately.\n   - For `TIPC_SERVICE_ADDR`, it performs a lookup via `tipc_nametbl_lookup_anycast`, which is a controlled operation and returns `-EHOSTUNREACH` if not found \u2014 this prevents sending to invalid or unresolvable addresses.\n   - For `TIPC_SOCKET_ADDR`, it directly uses `ua->sk`, which is assumed to be a valid socket address structure.\n\n3. **Destination Link Congestion Handling**:\n   - The function uses `tipc_wait_for_cond` to block or return if the destination link is congested. This is a proper mechanism to avoid overwhelming the network stack.\n\n4. **Message Header Construction**:\n   - The message header (`hdr`) is built using `msg_set_*` functions, which are likely safe and bounded.\n   - The `msg_set_destnode` and `msg_set_destport` are set based on `skaddr`, which is derived from validated input.\n   - The `msg_set_type`, `msg_set_hdr_sz`, and other fields are set based on the address type, with no unbounded or unchecked data.\n\n5. **Message Body and Packet Building**:\n   - The function uses `__skb_queue_head_init(&pkts)` to initialize a packet queue.\n   - It calls `tipc_msg_build` to build the message, passing `dlen`, `mtu`, and the packet queue. The function checks that `rc == dlen`, ensuring the entire message was processed.\n   - If `syn` is true (i.e., a connection setup), it attempts to clone the packet into `sk->sk_write_queue`. This is done safely with `tipc_msg_skb_clone`, which likely performs proper checks.\n\n6. **Message Transmission**:\n   - The message is sent via `tipc_node_xmit`, which is a trusted internal function.\n   - If `rc == -ELINKCONG`, it updates congestion state and returns 0 (success), which is a valid handling of link congestion.\n\n7. **Connection State Management**:\n   - If `syn` is true and the send succeeds, it sets the socket state to `TIPC_CONNECTING` and waits for connection completion if timeout is set. This is part of normal TIPC connection logic.\n\n8. **Potential Issues**:\n   - The only potential concern is the use of `ua` directly in `skaddr` assignments and lookups. However, all such uses are preceded by validation (`tipc_uaddr_valid`, `tipc_nametbl_lookup_anycast`, etc.).\n   - The `msg_namelen` is used in `tipc_uaddr_valid`, which prevents buffer overflows when accessing `ua`.\n   - There is no direct use of user-controlled data in string operations, format strings, or unbounded memory copies.\n   - All critical data structures are validated before use.\n\n9. **Conclusion**:\n   - The code performs comprehensive input validation.\n   - It uses safe functions for message construction and transmission.\n   - There are no known buffer overflows, use-after-free, or injection vulnerabilities.\n   - The logic for handling different address types and connection states is sound and secure.\n\n(2) NO: No security vulnerability."}
{"idx": 225563, "project": "tensorflow", "commit_id": "ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba4e8ac4dc2991e350d5cc407f8598c8d4ee70fb", "commit_message": "Fix potential divide by zero error when executing FractionalMaxPool, when pooling ratio is higher than input size for a particular dimension.\n\nPiperOrigin-RevId: 412151722\nChange-Id: I06e57cbb8eca43816eff79eac264fa7aae8f7163", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2022-21735", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `FractionalMaxPool` can be made to crash a TensorFlow process via a division by 0. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a kernel implementation (likely for a machine learning framework like TensorFlow) that performs pooling operations on a 4D tensor. It computes output values based on input data and pooling sequences.\n\n2) The code performs several input validations:\n   - Checks that the input tensor has exactly 4 dimensions\n   - Validates that pooling ratios are not larger than input dimensions\n   - Uses OP_REQUIRES and OP_REQUIRES_OK macros to ensure proper error handling\n\n3) Memory allocation is done safely:\n   - Output tensors are allocated using context->allocate_output with properly computed shapes\n   - The shapes are derived from input_size and pooling_ratio_, which are validated before use\n   - The code uses Eigen::Map to create views of tensor data without copying\n\n4) Array bounds are properly managed:\n   - The code uses std::min to cap height_end and width_end at height_max and width_max\n   - Loop bounds are carefully checked: height_cum_seq.size() - 1 and width_cum_seq.size() - 1\n   - The code uses proper indexing with bounds checking\n\n5) The code uses safe operations:\n   - Uses Eigen::NumTraits<T>::lowest() for initialization\n   - Uses cwiseMax for element-wise maximum operations\n   - Uses flat() to access tensor data in a safe manner\n\n6) There are no obvious buffer overflows, out-of-bounds accesses, or memory corruption issues. All array accesses are bounded by the validated dimensions and size checks.\n\n7) The code follows proper error handling patterns with OP_REQUIRES and OP_REQUIRES_OK, ensuring that invalid inputs are caught early.\n\n8) The use of GuardedPhiloxRandom and proper initialization of the generator is appropriate.\n\nAfter thorough analysis, there are no security vulnerabilities present in this code. The input validation, bounds checking, and memory management are all implemented correctly.\n\n(2) NO: No security vulnerability."}
{"idx": 437671, "project": "radare2", "commit_id": "d4ce40b516ffd70cf2e9e36832d8de139117d522", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/d4ce40b516ffd70cf2e9e36832d8de139117d522", "commit_message": "Fix oobread in symbols header parsing ##bin", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-1061", "cve_desc": "Heap Buffer Overflow in parseDragons in GitHub repository radareorg/radare2 prior to 5.6.8.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `parseDragons` is designed to parse a binary blob starting at offset `off` in a buffer `buf`. It reads data into a dynamically allocated buffer `b` of size `size`.\n\n2. The function first checks if `off` is beyond the buffer size. If so, it returns NULL. This prevents reading past the end of the buffer.\n\n3. It then checks if `size` (the amount of data to read) is less than 32. If so, it returns NULL. This is a reasonable check to ensure there's enough data to parse.\n\n4. It allocates memory with `malloc(size)`. If allocation fails, it returns NULL. This is safe.\n\n5. It reads data from the buffer using `r_buf_read_at(buf, off, b, size)`. It checks if the number of bytes read (`available`) equals `size`. If not, it prints a warning and returns NULL. This ensures that the full data is read, preventing partial reads.\n\n6. The code then checks for a \"magic\" pattern `\\x1a\\x2b\\xb2\\xa1` at two locations: `b` and `b + 8`. If both are found, `magicCombo` becomes 2. If not, it attempts a retry by reading 8 bytes earlier (`off - 8`) and re-checking the magic. This is a workaround for a possible misalignment.\n\n7. After successful magic detection, it prints debug info using `D eprintf`, which is conditional on debug mode.\n\n8. It reads a 32-bit little-endian value at `b + 12` using `r_read_le32`, which is safe as long as `b + 12` is within bounds. Since `size >= 32`, and `b + 12` is within the allocated buffer, this is safe.\n\n9. Finally, it frees the allocated buffer `b` and returns a new `RCoreSymCacheElement` using `r_coresym_cache_element_new`, passing `off + 16` as the offset.\n\nNow, let's look for vulnerabilities:\n\n- Buffer overflow: The buffer `b` is allocated with `size`, and data is read exactly `size` bytes. No overflow occurs.\n- Use after free: The buffer `b` is freed before returning, and no further use is made of it.\n- Off-by-one or index errors: The code checks `size >= 32`, and uses `b + 12` and `b + 16`, which are within bounds.\n- Memory corruption: No unsafe functions like `strcpy`, `sprintf`, or `memcpy` are used without bounds checks. `r_buf_read_at` is used safely with size validation.\n- Integer overflow: The `size` is derived from `r_buf_size(buf) - off`, which is non-negative due to the earlier check `off >= size`. No arithmetic overflow is possible here.\n- Retry logic: The retry reads from `off - 8`, but only if the original read succeeded. It reuses the same buffer `b`, but only after re-reading. The buffer size is unchanged, so it's safe.\n\nThe only potential concern is the use of `r_read_le32(b + 12)` \u2014 but since `size >= 32`, `b + 12` is within bounds. The `r_read_le32` function is assumed to be safe (it reads 4 bytes from a pointer, and the pointer is within the buffer).\n\nNo unsafe memory operations, no buffer overflows, no use of untrusted data in unsafe ways, and all input bounds are checked.\n\n(2) NO: No security vulnerability."}
{"idx": 459524, "project": "linux", "commit_id": "30e29a9a2bc6a4888335a6ede968b75cd329657a", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/30e29a9a2bc6a4888335a6ede968b75cd329657a", "commit_message": "bpf: Fix integer overflow in prealloc_elems_and_freelist()\n\nIn prealloc_elems_and_freelist(), the multiplication to calculate the\nsize passed to bpf_map_area_alloc() could lead to an integer overflow.\nAs a result, out-of-bounds write could occur in pcpu_freelist_populate()\nas reported by KASAN:\n\n[...]\n[   16.968613] BUG: KASAN: slab-out-of-bounds in pcpu_freelist_populate+0xd9/0x100\n[   16.969408] Write of size 8 at addr ffff888104fc6ea0 by task crash/78\n[   16.970038]\n[   16.970195] CPU: 0 PID: 78 Comm: crash Not tainted 5.15.0-rc2+ #1\n[   16.970878] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.13.0-1ubuntu1.1 04/01/2014\n[   16.972026] Call Trace:\n[   16.972306]  dump_stack_lvl+0x34/0x44\n[   16.972687]  print_address_description.constprop.0+0x21/0x140\n[   16.973297]  ? pcpu_freelist_populate+0xd9/0x100\n[   16.973777]  ? pcpu_freelist_populate+0xd9/0x100\n[   16.974257]  kasan_report.cold+0x7f/0x11b\n[   16.974681]  ? pcpu_freelist_populate+0xd9/0x100\n[   16.975190]  pcpu_freelist_populate+0xd9/0x100\n[   16.975669]  stack_map_alloc+0x209/0x2a0\n[   16.976106]  __sys_bpf+0xd83/0x2ce0\n[...]\n\nThe possibility of this overflow was originally discussed in [0], but\nwas overlooked.\n\nFix the integer overflow by changing elem_size to u64 from u32.\n\n  [0] https://lore.kernel.org/bpf/728b238e-a481-eb50-98e9-b0f430ab01e7@gmail.com/\n\nFixes: 557c0c6e7df8 (\"bpf: convert stackmap to pre-allocation\")\nSigned-off-by: Tatsuhiko Yasumatsu <th.yasumatsu@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nLink: https://lore.kernel.org/bpf/20210930135545.173698-1-th.yasumatsu@gmail.com", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-41864", "cve_desc": "prealloc_elems_and_freelist in kernel/bpf/stackmap.c in the Linux kernel before 5.14.12 allows unprivileged users to trigger an eBPF multiplication integer overflow with a resultant out-of-bounds write.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `prealloc_elems_and_freelist` is responsible for preallocating memory for elements and initializing a per-CPU freelist for a BPF stack map.\n\n2. The variable `elem_size` is calculated as the size of `struct stack_map_bucket` plus the `value_size` from the map configuration. This is done using `u64` to avoid integer overflow during the multiplication later.\n\n3. The function calls `bpf_map_area_alloc` to allocate memory for `smap->map.max_entries` number of elements, each of size `elem_size`. This allocation is done with a specific NUMA node (`smap->map.numa_node`), which is a valid and secure practice for performance and memory locality.\n\n4. If the allocation fails (`!smap->elems`), the function returns `-ENOMEM`, which is appropriate.\n\n5. The function then initializes a per-CPU freelist using `pcpu_freelist_init`. If this fails, it jumps to the `free_elems` label.\n\n6. The `pcpu_freelist_populate` function is called to populate the freelist with the allocated memory. It takes the freelist, the base address (`smap->elems`), the element size (`elem_size`), and the number of entries (`smap->map.max_entries`).\n\n7. The `pcpu_freelist_populate` function is expected to safely initialize the freelist with the provided memory block. This function is part of the kernel's memory management and is designed to handle such operations safely.\n\n8. The `free_elems` label correctly calls `bpf_map_area_free` to free the allocated memory if initialization fails, preventing memory leaks.\n\n9. The function uses proper error handling with early returns and cleanup, ensuring that no memory is leaked in case of failure.\n\n10. There is no evidence of buffer overflow, use-after-free, integer overflow, or improper bounds checking. The use of `u64` for `elem_size` helps prevent overflow during multiplication.\n\n11. The `pcpu_freelist_populate` function is assumed to be correctly implemented and safe, as it is part of the kernel's trusted codebase.\n\nConclusion: The code follows safe memory allocation and error handling practices. It properly checks for allocation failures, initializes the freelist only if allocation succeeds, and cleans up on failure. No exploitable vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 318099, "project": "wireless-drivers", "commit_id": "8b51dc7291473093c821195c4b6af85fadedbc2f", "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers.git/commit/?id=8b51dc7291473093c821195c4b6af85fadedbc2f", "commit_message": "rsi: fix a double free bug in rsi_91x_deinit()\n\n`dev` (struct rsi_91x_usbdev *) field of adapter\n(struct rsi_91x_usbdev *) is allocated  and initialized in\n`rsi_init_usb_interface`. If any error is detected in information\nread from the device side,  `rsi_init_usb_interface` will be\nfreed. However, in the higher level error handling code in\n`rsi_probe`, if error is detected, `rsi_91x_deinit` is called\nagain, in which `dev` will be freed again, resulting double free.\n\nThis patch fixes the double free by removing the free operation on\n`dev` in `rsi_init_usb_interface`, because `rsi_91x_deinit` is also\nused in `rsi_disconnect`, in that code path, the `dev` field is not\n (and thus needs to be) freed.\n\nThis bug was found in v4.19, but is also present in the latest version\nof kernel. Fixes CVE-2019-15504.\n\nReported-by: Hui Peng <benquike@gmail.com>\nReported-by: Mathias Payer <mathias.payer@nebelwelt.net>\nSigned-off-by: Hui Peng <benquike@gmail.com>\nReviewed-by: Guenter Roeck <linux@roeck-us.net>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>", "ground_truth": 0, "cwe": ["CWE-415"], "cve": "CVE-2019-15504", "cve_desc": "drivers/net/wireless/rsi/rsi_91x_usb.c in the Linux kernel through 5.2.9 has a Double Free via crafted USB device traffic (which may be remote via usbip or usbredir).", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `rsi_init_usb_interface` initializes a USB interface for a wireless network adapter (RSI 91x).\n2. It allocates memory for `rsi_dev` using `kzalloc` with `GFP_KERNEL`, which is appropriate for kernel space and handles allocation failure correctly by checking the return value.\n3. It sets up pointers and references: `rsi_dev->usbdev`, `rsi_dev->priv`, and `usb_set_intfdata(pfunction, adapter)`. These are standard practices in USB driver development.\n4. It calls `rsi_find_bulk_in_and_out_endpoints(pfunction, adapter)` to find USB endpoints. If this fails, it jumps to `fail_eps`, which is correct for error handling.\n5. It allocates a 2048-byte buffer for `tx_buffer` using `kmalloc`. If allocation fails, it jumps to `fail_rx`, where it frees the previously allocated `tx_buffer` \u2014 this is proper cleanup.\n6. It calls `rsi_usb_init_rx(adapter)` to initialize RX handling. If this fails, it logs an error and jumps to `fail_rx`, again freeing `tx_buffer` \u2014 correct error handling.\n7. It sets `tx_blk_size` and `block_size` to 252, which is a fixed value. No input validation is performed on this value, but since it's a hardcoded constant and not derived from user or device input, it's not a vulnerability.\n8. It sets function pointers for callbacks and host interface operations \u2014 standard and safe.\n9. The `CONFIG_RSI_DEBUGFS` conditional is used to set `num_debugfs_entries` to `MAX_DEBUGFS_ENTRIES - 1`. This is a safe adjustment and not exploitable.\n10. The function returns 0 on success, and on failure, it returns the appropriate error code (`-ENOMEM` or `-EINVAL`) after proper cleanup.\n\nKey points:\n- All memory allocations are checked for failure.\n- All allocated resources are properly freed in error paths (`fail_rx` and `fail_eps`).\n- No user-controlled data is used in a way that could lead to buffer overflows, use-after-free, or other memory corruption.\n- No unsafe string operations, format strings, or direct user input handling.\n- The code follows standard kernel driver practices for USB interface initialization.\n\nThere are no obvious security vulnerabilities such as buffer overflows, use-after-free, improper input validation, or unsafe memory management.\n\n(2) NO: No security vulnerability."}
{"idx": 225086, "project": "tensorflow", "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356", "ground_truth": 0, "cwe": ["CWE-617"], "cve": "CVE-2022-23565", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `RepeatedAttrDefEqual` compares two `protobuf::RepeatedPtrField<OpDef::AttrDef>` objects, which are collections of attribute definitions (likely used in a protocol buffer schema for defining operations in a system like TensorFlow).\n\n2. The function first builds a `std::unordered_map<string, const OpDef::AttrDef*>` from the first collection `a1`, mapping each attribute name to its corresponding `AttrDef` pointer. This is done to enable O(1) lookups when comparing attributes.\n\n3. During the construction of `a1_set`, the code checks if a name already exists in the map. If it does, it logs an error message indicating that attribute names must be unique. However, this check does not prevent the insertion of duplicate names\u2014it simply logs a warning. The map will overwrite the previous entry with the new one, so only the last occurrence of a duplicate name will be stored.\n\n4. The second loop iterates over `a2` and checks if each attribute name exists in `a1_set`. If not, it returns `false`. If it exists, it compares the attribute values using `AttrDefEqual`, and if they differ, returns `false`. It then removes the matched entry from `a1_set`.\n\n5. After processing all entries in `a2`, if `a1_set` is not empty, it returns `false`, meaning there were unmatched attributes in `a1`.\n\n6. The key issue here is: **the function does not enforce uniqueness of attribute names at the logical level\u2014it only logs a warning when a duplicate is detected during the first loop.** This means that if `a1` contains duplicate attribute names, the map will store only the last one, and the earlier ones will be silently lost. This can lead to incorrect behavior during comparison: two `AttrDef` fields that are logically different due to duplicates may be treated as equal, or mismatches may be missed.\n\n7. However, the question is whether this constitutes a **security vulnerability**.\n\n   - The function is not directly handling untrusted input in a way that could lead to memory corruption, code execution, or information disclosure.\n   - The logging of duplicate names is a diagnostic aid, not a security enforcement mechanism.\n   - The logic error (overwriting duplicate names) could lead to incorrect behavior in a system that relies on attribute uniqueness (e.g., schema validation), but this is a **functional correctness issue**, not a security vulnerability per se.\n   - There is no buffer overflow, use-after-free, or injection attack vector.\n   - No untrusted data is directly processed in a dangerous way (e.g., no string formatting, no memory copying without bounds checks, no unsafe parsing).\n\n8. While the code has a logical flaw (duplicate names are not properly enforced), it does not lead to exploitable security conditions such as arbitrary code execution, privilege escalation, or data leakage.\n\nTherefore, this is a **bug in correctness**, but not a **security vulnerability**.\n\n(2) NO: No security vulnerability."}
{"idx": 448912, "project": "zlib", "commit_id": "eff308af425b67093bab25f80f1ae950166bece1", "project_url": "https://github.com/madler/zlib", "commit_url": "https://github.com/madler/zlib/commit/eff308af425b67093bab25f80f1ae950166bece1", "commit_message": "Fix a bug when getting a gzip header extra field with inflate().\n\nIf the extra field was larger than the space the user provided with\ninflateGetHeader(), and if multiple calls of inflate() delivered\nthe extra header data, then there could be a buffer overflow of the\nprovided space. This commit assures that provided space is not\nexceeded.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-37434", "cve_desc": "zlib through 1.2.12 has a heap-based buffer over-read or buffer overflow in inflate in inflate.c via a large gzip header extra field. NOTE: only applications that call inflateGetHeader are affected. Some common applications bundle the affected zlib source code but may be unable to call inflateGetHeader (e.g., see the nodejs/node reference).", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step.\n\nThe code is a part of the zlib library's `inflate` function, which decompresses data compressed with the DEFLATE algorithm. This is a well-established, widely used, and heavily audited compression/decompression library. The function handles various states of the decompression process, including reading headers (gzip/zlib), decoding Huffman codes, copying literal and match data, and validating checksums.\n\nKey aspects to evaluate for security vulnerabilities:\n\n1. **Input Validation**:\n   - The function begins with `inflateStateCheck(strm)` and checks for null pointers (`strm->next_out == Z_NULL`, `strm->next_in == Z_NULL && strm->avail_in != 0`), returning `Z_STREAM_ERROR` if invalid. This prevents null pointer dereferences.\n   - It validates the zlib/gzip header (magic number, compression method, window size), ensuring the input is a valid compressed stream.\n   - It checks for invalid block types, invalid code lengths, and missing end-of-block codes.\n\n2. **Buffer Bounds Checking**:\n   - The code uses `have` (available input) and `left` (available output) to track how much data is available and how much space is left.\n   - Before copying data (e.g., in `COPY`, `MATCH` states), it ensures `copy = min(state->length, have, left)` \u2014 this prevents buffer overflows.\n   - In the `MATCH` state, it carefully checks whether the offset is valid relative to the window (`state->offset > state->whave`), and includes a fallback path (`INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR`) that safely handles out-of-bounds offsets by zero-filling, but only if the flag is defined. This is a known mitigation for a potential DoS vector.\n\n3. **Memory Safety**:\n   - The `zmemcpy` function is used for copying data, which is safe as long as the copy size is bounded by `have` and `left`.\n   - The `updatewindow` function is called to manage the sliding window, and it returns `Z_MEM_ERROR` on failure \u2014 this is properly handled.\n\n4. **Checksum and Integrity Verification**:\n   - The code verifies the Adler-32 or CRC-32 checksums at the end of the stream (`CHECK` state), which prevents tampering with compressed data.\n   - It checks both the data checksum and length (in `LENGTH` state for gzip), ensuring data integrity.\n\n5. **State Machine and Control Flow**:\n   - The state machine is well-structured and uses `switch` with `goto inf_leave` to exit cleanly.\n   - All transitions are guarded by checks, and invalid states lead to `BAD` or `MEM` mode, returning appropriate error codes.\n\n6. **Known Vulnerabilities**:\n   - There is a known historical vulnerability in zlib (CVE-2016-9840) related to integer overflows in `inflate` when processing malformed headers. However, this code includes checks like:\n     ```c\n     if (len > 15 || len > state->wbits) {\n         strm->msg = (char *)\"invalid window size\";\n         state->mode = BAD;\n         break;\n     }\n     ```\n     and similar bounds checks that prevent such overflows.\n   - The `INFLATE_STRICT` macro (if defined) adds an extra check: `if (state->offset > state->dmax)` \u2014 this prevents distance offsets that are too large, which could otherwise lead to memory access beyond the window.\n\n7. **Use of `PULLBYTE()` and `NEEDBITS()`**:\n   - These macros are used to safely read bits from input, with bounds checks on `have` and `next`. They prevent reading past the input buffer.\n\n8. **No Use of Dangerous Functions**:\n   - No `strcpy`, `sprintf`, `gets`, or similar unsafe functions are used.\n   - All memory operations are bounded by `have`, `left`, and `state->length`.\n\nConclusion:\nThe code is part of a mature, security-hardened library. It includes comprehensive input validation, buffer bounds checking, integrity verification, and proper error handling. All known attack vectors (e.g., buffer overflows, integer overflows, invalid offsets) are mitigated through explicit checks.\n\n(2) NO: No security vulnerability."}
{"idx": 276993, "project": "mruby", "commit_id": "da48e7dbb20024c198493b8724adae1b842083aa", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/da48e7dbb20024c198493b8724adae1b842083aa", "commit_message": "fiber.c: should pack 15+ arguments in an array.", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-0890", "cve_desc": "NULL Pointer Dereference in GitHub repository mruby/mruby prior to 3.2.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `fiber_switch` is responsible for switching between fibers (lightweight threads) in a Ruby-like VM (presumably mruby). It handles context switching, state validation, and argument passing.\n\n2. The function begins by retrieving the target fiber context `c` using `fiber_check(mrb, self)`, which ensures the fiber is valid. This is a safety check.\n\n3. It then checks the current status of the fiber using `c->status` and raises an error if the fiber is in an invalid or inconsistent state (e.g., double resume, resuming a dead or transferred fiber). These checks prevent misuse of fiber state.\n\n4. The function updates the status of the old context (`old_c`) and sets up the new fiber context (`c`) with proper `prev` pointer logic. This is standard for context switching.\n\n5. The key part is the handling of arguments passed to the fiber:\n   - If `status == MRB_FIBER_CREATED`, the function processes the incoming arguments (`a`, `len`).\n   - It checks if `len >= 15`. If so, it calls `mrb_stack_extend(mrb, 3)` to extend the stack, then creates a new array from the arguments using `mrb_ary_new_from_values(mrb, len, a)`. The `len` is then clamped to 15.\n   - Otherwise, it extends the stack by `len + 2` and copies the arguments from `a` to `c->stbase+1` using a loop.\n\n6. The function then sets `c->cibase->n = len` (number of arguments) and assigns the first stack value.\n\n7. If the fiber is not in the created state, it calls `fiber_result(mrb, a, len)` to retrieve the result, and if `vmexec` is true, it stores the result in the VM stack.\n\n8. Finally, if `vmexec` is true, it executes the fiber's code via `mrb_vm_exec`, and restores the old context (`mrb->c = old_c`). Otherwise, it marks the context as modified.\n\nNow, let's look for potential vulnerabilities:\n\n- The use of `mrb_ary_new_from_values(mrb, len, a)` is safe as long as `len` is within bounds. However, note that `len` is passed directly from user input (or external code) and is not validated against a maximum safe size. Although `len` is clamped to 15 in the `len >= 15` branch, the `else` branch allows `len` to be any value passed in, and `mrb_stack_extend(mrb, len+2)` is called with `len+2` as the argument.\n\n- The `mrb_stack_extend` function is responsible for extending the stack. If `len` is very large (e.g., millions), this could lead to excessive memory allocation, potentially causing a denial-of-service (DoS) via memory exhaustion.\n\n- However, the function does not perform any bounds checking on `len` beyond the `len >= 15` check. If `len` is extremely large (e.g., `INT_MAX`), `len + 2` could cause integer overflow, leading to a small stack extension, or if the system uses signed integers, it could wrap to a negative value, causing undefined behavior or a crash.\n\n- More critically, `mrb_stack_extend(mrb, len+2)` is called with `len+2` without checking if this value is reasonable. If `len` is untrusted (e.g., from user input), this could be exploited to trigger memory exhaustion or integer overflow.\n\n- Additionally, the `mrb_ary_new_from_values(mrb, len, a)` call uses `len` directly. If `len` is large, this could cause memory exhaustion.\n\n- There is no explicit validation of `len` to ensure it is within a safe range (e.g., `len < MAX_SAFE_ARGS`), which could allow an attacker to pass a large `len` value to exhaust system resources.\n\nTherefore, the function is vulnerable to a denial-of-service (DoS) attack via resource exhaustion (memory or stack) due to lack of bounds checking on the `len` parameter.\n\n(1) YES: A security vulnerability detected."}
{"idx": 232405, "project": "tensorflow", "commit_id": "02cc160e29d20631de3859c6653184e3f876b9d7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/02cc160e29d20631de3859c6653184e3f876b9d7", "commit_message": "Prevent nullptr deref in SparseTensorSliceDataset\n\nThe arguments must determine a valid sparse tensor. This means that when indices are empty then the values must be empty too (and the reverse).\n\nAlso added test, by modifying existing test with empty sparse tensor to now run with an invalid sparse tensor input.\n\nPiperOrigin-RevId: 388562757\nChange-Id: Id8b54cd7c2316025b4f9a77292c8fb5344d17609", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-37647", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When a user does not supply arguments that determine a valid sparse tensor, `tf.raw_ops.SparseTensorSliceDataset` implementation can be made to dereference a null pointer. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L240-L251) has some argument validation but fails to consider the case when either `indices` or `values` are provided for an empty sparse tensor when the other is not. If `indices` is empty, then [code that performs validation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/data/sparse_tensor_slice_dataset_op.cc#L260-L261) (i.e., checking that the indices are monotonically increasing) results in a null pointer dereference. If `indices` as provided by the user is empty, then `indices` in the C++ code above is backed by an empty `std::vector`, hence calling `indices->dim_size(0)` results in null pointer dereferencing (same as calling `std::vector::at()` on an empty vector). We have patched the issue in GitHub commit 02cc160e29d20631de3859c6653184e3f876b9d7. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of a TensorFlow op kernel that creates a SparseTensorSliceDataset. It takes three inputs: indices, values, and dense_shape tensors.\n\n2) The code performs several validation checks:\n   - Ensures indices is a matrix (2D tensor)\n   - Ensures values and dense_shape are vectors (1D tensors)\n   - Checks that if either indices or values are empty, both must be empty\n   - Validates that the batch dimension of the sparse tensor is ordered (non-decreasing)\n\n3) The key security consideration is input validation and bounds checking:\n   - The code uses OP_REQUIRES_OK and OP_REQUIRES macros which are TensorFlow's way of validating inputs and returning errors\n   - It checks tensor shapes and dimensions before processing\n   - It validates that indices are in non-decreasing order in the batch dimension\n   - It uses TensorShapeUtils::IsMatrix/IsVector to validate tensor types\n   - It checks for empty tensors and ensures consistency between indices and values\n\n4) The code properly handles tensor creation through sparse::SparseTensor::Create with proper error handling via OP_REQUIRES_OK.\n\n5) There are no obvious buffer overflows, out-of-bounds accesses, or unsafe memory operations. All operations are performed on validated tensor data with proper bounds checking.\n\n6) The only potential concern is the loop that checks ordering of batch indices, but this is a valid validation check that prevents processing of unsorted data, which is a reasonable requirement for this operation.\n\n7) All input validation is performed before any processing occurs, and the code returns appropriate error messages for invalid inputs.\n\n(2) NO: No security vulnerability."}
{"idx": 398518, "project": "rizin", "commit_id": "aa6917772d2f32e5a7daab25a46c72df0b5ea406", "project_url": "https://github.com/rizinorg/rizin", "commit_url": "https://github.com/rizinorg/rizin/commit/aa6917772d2f32e5a7daab25a46c72df0b5ea406", "commit_message": "Fix oob write for dwarf with abbrev with count 0 (Fix #2083) (#2086)", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-43814", "cve_desc": "Rizin is a UNIX-like reverse engineering framework and command-line toolset. In versions up to and including 0.3.1 there is a heap-based out of bounds write in parse_die() when reversing an AMD64 ELF binary with DWARF debug info. When a malicious AMD64 ELF binary is opened by a victim user, Rizin may crash or execute unintended actions. No workaround are known and users are advised to upgrade.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `parse_die` processes DWARF debugging information, parsing attributes from a binary buffer (`buf`) into a `RzBinDwarfDie` structure.\n\n2. The function iterates over `abbrev->count - 1` attributes (note: `i < abbrev->count - 1`, not `<=`), and for each, it calls `parse_attr_value` to extract attribute values. This function populates `die->attr_values[i]`.\n\n3. After parsing each attribute, it checks for two specific attributes:\n   - `DW_AT_comp_dir`: If the attribute form is `DW_FORM_strp` or `DW_FORM_string` and the content is non-null, it assigns `comp_dir` to `attribute->string.content`.\n   - `DW_AT_stmt_list`: If the attribute is a constant or reference, it sets `line_info_offset` to the value.\n\n4. Later, if both `comp_dir` and `line_info_offset` are valid (i.e., `comp_dir` is non-null and `line_info_offset != UT64_MAX`), it:\n   - Duplicates the `comp_dir` string using `strdup`.\n   - Inserts the duplicated string into a hash table `info->line_info_offset_comp_dir` using `line_info_offset` as the key.\n\n5. Key security considerations:\n   - The `comp_dir` value comes directly from the DWARF debug string section (`debug_str`), which is part of the binary being parsed. This data is untrusted and potentially malicious.\n   - The function uses `strdup` to copy `comp_dir`, which is safe as long as the string is null-terminated and not excessively long.\n   - The hash table `ht_up_insert` is used to store the mapping. The function does not validate the length of `comp_dir` before copying or inserting.\n   - However, `strdup` is a standard safe function that allocates memory and copies the string up to the null terminator. It does not perform bounds checking, but it is not vulnerable to buffer overflow if the input is a valid C string.\n   - The main risk would be if `comp_dir` is not null-terminated, but that would be a malformed DWARF section, and the parser should not assume valid input. However, `parse_attr_value` is responsible for ensuring proper string handling.\n   - The function does not perform any bounds checking on the length of `comp_dir`, but since `strdup` only copies until the null terminator, and the input is from `debug_str` (which is part of the binary), the only risk is if the string is extremely long, leading to memory exhaustion (DoS), but not a buffer overflow or code execution.\n\n6. However, there is a subtle issue: the loop runs for `i < abbrev->count - 1`, which means the last attribute (index `abbrev->count - 1`) is skipped. This could lead to incomplete parsing, but it's not a security vulnerability per se \u2014 it's a logic error that may cause missing data, not a vulnerability.\n\n7. The critical point: `strdup` is safe as long as the input is a valid null-terminated string. The DWARF specification ensures that `DW_FORM_strp` and `DW_FORM_string` values are null-terminated. Therefore, `strdup` will not overflow.\n\n8. There is no use of unsafe functions like `strcpy`, `sprintf`, or direct buffer copying without bounds checking. The only dynamic allocation is via `strdup`, which is safe for null-terminated strings.\n\n9. The hash table insertion (`ht_up_insert`) is not vulnerable because it uses `line_info_offset` as a key, which is a 64-bit integer, and the value is a string pointer. No string formatting or copying is done in a way that could overflow.\n\nConclusion: The code does not contain any exploitable buffer overflows, format string vulnerabilities, or unsafe memory operations. The use of `strdup` is safe given the context of DWARF debug data, which is expected to be well-formed. While there is a potential for DoS via extremely long strings, this is not a classic security vulnerability like buffer overflow or injection.\n\n(2) NO: No security vulnerability."}
{"idx": 337374, "project": "vim", "commit_id": "8e4b76da1d7e987d43ca960dfbc372d1c617466f", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/8e4b76da1d7e987d43ca960dfbc372d1c617466f", "commit_message": "patch 8.2.4901: NULL pointer access when using invalid pattern\n\nProblem:    NULL pointer access when using invalid pattern.\nSolution:   Check for failed regexp program.", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-1620", "cve_desc": "NULL Pointer Dereference in function vim_regexec_string at regexp.c:2729 in GitHub repository vim/vim prior to 8.2.4901. NULL Pointer Dereference in function vim_regexec_string at regexp.c:2729 allows attackers to cause a denial of service (application crash) via a crafted input.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `fname_match` takes three parameters:\n   - `rmp`: a pointer to a `regmatch_T` structure, which likely contains a compiled regular expression (`regprog`).\n   - `name`: a pointer to a character string (file name) to be matched.\n   - `ignore_case`: a flag indicating whether case should be ignored during matching.\n\n2. The function first checks if `name` is not NULL. If it is NULL, the function returns `NULL` (implied by the return statement at the end, since `match` is initialized to NULL and not set).\n\n3. The `rmp->rm_ic` field is set based on either the global `p_fic` (fileignorecase) or the `ignore_case` argument. This controls whether the regex engine performs case-insensitive matching.\n\n4. The function then calls `vim_regexec(rmp, name, 0)` to attempt to match the regex against `name`. If successful, `match` is set to `name`.\n\n5. If the first match fails but `rmp->regprog` is not NULL, the function attempts to replace `$(HOME)` with `~` using `home_replace_save(NULL, name)`. This function returns a new string with the substitution applied.\n\n6. If the substitution results in a non-NULL string (`p != NULL`), the function attempts to match the regex against the new string (`p`). If this succeeds, `match` is set to the original `name` (not the substituted one).\n\n7. The substituted string `p` is then freed with `vim_free(p)`.\n\n8. The function returns `match`, which is either `name` (if a match was found) or `NULL`.\n\nNow, let's assess for security vulnerabilities:\n\n- The function uses `vim_regexec` with user-provided input (`name`) as the string to match against a compiled regex. However, the regex is already compiled (`rmp->regprog`), so the input is not used to compile the regex \u2014 this prevents regex injection.\n- The `home_replace_save` function replaces `$(HOME)` with `~`. This is a safe transformation and does not involve untrusted input in a dangerous way.\n- The function does not perform any dynamic string construction that could lead to buffer overflows or format string vulnerabilities.\n- The use of `vim_free(p)` ensures that memory allocated by `home_replace_save` is properly freed, preventing memory leaks.\n- The function does not directly manipulate or copy strings into fixed-size buffers without bounds checking \u2014 it uses `vim_regexec` which is designed to work safely with strings.\n\nThe only potential concern is whether `home_replace_save` could be vulnerable to path traversal or injection if `name` contains malicious content. However, `home_replace_save` is a well-known Vim function that only replaces `$(HOME)` with `~` and does not interpret the rest of the string in a way that could lead to code execution or path traversal. It is not a shell command or file path expansion function that would be dangerous.\n\nTherefore, the function is using safe string handling and does not introduce any exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 432352, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function starts with `validate_msg_fds(dev, ctx, 0) != 0` check. This ensures that the message contains valid file descriptors, which is a good security practice.\n   - It then checks `ctx->msg.size != sizeof(ctx->msg.payload.inflight)`. This ensures the message size matches the expected size, preventing buffer overflows due to malformed messages.\n\n2. **Memory Allocation and Initialization**:\n   - `dev->inflight_info` is allocated using `rte_zmalloc_socket` with a specified NUMA node. This is safe as long as the size is valid and the allocation succeeds.\n   - The function checks for allocation failure and returns an error if it fails, preventing use of uninitialized or invalid memory.\n\n3. **Memory Mapping and File Descriptor Handling**:\n   - `inflight_mem_alloc` is used to allocate shared memory and return a file descriptor (`fd`). This function is assumed to be safe if it properly handles the size and mapping.\n   - The code correctly handles cleanup of previous `inflight_info` memory and file descriptor:\n     - `munmap` is called if `dev->inflight_info->addr` is non-null.\n     - `close` is called if `dev->inflight_info->fd >= 0`.\n   - This prevents resource leaks and ensures that old mappings are properly released before new ones are set.\n\n4. **Initialization of Shared Memory**:\n   - The allocated memory (`addr`) is zero-initialized with `memset(addr, 0, mmap_size)`. This prevents garbage data from being exposed to the guest.\n   - The code then initializes the `inflight_packed` structure for packed queues:\n     - Sets `used_wrap_counter` and `old_used_wrap_counter` to 1.\n     - Initializes a circular list of descriptors (`desc[j].next = j + 1`).\n   - This initialization is correct and safe for the expected data structure.\n\n5. **Message Payload and File Descriptor Setup**:\n   - The function sets `ctx->msg.payload.inflight.mmap_size = mmap_size`, `mmap_offset = 0`, and `ctx->fds[0] = fd`.\n   - It sets `ctx->fd_num = 1`, indicating one file descriptor is being sent back.\n   - These values are derived from validated inputs and are properly assigned.\n\n6. **Potential Issues**:\n   - The function uses `ctx->msg.payload.inflight.num_queues` and `queue_size` directly in calculations without bounds checking. However, these values are part of the message payload that was already validated for size (`ctx->msg.size == sizeof(...)`), and the `get_pervq_shm_size_*` functions are assumed to be safe.\n   - The `inflight_mem_alloc` function is not shown, but if it correctly validates the size and returns a valid mapping, then this is safe.\n   - The `memset(addr, 0, mmap_size)` ensures no stale data is exposed.\n   - The use of `rte_zmalloc_socket` and `munmap`/`close` ensures proper memory and resource management.\n\n7. **No Obvious Vulnerabilities**:\n   - No buffer overflows (no `strcpy`, `strcat`, etc.).\n   - No use of unsafe functions.\n   - No direct user input in unsafe contexts (e.g., string formatting, command execution).\n   - All memory and file descriptor handling is done with proper cleanup and validation.\n   - The shared memory is zero-initialized before use.\n\nConclusion: The code follows secure programming practices: input validation, safe memory allocation, proper cleanup, zero-initialization, and correct use of shared memory and file descriptors. There are no obvious security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 269330, "project": "tensorflow", "commit_id": "0f931751fb20f565c4e94aa6df58d54a003cdb30", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/0f931751fb20f565c4e94aa6df58d54a003cdb30", "commit_message": "Validate dimensions of input tensor in `FractionalAvgPoolGrad`\n\nPiperOrigin-RevId: 388286227\nChange-Id: Ieb7566155e92acc8993a2212c76deacadc0edc8a", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-37651", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation for `tf.raw_ops.FractionalAvgPoolGrad` can be tricked into accessing data outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/fractional_avg_pool_op.cc#L205) does not validate that the input tensor is non-empty. Thus, code constructs an empty `EigenDoubleMatrixMap` and then accesses this buffer with indices that are outside of the empty area. We have patched the issue in GitHub commit 0f931751fb20f565c4e94aa6df58d54a003cdb30. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a C++ implementation of a backpropagation function for a FractionalAvgPool operation in a machine learning framework (likely TensorFlow, given the use of OpKernelContext, Tensor, and OP_REQUIRES macros).\n\n2) The function takes several inputs:\n   - orig_input_tensor_shape: a 1D tensor with 4 elements representing input shape\n   - out_backprop: the gradient of the output\n   - row_seq_tensor and col_seq_tensor: pooling sequence tensors\n\n3) The code performs input validation:\n   - Checks that orig_input_tensor_shape is 1D with exactly 4 elements\n   - Validates that row_seq_tensor and col_seq_tensor have sufficient elements (at least out_rows+1 and out_cols+1 respectively)\n   - Ensures all dimensions are non-zero\n\n4) The core algorithm:\n   - Creates a temporary double-precision tensor to accumulate gradients\n   - Maps 4D tensors to 2D matrices for easier computation\n   - For each output element, determines the corresponding input region (pooling cell) using the sequence tensors\n   - Distributes the output gradient evenly across all elements in the pooling cell\n   - Uses double precision for accumulation to avoid floating-point precision issues\n\n5) The code properly handles:\n   - Array bounds checking through the use of OP_REQUIRES\n   - Index bounds with std::min to prevent out-of-bounds access\n   - Proper memory management through Tensor allocation and forwarding\n   - Type safety with explicit casting\n\n6) The only potential concern would be integer overflow in the index calculations, but:\n   - The code uses int64_t for all indices\n   - The bounds are validated through OP_REQUIRES\n   - The loop bounds are derived from tensor dimensions that are already validated\n\n7) There are no buffer overflows, use-after-free, null pointer dereferences, or other classic security vulnerabilities. The code follows safe programming practices with proper input validation and bounds checking.\n\n(2) NO: No security vulnerability."}
{"idx": 329925, "project": "cairo", "commit_id": "03a820b173ed1fdef6ff14b4468f5dbc02ff59be", "project_url": "https://gitlab.freedesktop.org/cairo/cairo", "commit_url": "https://gitlab.freedesktop.org/cairo/cairo/-/merge_requests/85/diffs?commit_id=03a820b173ed1fdef6ff14b4468f5dbc02ff59be", "commit_message": "Fix mask usage in image-compositor", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2020-35492", "cve_desc": "A flaw was found in cairo's image-compositor.c in all versions prior to 1.17.4. This flaw allows an attacker who can provide a crafted input file to cairo's image-compositor (for example, by convincing a user to open a file in an application using cairo, or if an application uses cairo on untrusted input) to cause a stack buffer overflow -> out-of-bounds WRITE. The highest impact from this vulnerability is to confidentiality, integrity, as well as system availability.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `_inplace_src_spans` is responsible for processing a list of spans (horizontal segments) in a rendering context, likely for compositing images using the Pixman library.\n\n2. The function takes:\n   - `abstract_renderer`: a pointer to a renderer context.\n   - `y`, `h`: the vertical position and height of the region being processed.\n   - `spans`: an array of `cairo_half_open_span_t` structures, each containing `x` (start x-coordinate) and `coverage` (alpha value).\n   - `num_spans`: the number of spans.\n\n3. The function begins by checking if `num_spans == 0`, and returns early if so \u2014 this is safe.\n\n4. It initializes:\n   - `x0` to the x-coordinate of the first span.\n   - `m` to point to the mask image data (`pixman_image_get_data(r->mask)`).\n   - `base` as the start of the mask data.\n\n5. The main loop processes spans in pairs (`spans[0]` and `spans[1]`) using a `do-while` loop that runs `num_spans - 1` times. This means the loop accesses `spans[1]` inside the loop body, which is only safe if `num_spans > 1`. However, the loop condition is `while (--num_spans > 1)`, so when `num_spans == 1`, the loop body is not entered. This is correct.\n\n6. The loop processes each span based on:\n   - `spans[0].coverage == 0xff` (fully opaque): triggers a composite operation using `PIXMAN_OP_SRC` and possibly a prior `LERP_SRC` or `OUT_REVERSE`/`ADD` combo.\n   - `spans[0].coverage == 0x0` (fully transparent): similar composite logic, but with a different path.\n   - Otherwise: writes the coverage value to the mask buffer (`*m++ = spans[0].coverage`), and if the span length is >1, uses `memset` to fill the buffer.\n\n7. The key concern is buffer access:\n   - `m` is initialized to `base = (uint8_t*)pixman_image_get_data(r->mask)`.\n   - The code writes to `m` using `*m++` and `memset(m, ..., len)`.\n   - The size of the mask buffer is not checked against the total number of spans or the total width being processed.\n   - The function does not verify that `m` stays within the bounds of the mask image data.\n\n8. The mask image data (`r->mask`) is assumed to be large enough to hold the coverage values for all spans. However, there is no validation that:\n   - The mask image has sufficient size.\n   - The total number of coverage values written (i.e., the sum of `len` across all spans) does not exceed the mask buffer size.\n\n9. Since `m` is incremented without bounds checking, and the mask buffer size is not verified, this could lead to a buffer overflow if the total number of coverage values exceeds the allocated size of the mask image.\n\n10. The function uses `spans[1].x - spans[0].x` to compute `len`, which is safe as long as `spans[1].x >= spans[0].x` (which is expected for a properly ordered span list). But again, no bounds check on the total output size.\n\n11. The `memset(m, spans[0].coverage, --len)` line decrements `len` before using it, so if `len` is 1, it becomes 0, and `memset` is skipped \u2014 this is safe.\n\n12. However, the critical issue is that the function assumes the mask buffer (`base`) is large enough to hold all the coverage values. If the input spans are malformed (e.g., extremely long or numerous), or if the mask image is smaller than expected, this will result in a buffer overflow.\n\n13. There is no call to `pixman_image_get_width()` or `pixman_image_get_stride()` to validate the mask buffer size, nor is there any check that `m` does not exceed the buffer bounds.\n\n14. This is a classic case of a buffer overflow vulnerability due to lack of bounds checking on a destination buffer (`m`) that is filled based on user-controlled or externally provided input (`spans`).\n\n(1) YES: A security vulnerability detected."}
{"idx": 441822, "project": "xserver", "commit_id": "144849ea27230962227e62a943b399e2ab304787", "project_url": "http://gitweb.freedesktop.org/?p=xorg/xserver", "commit_url": "https://gitlab.freedesktop.org/xorg/xserver/-/commit/144849ea27230962227e62a943b399e2ab304787", "commit_message": "Fix XkbSelectEvents() integer underflow\n\nCVE-2020-14361 ZDI-CAN 11573\n\nThis vulnerability was discovered by:\nJan-Niklas Sohn working with Trend Micro Zero Day Initiative\n\nSigned-off-by: Matthieu Herrb <matthieu@herrb.eu>", "ground_truth": 0, "cwe": ["CWE-191"], "cve": "CVE-2020-14361", "cve_desc": "A flaw was found in X.Org Server before xorg-x11-server 1.20.9. An Integer underflow leading to heap-buffer overflow may lead to a privilege escalation vulnerability. The highest threat from this vulnerability is to data confidentiality and integrity as well as system availability.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `SProcXkbSelectEvents` is a server-side procedure handler for XKB (X Keyboard Extension) events in the X Window System. It processes client requests to select which XKB events the client wants to receive.\n\n2) The function starts by:\n   - Using `REQUEST(xkbSelectEventsReq)` to get the request header\n   - Swapping bytes for network-to-host order using `swaps()` on several fields\n   - Validating the request size with `REQUEST_AT_LEAST_SIZE`\n\n3) The key logic is in the loop that processes event masks:\n   - It extracts the `affectWhich` mask and filters out `XkbMapNotifyMask`\n   - It iterates through each bit in the mask using `ndx` and `bit`\n   - For each bit that is set and not `XkbMapNotify`, it:\n     - Determines the size of data needed (1, 2, or 4 bytes)\n     - Checks if there's enough data left (`dataLeft < (size * 2)` \u2192 BadLength)\n     - Swaps the data based on size (using `swaps()` for 16-bit, `swapl()` for 32-bit)\n     - Advances the pointer and reduces dataLeft\n\n4) The critical check is: `if (dataLeft > 2) { ErrorF(...); return BadLength; }`\n   - This ensures no more than 2 extra bytes are present after the expected data\n   - This is a reasonable safeguard against buffer overflows\n\n5) The function properly:\n   - Validates request size upfront\n   - Checks for sufficient data before processing\n   - Uses proper byte-swapping for network data\n   - Handles different data sizes correctly\n   - Rejects invalid event types with BadValue\n   - Rejects extra data with BadLength\n\n6) There is no buffer overflow risk because:\n   - The data processing is bounded by `dataLeft`\n   - The loop only processes data up to the expected size\n   - The final check ensures no excess data remains\n   - All data access is within the bounds of the request\n\n7) The code follows secure practices for network protocol parsing, including proper size validation and bounds checking.\n\n(2) NO: No security vulnerability."}
{"idx": 277489, "project": "libmobi", "commit_id": "eafc415bc6067e72577f70d6dd5acbf057ce6e6f", "project_url": "https://github.com/bfabiszewski/libmobi", "commit_url": "https://github.com/bfabiszewski/libmobi/commit/eafc415bc6067e72577f70d6dd5acbf057ce6e6f", "commit_message": "Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-1533", "cve_desc": "Buffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11. This vulnerability is capable of arbitrary code execution.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `mobi_decode_infl` decodes data using a rule stream (`rule`) and modifies a buffer (`decoded`) in place, with `decoded_size` tracking the current size of the decoded data.\n\n2. The function uses a loop to process each byte in the `rule` array until a null byte is encountered (i.e., `while ((c = *rule++))`).\n\n3. The variable `pos` is initialized to `*decoded_size`, which represents the current insertion/deletion position in the `decoded` buffer.\n\n4. The function handles three types of rule bytes:\n   - `c <= 4`: Controls mode (`'i'` for insert, `'d'` for delete) and direction (`'<'` or `'>'`).\n   - `c > 10 && c < 20`: Adjusts position based on direction and subtracts `c - 10` from `pos`.\n   - Otherwise: Performs either an insert (`mod == 'i'`) or delete (`mod == 'd'`) operation.\n\n5. Critical checks:\n   - In the insert case (`mod == 'i'`), the code checks:\n     ```c\n     if (pos < 0 || l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX)\n     ```\n     This checks that:\n     - `pos` is non-negative.\n     - `l = *decoded_size - pos` is non-negative (ensuring `pos <= *decoded_size`).\n     - The destination buffer (`d + l`) does not exceed the maximum allowed buffer size (`INDX_INFLBUF_SIZEMAX`).\n\n   - In the delete case (`mod == 'd'`), similar checks are performed:\n     ```c\n     if (pos < 0 || l < 0 || s + l > decoded + INDX_INFLBUF_SIZEMAX)\n     ```\n     Again, `pos` and `l` are validated, and the buffer bounds are checked.\n\n6. However, note that `INDX_INFLBUF_SIZEMAX` is used as a hard limit for the buffer. But the function does not validate that `decoded` itself is a valid buffer of at least `INDX_INFLBUF_SIZEMAX` size before use. This is a potential issue if `decoded` is not properly allocated or if the caller passes a buffer that is too small.\n\n7. More importantly, the function uses `memmove` to shift data in the buffer. The `memmove` calls are:\n   - Insert: `memmove(d, s, (size_t) l)` \u2014 moves data from `pos` to `pos+1`.\n   - Delete: `memmove(d, s, (size_t) l)` \u2014 moves data from `pos+1` to `pos`.\n\n   The bounds checks before `memmove` are intended to prevent buffer overflows, but they rely on `INDX_INFLBUF_SIZEMAX` being a correct upper bound.\n\n8. The key vulnerability: The function does not validate the initial size of the `decoded` buffer or ensure that `decoded` is allocated with sufficient space. If `decoded` is too small (e.g., smaller than `INDX_INFLBUF_SIZEMAX`), then even with the bounds checks, the `memmove` calls could still write beyond the allocated buffer if `INDX_INFLBUF_SIZEMAX` is not the actual buffer size.\n\n9. However, the bounds check `d + l > decoded + INDX_INFLBUF_SIZEMAX` uses `INDX_INFLBUF_SIZEMAX` as a constant. This implies that the function assumes the buffer is at least `INDX_INFLBUF_SIZEMAX` bytes long. If the actual buffer passed by the caller is smaller than this, then the check may pass (because `decoded + INDX_INFLBUF_SIZEMAX` is beyond the real buffer), but `memmove` will still write past the real buffer.\n\n10. Therefore, the function is vulnerable to buffer overflow if the `decoded` buffer passed by the caller is smaller than `INDX_INFLBUF_SIZEMAX`, even though the bounds check uses `INDX_INFLBUF_SIZEMAX`. This is a classic case of trusting a constant size without validating the actual buffer size.\n\n11. Additionally, the function uses `debug_print` to log errors, but this does not prevent the overflow from occurring.\n\nConclusion: The function performs bounds checks using a constant `INDX_INFLBUF_SIZEMAX`, but does not verify that the `decoded` buffer is actually large enough to hold that many bytes. This creates a potential buffer overflow vulnerability if the caller passes a buffer smaller than `INDX_INFLBUF_SIZEMAX`.\n\n(1) YES: A security vulnerability detected."}
{"idx": 439266, "project": "ImageMagick6", "commit_id": "b268ce7a59440972f4476b9fd98104b6a836d971", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/b268ce7a59440972f4476b9fd98104b6a836d971", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1337", "ground_truth": 0, "cwe": ["CWE-835"], "cve": "CVE-2018-18024", "cve_desc": "In ImageMagick 7.0.8-13 Q16, there is an infinite loop in the ReadBMPImage function of the coders/bmp.c file. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted bmp file.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and File Header Parsing**:\n   - The function `ReadBMPImage` begins by validating input parameters (`image_info`, `exception`) and asserting their signatures.\n   - It reads the first 2 bytes of the file to check for \"BM\" or \"CI\" identifiers, which is standard for BMP files.\n   - It then reads the BMP header fields (file size, offset, width, height, bits per pixel, etc.) using `ReadBlobLSBLong`, `ReadBlobLSBShort`, etc., which are designed to read little-endian values safely.\n   - The code checks for malformed headers: e.g., `bmp_info.size < 40` triggers an error for non-OS/2 headers, and `bmp_info.width <= 0` or `bmp_info.height == 0` triggers a `CorruptImageError`.\n\n2. **Bounds Checking and Memory Allocation**:\n   - Before allocating memory for pixel data, the code computes `bytes_per_line` and `length` based on image dimensions and bits per pixel.\n   - It checks: `if (((MagickSizeType) length/8) > GetBlobSize(image))` \u2014 this ensures that the expected pixel data size does not exceed the actual file size.\n   - Memory is allocated using `AcquireVirtualMemory`, which is a safe memory allocation function in ImageMagick that checks for overflow and underflow conditions.\n   - The code also checks `if (count != (ssize_t) length)` after reading pixel data, which prevents reading beyond the file boundary.\n\n3. **Colormap and Pixel Data Handling**:\n   - For indexed images (1, 4, 8 bpp), the code reads the colormap using `ReadBlob` with a size based on `image->colors` and `packet_size`.\n   - It validates that the read count matches the expected size: `if (count != (ssize_t) (packet_size*image->colors))` \u2014 this prevents buffer overflows.\n   - The colormap is read into a temporary buffer (`bmp_colormap`) and then copied safely into `image->colormap` using `ScaleCharToQuantum`, which is a safe scaling function.\n\n4. **Image Data Conversion and Pixel Processing**:\n   - The code processes pixel data in scanlines, using `QueueAuthenticPixels` and `SyncAuthenticPixels` to safely access image pixel buffers.\n   - For each pixel format (1, 4, 8, 16, 24, 32 bpp), the code uses safe bit manipulation and masking to extract color components.\n   - The bitfield masks (`red_mask`, `green_mask`, `blue_mask`, `alpha_mask`) are used to extract pixel values, and the code computes shift and quantum bits safely using loops that are bounded by 32 bits.\n   - The `IsValidColormapIndex` function is used to validate indices before setting them, preventing out-of-bounds access.\n\n5. **Loop and Index Bounds**:\n   - All loops use `ssize_t` for loop variables (`y`, `x`, `i`) and are bounded by `image->rows` and `image->columns`, which are derived from the BMP header and validated earlier.\n   - The code checks `if (x < (ssize_t) image->columns)` after processing partial scanlines, ensuring no out-of-bounds access.\n\n6. **File Traversal and Multiple Image Support**:\n   - The function supports multiple images in a single file via a `do-while` loop that checks for \"BM\" or \"CI\" at the start of each image.\n   - It uses `SeekBlob` and `ReadBlob` safely, and checks `EOFBlob` to avoid reading past the end of the file.\n\n7. **Error Handling and Exception Safety**:\n   - The code uses `ThrowReaderException` and `ThrowMagickException` to report errors, and `RelinquishVirtualMemory` and `DestroyImageList` to clean up resources on failure.\n   - All memory allocations are checked, and cleanup is performed on error paths.\n\n8. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, `gets`, or other unsafe C library functions.\n   - All data copying is done with size-checked `ReadBlob`, `memcpy`, or safe pixel access functions.\n\n9. **No Buffer Overflows or Integer Overflows**:\n   - The code uses `MagickSizeType` and `ssize_t` appropriately.\n   - It checks for integer overflow in `length` computation: `if (((MagickSizeType) length/8) > GetBlobSize(image))`.\n   - The `AcquireVirtualMemory` function is designed to prevent integer overflow during allocation.\n\n10. **Security Best Practices**:\n    - The code validates all input from the file (headers, sizes, colors, compression).\n    - It uses safe memory allocation and bounds checking.\n    - It avoids direct user input manipulation and relies on structured parsing.\n\nAfter thorough analysis, there are no signs of buffer overflows, integer overflows, use-after-free, null pointer dereferences, or other classic security vulnerabilities. All input is validated, and all memory operations are bounded and safe.\n\n(2) NO: No security vulnerability."}
{"idx": 275987, "project": "micro-ecc", "commit_id": "1b5f5cea5145c96dd8791b9b2c41424fc74c2172", "project_url": "https://github.com/kmackay/micro-ecc", "commit_url": "https://github.com/kmackay/micro-ecc/commit/1b5f5cea5145c96dd8791b9b2c41424fc74c2172", "commit_message": "Fix for #168", "ground_truth": 0, "cwe": ["CWE-415"], "cve": "CVE-2020-27209", "cve_desc": "The ECDSA operation of the micro-ecc library 1.0 is vulnerable to simple power analysis attacks which allows an adversary to extract the private ECC key.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Function Purpose and Context**:\n   - This function `uECC_sign_with_k` is part of an elliptic curve cryptography (ECC) library, specifically for signing a message using a private key and a given nonce `k`.\n   - It computes the ECDSA signature (r, s) where:\n     - r is the x-coordinate of the point k*G (G is the generator point),\n     - s = (e + r*d) / k mod n, where e is the hash of the message, d is the private key.\n\n2. **Input Validation**:\n   - The function checks that `k` is in the valid range: 0 < k < curve->n. This is critical because using k = 0 or k \u2265 n would break the signature scheme and potentially leak information.\n   - It uses `uECC_vli_isZero(k, num_words)` and `uECC_vli_cmp(curve->n, k, num_n_words) != 1` to ensure k is strictly less than n and non-zero.\n   - If invalid, it returns 0 (failure), which is correct behavior.\n\n3. **Randomness and Side-Channel Protection**:\n   - The function attempts to improve resistance to side-channel attacks by:\n     - Using a random initial Z value (via `g_rng_function`) when available.\n     - Using a random multiplier `tmp` to obscure the value of `k` during modular inversion (`uECC_vli_modInv`), which prevents timing or power analysis from revealing bits of `k` or the private key.\n   - The use of `regularize_k` ensures that `k` is properly reduced modulo `n` and normalized.\n   - The randomization of `k` via multiplication by a random `tmp` before inversion and then re-multiplication to recover `1/k` is a known technique to prevent side-channel leakage during modular inverse computation.\n\n4. **Use of `g_rng_function`**:\n   - If `g_rng_function` is not set (i.e., no RNG), it sets `tmp = 1` (a constant), which is acceptable in this context because the randomness is only used to obscure the modular inverse step. However, this means that in the absence of a proper RNG, the side-channel protection is weakened.\n   - But note: the function still returns 0 if `uECC_generate_random_int` fails, so it does not proceed with invalid randomness.\n\n5. **Memory and Buffer Handling**:\n   - The function uses local buffers (`tmp`, `s`, `p`) of size `uECC_MAX_WORDS`, which is defined to be sufficient for the curve.\n   - It uses `uECC_vli_set`, `uECC_vli_modMult`, `uECC_vli_modAdd`, etc., which are assumed to be safe and bounds-checked.\n   - The use of `bcopy` and `uECC_vli_nativeToBytes` is conditional on endianness, but no buffer overflows are evident because:\n     - `curve->num_bytes` is used to limit the size of data copied.\n     - The `signature` buffer is assumed to be large enough (typically 2 * curve->num_bytes).\n   - No direct use of `strcpy`, `memcpy` with unbounded sizes, or unsafe string operations.\n\n6. **Final Signature Output**:\n   - The function stores `r` (from point p) and `s` (computed as (e + r*d)/k) into the `signature` buffer.\n   - It checks that `s` does not exceed the bit length of `curve->num_bytes * 8`, which prevents invalid signatures.\n   - The output is properly formatted based on endianness.\n\n7. **Potential Issues**:\n   - **Use of `tmp` as a constant when RNG is not available**: If `g_rng_function` is not set, `tmp` is set to 1. This means the side-channel protection is disabled. However, this is not a vulnerability per se \u2014 it's a fallback behavior. The function still ensures correctness and does not leak information via the signature computation path. The security of the overall ECDSA scheme relies on the randomness of `k`, not on the randomization of the modular inverse step. So this is a trade-off, not a flaw.\n   - **No check on `signature` buffer size**: The function assumes `signature` is large enough (2 * curve->num_bytes). If the caller passes a smaller buffer, this could lead to a buffer overflow. However, this is a **caller responsibility** issue, not a flaw in the function itself. The function does not perform bounds checks on `signature`, but this is typical in low-level crypto libraries where the caller is expected to provide properly sized buffers.\n\n8. **Conclusion**:\n   - The function performs proper input validation.\n   - It includes side-channel mitigation techniques (randomization of k during modular inverse).\n   - It avoids buffer overflows through proper use of `uECC_vli_*` functions and size limits.\n   - The only potential concern is the lack of bounds checking on the `signature` buffer, but this is not a vulnerability in the function's logic \u2014 it's a design choice common in crypto libraries where the caller must ensure buffer safety.\n\nTherefore, **no exploitable security vulnerability is present in the code as written**.\n\n(2) NO: No security vulnerability."}
{"idx": 222739, "project": "gpac", "commit_id": "893fb99b606eebfae46cde151846a980e689039b", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/893fb99b606eebfae46cde151846a980e689039b", "commit_message": "fixed #1902", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-40565", "cve_desc": "A Segmentation fault caused by a null pointer dereference vulnerability exists in Gpac through 1.0.1 via the gf_avc_parse_nalu function in av_parsers.c when using mp4box, which causes a denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Buffer Management**:\n   - The function `gf_avc_parse_nalu` takes a `GF_BitStream *bs` and an `AVCState *avc` as inputs.\n   - `gf_bs_read_u8(bs)` reads a single byte from the bitstream, which is used to extract the NAL unit header (`nal_hdr`).\n   - The function uses `gf_bs_enable_emulation_byte_removal(bs, GF_TRUE);` to handle emulation prevention bytes, which is a standard and safe practice in H.264/AVC parsing to prevent malformed streams from causing buffer overflows or misinterpretation.\n\n2. **Memory Copy and Structure Initialization**:\n   - `memcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo));` copies the current slice state into a local `n_state` structure. This is safe as long as `avc->s_info` is valid and properly initialized.\n   - Later, `memcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));` updates the global state with the parsed values. This is a standard pattern in stateful decoders and is not inherently unsafe.\n\n3. **Switch Statement and NAL Unit Type Handling**:\n   - The function handles various NAL unit types (e.g., IDR slice, non-IDR slice, SPS, PPS, SEI, etc.).\n   - For each type, it calls appropriate parsing functions (e.g., `avc_parse_slice`, `SVC_ReadNal_header_extension`, `gf_avc_read_sps_bs_internal`, etc.).\n   - These internal functions are assumed to be well-behaved and properly validate input, but we must check for potential issues in this function.\n\n4. **Potential Issues in Logic and Control Flow**:\n   - In the `case GF_AVC_NALU_SVC_SLICE` and `case GF_AVC_NALU_SVC_PREFIX_NALU`, the code calls `SVC_ReadNal_header_extension(bs, &n_state.NalHeader);` and returns 0. This is safe as long as `SVC_ReadNal_header_extension` does not read beyond the bitstream bounds.\n   - In the `case GF_AVC_NALU_IDR_SLICE` and `GF_AVC_NALU_NON_IDR_SLICE`, the function calls `avc_parse_slice(bs, avc, idr_flag, &n_state);` with `idr_flag` initialized to 0. However, `idr_flag` is never updated based on the NAL header \u2014 it's always 0. This could lead to incorrect parsing of IDR flag logic, but it's not a direct security vulnerability (more of a functional bug).\n   - The function checks `avc->s_info.sps` before accessing `sps->poc_type`, etc. This is a good defensive check to prevent null pointer dereference.\n   - The `default` case handles unknown NAL unit types. It sets `ret` based on comparisons between old and new NAL types. The logic is complex but does not involve unbounded memory access or unsafe operations.\n\n5. **No Buffer Overflows or Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, or other unsafe string functions.\n   - No fixed-size buffers are written to without bounds checking \u2014 all data is read via `gf_bs_read_*` functions, which are designed to be safe and respect bitstream boundaries.\n   - The use of `memcpy` is bounded by `sizeof(AVCSliceInfo)`, which is a fixed size and not user-controlled.\n\n6. **Input Validation and State Management**:\n   - The function validates the `sps` pointer before dereferencing it.\n   - It uses `gf_bs_read_ue(bs)` for unsigned exponential-Golomb decoding, which is a standard and safe method in H.264 parsing.\n   - The function returns early on error conditions (e.g., `return -1`), preventing further processing of invalid data.\n\n7. **No Evidence of Memory Corruption or Code Execution Risk**:\n   - There is no use of dynamic memory allocation or pointer arithmetic that could lead to heap corruption.\n   - No format string vulnerabilities or unsafe function calls.\n   - All data is read from the bitstream in a controlled, bounded manner.\n\n8. **Conclusion**:\n   - The code follows safe parsing practices: input validation, bounded reads, defensive checks, and proper state management.\n   - While there may be a minor logic issue (e.g., `idr_flag` is not updated), it does not lead to a security vulnerability such as buffer overflow, use-after-free, or arbitrary code execution.\n   - The function does not expose any exploitable weaknesses under normal or malicious input.\n\n(2) NO: No security vulnerability."}
{"idx": 328807, "project": "vim", "commit_id": "d25f003342aca9889067f2e839963dfeccf1fe05", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/d25f003342aca9889067f2e839963dfeccf1fe05", "commit_message": "patch 9.0.0011: reading beyond the end of the line with put command\n\nProblem:    Reading beyond the end of the line with put command.\nSolution:   Adjust the end mark position.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-2264", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 9.0.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `do_put` is part of the Vim editor (likely from the `put.c` file), responsible for implementing the `put` command (e.g., `p`, `P`, `:put`) that inserts text from a register into the buffer. It handles various modes:\n- Character mode (`MCHAR`)\n- Line mode (`MLINE`)\n- Block mode (`MBLOCK`)\n- Special registers (e.g., `=`, `%`, `#`, `.`)\n\nIt processes user input (register name, count, direction) and inserts text accordingly, with support for undo, visual mode, indentation, and cursor positioning.\n\n---\n\n### Step 2: Identify potential security concerns\n\nSecurity vulnerabilities in such code typically arise from:\n- Buffer overflows\n- Memory corruption (use-after-free, double-free)\n- Improper input validation\n- Use of unsafe string/memory functions\n- Unchecked user-controlled data in memory operations\n\nLet\u2019s examine key aspects:\n\n#### A. Input validation\n- `regname` is an integer (register name), validated via `get_spec_reg()` and `get_yank_register()`.\n- `expr_result` is only used if `regname == '='`, and is passed directly to `insert_string`.\n- `count` is a `long`, but used in loops and memory allocations with checks for overflow.\n- `dir` is either `FORWARD` or `BACKWARD`, validated via `if (dir == FORWARD)` etc.\n\n#### B. Memory allocation and usage\n- `y_array` is allocated via `ALLOC_MULT` or assigned from existing data.\n- `newp = alloc(totlen + oldlen + 1);` \u2014 memory is allocated based on `totlen` and `oldlen`.\n- `totlen` is computed as:\n  ```c\n  totlen = count * (yanklen + spaces) + bd.startspaces + bd.endspaces;\n  ```\n  This is checked for overflow:\n  ```c\n  if (yanklen + spaces != 0\n       && count > ((INT_MAX - (bd.startspaces + bd.endspaces))\n                    / (yanklen + spaces)))\n  {\n      emsg(_(e_resulting_text_too_long));\n      break;\n  }\n  ```\n  This is a **correct overflow check** \u2014 it prevents integer overflow in the multiplication.\n\n#### C. String handling\n- `STRLEN`, `STRCPY`, `STRCAT`, `mch_memmove`, `vim_memset` are used.\n- All string operations are bounded by known lengths (`yanklen`, `oldlen`, etc.).\n- No use of `strcpy`, `strcat`, `gets`, or other unsafe functions.\n- `vim_strsave`, `vim_strnsave` are used safely (return `NULL` on failure).\n- `ml_get`, `ml_replace`, `ml_append` are internal Vim functions that manage line buffers safely.\n\n#### D. User-controlled data in memory operations\n- The `insert_string` comes from:\n  - `expr_result` (from compiled code, possibly user-provided expression)\n  - `get_spec_reg()` (special registers like `%`, `#`, `:`, etc.)\n  - `get_yank_register()` (user\u2019s yank buffer)\n\nThese are **not directly user input** but are derived from the user\u2019s register content. However, **if a user can control the content of a register**, then yes, they can inject arbitrary data.\n\nBut the key point: **Vim does not execute arbitrary code from register content**. The `do_put` function only **inserts text** into the buffer. It does not interpret or evaluate it.\n\n#### E. Potential for buffer overflow?\n- All allocations are bounded by computed sizes with overflow checks.\n- No fixed-size buffers used without bounds checking.\n- `newp` is allocated with `totlen + oldlen + 1`, and `totlen` is checked for overflow.\n- `mch_memmove` is used with explicit size arguments (`(size_t)bd.textcol`, etc.), so no off-by-one or buffer overflow.\n\n#### F. Use of `vim_free` and `ALLOC_MULT`\n- `vim_free(insert_string)` is called only if `allocated` is true.\n- `vim_free(y_array)` is called only if `regname == '='` \u2014 this is safe because `y_array` was allocated in that case.\n- No double-free or use-after-free.\n\n#### G. Side effects and state changes\n- `u_save()` is called to save undo state \u2014 this is safe.\n- `mark_adjust()` is called \u2014 safe.\n- `changed_lines()` and `changed_bytes()` are used \u2014 safe.\n\n#### H. Special case: `regname == '.'` (inserted text)\n- This handles `:put` with `.` register (last inserted text).\n- Uses `stuffcharReadbuff()` \u2014 this is safe and part of Vim\u2019s input simulation.\n\n#### I. No code execution from user data\n- The function **does not execute** any code from the inserted text.\n- It does not use `eval`, `system`, `shell`, or `exec` functions.\n- It does not interpret the text as commands.\n\n---\n\n### Step 3: Conclusion\n\nDespite the complexity and the fact that user-controlled data (from registers) is inserted into the buffer, **this function does not perform any unsafe operations**:\n- No buffer overflows (due to overflow checks and bounded memory operations).\n- No use of unsafe string functions.\n- No code execution from user input.\n- All memory allocations are checked for overflow.\n- All pointers are validated before use.\n\nThe only potential risk would be if a user could **inject a very large amount of data** to cause denial-of-service (DoS) via memory exhaustion. However, this is **not a security vulnerability** in the traditional sense (like buffer overflow, RCE, etc.), but rather a resource exhaustion issue, which is not typically classified as a \"security vulnerability\" unless explicitly exploitable in a way that leads to code execution or privilege escalation.\n\nMoreover, Vim already has protections against such DoS (e.g., `maxmem` limit, `maxmemtot`, etc.), and the code includes overflow checks.\n\n---\n\n### Final Decision\n\n(2) NO: No security vulnerability."}
{"idx": 282862, "project": "linux", "commit_id": "d563131ef23cbc756026f839a82598c8445bc45f", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/d563131ef23cbc756026f839a82598c8445bc45f", "commit_message": "rsi: release skb if rsi_prepare_beacon fails\n\nIn rsi_send_beacon, if rsi_prepare_beacon fails the allocated skb should\nbe released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Kalle Valo <kvalo@codeaurora.org>", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2019-19071", "cve_desc": "A memory leak in the rsi_send_beacon() function in drivers/net/wireless/rsi/rsi_91x_mgmt.c in the Linux kernel through 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering rsi_prepare_beacon() failures, aka CID-d563131ef23c.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `rsi_send_beacon` is responsible for preparing and sending a beacon frame in a wireless network driver.\n\n2. It allocates a socket buffer (`skb`) of size `MAX_MGMT_PKT_SIZE` using `dev_alloc_skb`. This is a standard way to allocate network packet buffers in Linux kernel drivers.\n\n3. It initializes the buffer data to zero using `memset(skb->data, 0, MAX_MGMT_PKT_SIZE)`. This ensures that the buffer starts with a clean state.\n\n4. The code calculates `dword_align_bytes` as the alignment of `skb->data` with respect to a 64-byte boundary (since `0x3f` is 63, and `& 0x3f` gives the remainder when divided by 64). If the data is not aligned to a 64-byte boundary, it uses `skb_pull` to remove bytes from the beginning of the buffer to align it.\n\n   - This alignment is likely for hardware or DMA requirements, but note: `skb_pull` reduces the data length of the skb, and the data pointer is adjusted accordingly.\n   - However, the code does not recheck the buffer size after `skb_pull`. If `dword_align_bytes` is non-zero, it pulls `(64 - dword_align_bytes)` bytes, which could potentially pull more than the available data, but since `skb->data` is aligned to a 64-byte boundary, and the buffer is allocated with `dev_alloc_skb`, the alignment is typically safe.\n\n5. The function calls `rsi_prepare_beacon(common, skb)` to fill the skb with beacon frame data. This function is expected to write the beacon frame into the buffer.\n\n6. If `rsi_prepare_beacon` fails, the function logs an error, frees the skb, and returns `-EINVAL`.\n\n7. Otherwise, the skb is queued to `common->tx_queue[MGMT_BEACON_Q]`, and the transmission thread is signaled.\n\n8. The function logs success.\n\nNow, consider potential vulnerabilities:\n\n- Buffer overflow: The `skb` is allocated with `MAX_MGMT_PKT_SIZE`, and `memset` initializes it. The `rsi_prepare_beacon` function is expected to write data into the buffer. If this function writes more than `MAX_MGMT_PKT_SIZE` bytes, it would cause a buffer overflow. However, the function is responsible for ensuring it does not exceed the buffer size. There is no evidence in the code that it does so.\n\n- Use of `skb_pull` to align data: This is a common technique in kernel drivers to align data for hardware requirements. The pull operation is safe as long as the amount pulled does not exceed the buffer size. Since `dword_align_bytes` is at most 63, and the buffer is at least 64 bytes (implied by `MAX_MGMT_PKT_SIZE` being large enough), pulling up to 63 bytes is safe.\n\n- No input validation: The function does not take user input directly. It operates on internal state (`common`) and generates a beacon frame based on internal parameters. The only data source is `common`, which is a driver context.\n\n- No dynamic memory allocation beyond `dev_alloc_skb`, and proper cleanup with `dev_kfree_skb` on error.\n\n- The `skb` is properly managed: allocated, used, queued, and freed on error.\n\nConclusion: The code follows safe kernel programming practices. It properly allocates, initializes, aligns, uses, and frees the buffer. There is no evidence of buffer overflow, use-after-free, or other memory safety issues. The alignment logic is standard and safe.\n\n(2) NO: No security vulnerability."}
{"idx": 220449, "project": "tensorflow", "commit_id": "e7f497570abb6b4ae5af4970620cd880e4c0c904", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904", "commit_message": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7", "ground_truth": 0, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Function Context and Input Validation**:\n   - The function is a kernel implementation for grouped convolution in a machine learning framework (likely TensorFlow or similar).\n   - It takes various parameters including input tensor, filter tensor, strides, dilations, padding, explicit paddings, output tensor, and data format.\n   - The function begins with a DCHECK that enforces the data format to be NHWC. This is a runtime assertion (debug-only), not a security check, but it ensures correctness in the supported format.\n\n2. **Tensor Dimension Calculations**:\n   - `in_depth` is the depth of the input tensor (dimension 3).\n   - `patch_depth` is the depth of the filter (dimension 2).\n   - `num_groups` is computed as `in_depth / patch_depth`. This assumes that the input depth is divisible by the filter depth, which is a valid assumption for grouped convolutions. No bounds checking is performed here, but this is a mathematical constraint of the operation, not a vulnerability.\n\n3. **Tensor Shuffling**:\n   - The code uses `shuffle` and `rev_shuffle` arrays to rearrange tensor dimensions for grouped convolution.\n   - Temporary tensors (`input_shuffled`, `filter_shuffled`, `output_shuffled`) are allocated using `ctx->allocate_temp`, which is a safe method provided by the framework for temporary memory allocation.\n   - The shuffling is done via Eigen's `shuffle` method, which is a well-defined, safe operation on tensors.\n\n4. **Memory Allocation and Usage**:\n   - All temporary tensors are allocated with `TensorShape` derived from `post_shuffle`, which is computed from the input tensor shapes.\n   - The `OP_REQUIRES_OK` macro is used to check the success of allocation and assignment. If allocation fails, the kernel will return an error, preventing undefined behavior.\n\n5. **Parallel Execution and Synchronization**:\n   - The code uses `absl::BlockingCounter` and `on_shuffled` callback to ensure that shuffling of input and filter tensors completes before proceeding.\n   - The shuffling is performed asynchronously using Eigen's `device` with a callback, and `shuffles_completed.Wait()` ensures synchronization.\n   - This is a correct and safe use of asynchronous operations.\n\n6. **Grouped Convolution Loop**:\n   - The loop iterates over `num_groups`, slicing the shuffled tensors using `chip<0>(i)`.\n   - Each group is processed independently using `functor::SpatialConvolution`, which is a well-defined convolution operation.\n   - The padding is handled correctly: either via `EXPLICIT` with `explicit_paddings` or via `BrainPadding2EigenPadding` for other padding types.\n   - No user input is directly used in a way that could lead to buffer overflows, memory corruption, or code execution.\n\n7. **Final Shuffle Back**:\n   - The output is shuffled back using `rev_shuffle` and written to the original output tensor.\n   - The `shaped<T, 5>` method is used to reinterpret the tensor shape, and the assignment is done via Eigen's device, which is safe.\n\n8. **Security Considerations**:\n   - There is no user-controlled data being used in a way that could lead to buffer overflows, format string vulnerabilities, or memory corruption.\n   - All tensor dimensions are derived from input tensor shapes, which are validated by the framework before reaching this kernel.\n   - The code uses safe tensor operations (Eigen, `allocate_temp`, `shaped`, `chip`, `shuffle`) that are designed to prevent out-of-bounds access.\n   - No dynamic memory allocation with user-controlled sizes is performed directly.\n   - The use of `OP_REQUIRES_OK` ensures that any allocation or operation failure is caught early.\n\nConclusion: The code is a well-structured, safe implementation of grouped convolution with proper memory management, synchronization, and input validation. It does not contain any exploitable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 187732, "project": "qemu", "commit_id": "f9a70e79391f6d7c2a912d785239ee8effc1922d", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://git.qemu.org/?p=qemu.git;a=commit;h=e6908bfe8e07f2b452e78e677da1b45b1c0f6829", "commit_message": "vnc: sanitize bits_per_pixel from the client\n\nbits_per_pixel that are less than 8 could result in accessing\nnon-initialized buffers later in the code due to the expectation\nthat bytes_per_pixel value that is used to initialize these buffers is\nnever zero.\n\nTo fix this check that bits_per_pixel from the client is one of the\nvalues that the rfb protocol specification allows.\n\nThis is CVE-2014-7815.\n\nSigned-off-by: Petr Matousek <pmatouse@redhat.com>\n\n[ kraxel: apply codestyle fix ]\n\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>", "ground_truth": 0, "cwe": ["CWE-264"], "cve": "CVE-2014-7815", "cve_desc": "The set_pixel_format function in ui/vnc.c in QEMU allows remote attackers to cause a denial of service (crash) via a small bytes_per_pixel value.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `protocol_client_msg` processes incoming VNC client messages via `data` and `len`.\n   - The function uses `read_u8`, `read_u16`, `read_u32`, etc., which are assumed to be safe wrappers for reading from the `data` buffer. However, the code does not validate whether the `len` parameter is sufficient for the requested reads (e.g., reading `read_u16(data, 10)` when `len` is only 11). This could lead to out-of-bounds reads if `len` is too small.\n\n2. **Critical Issue: Missing Length Validation Before Accessing Data**:\n   - In the `VNC_MSG_CLIENT_SET_ENCODINGS` case:\n     ```c\n     if (len == 4) {\n         limit = read_u16(data, 2);\n         if (limit > 0)\n             return 4 + (limit * 4);\n     } else\n         limit = read_u16(data, 2);\n     ```\n     Here, `limit` is read from `data[2]` and `data[3]` (via `read_u16`), but there is no check that `len >= 4` before reading `data[2]` and `data[3]`. If `len < 4`, this would cause an out-of-bounds read.\n     - Similarly, in the `for` loop:\n       ```c\n       for (i = 0; i < limit; i++) {\n           int32_t val = read_s32(data, 4 + (i * 4));\n           memcpy(data + 4 + (i * 4), &val, sizeof(val));\n       }\n       ```\n       This loop assumes that `4 + (limit * 4)` is within bounds of `len`. But if `limit` is large (e.g., 1000), and `len` is only 10, this will read far beyond the buffer, causing a buffer overflow or memory corruption.\n\n   - The function returns `4 + (limit * 4)` as a suggested length, but this is only used for future reads. The current `len` is not validated against the required size before accessing `data`.\n\n3. **Use of `memcpy` with Untrusted Data**:\n   - In the `VNC_MSG_CLIENT_SET_ENCODINGS` case, the code does:\n     ```c\n     memcpy(data + 4 + (i * 4), &val, sizeof(val));\n     ```\n     This overwrites the input buffer with a possibly modified value. However, the real issue is that `val` is read from `data` using `read_s32`, which may read beyond the buffer if `len` is too small. This is a classic buffer overflow vulnerability.\n\n4. **Untrusted `len` Used in Calculations**:\n   - The `limit` variable is derived from `read_u16(data, 2)` without checking if `len >= 4`. If `len < 4`, this is undefined behavior.\n   - Then, `limit` is used in a loop that accesses `data + 4 + (i * 4)`, which could be far beyond the actual `len`.\n\n5. **Other Cases**:\n   - In `VNC_MSG_CLIENT_CUT_TEXT`, there is a check:\n     ```c\n     if (dlen > (1 << 20)) {\n         error_report(\"vnc: client_cut_text msg payload has %u bytes which exceeds our limit of 1MB.\");\n         vnc_client_error(vs);\n         break;\n     }\n     ```\n     This is good \u2014 it limits the payload size to 1MB. However, the check is only done when `len == 8`. If `len > 8`, it proceeds to `client_cut_text(vs, read_u32(data, 4), data + 8);` without validating that `len` is at least `8 + dlen`. This could lead to reading beyond the buffer.\n\n6. **Return Values for Length Negotiation**:\n   - The function returns values like `return 20;`, `return 4 + (limit * 4);`, etc., which are used by the caller to determine how much more data to read. However, these return values are based on untrusted input (`len` and `data`), and if the input is malicious, the returned length could be huge, leading to memory exhaustion or buffer overflows in the caller.\n\n7. **No Input Sanitization or Bounds Checks**:\n   - The code assumes that `len` is sufficient for all reads, but it does not validate that `len` is large enough before accessing `data` at offsets like `4 + (i * 4)` or `6`, etc.\n\nConclusion:\n- The code fails to validate the `len` parameter against the required size before accessing `data` at various offsets.\n- It uses untrusted data (e.g., `limit`, `dlen`) to control loop counts and memory access without proper bounds checks.\n- This leads to potential out-of-bounds reads and writes, which can result in buffer overflows, memory corruption, and remote code execution.\n\n(1) YES: A security vulnerability detected."}
{"idx": 413623, "project": "radare2", "commit_id": "10517e3ff0e609697eb8cde60ec8dc999ee5ea24", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/10517e3ff0e609697eb8cde60ec8dc999ee5ea24", "commit_message": "aaef on arm/thumb switches causes uaf ##crash\n\n* Reported by peacock-doris via huntr.dev\n* Reproducer: poc_uaf_r_reg_get", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-0849", "cve_desc": "Use After Free in r_reg_get_name_idx in GitHub repository radareorg/radare2 prior to 5.6.6.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `r_core_anal_esil` is part of Radare2, a reverse engineering framework. It performs **ESIL (Evaluable Static Instruction Language)** analysis on binary code to:\n- Disassemble instructions\n- Emulate them using ESIL\n- Identify references (xrefs) to memory addresses, strings, functions, etc.\n- Set flags, metadata, and analyze control flow (jumps, calls, etc.)\n\nIt reads binary data from an offset, processes each instruction via `r_anal_op`, and uses ESIL to simulate execution and detect data references.\n\n---\n\n### Step 2: Identify potential security issues\n\n#### A. **Buffer Handling and Memory Safety**\n- `buf = malloc((size_t)iend + 2);` \u2014 Allocates memory based on `iend`, which is derived from `end - start`.\n- `r_io_read_at(core->io, start, buf, iend + 1);` \u2014 Reads `iend + 1` bytes into `buf`.\n\n\u26a0\ufe0f **Potential issue**: The size `iend + 1` is used for reading, but `iend` is calculated as `end - start`. If `end < start`, `iend` becomes negative, but this is checked:\n```c\nif (iend < 0) {\n    return;\n}\n```\nSo negative sizes are avoided.\n\nAlso, `iend > MAX_SCAN_SIZE` is checked:\n```c\nif (iend > MAX_SCAN_SIZE) {\n    eprintf(\"Warning: Not going to analyze 0x%08\"PFMT64x\" bytes.\\n\", (ut64)iend);\n    return;\n}\n```\nThis prevents excessive memory allocation and potential DoS via large input.\n\n\u2705 **No buffer overflow here** due to bounds checks.\n\n#### B. **Input Validation and User-Controlled Data**\n- `str` and `target` are user-provided inputs.\n- `target` is parsed via `r_num_math(core->num, expr)`, which is safe if `r_num_math` is properly implemented.\n- `str` is used to determine behavior (e.g., `if (!strcmp(str, \"f\"))`), but no direct string formatting or injection occurs.\n\n\u26a0\ufe0f **Potential concern**: `r_num_math` could be vulnerable to malformed expressions (e.g., infinite loops, memory exhaustion), but Radare2's `r_num_math` is known to be safe with input validation and timeouts (via `r_cons_is_breaked`).\n\n\u2705 **No exploitable injection** \u2014 the input is not used in unsafe string formatting or command execution.\n\n#### C. **Use of `esilbreak_last_read` and `esilbreak_last_data`**\n- These are global variables used to track memory reads during ESIL execution.\n- They are set by `esilbreak_mem_read` hook, which is called during `r_anal_esil_parse`.\n\n\u26a0\ufe0f **Risk**: If `esilbreak_last_read` is not properly initialized or validated, it could lead to use-after-free or invalid memory access.\n\nBut:\n- `esilbreak_last_read = UT64_MAX;` is initialized at the top.\n- It is only used if it's not `UT64_MAX`, and only after a valid memory read.\n- The check `if (dst != UT64_MAX && CHECKREF(dst))` ensures it's only used when valid.\n\n\u2705 **No vulnerability** \u2014 safe usage with proper initialization.\n\n#### D. **Use of `r_anal_esil_parse` with `esilstr`**\n- `esilstr = R_STRBUF_SAFEGET(&op.esil);` \u2014 gets the ESIL string from the instruction.\n- `r_anal_esil_parse(ESIL, esilstr);` \u2014 parses and executes the ESIL.\n\n\u26a0\ufe0f **Risk**: If `esilstr` contains malicious ESIL code (e.g., infinite loops, memory corruption), it could cause DoS.\n\nBut:\n- The function uses `r_cons_is_breaked()` and `esil_anal_stop` to allow interruption via `^C`.\n- `r_cons_break_push(cccb, core);` sets up a break handler.\n- `esil_parse` is designed to respect these break conditions.\n\n\u2705 **No remote code execution or memory corruption** \u2014 the ESIL interpreter is sandboxed and interruptible.\n\n#### E. **Use of `r_flag_set_next`, `r_meta_set_string`, `r_core_flag_get_by_spaces`**\n- These functions are used to set flags and metadata based on analysis results.\n- `r_strf_buffer(64)` and `r_str_newf` are used for string formatting.\n\n\u26a0\ufe0f **Potential issue**: `r_str_newf(\"syscall.%s\", si->name)` \u2014 if `si->name` contains format specifiers (e.g., `%s`), could lead to format string vulnerability?\n\nBut:\n- `r_str_newf` is a safe wrapper that uses `r_strf` internally.\n- Radare2's `r_strf` and `r_str_newf` are **not** vulnerable to format string attacks because they do not use `printf`-style formatting directly.\n- The format string is hardcoded: `\"syscall.%s\"`, and `si->name` is passed as argument \u2014 **no user-controlled format string**.\n\n\u2705 **No format string vulnerability**.\n\n#### F. **Use of `r_str_replace_char` to replace `%` with `&`**\n- This is a **known workaround** for a bug in Radare2 (issue #6937) where `%` in strings could crash disassembly.\n- It's a defensive measure, not a vulnerability.\n\n\u2705 **Safe and intentional**.\n\n#### G. **Memory Management**\n- `free(pcname)`, `free(spname)`, `free(buf)` \u2014 all allocated memory is freed.\n- `r_list_free(ictx.bbl)`, `r_list_free(ictx.path)`, etc. \u2014 proper cleanup.\n- `r_reg_arena_pop` restores register state.\n\n\u2705 **No memory leaks**.\n\n#### H. **Use of `r_io_is_valid_offset`**\n- Used to check if `cur` is a valid offset before reading.\n- Prevents out-of-bounds access.\n\n\u2705 **Safe**.\n\n---\n\n### Step 3: Summary of Findings\n- All user inputs are validated or sanitized.\n- Memory allocation is bounded and checked.\n- No unsafe string formatting or injection.\n- ESIL execution is interruptible and sandboxed.\n- No buffer overflows, use-after-free, or code injection.\n- All resources are properly freed.\n- Known issues (like format string in comments) are mitigated.\n\n---\n\n### Final Decision\n(2) NO: No security vulnerability."}
{"idx": 351182, "project": "shapelib", "commit_id": "c75b9281a5b9452d92e1682bdfe6019a13ed819f", "project_url": "https://github.com/OSGeo/shapelib", "commit_url": "https://github.com/OSGeo/shapelib/commit/c75b9281a5b9452d92e1682bdfe6019a13ed819f", "commit_message": "Remove double free() in contrib/shpsrt, issue #39\n\nThis fixes issue #39", "ground_truth": 0, "cwe": ["CWE-415"], "cve": "CVE-2022-0699", "cve_desc": "A double-free condition exists in contrib/shpsort.c of shapelib 1.5.0 and older releases. This issue may allow an attacker to cause a denial of service or have other unspecified impact via control over malloc.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `split` takes a string `arg` and a delimiter `delim`, and splits `arg` into tokens based on `delim`, returning an array of strings (`char **`).\n\n2. It starts by making a copy of `arg` using `dupstr(arg)`. This is safe as long as `dupstr` properly allocates memory and copies the string.\n\n3. It initializes `result` to `NULL` and uses a loop with `strtok` to tokenize the string. `strtok` is used in a standard way: first call with `copy` and `delim`, then subsequent calls with `NULL` to continue parsing.\n\n4. Inside the loop:\n   - It attempts to reallocate `result` to hold one more pointer (`i + 1` elements).\n   - If `realloc` fails and `result` is not NULL, it cleans up all previously allocated strings and the copy, then returns `NULL`. This is good error handling.\n\n5. After the loop, it checks if any tokens were found (`i > 0`). If so, it reallocates `result` to be one element larger (to hold the final `NULL` terminator), and sets `result[i] = NULL`.\n\n6. The function returns `result`, which is a null-terminated array of strings.\n\nNow, let's look for potential vulnerabilities:\n\n- `strtok` modifies the input string in place. However, the function uses `dupstr` to make a copy, so the original `arg` is not modified. This is safe.\n\n- The use of `realloc` with `sizeof *result * (i + 1)` is correct: it resizes the array to hold `i+1` pointers.\n\n- The cleanup logic in case of `realloc` failure is correct: it frees all previously allocated strings and the copy, preventing memory leaks.\n\n- The final `NULL` terminator is properly added, so the returned array is null-terminated.\n\n- There is no buffer overflow because:\n  - `strtok` is used safely on a copy of the input.\n  - Memory is allocated dynamically and only for the number of tokens found.\n  - No fixed-size buffers are used.\n\n- The function does not perform any unsafe string operations like `strcpy`, `strcat`, or `sprintf`.\n\n- The function correctly handles edge cases: empty input, no tokens, and memory allocation failures.\n\n- The `dupstr` function is assumed to be safe (not shown, but standard in such contexts).\n\nConclusion: The function is carefully written with proper memory management, error handling, and safe use of string tokenization. There are no obvious security vulnerabilities such as buffer overflows, use-after-free, or memory leaks.\n\n(2) NO: No security vulnerability."}
{"idx": 224862, "project": "tensorflow", "commit_id": "e952a89b7026b98fe8cbe626514a93ed68b7c510", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e952a89b7026b98fe8cbe626514a93ed68b7c510", "commit_message": "Prevent overflow in sparse dense cwise ops.\n\nPiperOrigin-RevId: 415543171\nChange-Id: I22dab7c41be2121ab5efe5403ca0e2f9b7cb24b8", "ground_truth": 0, "cwe": ["CWE-190"], "cve": "CVE-2022-23567", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementations of `Sparse*Cwise*` ops are vulnerable to integer overflows. These can be used to trigger large allocations (so, OOM based denial of service) or `CHECK`-fails when building new `TensorShape` objects (so, assert failures based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Input Validation and Bounds Checking**:\n   - The code begins by retrieving input tensors (`sp_indices`, `sp_values`, `sp_shape`, `dense`) using `ctx->input(...)`, with proper error handling via `OP_REQUIRES_OK`.\n   - It validates that `sp_indices` is a matrix (`IsMatrix`), `sp_values` and `sp_shape` are vectors (`IsVector`), and checks that the number of elements in `sp_shape` is greater than zero.\n   - It ensures that the first dimension of `values_t` matches that of `indices_t` (i.e., number of non-zero entries), and that the number of dimensions in `sp_shape` matches the second dimension of `indices_t` (which is the number of dimensions of the sparse tensor).\n   - These checks are essential for ensuring that the input data is structurally valid and prevents malformed inputs from causing undefined behavior.\n\n2. **Shape and Broadcasting Validation**:\n   - The code constructs `lhs_dims` from `shape_t` and `rhs_dims` from `dense_t`, then uses `BCast` to perform broadcasting validation.\n   - It checks that `VecGreaterEq(lhs_dims, rhs_dims)` and that `b.IsValid()` \u2014 meaning the broadcasting is valid and the dense tensor can be broadcast to match the sparse tensor\u2019s shape.\n   - This prevents invalid or unexpected broadcasting that could lead to memory corruption or incorrect computation.\n\n3. **Memory Allocation and Output Handling**:\n   - The code allocates output tensor `output_values` with shape `{nnz}` (number of non-zero entries), and a temporary tensor `dense_gathered` of the same size.\n   - Both allocations are done via `ctx->allocate_output` and `ctx->allocate_temp`, which are safe and context-managed operations in TensorFlow\u2019s kernel framework.\n\n4. **Index Bounds Checking in Loop**:\n   - Inside the `switch (ndims)` block, the code iterates over each non-zero index in `indices_mat`.\n   - For each index, it constructs an `idx` array and checks `FastBoundsCheck(idx[d], rhs_ref.dimension(d))` for each dimension `d`.\n   - If any index is out of bounds, `indices_valid` is set to `false`, and the code fails with `OP_REQUIRES(ctx, indices_valid, ...)` \u2014 explicitly rejecting invalid indices.\n   - This is a critical safety check: it ensures that the indices used to access the dense tensor are within bounds, even after broadcasting.\n\n5. **Division-by-Zero Protection**:\n   - If the operation is a division (`op_is_div`), the code checks that `dense_gathered_flat(i) != 0` before performing the division.\n   - This prevents division by zero, which could cause runtime errors or undefined behavior.\n\n6. **Use of Safe Tensor Access**:\n   - The code uses `TensorRef` and `broadcast()` with `Eigen::array` and `coeff()` for safe access to tensor elements.\n   - The use of `internal::SubtleMustCopy` for index values is safe and avoids aliasing issues.\n   - The `flat<T>()` access is safe as long as the tensor is properly allocated and sized \u2014 which it is.\n\n7. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `memcpy`, `sprintf`, or any other function that could lead to buffer overflows.\n   - No dynamic memory allocation with `new` or `malloc` is used directly; all memory is managed via TensorFlow\u2019s context and tensor allocation system.\n   - No string concatenation with user input is present \u2014 all inputs are structured tensors, not strings.\n\n8. **No Injection or Code Execution Risks**:\n   - The code does not interpret any input as code, script, or command.\n   - It does not perform dynamic evaluation, file I/O, or system calls.\n   - The only operations are mathematical and tensor-based, with strict bounds checking.\n\n9. **Conclusion**:\n   - All input validation, bounds checking, and error handling are in place.\n   - The code explicitly checks for out-of-bounds indices and division by zero.\n   - The use of TensorFlow\u2019s safe tensor access and allocation mechanisms ensures memory safety.\n   - There are no known vulnerabilities such as buffer overflows, use-after-free, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 302095, "project": "radare2", "commit_id": "48f0ea79f99174fb0a62cb2354e13496ce5b7c44", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/48f0ea79f99174fb0a62cb2354e13496ce5b7c44", "commit_message": "Fix null deref in ne parser ##crash\n\n* Reported by @cnitlrt via huntr.dev\n* BountyID: d8b6d239-6d7b-4783-b26b-5be848c01aa1/\n* Reproducer: nenull", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-1382", "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of making the radare2 crash, thus affecting the availability of the system.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `r_bin_ne_get_segments` is responsible for extracting segment information from a NE (New Executable) binary format and populating a list of `RBinSection` structures.\n\n2. Input validation is performed at the beginning:\n   - It checks if `bin` or `bin->segment_entries` is NULL, and returns NULL if so. This prevents null pointer dereference.\n\n3. A new list `segments` is created using `r_list_newf(free)`, which means the list will automatically free each element when the list is destroyed. This is safe.\n\n4. The loop iterates over `bin->ne_header->SegCount` entries, which is the number of segment entries in the NE header.\n\n5. For each segment:\n   - A new `RBinSection` is allocated with `R_NEW0`, which initializes memory to zero. If allocation fails, the function returns the partially constructed list (which is safe because the list is not destroyed).\n   - The segment's size, virtual size, bits, data flag, permissions, physical address, and name are populated from the NE header data.\n\n6. The physical address is computed as `(ut64)se->offset * bin->alignment`. This multiplication could potentially overflow if `se->offset` is large and `bin->alignment` is large, but since `se->offset` is a field from a binary header, it is typically constrained by the format. However, no bounds checking is performed on `se->offset` or `bin->alignment` before multiplication.\n\n7. The segment name is constructed using `r_str_newf` with a format string: `%s.%\" PFMT64d`. The first part is either \"MOVEABLE\" or \"FIXED\" based on `se->flags & IS_MOVEABLE`. The second part is the physical address (`bs->paddr`) as a 64-bit integer.\n\n8. The `r_str_newf` function is used to format the string. This function is generally safe if the format string and arguments are controlled, but here the format string is static and the arguments are derived from the binary data. However, `PFMT64d` is a macro for printing `int64_t` values, and `bs->paddr` is a `ut64`, which is `uint64_t`. This is a potential mismatch: `PFMT64d` is for signed 64-bit integers, but `ut64` is unsigned. This could lead to incorrect formatting (e.g., negative numbers displayed as large positive values) if the value is large enough to be interpreted as negative in signed representation. However, this is not a security vulnerability per se, but a potential logic bug.\n\n9. More critically, the `r_str_newf` function is used with user-controlled data (from the binary file) as input. However, since the format string is fixed and the arguments are not user-controlled in a way that can inject format specifiers, there is no risk of format string vulnerability.\n\n10. The function does not perform any bounds checking on `se->offset` or `bin->alignment` before multiplication, which could lead to integer overflow in `bs->paddr`. If `se->offset` is large and `bin->alignment` is large, the multiplication could wrap around, leading to an incorrect or potentially invalid physical address. This could be exploited in a crafted binary to cause memory corruption or unexpected behavior, especially if the resulting `paddr` is used in memory mapping or access.\n\n11. However, the NE format is a legacy Windows format, and `se->offset` and `bin->alignment` are typically small and well-defined. But since the code does not validate these values, it is vulnerable to integer overflow if the input is malicious.\n\n12. The function does not validate that `bin->ne_header->SegCount` is reasonable (e.g., not extremely large), which could lead to a denial-of-service via excessive memory allocation or infinite loop. However, `SegCount` is read from the header, and if it's too large, the loop could consume excessive memory or time.\n\n13. The function does not validate that `bin->alignment` is non-zero, which would cause division by zero if used elsewhere, but here it's used in multiplication. A zero alignment would result in `paddr = 0`, which is not inherently dangerous.\n\n14. The main risk is integer overflow in the multiplication `(ut64)se->offset * bin->alignment`. If this overflows, it could result in a small or negative value, leading to incorrect segment placement. While this may not directly lead to arbitrary code execution, it could be exploited in a crafted binary to cause memory corruption or bypass security checks.\n\n15. However, since `ut64` is 64-bit unsigned, and `se->offset` and `bin->alignment` are likely 16-bit or 32-bit values (as per NE format), the risk of overflow is low in practice. But the code does not prevent it, and in a security context, relying on format constraints is risky.\n\n16. The function does not validate the `se->flags` field for invalid values, but `IS_DATA` and `IS_MOVEABLE` are defined constants, so bitwise operations are safe.\n\n17. The `__translate_perms` function is called with `se->flags`, but we don't see its implementation. If it performs bounds checking or validation, it's safe. Otherwise, it could return invalid permissions, but this is not a direct security vulnerability.\n\n18. The most serious issue is the lack of bounds checking on `se->offset` and `bin->alignment` before multiplication, which could lead to integer overflow and incorrect `paddr`. This is a potential security vulnerability if a malicious binary can cause overflow and trigger memory corruption.\n\n19. Additionally, the loop runs `SegCount` times, which is read from the header. If `SegCount` is extremely large (e.g., millions), it could cause a denial-of-service via excessive memory allocation or CPU usage. The code does not validate that `SegCount` is within a reasonable range.\n\n20. Therefore, the code lacks input validation on critical fields (`SegCount`, `se->offset`, `bin->alignment`) that could be exploited to cause integer overflow or denial-of-service.\n\n(1) YES: A security vulnerability detected."}
{"idx": 336484, "project": "qemu", "commit_id": "9302e863aa8baa5d932fc078967050c055fa1a7f", "project_url": "https://github.com/bonzini/qemu", "commit_url": "http://git.qemu.org/?p=qemu.git;a=commit;h=9302e863aa8baa5d932fc078967050c055fa1a7f", "commit_message": "parallels: Sanity check for s->tracks (CVE-2014-0142)\n\nThis avoids a possible division by zero.\n\nConvert s->tracks to unsigned as well because it feels better than\nsurviving just because the results of calculations with s->tracks are\nconverted to unsigned anyway.\n\nSigned-off-by: Kevin Wolf <kwolf@redhat.com>\nReviewed-by: Max Reitz <mreitz@redhat.com>\nSigned-off-by: Stefan Hajnoczi <stefanha@redhat.com>", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2014-0142", "cve_desc": "QEMU, possibly before 2.0.0, allows local users to cause a denial of service (divide-by-zero error and crash) via a zero value in the (1) tracks field to the seek_to_sector function in block/parallels.c or (2) extent_size field in the bochs function in block/bochs.c.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `parallels_open` is responsible for opening a Parallels disk image and initializing the state.\n\n2. The code reads the Parallels header from the file using `bdrv_pread` at offset 0 into a `struct parallels_header ph`. This is a standard way to read metadata.\n\n3. It checks the magic bytes and version to ensure the image is in the correct format. If not, it returns an error. This is a good validation step.\n\n4. The total number of sectors is read from the header and stored in `bs->total_sectors`. This value is derived from `ph.nb_sectors`, which is converted from little-endian using `le32_to_cpu`.\n\n5. The code reads the number of tracks (`s->tracks`) from the header and validates that it is not zero. If zero, it returns an error. This prevents division by zero or invalid data structures.\n\n6. The catalog size (`s->catalog_size`) is read from `ph.catalog_entries` and converted from little-endian. Then it checks if `s->catalog_size > INT_MAX / 4`. This is a critical check: it prevents integer overflow when allocating memory for `s->catalog_bitmap` (which is `s->catalog_size * 4` bytes). This is a defensive programming practice to avoid heap overflow due to integer overflow.\n\n7. Memory is allocated using `g_malloc(s->catalog_size * 4)`. The check above ensures that this multiplication won't overflow, so the allocation is safe.\n\n8. The catalog bitmap is then read from the file at offset 64 using `bdrv_pread`. The size is `s->catalog_size * 4`, which is safe due to the prior bounds check.\n\n9. The code loops through the catalog bitmap and converts each 32-bit value from little-endian to CPU endianness using `le32_to_cpus`. This is correct and safe as long as the buffer is properly allocated and the size is valid.\n\n10. The mutex is initialized with `qemu_co_mutex_init(&s->lock)`, which is safe.\n\n11. In the `fail` label, the code frees `s->catalog_bitmap` before returning, preventing a memory leak.\n\n12. The only potential concern is whether the `catalog_size` value from the file could be maliciously large. However, the check `if (s->catalog_size > INT_MAX / 4)` ensures that the multiplication `s->catalog_size * 4` will not overflow, and thus the allocation is safe. This is a well-known mitigation for integer overflow in memory allocation.\n\n13. There is no use of unsafe string functions, no buffer overflows, no format string vulnerabilities, and no direct user input manipulation without validation.\n\n14. All critical data from the file is validated before being used in memory allocation or processing.\n\nConclusion: The code includes proper bounds checking, safe memory allocation, and error handling. The integer overflow protection for the catalog size is correctly implemented.\n\n(2) NO: No security vulnerability."}
{"idx": 452377, "project": "vim", "commit_id": "4e889f98e95ac05d7c8bd3ee933ab4d47820fdfa", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/4e889f98e95ac05d7c8bd3ee933ab4d47820fdfa", "commit_message": "patch 8.2.4436: crash with weird 'vartabstop' value\n\nProblem:    Crash with weird 'vartabstop' value.\nSolution:   Check for running into the end of the line.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-0714", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.4436.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - The function `change_indent` is responsible for changing the indentation of a line in a text editor (likely Vim or a derivative).\n   - It handles various modes: Replace (REPLACE), Visual Replace (VREPLACE), Insert, and Indent operations.\n   - It manipulates cursor position, line content, and the replace stack (used in Replace mode).\n\n2. **Input Parameters**:\n   - `type`: Determines the type of indentation change (set, increase, decrease).\n   - `amount`: The amount of indentation to change.\n   - `round`: Whether to round to a multiple of `shiftwidth`.\n   - `replaced`: The character that was replaced (used in Replace mode).\n   - `call_changed_bytes`: Whether to call `changed_bytes()` after changes.\n\n3. **Memory Handling**:\n   - `vim_strsave(ml_get_curline())` is used to save the original line in VREPLACE mode. This function allocates memory for a copy of the current line.\n   - `alloc(i + 1)` is used to allocate space for inserting spaces during cursor positioning.\n   - `vim_free(ptr)` is used to free allocated memory, which is good practice.\n\n4. **Potential Vulnerabilities**:\n   - **Buffer Overflows**: The code uses `ml_get_curline()` to get the current line, which returns a `char_u*`. This is used in `vim_strsave()` and `ins_bytes()`, which are safe if the string is null-terminated. However, `ml_get_curline()` is assumed to return a valid null-terminated string, which is typical in Vim.\n   - **Use of `ins_bytes()` and `ins_str()`**: These functions insert text into the buffer. They are part of Vim\u2019s internal API and are designed to handle arbitrary strings safely, including those with embedded NULs (though NULs are not valid in text content). However, `ins_bytes()` is used with `new_line` which is truncated at `curwin->w_cursor.col` with `new_line[curwin->w_cursor.col] = NUL`. This is safe because it null-terminates the string before insertion.\n   - **Replace Stack Handling**:\n     - In `REPLACE_NORMAL(State)`, the code adjusts the replace stack using `replace_join()` and `replace_push()`. These functions are part of Vim\u2019s internal replace stack mechanism and are designed to handle stack operations safely.\n     - The loop conditions are based on `start_col` and `curwin->w_cursor.col`, which are `int` and `colnr_T` (typically `int` or `long`). No arithmetic overflow is evident.\n   - **VREPLACE Mode**:\n     - The code saves the original line with `vim_strsave()`, then saves the new line with `vim_strsave()`. Both are freed with `vim_free()`, so no memory leak.\n     - The line is modified by `ml_replace()` and `ins_bytes()`, which are safe functions.\n     - The use of `backspace_until_column(0)` is safe as it removes characters from the cursor to the start of the line.\n   - **No User Input Directly**:\n     - The function does not directly accept user input. All inputs are from internal state (`curwin`, `State`, `Insstart`, etc.), which are controlled by the editor\u2019s internal logic.\n     - The only external input is through the function parameters, which are integers and not strings that could be exploited.\n\n5. **Security Considerations**:\n   - No use of unsafe string functions like `strcpy`, `strcat`, `sprintf`, etc.\n   - No direct manipulation of raw buffers without bounds checking.\n   - All memory allocation and deallocation is balanced (`alloc`/`vim_free`, `vim_strsave`/`vim_free`).\n   - The code handles edge cases (e.g., `orig_line == NULL`, `new_line == NULL`) gracefully.\n   - The replace stack operations are bounded by the cursor position and do not allow arbitrary stack growth.\n\n6. **Conclusion**:\n   - The code is part of a well-established text editor (Vim) and follows secure coding practices.\n   - All operations are within bounds, memory is properly managed, and no direct user-controlled data is used in unsafe ways.\n   - There are no obvious buffer overflows, use-after-free, or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 261220, "project": "wolfMQTT", "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2", "project_url": "https://github.com/wolfSSL/wolfMQTT", "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2", "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2021-45936", "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function begins with a check for null pointers: `if (client == NULL || packet_obj == NULL) return MQTT_CODE_ERROR_BAD_ARG;`. This is good practice to prevent null pointer dereferences.\n\n2. **Use of `MqttMsgStat* mms_stat = (MqttMsgStat*)packet_obj;`**:\n   - The `packet_obj` is cast to `MqttMsgStat*`, which is assumed to be a structure that contains a state field (`*mms_stat`). This is a common pattern in state machines.\n   - The function uses `*mms_stat` to control the flow via a `switch` statement. The state is initialized to `MQTT_MSG_BEGIN` at the start of the function (via `*mms_stat = MQTT_MSG_BEGIN;` in the `case MQTT_MSG_BEGIN` block).\n   - The state is updated during execution: `*mms_stat = MQTT_MSG_WAIT`, `*mms_stat = MQTT_MSG_READ`, etc.\n   - The state is reset to `MQTT_MSG_BEGIN` at the end if `rc >= 0` and not `MQTT_CODE_CONTINUE`.\n\n3. **Thread Safety and Locking**:\n   - The code uses `#ifdef WOLFMQTT_MULTITHREAD` to conditionally compile mutex locking via `wm_SemLock` and `wm_SemUnlock`.\n   - The `lockRecv` mutex is acquired before reading from the socket and released after.\n   - The `lockClient` mutex is used to protect access to the response list (`pendResp`), which is critical in a multithreaded environment.\n   - The use of `wm_SemLock` and `wm_SemUnlock` is consistent and appears to prevent race conditions when accessing shared data structures like `client->resp_list`.\n\n4. **Packet Handling and State Machine**:\n   - The function implements a state machine to wait for a specific MQTT packet type and ID.\n   - It reads packets via `MqttPacket_Read`, decodes them via `MqttClient_DecodePacket`, and then checks if the received packet matches the expected type and ID.\n   - The matching logic is:\n     ```c\n     if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n          wait_type == packet_type ||\n          (MqttIsPubRespPacket(packet_type) &&\n           MqttIsPubRespPacket(wait_type))) &&\n         (wait_packet_id == 0 || wait_packet_id == packet_id))\n     ```\n     This is correct: it allows for any packet type (`ANY`), exact type match, or special handling for publish response packets (e.g., PUBACK, PUBREC, etc.).\n   - The `waitMatchFound` flag is set only if the packet matches the expected criteria.\n\n5. **Use of `goto wait_again`**:\n   - The function loops via `goto wait_again` if `waitMatchFound` is false, meaning the received packet did not match the expected type or ID.\n   - This is a common pattern in asynchronous or non-blocking I/O loops.\n   - The loop is safe because:\n     - The state is reset to `MQTT_MSG_BEGIN` at the start of each iteration (via `*mms_stat = MQTT_MSG_BEGIN;` in the `case MQTT_MSG_BEGIN` block).\n     - The `timeout_ms` parameter is passed to `MqttPacket_Read`, which should handle timeouts properly (though we don\u2019t see the implementation here, it\u2019s assumed to be correct).\n     - The function does not re-enter the `case MQTT_MSG_WAIT` block without re-initializing the state.\n\n6. **Memory Safety**:\n   - The function uses `client->rx_buf` and `client->rx_buf_len` for reading packets. These are assumed to be properly allocated and sized by the caller.\n   - The `MqttClient_DecodePacket` function is called with `client->rx_buf` and `client->packet.buf_len`, which is set to the return value of `MqttPacket_Read`. This is safe as long as `MqttPacket_Read` does not write beyond the buffer.\n   - There is no direct use of unsafe string functions (like `strcpy`, `strcat`, etc.) or buffer overflows.\n\n7. **No Use of User Input in Unsafe Ways**:\n   - The function does not directly process user input in a way that could lead to injection (e.g., no string concatenation into SQL or shell commands).\n   - The only input is `wait_type`, `wait_packet_id`, and `timeout_ms`, which are used in comparisons and are not used to construct dynamic strings or commands.\n\n8. **No Known Buffer Overflows or Use-After-Free**:\n   - The code does not manipulate raw buffers without bounds checking.\n   - The `pendResp` structure is managed via `MqttClient_RespList_Find` and `MqttClient_RespList_Remove`, which are assumed to be safe.\n   - The `packet_obj` is passed to `MqttClient_HandlePacket`, but it is not modified in a way that could cause memory corruption.\n\n9. **Error Handling**:\n   - The function handles errors from `wm_SemLock`, `MqttPacket_Read`, and `MqttClient_DecodePacket` appropriately.\n   - It returns early on failure and cleans up locks.\n\n10. **No Obvious Security Flaws**:\n    - No SQL injection, XSS, command injection, or buffer overflow.\n    - No use of unsafe functions.\n    - Proper locking in multithreaded context.\n    - Correct state machine logic.\n\nConclusion: The code is well-structured, uses proper input validation, thread-safe practices, and avoids common security pitfalls. There are no detectable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 219912, "project": "gpac", "commit_id": "ad18ece95fa064efc0995c4ab2c985f77fb166ec", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/ad18ece95fa064efc0995c4ab2c985f77fb166ec", "commit_message": "fixed #1904", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2021-40576", "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the gf_isom_get_payt_count function in hint_track.c, which allows attackers to cause a denial of service.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `GetHintFormat` takes a pointer to a `GF_TrackBox` structure (`trak`) and attempts to retrieve the format (subType) of a hint media header box (`GF_HintMediaHeaderBox`).\n\n2. The function first checks if `hmhd` is null or if its type is not `GF_ISOM_BOX_TYPE_HMHD`. If either condition is true, it returns 0. This is a valid safety check to prevent dereferencing invalid or incorrect box types.\n\n3. Then, there is a second check: `if (!hmhd || !hmhd->subType)`. This condition is problematic because:\n   - The first part (`!hmhd`) is redundant since we already checked `hmhd` in the previous condition.\n   - The second part (`!hmhd->subType`) checks if the `subType` field is null or zero.\n   - If `hmhd` is valid but `subType` is missing, the code attempts to retrieve the first box from `trak->Media->information->sampleTable->SampleDescription->child_boxes`.\n\n4. The code casts the first child box to `GF_Box *` and assigns it to `a`. Then it checks if `a` is non-null. If `a` is null, it returns `0` (from `a ? a->type : 0`). If `a` is not null, it assigns `a->type` to `hmhd->subType`.\n\n5. However, there is a critical flaw in the logic:\n   - The function checks `!hmhd` again inside the second block, but `hmhd` was already validated in the first condition. So this check is redundant and potentially misleading.\n   - More importantly, if `hmhd` is valid but `subType` is missing, the code assigns `a->type` to `hmhd->subType`. But `a` is a `GF_Box *` from `child_boxes`, which may be a `GF_SampleDescriptionBox` or another type. The `type` field of a generic `GF_Box` is a 32-bit value (u32), but it's not guaranteed to be a valid hint format identifier.\n   - There is no validation that `a` is actually a valid sample description box or that its `type` field is a valid format (e.g., a known codec type). This could lead to a use of an invalid or unexpected `subType` value.\n\n6. Furthermore, the function returns `hmhd->subType` without validating that the assigned `subType` is valid or safe. If `a->type` is an arbitrary value (e.g., from malformed or malicious input), this could propagate an invalid or dangerous value.\n\n7. The core issue is that the code assumes that the first `child_box` in `SampleDescription` is a valid source for `subType`, but it does not validate the type of that box or ensure that `a->type` is a valid format. This could lead to incorrect behavior or potential exploitation if the `type` field is used in a context where it controls behavior (e.g., format-specific processing).\n\n8. While this may not be a classic buffer overflow or memory corruption vulnerability, it is a logic flaw that could lead to incorrect or unsafe behavior based on unvalidated input. In security-sensitive contexts like media parsing, such assumptions can be exploited to cause denial of service, incorrect processing, or potentially trigger other vulnerabilities.\n\nTherefore, this code contains a security vulnerability due to unvalidated use of a box type from an untrusted source.\n\n(1) YES: A security vulnerability detected."}
{"idx": 440872, "project": "xserver", "commit_id": "da15c7413916f754708c62c2089265528cd661e2", "project_url": "http://gitweb.freedesktop.org/?p=xorg/xserver", "commit_url": "https://gitlab.freedesktop.org/xorg/xserver/commit/da15c7413916f754708c62c2089265528cd661e2", "commit_message": "LogFilePrep: add a comment to the unsafe format string.\n\nCVE-2018-14665 also made it possible to exploit this to access\nmemory. With -logfile forbidden when running with elevated privileges\nthis is no longer an issue.\n\nSigned-off-by: Matthieu Herrb <matthieu@herrb.eu>\nReviewed-by: Adam Jackson <ajax@redhat.com>\n(cherry picked from commit 248d164eae27f1f310266d78e52f13f64362f81e)", "ground_truth": 0, "cwe": ["CWE-863"], "cve": "CVE-2018-14665", "cve_desc": "A flaw was found in xorg-x11-server before 1.20.3. An incorrect permission check for -modulepath and -logfile options when starting Xorg. X server allows unprivileged users with the ability to log in to the system via physical console to escalate their privileges and run arbitrary code under root privileges.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `LogFilePrep` takes three parameters: `fname` (format string for log file name), `backup` (format string for backup file name), and `idstring` (a string used to format the file names).\n\n2. The function uses `asprintf(&logFileName, fname, idstring)` to dynamically allocate a log file name based on `fname` and `idstring`. This means the format string `fname` is controlled by the caller, and `idstring` is used as a variable argument.\n\n3. The key concern is that `fname` is user-controlled (as noted in the comment: \"the format string below is controlled by the user\"). If `fname` contains format specifiers (like `%s`, `%d`, etc.), and `idstring` is user-controlled, then this could lead to format string vulnerabilities if not properly handled.\n\n4. However, `asprintf` is used safely here: it takes a format string and arguments, and it's not using `printf`-style functions that are vulnerable to format string attacks. The `asprintf` function is safe as long as the format string is not user-controlled in a way that allows arbitrary format specifiers to be injected.\n\n5. But the comment explicitly says: \"the format string below is controlled by the user\", which implies that `fname` is not trusted. If `fname` contains format specifiers (e.g., `%s`, `%n`, etc.), and `idstring` is passed as an argument, then an attacker could potentially exploit this.\n\n6. For example, if `fname` is set to `%s`, and `idstring` is set to `test`, then `asprintf` will work fine. But if `fname` is set to `%n`, then `asprintf` will write the number of characters written to the address pointed to by `idstring`, which is undefined behavior and could lead to memory corruption or information disclosure.\n\n7. More critically, if `fname` contains format specifiers like `%s`, and `idstring` is not properly validated, an attacker could inject format specifiers that cause unintended behavior. However, `asprintf` does not interpret format specifiers in the same way as `printf` when used with `asprintf` \u2014 it only interprets them if they are present in the format string.\n\n8. The real danger is that if `fname` is user-controlled and contains format specifiers, and `idstring` is passed as a single argument, then `asprintf` will interpret the format string and use `idstring` as the argument. If `fname` contains `%n`, then `asprintf` will write the number of characters written to the address of `idstring`, which is a pointer to a string \u2014 this could lead to a buffer overflow or memory corruption.\n\n9. However, `asprintf` is not vulnerable to format string attacks in the same way as `printf` because it doesn't use variadic arguments in a way that allows arbitrary memory access. But if `fname` contains `%n`, and `idstring` is a pointer to a string, then `asprintf` will try to write the number of characters to the address of `idstring`, which is not a valid location for writing an integer \u2014 this could cause a crash or undefined behavior.\n\n10. The function also uses `asprintf` for `suffix` and `oldLog`, using `backup` as the format string and `idstring` as the argument. The same risk applies: if `backup` is user-controlled and contains format specifiers, this could lead to format string vulnerabilities.\n\n11. The comment says: \"this code should never be called with elevated privileges\" \u2014 this suggests that the function is intended to be used in a non-privileged context, but it does not mitigate the risk of format string attacks.\n\n12. Therefore, the use of `asprintf` with user-controlled format strings (`fname` and `backup`) is a security vulnerability because it allows an attacker to inject format specifiers that can lead to memory corruption, crashes, or information disclosure.\n\n(1) YES: A security vulnerability detected."}
{"idx": 416366, "project": "vim", "commit_id": "1c3dd8ddcba63c1af5112e567215b3cec2de11d0", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/1c3dd8ddcba63c1af5112e567215b3cec2de11d0", "commit_message": "patch 9.0.0490: using freed memory with cmdwin and BufEnter autocmd\n\nProblem:    Using freed memory with cmdwin and BufEnter autocmd.\nSolution:   Make sure pointer to b_p_iminsert is still valid.", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-3235", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0490.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `getcmdline_int` is part of the Vim editor's command-line input handling system. It is responsible for:\n- Reading user input from the command line (e.g., `:`, `/`, `?`, `@`).\n- Handling keypresses, including special keys (like Ctrl-C, ESC, arrow keys).\n- Supporting features like:\n  - Command history.\n  - Tab completion.\n  - Abbreviations.\n  - Input method support (e.g., for non-Latin scripts).\n  - Wildcard expansion.\n  - Autocommands (CmdlineEnter, CmdlineChanged, CmdlineLeave).\n  - Mouse and GUI interactions.\n\nThis function is central to user interaction with Vim and processes raw input from the user.\n\n---\n\n### Step 2: Look for potential security vulnerabilities\n\nWe need to check for common vulnerabilities such as:\n- Buffer overflows.\n- Use-after-free.\n- Improper input validation.\n- Code injection (e.g., command injection).\n- Memory corruption.\n- Unsafe string handling.\n\n#### A. Buffer handling\n\n- The function uses `ccline.cmdbuff` to store the command line input.\n- It checks `ccline.cmdlen` and `ccline.cmdpos` to manage the current position.\n- The function uses `put_on_cmdline()` to insert characters into the buffer.\n- There is no direct use of `strcpy`, `strcat`, or `sprintf` that could overflow.\n- The function uses `(*mb_char2bytes)(c, IObuff)` for multibyte characters, which is safe if the buffer size is respected.\n- The `IObuff` is used for temporary storage and is not exposed to user input beyond safe limits.\n\n\u2705 No buffer overflow detected.\n\n#### B. Input validation and sanitization\n\n- The function processes input via `safe_vgetc()`, which is designed to safely read input and handle special keys.\n- It checks for special keys (e.g., `Ctrl_C`, `ESC`, `K_BS`, `K_DEL`) and handles them appropriately.\n- It uses `IS_SPECIAL(c)` to distinguish between special and regular characters.\n- It avoids processing certain keys (e.g., `K_IGNORE`, `K_NOP`) and ignores mouse events unless explicitly allowed.\n- It uses `mod_mask` to track modifier keys (e.g., Shift, Ctrl), but does not use them in unsafe ways.\n\n\u2705 Input is validated and sanitized.\n\n#### C. Command injection or execution\n\n- The function does **not** directly execute the command line string.\n- It only builds the command line buffer (`ccline.cmdbuff`) and later passes it to `do_cmdline()` (not shown here).\n- The actual execution happens elsewhere, and the command is not evaluated here.\n- The function does not use `system()`, `exec()`, or `eval()` on user input.\n- It does not concatenate user input into shell commands.\n\n\u2705 No command injection.\n\n#### D. Memory safety\n\n- The function uses `VIM_CLEAR(lookfor)` to free memory when appropriate.\n- It uses `ExpandInit(&xpc)` and `ExpandCleanup(&xpc)` to manage expansion state.\n- It saves and restores `ccline` state when recursive calls occur (`save_cmdline`, `restore_cmdline`).\n- It uses `--depth` to prevent infinite recursion (max 50 levels).\n- It checks for `ccline.cmdbuff != NULL` before saving/restoring.\n\n\u2705 Memory management is safe.\n\n#### E. Use of unsafe functions\n\n- No use of `strcpy`, `strcat`, `gets`, `sprintf`, etc.\n- Uses `vim_strsave`, `vim_free`, `vim_iswordc`, `mb_char2bytes`, `mb_ptr2len`, etc. \u2014 all safe and well-known Vim internal functions.\n\n\u2705 No unsafe functions.\n\n#### F. Special features (e.g., digraphs, input method, clipboard)\n\n- `do_digraph()` is used safely \u2014 it reads input and returns a character.\n- `cmdline_paste()` is used for clipboard input, but it is restricted to GUI or clipboard-enabled contexts.\n- `cmdline_insert_reg()` handles register insertion safely.\n- `bracketed_paste()` is used for secure paste handling (via bracketed paste mode).\n\n\u2705 These features are implemented safely.\n\n#### G. Recursive call protection\n\n- `depth` is incremented at the start and decremented at the end.\n- If `depth == 50`, it emits an error and exits: `emsg(_(e_command_too_recursive));`.\n- This prevents stack overflow from infinite recursion.\n\n\u2705 Safe recursion handling.\n\n#### H. Autocommands and side effects\n\n- The function triggers autocommands (`CmdlineEnter`, `CmdlineChanged`, `CmdlineLeave`).\n- However, these are part of Vim\u2019s normal behavior and are not triggered with untrusted input.\n- The autocommands are not executed with user input directly \u2014 they are just notifications.\n\n\u2705 Safe use of autocommands.\n\n---\n\n### Step 3: Conclusion\n\nAfter a thorough analysis:\n- The function handles user input safely.\n- It uses proper bounds checking, memory management, and input validation.\n- It avoids dangerous functions and does not expose the user to command injection or buffer overflow.\n- All features (completion, history, input methods, mouse, clipboard) are implemented with security in mind.\n\nThere is **no evidence of a security vulnerability** in this code.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 463476, "project": "linux", "commit_id": "82e31755e55fbcea6a9dfaae5fe4860ade17cbc0", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/82e31755e55fbcea6a9dfaae5fe4860ade17cbc0", "commit_message": "ax25: Fix UAF bugs in ax25 timers\n\nThere are race conditions that may lead to UAF bugs in\nax25_heartbeat_expiry(), ax25_t1timer_expiry(), ax25_t2timer_expiry(),\nax25_t3timer_expiry() and ax25_idletimer_expiry(), when we call\nax25_release() to deallocate ax25_dev.\n\nOne of the UAF bugs caused by ax25_release() is shown below:\n\n      (Thread 1)                    |      (Thread 2)\nax25_dev_device_up() //(1)          |\n...                                 | ax25_kill_by_device()\nax25_bind()          //(2)          |\nax25_connect()                      | ...\n ax25_std_establish_data_link()     |\n  ax25_start_t1timer()              | ax25_dev_device_down() //(3)\n   mod_timer(&ax25->t1timer,..)     |\n                                    | ax25_release()\n   (wait a time)                    |  ...\n                                    |  ax25_dev_put(ax25_dev) //(4)FREE\n   ax25_t1timer_expiry()            |\n    ax25->ax25_dev->values[..] //USE|  ...\n     ...                            |\n\nWe increase the refcount of ax25_dev in position (1) and (2), and\ndecrease the refcount of ax25_dev in position (3) and (4).\nThe ax25_dev will be freed in position (4) and be used in\nax25_t1timer_expiry().\n\nThe fail log is shown below:\n==============================================================\n\n[  106.116942] BUG: KASAN: use-after-free in ax25_t1timer_expiry+0x1c/0x60\n[  106.116942] Read of size 8 at addr ffff88800bda9028 by task swapper/0/0\n[  106.116942] CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.17.0-06123-g0905eec574\n[  106.116942] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-14\n[  106.116942] Call Trace:\n...\n[  106.116942]  ax25_t1timer_expiry+0x1c/0x60\n[  106.116942]  call_timer_fn+0x122/0x3d0\n[  106.116942]  __run_timers.part.0+0x3f6/0x520\n[  106.116942]  run_timer_softirq+0x4f/0xb0\n[  106.116942]  __do_softirq+0x1c2/0x651\n...\n\nThis patch adds del_timer_sync() in ax25_release(), which could ensure\nthat all timers stop before we deallocate ax25_dev.\n\nSigned-off-by: Duoming Zhou <duoming@zju.edu.cn>\nSigned-off-by: Paolo Abeni <pabeni@redhat.com>", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-1205", "cve_desc": "A NULL pointer dereference flaw was found in the Linux kernel\u2019s Amateur Radio AX.25 protocol functionality in the way a user connects with the protocol. This flaw allows a local user to crash the system.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `ax25_release` is a socket release handler for an AX.25 (Amateur X.25) network protocol implementation in the Linux kernel. It is responsible for cleaning up socket resources when a socket is closed.\n\n2. The function starts by retrieving the socket structure (`sk`) and casting it to an `ax25_cb` structure (`ax25`) and an `ax25_dev` structure (`ax25_dev`). These are protocol-specific control blocks and device structures.\n\n3. The function checks if `sk` is NULL. If so, it returns 0 immediately. This is safe and prevents null pointer dereference.\n\n4. It calls `sock_hold(sk)` to increment the socket reference count, then `lock_sock(sk)` to acquire the socket lock. This ensures exclusive access to the socket during cleanup.\n\n5. `sock_orphan(sk)` is called, which removes the socket from any process's file descriptor table and marks it as orphaned.\n\n6. The function then checks `sk->sk_type == SOCK_SEQPACKET`. This is a valid check for the type of socket being released.\n\n7. Depending on the state of the AX.25 connection (`ax25->state`), different cleanup actions are taken:\n   - For `AX25_STATE_0`: It disconnects the socket and destroys it.\n   - For `AX25_STATE_1` and `AX25_STATE_2`: It sends a DISC frame, disconnects, and conditionally destroys the socket if not already destroyed.\n   - For `AX25_STATE_3` and `AX25_STATE_4`: It clears queues, stops timers, sends a DISC frame, resets timers, transitions to `AX25_STATE_2`, and marks the socket as destroyed.\n   - For other states: No action is taken.\n\n8. For non-SEQPACKET sockets, it simply sets the socket state to TCP_CLOSE, marks it for shutdown, and destroys the socket.\n\n9. After handling the state-specific logic, the function checks if `ax25_dev` is non-NULL:\n   - It calls `del_timer_sync()` on multiple timers (`timer`, `t1timer`, `t2timer`, `t3timer`, `idletimer`). This is safe because `del_timer_sync()` is designed to wait for the timer to complete if it's running, preventing use-after-free.\n   - It calls `dev_put_track()` to release a reference to the network device, using a tracker to ensure proper cleanup.\n   - It calls `ax25_dev_put(ax25_dev)` to release the device reference.\n\n10. Finally, it sets `sock->sk = NULL`, releases the socket lock with `release_sock(sk)`, and decrements the socket reference with `sock_put(sk)`.\n\nKey security considerations:\n- All access to `ax25`, `ax25_dev`, and `sk` is protected by `lock_sock(sk)` and `sock_hold(sk)`, ensuring that the socket is not freed while being accessed.\n- The use of `del_timer_sync()` is correct and safe for kernel timers; it prevents race conditions and use-after-free.\n- The `dev_put_track()` and `ax25_dev_put()` calls are properly paired and handle reference counting.\n- The socket is properly orphaned and destroyed, with no dangling pointers.\n- There are no buffer overflows, use-after-free, or improper input validation issues.\n- The code follows kernel socket cleanup patterns correctly.\n\nNo obvious security vulnerabilities such as use-after-free, race conditions, or improper memory management are present.\n\n(2) NO: No security vulnerability."}
{"idx": 326914, "project": "linux", "commit_id": "e6a21a14106d9718aa4f8e115b1e474888eeba44", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=v5.19-rc2&id=e6a21a14106d9718aa4f8e115b1e474888eeba44", "commit_message": "media: vidtv: Check for null return of vzalloc\n\nAs the possible failure of the vzalloc(), e->encoder_buf might be NULL.\nTherefore, it should be better to check it in order\nto guarantee the success of the initialization.\nIf fails, we need to free not only 'e' but also 'e->name'.\nAlso, if the allocation for ctx fails, we need to free 'e->encoder_buf'\nelse.\n\nFixes: f90cf6079bf6 (\"media: vidtv: add a bridge driver\")\nSigned-off-by: Jiasheng Jiang <jiasheng@iscas.ac.cn>\nSigned-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>\nSigned-off-by: Mauro Carvalho Chehab <mchehab@kernel.org>", "ground_truth": 0, "cwe": ["CWE-476"], "cve": "CVE-2022-3078", "cve_desc": "An issue was discovered in the Linux kernel through 5.16-rc6. There is a lack of check after calling vzalloc() and lack of free after allocation in drivers/media/test-drivers/vidtv/vidtv_s302m.c.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `vidtv_s302m_encoder_init` initializes a video encoder context (`struct vidtv_encoder`) and its private context (`struct vidtv_s302m_ctx`).\n\n2. Memory is allocated for the encoder (`e`) using `kzalloc`, and if allocation fails, the function returns `NULL` \u2014 this is safe.\n\n3. The `e->name` is assigned using `kstrdup` only if `args.name` is non-NULL. This is safe because `kstrdup` allocates memory and copies the string, and the caller is responsible for ensuring `args.name` is valid.\n\n4. The encoder buffer (`e->encoder_buf`) is allocated using `vzalloc` with a fixed size `VIDTV_S302M_BUF_SZ`. This is a zero-initialized allocation, which is safe and appropriate for a buffer.\n\n5. The function sets `e->encoder_buf_sz` and `e->encoder_buf_offset` correctly. No buffer overflow is possible here because the size is fixed and used consistently.\n\n6. The source buffer (`e->src_buf`) is assigned from `args.src_buf` only if provided, and its size is set accordingly. There is no copying of data from `args.src_buf` into a fixed-size buffer \u2014 only a pointer is stored. This avoids buffer overflow risks.\n\n7. The function sets `e->ctx` to a newly allocated `struct vidtv_s302m_ctx` using `kzalloc`. The size is `sizeof(struct vidtv_s302m_ctx)`, which is fixed and known. No overflow occurs here.\n\n8. The function assigns function pointers (`encode`, `clear`, `destroy`) to internal functions \u2014 this is safe and standard.\n\n9. The `es_pid` and `stream_id` are set using `cpu_to_be16`, which is safe for 16-bit values.\n\n10. The `sync`, `sampling_rate_hz`, and `last_sample_cb` are assigned directly from `args`. These are either constants or function pointers, so no memory corruption is possible.\n\n11. The `args.head` manipulation is used to link the new encoder into a list. The code traverses the list until the last node and appends `e`. However, this is only done if `args.head` is non-NULL. There is no validation of `args.head` itself \u2014 but the function does not dereference `args.head` beyond checking `args.head->next`. If `args.head` is NULL, the `if (args.head)` block is skipped, so no dereference occurs. This is safe.\n\n12. The `destroy` function pointer is set correctly.\n\n13. Error paths (`out_kfree_buf`, `out_kfree_e`) properly free allocated memory in reverse order, preventing memory leaks.\n\n14. No user-controlled data is copied into fixed-size buffers without bounds checking \u2014 all data is either stored as pointers or used in safe operations.\n\n15. No use of unsafe string functions (like `strcpy`, `strcat`, etc.), no format string vulnerabilities, no integer overflows in buffer sizing (since sizes are fixed or derived from known safe values).\n\nConclusion: The code performs proper memory allocation, error handling, and avoids unsafe operations. All data handling is safe, and there are no obvious buffer overflows, use-after-free, or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 221123, "project": "tensorflow", "commit_id": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b", "commit_message": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-23584", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Input Validation and Initialization**:\n   - The function `DecodePngV2` takes a `StringPiece input` representing the PNG data.\n   - It initializes a `png::DecodeContext` using `png::CommonInitDecode`, which performs basic validation of the PNG header and structure. This is a good first step in preventing malformed input from causing issues.\n\n2. **Size Validation**:\n   - The code extracts `width` and `height` from the decode context and casts them to `int`.\n   - It then checks for potential integer overflow and size limits:\n     - `width` and `height` must be positive and less than `1 << 27` (134,217,728), which is a very large but reasonable upper bound.\n     - The total pixel count (`width * height`) is checked to be less than `1 << 29` (~536 million pixels).\n   - These checks are crucial to prevent integer overflow and excessive memory allocation, which could lead to denial-of-service (DoS) or memory exhaustion attacks.\n\n3. **Memory Allocation**:\n   - The function allocates an output tensor using `context->allocate_output`, with shape depending on `op_type_`.\n   - The allocation is based on validated `width`, `height`, and `channels`, so the size is bounded by the earlier checks.\n   - For `DecodeBmp` and `DecodeAndCropJpeg`, the code explicitly rejects PNG input with an error \u2014 this is correct behavior since those ops are not meant to handle PNGs.\n\n4. **Data Decoding**:\n   - The function calls `png::CommonFinishDecode` to decode the image data into the allocated output buffer.\n   - For `DT_UINT8` and `DT_UINT16`, it directly decodes into the output tensor.\n   - For `DT_FLOAT`, it:\n     - Allocates a temporary `uint16[]` buffer (size: `height * width * channels`).\n     - Decodes into this buffer (using `CommonFinishDecode`).\n     - Converts the `uint16` data to `float` using Eigen's device and casting.\n   - The temporary buffer is managed via `std::unique_ptr`, ensuring no memory leaks.\n\n5. **Security Considerations**:\n   - The `width` and `height` are validated against large upper bounds (`1 << 27`) to prevent integer overflow in subsequent calculations.\n   - The total size (`width * height`) is checked against `1 << 29`, which is a safe limit for most use cases and prevents excessive memory allocation.\n   - The use of `static_cast<int64_t>` for intermediate calculations avoids overflow during multiplication.\n   - The `CommonFinishDecode` function is assumed to be safe and bounds-checked, as it's part of a well-established PNG decoding library (likely libpng wrapper).\n   - The code does not perform any unsafe memory operations (e.g., `strcpy`, `memcpy` without bounds) or direct user input manipulation.\n   - The `StringPiece` input is not directly used in unsafe operations; it's passed to a safe decoder.\n\n6. **Potential Risks**:\n   - Could the PNG decoder itself be vulnerable to crafted inputs (e.g., malicious PNGs causing buffer overflows)?\n     - This is a concern, but the code relies on `png::CommonInitDecode` and `CommonFinishDecode`, which are likely wrappers around a secure PNG library (e.g., libpng). If those are properly maintained and not vulnerable, this is not a flaw in the code.\n     - The code does not introduce new vulnerabilities \u2014 it only validates size and uses safe APIs.\n\n7. **Conclusion**:\n   - The code performs comprehensive input validation, size checks, and safe memory management.\n   - It avoids unsafe operations and uses proper bounds checking.\n   - The only potential risk is if the underlying PNG library has vulnerabilities, but that is outside the scope of this code's responsibility.\n   - The code itself does not contain exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 489221, "project": "linux-2.6", "commit_id": "649f1ee6c705aab644035a7998d7b574193a598a", "project_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6", "commit_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=649f1ee6c705aab644035a7998d7b574193a598a", "commit_message": "hfsplus: check read_mapping_page() return value\n\nWhile testing more corrupted images with hfsplus, i came across\none which triggered the following bug:\n\n[15840.675016] BUG: unable to handle kernel paging request at fffffffb\n[15840.675016] IP: [<c0116a4f>] kmap+0x15/0x56\n[15840.675016] *pde = 00008067 *pte = 00000000\n[15840.675016] Oops: 0000 [#1] PREEMPT DEBUG_PAGEALLOC\n[15840.675016] Modules linked in:\n[15840.675016]\n[15840.675016] Pid: 11575, comm: ln Not tainted (2.6.27-rc4-00123-gd3ee1b4-dirty #29)\n[15840.675016] EIP: 0060:[<c0116a4f>] EFLAGS: 00010202 CPU: 0\n[15840.675016] EIP is at kmap+0x15/0x56\n[15840.675016] EAX: 00000246 EBX: fffffffb ECX: 00000000 EDX: cab919c0\n[15840.675016] ESI: 000007dd EDI: cab0bcf4 EBP: cab0bc98 ESP: cab0bc94\n[15840.675016]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 0068\n[15840.675016] Process ln (pid: 11575, ti=cab0b000 task=cab919c0 task.ti=cab0b000)\n[15840.675016] Stack: 00000000 cab0bcdc c0231cfb 00000000 cab0bce0 00000800 ca9290c0 fffffffb\n[15840.675016]        cab145d0 cab919c0 cab15998 22222222 22222222 22222222 00000001 cab15960\n[15840.675016]        000007dd cab0bcf4 cab0bd04 c022cb3a cab0bcf4 cab15a6c ca9290c0 00000000\n[15840.675016] Call Trace:\n[15840.675016]  [<c0231cfb>] ? hfsplus_block_allocate+0x6f/0x2d3\n[15840.675016]  [<c022cb3a>] ? hfsplus_file_extend+0xc4/0x1db\n[15840.675016]  [<c022ce41>] ? hfsplus_get_block+0x8c/0x19d\n[15840.675016]  [<c06adde4>] ? sub_preempt_count+0x9d/0xab\n[15840.675016]  [<c019ece6>] ? __block_prepare_write+0x147/0x311\n[15840.675016]  [<c0161934>] ? __grab_cache_page+0x52/0x73\n[15840.675016]  [<c019ef4f>] ? block_write_begin+0x79/0xd5\n[15840.675016]  [<c022cdb5>] ? hfsplus_get_block+0x0/0x19d\n[15840.675016]  [<c019f22a>] ? cont_write_begin+0x27f/0x2af\n[15840.675016]  [<c022cdb5>] ? hfsplus_get_block+0x0/0x19d\n[15840.675016]  [<c0139ebe>] ? tick_program_event+0x28/0x4c\n[15840.675016]  [<c013bd35>] ? trace_hardirqs_off+0xb/0xd\n[15840.675016]  [<c022b723>] ? hfsplus_write_begin+0x2d/0x32\n[15840.675016]  [<c022cdb5>] ? hfsplus_get_block+0x0/0x19d\n[15840.675016]  [<c0161988>] ? pagecache_write_begin+0x33/0x107\n[15840.675016]  [<c01879e5>] ? __page_symlink+0x3c/0xae\n[15840.675016]  [<c019ad34>] ? __mark_inode_dirty+0x12f/0x137\n[15840.675016]  [<c0187a70>] ? page_symlink+0x19/0x1e\n[15840.675016]  [<c022e6eb>] ? hfsplus_symlink+0x41/0xa6\n[15840.675016]  [<c01886a9>] ? vfs_symlink+0x99/0x101\n[15840.675016]  [<c018a2f6>] ? sys_symlinkat+0x6b/0xad\n[15840.675016]  [<c018a348>] ? sys_symlink+0x10/0x12\n[15840.675016]  [<c01038bd>] ? sysenter_do_call+0x12/0x31\n[15840.675016]  =======================\n[15840.675016] Code: 00 00 75 10 83 3d 88 2f ec c0 02 75 07 89 d0 e8 12 56 05 00 5d c3 55 ba 06 00 00 00 89 e5 53 89 c3 b8 3d eb 7e c0 e8 16 74 00 00 <8b> 03 c1 e8 1e 69 c0 d8 02 00 00 05 b8 69 8e c0 2b 80 c4 02 00\n[15840.675016] EIP: [<c0116a4f>] kmap+0x15/0x56 SS:ESP 0068:cab0bc94\n[15840.675016] ---[ end trace 4fea40dad6b70e5f ]---\n\nThis happens because the return value of read_mapping_page() is passed on\nto kmap unchecked.  The bug is triggered after the first\nread_mapping_page() in hfsplus_block_allocate(), this patch fixes all\nthree usages in this functions but leaves the ones further down in the\nfile unchanged.\n\nSigned-off-by: Eric Sesterhenn <snakebyte@gmx.de>\nCc: Roman Zippel <zippel@linux-m68k.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>", "ground_truth": 0, "cwe": ["CWE-20"], "cve": "CVE-2008-4934", "cve_desc": "The hfsplus_block_allocate function in fs/hfsplus/bitmap.c in the Linux kernel before 2.6.28-rc1 does not check a certain return value from the read_mapping_page function before calling kmap, which allows attackers to cause a denial of service (system crash) via a crafted hfsplus filesystem image.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose**:  \n   The function `hfsplus_block_allocate` is responsible for allocating blocks in a HFS+ filesystem's allocation bitmap. It searches for contiguous free blocks (zero bits) in a bitmap stored in a file, and returns the starting block number and the number of allocated blocks.\n\n2. **Input Parameters**:  \n   - `sb`: pointer to the super_block (filesystem metadata).  \n   - `size`: total size of the region to search (in blocks).  \n   - `offset`: starting offset in the bitmap to search from.  \n   - `max`: pointer to a variable that holds the maximum number of blocks to allocate; it is updated with the actual number allocated.\n\n3. **Key Security Considerations**:\n   - The function reads from a file (`HFSPLUS_SB(sb).alloc_file`) via `read_mapping_page`, which maps pages from the file into memory. This is a legitimate operation for a filesystem driver.\n   - The function uses `kmap` and `kunmap` to map kernel pages for direct access. These are safe when used correctly with proper locking and bounds checking.\n   - The function performs bounds checks on `offset` and `size` via `PAGE_CACHE_BITS` and `PAGE_CACHE_BITS / 32` calculations, and uses `min()` and `len` to limit allocations.\n   - The `curr` pointer is advanced through the bitmap in 32-bit chunks (`__be32`), and the loop conditions are based on `end`, which is derived from `size` and `offset`. The `end` calculation is:\n     ```c\n     if ((size ^ offset) / PAGE_CACHE_BITS)\n         end = pptr + PAGE_CACHE_BITS / 32;\n     else\n         end = pptr + ((size + 31) & (PAGE_CACHE_BITS - 1)) / 32;\n     ```\n     This logic is complex but appears to be designed to handle partial pages correctly. The `((size + 31) & (PAGE_CACHE_BITS - 1)) / 32` ensures that only the relevant portion of the last page is scanned.\n\n4. **Potential Issues**:\n   - **Integer Overflow/Underflow**: The expression `(size ^ offset) / PAGE_CACHE_BITS` could be problematic if `size` and `offset` are large and their XOR causes overflow, but since `size` and `offset` are `u32`, and `PAGE_CACHE_BITS` is typically 4096 (i.e., 12 bits), this division is safe as long as `PAGE_CACHE_BITS` is a power of two (which it is). The use of `u32` and `PAGE_CACHE_BITS` (a constant) makes this safe.\n   - **Buffer Overrun in `curr`**: The `curr` pointer is incremented within `pptr` and `end`. The `end` is calculated based on `size` and `offset`, and the loop condition `curr < end` is checked. Since `end` is derived from `size` and `offset`, and `size` is passed from the caller, we must ensure that `size` is not maliciously large.\n   - **Untrusted Input**: The `size` and `offset` parameters come from the filesystem layer, but in a kernel context, they are typically validated earlier. However, if `size` is extremely large (e.g., near `UINT32_MAX`), the loop could run for a long time or cause memory exhaustion. But this is a performance issue, not a direct security vulnerability.\n   - **Use of `kmap` and `kunmap`**: These are used correctly with `page` and `pptr`, and `kunmap` is called after each page is processed. No use-after-free or double-unmap is evident.\n   - **Memory Corruption Risk**: The function writes to `*curr = cpu_to_be32(n)` and `*curr++`, but only within the bounds of `end`, which is derived from `size` and `offset`. The `end` is calculated to be within the current page, so no out-of-bounds write occurs.\n   - **`*max` Update**: The function updates `*max` with the number of allocated blocks. This is used to update `HFSPLUS_SB(sb).free_blocks`, which is a counter. The update is done only after successful allocation, and the value is derived from `start` and `offset`, so no overflow is evident.\n\n5. **Critical Check: Bounds on `size` and `offset`**:\n   - The function assumes that `size` and `offset` are valid and within the bounds of the filesystem's allocation bitmap. However, if the caller passes an invalid `size` (e.g., `size = 0`), the function returns early. If `size` is very large, the loop may iterate many times, but this is a DoS risk, not a memory corruption vulnerability.\n   - The function uses `min(size - start, len)` to limit the number of blocks allocated, which prevents over-allocation.\n\n6. **Conclusion**:\n   - The code performs proper bounds checking.\n   - It uses safe memory access patterns with `kmap`/`kunmap`.\n   - It does not perform unsafe operations like `strcpy`, `memcpy` without size checks, or direct user input manipulation.\n   - The logic for scanning the bitmap is complex but correct in its bounds handling.\n   - There is no evidence of buffer overflow, use-after-free, integer overflow, or other classic vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 270119, "project": "tensorflow", "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76", "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401", "ground_truth": 0, "cwe": ["CWE-369"], "cve": "CVE-2021-37681", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `GetVariableInput` takes a `TfLiteContext*`, a `const TfLiteNode*`, and an `int index` as parameters.\n2. It calls `GetMutableInput(context, node, index)` to retrieve a mutable input tensor at the given index.\n3. If `GetMutableInput` returns `nullptr`, the function immediately returns `nullptr`.\n4. Otherwise, it checks whether the returned tensor has the `is_variable` flag set to true.\n5. If `is_variable` is true, it returns the tensor; otherwise, it returns `nullptr`.\n\nNow, let's analyze for potential security vulnerabilities:\n\n- The function does not perform any bounds checking on the `index` parameter. However, `GetMutableInput` is expected to handle bounds checking internally, as it is a standard TensorFlow Lite API function. Assuming `GetMutableInput` is correctly implemented, this is not a vulnerability.\n- The function does not perform any memory corruption or buffer overflow operations.\n- The function only returns a tensor if it is marked as a variable. This is a valid check to ensure that only variable tensors are returned, which is likely intended behavior in the context of TensorFlow Lite's variable handling.\n- There is no direct manipulation of user-controlled data, no unsafe memory operations, no format string vulnerabilities, and no injection vectors.\n- The function is defensive: it checks for null pointers and returns early if the input is invalid.\n\nGiven that the function performs proper null checks and uses a well-defined API (`GetMutableInput`) that should handle input validation, and that the logic is sound (only returning variable tensors), there is no evidence of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 240276, "project": "vim", "commit_id": "44db8213d38c39877d2148eff6a72f4beccfb94e", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/44db8213d38c39877d2148eff6a72f4beccfb94e", "commit_message": "patch 8.2.4219: reading before the start of the line\n\nProblem:    Reading before the start of the line.\nSolution:   Check boundary before trying to read the character.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-0407", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `yank_copy_line` is responsible for copying a line of text (from a `block_def` structure) into a newly allocated buffer (`pnew`) and storing it in `y_current->y_array[y_idx]`.\n\n2. The function first checks if `exclude_trailing_space` is true, and if so, sets `bd->endspaces = 0`. This suggests that trailing spaces are being removed from the output.\n\n3. It allocates memory for the new string using `alloc()`, with size: `bd->startspaces + bd->endspaces + bd->textlen + 1`. The `+1` is for the null terminator. This is correct because the total length of the string will be:\n   - `startspaces` (leading spaces),\n   - `textlen` (actual text),\n   - `endspaces` (trailing spaces),\n   - and 1 for the null terminator.\n\n4. The function then:\n   - Fills the first `startspaces` bytes with spaces.\n   - Copies `textlen` bytes from `bd->textstart` into the buffer.\n   - Fills the next `endspaces` bytes with spaces.\n   - Then, if `exclude_trailing_space` is true, it attempts to remove trailing whitespace by:\n     - Starting from the end of the text (including trailing spaces),\n     - Using `VIM_ISWHITE` to check for whitespace,\n     - Using `*mb_head_off` to correctly handle multi-byte characters (this is important for UTF-8).\n     - It decrements `s` and `pnew` accordingly, effectively \"trimming\" the buffer.\n\n5. Finally, it null-terminates the string with `*pnew = NUL`.\n\n6. Key points:\n   - The memory allocation is based on `bd->startspaces + bd->endspaces + bd->textlen + 1`, which is correct.\n   - The function uses `mch_memmove` to copy `textlen` bytes from `bd->textstart`, which is safe as long as `bd->textlen` is valid.\n   - The trimming logic uses `mb_head_off`, which is a safe function for multi-byte character boundaries, so it avoids breaking UTF-8 sequences.\n   - The pointer `pnew` is adjusted correctly during trimming, and the final null terminator is placed at the correct position.\n\n7. There is no buffer overflow because:\n   - The allocated size accounts for all characters and the null terminator.\n   - The trimming only moves the pointer backward (decrements `pnew`), but never writes beyond the allocated buffer.\n   - The final `*pnew = NUL` is done at the correct position after trimming.\n\n8. The function does not rely on untrusted input to determine buffer sizes in a way that could be manipulated (e.g., no `strlen` on untrusted data without bounds checking), and all sizes come from the `block_def` structure, which is assumed to be internally consistent.\n\n9. The use of `VIM_ISWHITE` and `mb_head_off` ensures that multi-byte characters are not split, which is a good security practice.\n\nConclusion: The function correctly allocates memory, copies data safely, trims trailing whitespace without causing buffer overflows or memory corruption, and properly null-terminates the string.\n\n(2) NO: No security vulnerability."}
{"idx": 264657, "project": "gpac", "commit_id": "c535bad50d5812d27ee5b22b54371bddec411514", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/c535bad50d5812d27ee5b22b54371bddec411514", "commit_message": "fixed #2194", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-1795", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to v2.1.0-DEV.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `BM_ParseGlobalQuantizer` is responsible for parsing a global quantizer node in a BIFS (Binary Format for Scenes) decoder, which is part of MPEG-4 Part 14 (AVC/MP4) scene description.\n\n2. The function first calls `gf_bifs_dec_node` to decode a node from the bitstream. This node is expected to be of type `SFWorldNode`. If the node is not successfully decoded, it returns `GF_NON_COMPLIANT_BITSTREAM`, which is a valid error handling mechanism.\n\n3. The function then checks if there is already a global quantizer node registered in the scene graph (`codec->scenegraph->global_qp`). If so, it unregisters it and resets the active quantizer pointer. This is a proper cleanup step.\n\n4. It then checks if the decoded node is actually a `TAG_MPEG4_QuantizationParameter` node. If not, it checks whether the node was just created (i.e., `num_instances == 0`). If so, it registers the node for cleanup (via `gf_node_unregister`) and returns an error. This prevents misuse of invalid or improperly created nodes.\n\n5. If the node is valid, it sets:\n   - `codec->ActiveQP = node`\n   - `node->isLocal = 0` (indicating it's a global quantizer)\n   - `codec->scenegraph->global_qp = node`\n\n6. Then, it calls `gf_node_unregister(node, NULL)` **twice**. This is suspicious. `gf_node_unregister` is typically used to remove a node from a reference list or to signal that it's no longer needed. Calling it twice on the same node may lead to undefined behavior if the node is already unregistered or if the internal reference count is not properly managed. However, in this context, it's likely intended to remove the node from two different reference lists (e.g., one for the command and one for the scenegraph). But the code does not show any explicit reference counting or safety checks.\n\n7. The function then creates a command (`GF_Command`) for the global quantizer and adds it to the command list (`com_list`). It sets the `new_node` field to the node and registers it properly.\n\n8. The key concern: **Calling `gf_node_unregister(node, NULL)` twice on the same node without ensuring that the node is still valid or that the second call is safe**. If the first `gf_node_unregister` already removed the node from a list or freed it, the second call could result in a use-after-free or double-free vulnerability.\n\n9. Additionally, the function does not validate whether the node is already in a state where it can be safely unregistered twice. There is no check for whether the node is already unregistered or whether the internal structure supports multiple unregisters.\n\n10. This pattern of double unregistering without proper reference counting or state tracking is a known source of memory safety vulnerabilities, especially in C code where manual memory management is involved.\n\n(1) YES: A security vulnerability detected."}
{"idx": 336106, "project": "net", "commit_id": "7892032cfe67f4bde6fc2ee967e45a8fbaf33756", "project_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net", "commit_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?id=7892032cfe67f4bde6fc2ee967e45a8fbaf33756", "commit_message": "ip6_gre: fix ip6gre_err() invalid reads\n\nAndrey Konovalov reported out of bound accesses in ip6gre_err()\n\nIf GRE flags contains GRE_KEY, the following expression\n*(((__be32 *)p) + (grehlen / 4) - 1)\n\naccesses data ~40 bytes after the expected point, since\ngrehlen includes the size of IPv6 headers.\n\nLet's use a \"struct gre_base_hdr *greh\" pointer to make this\ncode more readable.\n\np[1] becomes greh->protocol.\ngrhlen is the GRE header length.\n\nFixes: c12b395a4664 (\"gre: Support GRE over IPv6\")\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nReported-by: Andrey Konovalov <andreyknvl@google.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2017-5897", "cve_desc": "The ip6gre_err function in net/ipv6/ip6_gre.c in the Linux kernel allows remote attackers to have unspecified impact via vectors involving GRE flags in an IPv6 packet, which trigger an out-of-bounds access.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `ip6gre_err` is a handler for ICMPv6 error messages received on an IPv6 GRE tunnel. It processes the error type (e.g., destination unreachable, time exceeded, parameter problem, packet too big) and updates tunnel state accordingly.\n\n2. The function begins by validating the packet using `pskb_may_pull`, which ensures that the packet has enough data to read the GRE header and potentially the key field. This is a good practice to prevent buffer over-reads.\n\n3. It extracts the GRE header (`greh`) and checks for unsupported GRE flags: `GRE_VERSION` and `GRE_ROUTING`. If either is set, the packet is dropped. This prevents processing of malformed or non-standard GRE packets, which is a security precaution.\n\n4. The code checks for `GRE_CSUM` and `GRE_KEY` flags and adjusts `grehlen` accordingly. If `GRE_KEY` is set, it calculates `key_off` and reads the key from the packet. This is done safely using `pskb_may_pull` before accessing the data, so no buffer overflow occurs.\n\n5. The function then extracts the IPv6 header and uses it to look up the tunnel via `ip6gre_tunnel_lookup`, which uses the destination and source addresses, key, and protocol. This lookup is critical and must be secure.\n\n6. The function handles different ICMPv6 error types:\n   - For `ICMPV6_DEST_UNREACH`: logs a debug message.\n   - For `ICMPV6_TIME_EXCEED`: checks if it's due to hop limit and logs accordingly.\n   - For `ICMPV6_PARAMPROB`: parses the TLV encapsulation limit (`ipv6_tlv_tnl_enc_lim`) using `ip6_tnl_parse_tlv_enc_lim`. This function is called only if `code == ICMPV6_HDR_FIELD`, and the returned `teli` is validated against `info`. The `info` field is used to compute the expected offset, and the code checks if the encapsulation limit is zero. This is a valid check for routing loops.\n   - For `ICMPV6_PKT_TOOBIG`: updates the tunnel MTU based on the `info` field (which contains the MTU from the ICMP message). The code ensures the MTU is at least `IPV6_MIN_MTU`.\n\n7. The function maintains an error counter (`err_count`) and timestamp (`err_time`) to rate-limit error logging. It uses `time_before` to check if the error rate is too high, and resets the counter if the time window has passed. This prevents denial-of-service via excessive error logging.\n\n8. Critical security checks:\n   - All accesses to `skb->data` are preceded by `pskb_may_pull`, which ensures the required data is available.\n   - The `key_off` and `teli` offsets are derived from packet data but are validated before use (e.g., `teli` is checked against `info`).\n   - The `ip6_tnl_parse_tlv_enc_lim` function is called only when `code == ICMPV6_HDR_FIELD`, and the returned value is validated before dereferencing.\n   - The `info` field is used to compute `teli`, but the code checks `teli == be32_to_cpu(info) - 2`, which ensures the offset is consistent with the expected structure.\n\n9. No buffer overflows, use-after-free, or unsafe memory access is evident. All pointer dereferences are guarded by bounds checks via `pskb_may_pull` and proper offset validation.\n\n10. The function does not perform any untrusted input parsing that could lead to memory corruption or code execution. It only updates tunnel state based on validated ICMP error messages.\n\nConclusion: The code follows safe practices for handling network packets, uses bounds checking, validates input, and avoids unsafe operations. There are no exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 261769, "project": "njs", "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53", "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.", "ground_truth": 0, "cwe": ["CWE-416"], "cve": "CVE-2022-27007", "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().", "vuln": 1, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose**:  \n   The function `njs_function_frame_save` is responsible for saving the current execution frame (state) of a JavaScript VM (njs_vm_t) into a new frame structure (`njs_frame_t`). It copies values, arguments, local variables, and other metadata from the active frame to the new frame.\n\n2. **Memory Layout and Pointer Arithmetic**:  \n   The function uses pointer arithmetic to allocate space for values in the new frame:\n   - `new = (njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE);`\n   - `value = (njs_value_t *) (new + value_count + function->u.lambda->temp);`\n   - This assumes that `NJS_FRAME_SIZE` is large enough to accommodate the `native` structure and that the subsequent memory is available and properly aligned.\n\n3. **Bounds Checking on `value_count` and `function->u.lambda->temp`**:  \n   - `value_count` is obtained via `njs_function_frame_value_count(active)`, which likely returns the number of values in the current frame.\n   - `function->u.lambda->temp` is the number of temporary values used by the function.\n   - The code then computes:\n     ```c\n     value = (njs_value_t *) (new + value_count + function->u.lambda->temp);\n     ```\n     This assumes that the memory after `native` is large enough to hold `value_count + temp` number of `njs_value_t` elements.\n\n4. **Potential Vulnerability: Buffer Overflow via Unchecked Size Calculations**:\n   - The function does **not validate** whether the computed size (`value_count + function->u.lambda->temp`) exceeds the available space in the frame.\n   - The frame size is fixed (`NJS_FRAME_SIZE`), and the code assumes that `native` is followed by enough memory to hold all values.\n   - If `value_count` or `function->u.lambda->temp` is maliciously large (e.g., due to corrupted function metadata), the pointer arithmetic could result in writing beyond the allocated frame buffer.\n   - This could lead to **buffer overflow**, **memory corruption**, or **arbitrary memory writes**, especially if the frame is allocated on the stack or in a fixed-size buffer.\n\n5. **No Input Validation on `function->u.lambda->temp` or `value_count`**:\n   - These values come from the function's metadata, which may be loaded from untrusted JavaScript code.\n   - If an attacker can craft a function with an extremely large `temp` or `value_count`, the `new + value_count + temp` computation could overflow the allocated frame buffer.\n\n6. **No Bounds Checks on Array Access**:\n   - The loop:\n     ```c\n     while (start < end) {\n         *p = *start++;\n         *new++ = p++;\n     }\n     ```\n     copies values from `start` to `p`, but there is no check that `p` stays within bounds of the allocated memory. The size of the destination is determined by `value_count`, but if `value_count` is too large, this loop will write past the end of the buffer.\n\n7. **No Validation of `function->args_count` or `args_offset`**:\n   - These are used to compute `native->local` and `native->arguments_offset`, and are used in a for-loop:\n     ```c\n     for (n = 0; n < function->args_count; n++) {\n         if (!njs_is_valid(p)) {\n             njs_set_undefined(p);\n         }\n         *local++ = p++;\n     }\n     ```\n     If `function->args_count` is large, this loop could write beyond the allocated memory.\n\n8. **Conclusion**:\n   - The function performs no bounds checking on values derived from the function's metadata (`value_count`, `temp`, `args_count`, `args_offset`).\n   - These values are used in pointer arithmetic and loops without validation.\n   - If an attacker can control or corrupt the function metadata (e.g., via malicious JavaScript code), they could trigger a buffer overflow or memory corruption.\n   - This is a classic case of **unchecked size values leading to buffer overflow**.\n\n(1) YES: A security vulnerability detected."}
{"idx": 313134, "project": "libvirt", "commit_id": "524de6cc35d3b222f0e940bb0fd027f5482572c5", "project_url": "https://github.com/libvirt/libvirt", "commit_url": "https://github.com/libvirt/libvirt/commit/524de6cc35d3b222f0e940bb0fd027f5482572c5", "commit_message": "virstoragetest: testBackingParse: Use VIR_DOMAIN_DEF_FORMAT_SECURE when formatting xml\n\nWe want to format even the secure information in tests.\n\nSigned-off-by: Peter Krempa <pkrempa@redhat.com>\nReviewed-by: Erik Skultety <eskultet@redhat.com>", "ground_truth": 0, "cwe": ["CWE-212"], "cve": "CVE-2020-14301", "cve_desc": "An information disclosure vulnerability was found in libvirt in versions before 6.3.0. HTTP cookies used to access network-based disks were saved in the XML dump of the guest domain. This flaw allows an attacker to access potentially sensitive information in the domain configuration via the `dumpxml` command.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `testBackingParse` is designed to test the parsing of a backing store string into a storage source structure and then format it back to XML for comparison.\n\n2) The function takes a `const void *args` parameter which is cast to `const struct testBackingParseData *data`. This data includes:\n   - `data->backing`: the input backing store string to parse\n   - `data->expect`: the expected XML output\n   - `data->rv`: the expected return value\n\n3) The function uses `g_auto(virBuffer)` to create a buffer for XML generation, which is automatically cleaned up. This is safe.\n\n4) It uses `g_autofree char *xml` and `g_autoptr(virStorageSource) src` for automatic memory management, which prevents memory leaks.\n\n5) The function calls `virStorageSourceNewFromBackingAbsolute()` to parse the backing string into a storage source object. This function is responsible for parsing and validating the input.\n\n6) The function checks the return code against the expected value (`erc`) and reports mismatches.\n\n7) It validates that if `data->expect` is NULL, then the parsing should fail (return non-zero), and if parsing succeeds when it shouldn't, it reports an error.\n\n8) The XML formatting is done via `virDomainDiskSourceFormat()`, which is a well-known function in libvirt for safely formatting storage source XML. It takes the source object and produces XML output.\n\n9) The function compares the generated XML with the expected XML using `STRNEQ()`. This is a standard string comparison.\n\n10) The function does not perform any unsafe operations like buffer overflows, format string vulnerabilities, or direct string concatenation with user input. All input is processed through well-defined APIs that handle parsing and formatting safely.\n\n11) The use of `virBuffer` ensures that the XML generation is safe and does not overflow.\n\n12) The function is a test function, not production code, and its purpose is to validate behavior. It does not expose any direct security vulnerabilities.\n\nConclusion: The code uses safe memory management, proper input validation, and secure APIs for parsing and formatting. There are no obvious security vulnerabilities such as buffer overflows, injection, or unsafe string operations.\n\n(2) NO: No security vulnerability."}
{"idx": 281119, "project": "ipsec", "commit_id": "7bab09631c2a303f87a7eb7e3d69e888673b9b7e", "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec.git/commit/?id=7bab09631c2a303f87a7eb7e3d69e888673b9b7e", "commit_message": "xfrm: policy: check policy direction value\n\nThe 'dir' parameter in xfrm_migrate() is a user-controlled byte which is used\nas an array index. This can lead to an out-of-bound access, kernel lockup and\nDoS. Add a check for the 'dir' value.\n\nThis fixes CVE-2017-11600.\n\nReferences: https://bugzilla.redhat.com/show_bug.cgi?id=1474928\nFixes: 80c9abaabf42 (\"[XFRM]: Extension for dynamic update of endpoint address(es)\")\nCc: <stable@vger.kernel.org> # v2.6.21-rc1\nReported-by: \"bo Zhang\" <zhangbo5891001@gmail.com>\nSigned-off-by: Vladis Dronov <vdronov@redhat.com>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2017-11600", "cve_desc": "net/xfrm/xfrm_policy.c in the Linux kernel through 4.12.3, when CONFIG_XFRM_MIGRATE is enabled, does not ensure that the dir value of xfrm_userpolicy_id is XFRM_POLICY_MAX or less, which allows local users to cause a denial of service (out-of-bounds access) or possibly have unspecified other impact via an XFRM_MSG_MIGRATE xfrm Netlink message.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `xfrm_migrate` is part of the Linux kernel's XFRM (eXtensible FrameWork for Routing and Mobility) subsystem, which handles IPsec security associations and policies.\n\n2) The function takes several parameters including:\n   - `sel`: a selector for matching traffic\n   - `dir`: direction (inbound/outbound)\n   - `type`: policy type\n   - `m`: array of migration specifications\n   - `num_migrate`: number of migrations\n   - `k`: key management address\n   - `net`: network namespace\n   - `encap`: encapsulation template\n\n3) The function performs several stages:\n   - Stage 0: Input validation via `xfrm_migrate_check()`\n   - Stage 1: Finds the policy using `xfrm_migrate_policy_find()`\n   - Stage 2: Finds existing states and migrates them using `xfrm_state_migrate()`\n   - Stage 3: Updates the policy\n   - Stage 4: Deletes old states\n   - Stage 5: Announces migration\n\n4) Key security considerations:\n   - The function validates `dir` against `XFRM_POLICY_MAX`, preventing out-of-bounds access\n   - It uses `xfrm_migrate_check()` to validate the migration structure\n   - It properly handles error paths with cleanup in the `restore_state` label\n   - It uses `xfrm_states_put()` and `xfrm_states_delete()` to properly manage state references\n   - The migration process is contained within the kernel's security framework\n\n5) The function does not directly handle user input in a way that could lead to buffer overflows, format string vulnerabilities, or other classic security issues. The parameters are validated, and the function operates within the kernel's established security model for IPsec.\n\n6) The error handling is comprehensive, with proper cleanup in both the `out` and `restore_state` paths, preventing resource leaks and potential use-after-free scenarios.\n\n7) The function is part of a well-established kernel subsystem with extensive review and testing, and there are no obvious vulnerabilities in the code structure.\n\n(2) NO: No security vulnerability."}
{"idx": 349528, "project": "linux", "commit_id": "1d0688421449718c6c5f46e458a378c9b530ba18", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=1d0688421449718c6c5f46e458a378c9b530ba18", "commit_message": "Bluetooth: virtio_bt: fix memory leak in virtbt_rx_handle()\n\nOn the reception of packets with an invalid packet type, the memory of\nthe allocated socket buffers is never freed. Add a default case that frees\nthese to avoid a memory leak.\n\nFixes: afd2daa26c7a (\"Bluetooth: Add support for virtio transport driver\")\nSigned-off-by: Soenke Huster <soenke.huster@eknoes.de>\nSigned-off-by: Marcel Holtmann <marcel@holtmann.org>", "ground_truth": 0, "cwe": ["CWE-772"], "cve": "CVE-2022-26878", "cve_desc": "drivers/bluetooth/virtio_bt.c in the Linux kernel before 5.16.3 has a memory leak (socket buffers have memory allocated but not freed).", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `virtbt_rx_handle` is responsible for handling incoming Bluetooth packets via a virtio-based Bluetooth device (`struct virtio_bluetooth *vbt`) and a socket buffer (`struct sk_buff *skb`).\n\n2. The code reads the first byte of the packet data (`skb->data`) into `pkt_type` using `*((__u8 *) skb->data)`. This is a common way to extract a packet type field from the beginning of a Bluetooth HCI packet.\n\n3. Then, `skb_pull(skb, 1)` is called to remove the first byte (the packet type) from the buffer. This is correct behavior for processing a packet where the header (in this case, the packet type) has been consumed.\n\n4. The `switch` statement checks the `pkt_type` against known HCI packet types:\n   - `HCI_EVENT_PKT`\n   - `HCI_ACLDATA_PKT`\n   - `HCI_SCODATA_PKT`\n   - `HCI_ISODATA_PKT`\n\n   If the packet type matches one of these, the function sets `hci_skb_pkt_type(skb)` to the packet type and calls `hci_recv_frame(vbt->hdev, skb)` to pass the packet to the Bluetooth stack.\n\n5. For any other (unknown) packet type, the code calls `\tkfree_skb(skb)` to free the buffer.\n\n6. Now, consider potential security issues:\n   - The `pkt_type` is read directly from `skb->data` without any bounds checking. However, since `skb->data` is part of a socket buffer that is expected to be valid and properly sized (as it's passed from the network stack), and the `skb_pull` is only done after reading the first byte, this is not inherently unsafe.\n   - The `skb_pull` is safe because it only removes one byte, and the code assumes the buffer has at least one byte (which is reasonable for a valid HCI packet).\n   - The `switch` statement covers all known valid packet types. Any unknown type is handled by `kfree_skb`, which safely frees the memory.\n   - There is no buffer overflow, no use of unsafe string functions, no memory corruption, and no injection vector.\n   - The function does not perform any untrusted input processing that could lead to code execution or memory corruption.\n\n7. The only potential concern might be if the `skb` is malformed or has insufficient data, but the code assumes that `skb->data` is valid and has at least one byte. However, in the Linux kernel, `skb` validation is typically done earlier in the stack, and this function is expected to receive valid packets. The `skb_pull` is safe as long as the buffer has at least one byte, which is guaranteed by the `pkt_type` read.\n\n8. Therefore, there is no evidence of a security vulnerability in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 357668, "project": "squirrel", "commit_id": "23a0620658714b996d20da3d4dd1a0dcf9b0bd98", "project_url": "https://github.com/albertodemichelis/squirrel", "commit_url": "https://github.com/albertodemichelis/squirrel/commit/23a0620658714b996d20da3d4dd1a0dcf9b0bd98", "commit_message": "check max member count in class", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2021-41556", "cve_desc": "sqclass.cpp in Squirrel through 2.2.5 and 3.x through 3.1 allows an out-of-bounds read (in the core interpreter) that can lead to Code Execution. If a victim executes an attacker-controlled squirrel script, it is possible for the attacker to break out of the squirrel script sandbox even if all dangerous functionality such as File System functions has been disabled. An attacker might abuse this bug to target (for example) Cloud services that allow customization via SquirrelScripts, or distribute malware through video games that embed a Squirrel Engine.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine if there are any security vulnerabilities.\n\n1. The function `SQClass::NewSlot` is responsible for adding a new slot (member or method) to a class in a scripting engine (likely a custom or lightweight Lua-like interpreter, given the naming and structure).\n\n2. The function takes parameters:\n   - `ss`: a pointer to shared state (likely global interpreter state).\n   - `key`: the name of the slot (e.g., method or field name).\n   - `val`: the value to assign (could be a function, closure, or data).\n   - `bstatic`: whether the slot is static.\n\n3. The function first checks if the class is locked (`_locked`) and if the value is not a closure or native closure or not marked as static. If so, it returns false \u2014 this prevents modification of a class after it has been instantiated, which is a reasonable safety measure.\n\n4. It checks if the key already exists in `_members` and if it's a field (via `_isfield(temp)`). If so, it updates the default value. This is safe as long as `_defaultvalues` is properly managed.\n\n5. It checks if the number of used members exceeds `MEMBER_MAX_COUNT`. If so, it returns false \u2014 this prevents buffer overflow or excessive memory usage.\n\n6. For static members (or closures), it handles metamethods via `GetMetaMethodIdxByName`. This is safe as long as the index is validated (and it is, since it returns -1 on failure).\n\n7. For closures, it clones the closure and sets the base to `_base`, and increases the reference count. This is a correct memory management pattern (ref counting), assuming `__ObjAddRef` is safe and properly implemented.\n\n8. It checks if the key matches the constructor (via `IsEqual` with `_constructoridx`). If so, it assigns the method index accordingly. This is safe as long as the comparison is secure.\n\n9. It adds the method to `_methods` and updates `_members` with a new slot. The use of `_make_method_idx` and `_methods.size()` suggests proper indexing.\n\n10. For non-static members, it adds the value to `_defaultvalues` and assigns a field index via `_make_field_idx`. Again, this is safe as long as `_defaultvalues` and `_members` are properly bounded.\n\n11. The function uses `SQObjectPtr` and `SQObjectPtr` \u2014 these are likely smart pointers or reference-counted objects, which helps prevent memory leaks.\n\n12. There is no direct use of unsafe functions like `strcpy`, `sprintf`, or raw memory access.\n\n13. Input validation is performed:\n   - Null checks (implicit via `Get` and `IsEqual`).\n   - Size limits via `CountUsed()` and `MEMBER_MAX_COUNT`.\n   - Type checks via `sq_type()`.\n\n14. No dynamic memory allocation without bounds checking, no buffer overflows, no format string vulnerabilities, no unsafe string operations.\n\n15. The only potential concern is if `MEMBER_MAX_COUNT` is too small or if `_defaultvalues` or `_methods` can grow without bounds \u2014 but the code explicitly checks `CountUsed() >= MEMBER_MAX_COUNT` and returns false, which prevents overflow.\n\n16. The use of `sq_type(val)` and `sq_type(temp)` ensures type safety.\n\n17. The function does not perform any untrusted input parsing that could lead to code execution, injection, or memory corruption.\n\nConclusion: The code performs proper bounds checking, type validation, reference counting, and prevents modification of locked classes. It avoids unsafe operations and uses safe container operations. There are no obvious security vulnerabilities such as buffer overflows, use-after-free, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 241369, "project": "tensorflow", "commit_id": "579261dcd446385831fe4f7457d802a59685121d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d", "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335", "ground_truth": 0, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Input Validation**:\n   - The code begins by retrieving input tensors and validating their dimensions.\n   - It checks that the input has rank \u2265 2, that the right-hand side (rhs) has the same rank, and that the matrix dimensions are consistent (e.g., square matrices, matching row counts).\n   - These checks are performed using `OP_REQUIRES_ASYNC`, which ensures that invalid inputs are rejected early with appropriate error messages.\n   - This prevents malformed or maliciously crafted inputs from causing undefined behavior.\n\n2. **Memory Allocation and Buffer Management**:\n   - The code uses `solver->allocate_scoped_tensor` and `solver->forward_input_or_allocate_scoped_tensor` to manage GPU memory safely.\n   - These functions are part of a well-structured GPU kernel framework (likely TensorFlow's C++ kernel system), which ensures that memory is properly allocated and scoped.\n   - The use of `std::unique_ptr<CudaSolver>` ensures proper lifetime management of the solver object.\n   - Temporary tensors like `input_copy`, `pivots`, `transposed_rhs`, and scratch space are all allocated with explicit size checks and are tied to the context\u2019s memory management system.\n\n3. **Data Copying and Memory Safety**:\n   - When copying data between tensors (e.g., `device.memcpy`), the code uses `NumElements() * sizeof(Scalar)` to compute the correct byte count.\n   - This is safe because `NumElements()` returns the total number of elements, and the size is derived from the tensor\u2019s shape and data type.\n   - The use of `flat<Scalar>().data()` is safe as long as the tensor is properly allocated and not accessed out of bounds \u2014 which is ensured by the prior validation and allocation steps.\n\n4. **Use of GPU Libraries (cuBLAS, cuSOLVER)**:\n   - The code interfaces with GPU-accelerated linear algebra libraries (cuBLAS, cuSOLVER) via wrapper functions (`GetrfBatched`, `GetrsBatched`, etc.).\n   - These functions are called with properly validated parameters (e.g., `n`, `batch_size`, pointers to data).\n   - The use of `GetScratchSpace` ensures that temporary device pointers are allocated on the host and passed safely to GPU kernels.\n   - The `dev_info` and `host_infos` are used to check for errors after kernel execution, and the code explicitly checks for `host_info <= 0` to detect singular matrices (a valid condition, not a vulnerability).\n\n5. **No User Input Directly in Memory Operations**:\n   - All inputs are tensors passed through the `OpKernelContext`, which is part of a trusted framework (TensorFlow).\n   - There is no direct string formatting, dynamic memory allocation from untrusted input, or unsafe function calls (like `strcpy`, `sprintf`, etc.).\n   - The code does not perform any unsafe pointer arithmetic or buffer overflows.\n\n6. **Error Handling and Callbacks**:\n   - The `info_checker` callback ensures that any GPU kernel errors (e.g., singular matrices) are properly handled and converted into meaningful error messages.\n   - The use of `OP_REQUIRES_OK_ASYNC` ensures that any failure in GPU operations is caught and propagated correctly.\n\n7. **No Obvious Vulnerabilities**:\n   - No buffer overflows, use-after-free, or memory leaks are evident.\n   - No unsafe string operations, no direct user input manipulation.\n   - All tensor shapes and sizes are validated before use.\n   - The code follows safe patterns for GPU kernel execution in TensorFlow.\n\nConclusion: The code is well-structured, uses safe memory management practices, performs thorough input validation, and leverages secure GPU library interfaces with proper error checking. There are no indications of buffer overflows, memory corruption, or other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 373535, "project": "ovs", "commit_id": "803ed12e31b0377c37d7aa8c94b3b92f2081e349", "project_url": "https://github.com/openvswitch/ovs", "commit_url": "https://github.com/openvswitch/ovs/commit/803ed12e31b0377c37d7aa8c94b3b92f2081e349", "commit_message": "ipf: release unhandled packets from the batch\n\nSince 640d4db788ed (\"ipf: Fix a use-after-free error, ...\") the ipf\nframework unconditionally allocates a new dp_packet to track\nindividual fragments.  This prevents a use-after-free.  However, an\nadditional issue was present - even when the packet buffer is cloned,\nif the ip fragment handling code keeps it, the original buffer is\nleaked during the refill loop.  Even in the original processing code,\nthe hardcoded dnsteal branches would always leak a packet buffer from\nthe refill loop.\n\nThis can be confirmed with valgrind:\n\n==717566== 16,672 (4,480 direct, 12,192 indirect) bytes in 8 blocks are definitely lost in loss record 390 of 390\n==717566==    at 0x484086F: malloc (vg_replace_malloc.c:380)\n==717566==    by 0x537BFD: xmalloc__ (util.c:137)\n==717566==    by 0x537BFD: xmalloc (util.c:172)\n==717566==    by 0x46DDD4: dp_packet_new (dp-packet.c:153)\n==717566==    by 0x46DDD4: dp_packet_new_with_headroom (dp-packet.c:163)\n==717566==    by 0x550AA6: netdev_linux_batch_rxq_recv_sock.constprop.0 (netdev-linux.c:1262)\n==717566==    by 0x5512AF: netdev_linux_rxq_recv (netdev-linux.c:1511)\n==717566==    by 0x4AB7E0: netdev_rxq_recv (netdev.c:727)\n==717566==    by 0x47F00D: dp_netdev_process_rxq_port (dpif-netdev.c:4699)\n==717566==    by 0x47FD13: dpif_netdev_run (dpif-netdev.c:5957)\n==717566==    by 0x4331D2: type_run (ofproto-dpif.c:370)\n==717566==    by 0x41DFD8: ofproto_type_run (ofproto.c:1768)\n==717566==    by 0x40A7FB: bridge_run__ (bridge.c:3245)\n==717566==    by 0x411269: bridge_run (bridge.c:3310)\n==717566==    by 0x406E6C: main (ovs-vswitchd.c:127)\n\nThe fix is to delete the original packet when it isn't able to be\nreinserted into the packet batch.  Subsequent valgrind runs show that\nthe packets are not leaked from the batch any longer.\n\nFixes: 640d4db788ed (\"ipf: Fix a use-after-free error, and remove the 'do_not_steal' flag.\")\nFixes: 4ea96698f667 (\"Userspace datapath: Add fragmentation handling.\")\nReported-by: Wan Junjie <wanjunjie@bytedance.com>\nReported-at: https://github.com/openvswitch/ovs-issues/issues/226\nSigned-off-by: Aaron Conole <aconole@redhat.com>\nReviewed-by: David Marchand <david.marchand@redhat.com>\nTested-by: Wan Junjie <wanjunjie@bytedance.com>\nSigned-off-by: Alin-Gabriel Serdean <aserdean@ovn.org>", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2021-3905", "cve_desc": "A memory leak was found in Open vSwitch (OVS) during userspace IP fragmentation processing. An attacker could use this flaw to potentially exhaust available memory by keeping sending packet fragments.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `ipf_extract_frags_from_batch` processes a batch of packets (`dp_packet_batch`) and checks whether each packet is a valid IP fragment (IPv4 or IPv6) using `ipf_is_valid_v4_frag` or `ipf_is_valid_v6_frag`.\n\n2) If the packet is a valid fragment, it acquires a mutex (`ovs_mutex_lock(&ipf->ipf_lock)`), then calls `ipf_handle_frag` to process the fragment. The return value of `ipf_handle_frag` determines the next action:\n   - If it returns false: the packet is refilled back into the batch via `dp_packet_batch_refill(pb, pkt, pb_idx)`.\n   - If it returns true: the packet is deleted via `dp_packet_delete(pkt)`.\n\n3) After processing, the mutex is released with `ovs_mutex_unlock(&ipf->ipf_lock)`.\n\n4) If the packet is not a valid fragment, it is simply refilled into the batch.\n\n5) Key observation: The function uses `dp_packet_batch_refill` to return packets to the batch. This function is typically used to reinsert a packet into the batch for further processing. However, the critical point is that `dp_packet_delete(pkt)` is called only when `ipf_handle_frag` returns true.\n\n6) The potential issue lies in the order of operations and the use of `dp_packet_batch_refill` after `dp_packet_delete`. Specifically:\n   - If `ipf_handle_frag` returns true, the packet is deleted with `dp_packet_delete(pkt)`.\n   - But if `ipf_handle_frag` returns false, the packet is refilled using `dp_packet_batch_refill(pb, pkt, pb_idx)`, which is safe.\n\n7) However, there is a subtle but serious problem: `dp_packet_batch_refill` is called with `pkt` as an argument, but if `ipf_handle_frag` returns true, the packet has already been deleted. But in that case, the code does not call `dp_packet_batch_refill` \u2014 it only calls `dp_packet_delete(pkt)`.\n\n8) So the actual issue is not in the refilling after deletion, but rather: **what happens if `ipf_handle_frag` modifies the packet or its metadata in a way that affects the batch?** But more importantly, consider the following:\n\n   - The `dp_packet_batch_refill` function is used to reinsert a packet into the batch for further processing. However, if the packet has already been deleted (via `dp_packet_delete`), then calling `dp_packet_batch_refill` on it would be invalid.\n\n   - But in this code, `dp_packet_batch_refill` is only called when `ipf_handle_frag` returns false \u2014 meaning the packet is not handled and should be kept for later processing.\n\n   - The packet is deleted only when `ipf_handle_frag` returns true \u2014 so in that case, `dp_packet_batch_refill` is not called.\n\n   - Therefore, there is no case where `dp_packet_batch_refill` is called on a deleted packet.\n\n9) However, there is a **race condition** or **use-after-free** risk if `ipf_handle_frag` modifies the packet in a way that causes it to be freed or invalidated, but the code assumes that `dp_packet_delete` is only called when the packet is no longer needed.\n\n10) But more critically: the function uses `dp_packet_batch_refill` to reinsert the packet into the batch. This function is typically used in a loop where packets are processed and potentially reinserted. However, if `ipf_handle_frag` returns false, the packet is refilled \u2014 but what if the packet was already processed and the batch is being iterated? The `DP_PACKET_BATCH_REFILL_FOR_EACH` macro may not handle reinserted packets correctly if they are refilled after the current iteration.\n\n11) The real issue: **`dp_packet_batch_refill` is called with `pkt` and `pb_idx`, but if the packet is refilled, it may be processed again in the same batch iteration. However, the `DP_PACKET_BATCH_REFILL_FOR_EACH` macro may not safely handle reinserted packets, especially if the batch is being iterated in a way that assumes the packet list is stable.**\n\n12) But more importantly: **the function does not check whether `dp_packet_batch_refill` is safe to call after `dp_packet_delete`. However, in this code, `dp_packet_batch_refill` is only called when the packet is not deleted. So no use-after-free occurs.**\n\n13) However, there is a **critical flaw**: the `ipf_handle_frag` function may call `dp_packet_delete` internally, but the code already calls `dp_packet_delete(pkt)` after `ipf_handle_frag` returns true. This could lead to **double-free** if `ipf_handle_frag` already deleted the packet.\n\n14) But the code says: if `ipf_handle_frag` returns true, then `dp_packet_delete(pkt)` is called. So if `ipf_handle_frag` already deleted the packet, calling `dp_packet_delete` again would be a double-free.\n\n15) Therefore, the vulnerability is: **if `ipf_handle_frag` deletes the packet internally, and then the code deletes it again, a double-free occurs.**\n\n16) This is a classic security vulnerability: **double-free**. It can lead to memory corruption and potentially arbitrary code execution.\n\n17) The code assumes that `ipf_handle_frag` does not delete the packet, but instead returns true to indicate that the packet has been handled and should be deleted by the caller. But if `ipf_handle_frag` already deleted the packet, then the caller's `dp_packet_delete(pkt)` will cause a double-free.\n\n18) This is a **security vulnerability** because it allows for memory corruption and potential exploitation.\n\n(1) YES: A security vulnerability detected."}
{"idx": 220168, "project": "tensorflow", "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9", "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b", "ground_truth": 0, "cwe": ["CWE-401"], "cve": "CVE-2022-23585", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Initialization**:\n   - The function `DecodePngV2` takes a `StringPiece input` representing the PNG data.\n   - It initializes a `png::DecodeContext` using `png::CommonInitDecode`, which is guarded by `OP_REQUIRES`. This ensures that invalid or malformed PNGs are rejected early, preventing further processing of corrupted data.\n\n2. **Resource Management with Cleanup**:\n   - A `gtl::MakeCleanup` object is used to ensure that `png::CommonFreeDecode(&decode)` is called when the function exits, even if an error occurs. This prevents memory leaks and ensures proper cleanup of the decode context. This is a good practice and does not introduce a vulnerability.\n\n3. **Size Validation**:\n   - The code checks for potential integer overflow and excessive image dimensions:\n     - It converts `decode.width` and `decode.height` to `int` and validates they are positive and less than `1 << 27` (134,217,728), which is a reasonable upper bound.\n     - It computes `total_size = width * height` as `int64_t` and checks that it is less than `1 << 29` (536,870,912), which prevents excessive memory allocation.\n   - These checks are performed carefully using `int64_t` to avoid overflow during multiplication, and the comparisons are done with proper type casting. This prevents integer overflow and denial-of-service via large image sizes.\n\n4. **Output Tensor Allocation**:\n   - The output tensor is allocated using `context->allocate_output`, with shape based on `height`, `width`, and `channels`.\n   - The shape is validated based on the `op_type_` (e.g., `DecodeGif` uses a 4D shape, others use 3D). This is safe as long as the dimensions are valid, which they are due to prior checks.\n\n5. **Op Type Validation**:\n   - The code checks for invalid op types (`DecodeBmp`, `DecodeAndCropJpeg`) and returns an error if the operation is not appropriate for PNG. This prevents misuse and ensures correct behavior.\n\n6. **Data Decoding**:\n   - For `DT_UINT8` and `DT_UINT16`, it calls `png::CommonFinishDecode` with a properly sized output buffer. The buffer size is computed as `decode.channels * width * sizeof(uintX)`, which is correct and bounded by prior size checks.\n   - For `DT_FLOAT`, it allocates a `uint16[]` buffer (on the heap via `std::unique_ptr`) and decodes into it. The size is again bounded by the same checks. Then it converts the data to `float` using Eigen's device and casting. This is safe because:\n     - The buffer size is validated.\n     - The conversion uses `cast<float>() * scale`, which is safe and avoids overflow.\n     - The use of `unique_ptr` ensures no memory leak.\n\n7. **No Buffer Overflows or Unsafe Operations**:\n   - There are no calls to unsafe functions like `strcpy`, `memcpy` without bounds, or direct pointer arithmetic without bounds checking.\n   - All memory allocations are bounded by validated image dimensions.\n   - The use of `StringPiece` ensures that the input is not null-terminated in a way that could cause issues (it's just a view into the input data).\n\n8. **No Injection or Code Execution Risks**:\n   - This is a PNG decoder, not a parser for user-controlled code. The only risk would be in handling malformed or malicious PNGs, but the code includes:\n     - Early validation via `CommonInitDecode`.\n     - Size checks to prevent excessive memory allocation.\n     - Proper cleanup.\n   - These measures mitigate risks like denial-of-service (DoS) via large images or memory exhaustion.\n\nConclusion: The code performs comprehensive input validation, uses safe memory management (cleanups, unique_ptr), avoids integer overflow via `int64_t` arithmetic, and ensures that all allocations are bounded by safe limits. There are no known security vulnerabilities such as buffer overflows, integer overflows, use-after-free, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 361303, "project": "admesh", "commit_id": "e84d8353f1347e1f26f0a95770d92ba14e6ede38", "project_url": "https://github.com/admesh/admesh", "commit_url": "https://github.com/admesh/admesh/commit/e84d8353f1347e1f26f0a95770d92ba14e6ede38", "commit_message": "Fix heap buffer overflow in stl_update_connects_remove_1\n\n\n- Add argument value check to the stl_update_connects_remove_1\n- Add neighbor value check in stl_remove_degenerate\n\nFixes https://github.com/admesh/admesh/issues/28\nMerges https://github.com/admesh/admesh/pull/55", "ground_truth": 0, "cwe": ["CWE-125"], "cve": "CVE-2018-25033", "cve_desc": "ADMesh through 0.98.4 has a heap-based buffer over-read in stl_update_connects_remove_1 (called from stl_remove_degenerate) in connect.c in libadmesh.a.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `stl_remove_degenerate` is designed to remove degenerate facets from an STL file representation. A degenerate facet is one where two or more vertices are identical, making it geometrically invalid (e.g., a line or point instead of a triangle).\n\n2. The function first checks if `stl->error` is set \u2014 if so, it returns early. This is safe and expected behavior.\n\n3. It checks if all three vertices of the facet are equal using `memcmp`. If so, it logs a message and calls `stl_remove_facet` to remove the facet. This is a valid handling of a degenerate case.\n\n4. It then checks pairwise equality of vertices to determine which two vertices are equal. Based on this, it sets `edge1`, `edge2`, and `edge3` to identify the edge between the two equal vertices and the third vertex.\n\n5. It retrieves neighbor information for the edges of the facet. The neighbors are stored in `stl->neighbors_start[facet].neighbor[]`, and the corresponding \"which vertex not\" indices are stored in `which_vertex_not[]`.\n\n6. The function handles cases where one or both neighbors of the degenerate edge are missing (i.e., `-1`). It calls `stl_update_connects_remove_1` on the non-null neighbor(s), which likely updates connectivity information.\n\n7. It then updates the neighbor and vertex-not information in the neighboring facets:\n   - For `neighbor1` and `neighbor2`, it updates their neighbor and which_vertex_not fields to reflect the removal of the current facet.\n   - The update uses `(vnot1 + 1) % 3` to compute the correct index in the neighbor\u2019s array \u2014 this is a standard way to handle triangle neighbor indexing in 3D mesh data structures.\n\n8. After updating the neighbors, it removes the current facet via `stl_remove_facet`.\n\n9. Finally, if `neighbor3` (the neighbor across the third edge) exists, it calls `stl_update_connects_remove_1` and sets the corresponding neighbor entry to `-1`.\n\nNow, let\u2019s look for potential vulnerabilities:\n\n- The function assumes that `facet` is a valid index into `stl->facet_start` and `stl->neighbors_start`. However, the code does not validate that `facet` is within bounds (e.g., less than `stl->num_facets`). If an invalid `facet` is passed, this could lead to out-of-bounds memory access.\n\n- The function uses `memcmp` to compare `stl_vertex` structures. This is safe only if `stl_vertex` is a POD (plain old data) type and the comparison is meaningful. Assuming that\u2019s the case, this is acceptable.\n\n- The use of `(vnot1 + 1) % 3` is correct in the context of triangle neighbor indexing, as it cycles through the three edges.\n\n- The function calls `stl_remove_facet`, which presumably removes the facet and updates the data structure. If `stl_remove_facet` is implemented correctly, this is safe.\n\n- The critical issue: **There is no bounds check on the `facet` parameter.** If an attacker can control the `facet` value (e.g., via malformed STL file input), they could pass an invalid index, leading to out-of-bounds access in `stl->facet_start[facet]` and `stl->neighbors_start[facet]`.\n\n- This is a classic **out-of-bounds memory access** vulnerability, which can lead to crashes, information disclosure, or even code execution if exploited.\n\nTherefore, despite the careful handling of degenerate facets and neighbor updates, the lack of input validation on the `facet` index is a serious security flaw.\n\n(1) YES: A security vulnerability detected."}
{"idx": 256441, "project": "pjproject", "commit_id": "11559e49e65bdf00922ad5ae28913ec6a198d508", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/11559e49e65bdf00922ad5ae28913ec6a198d508", "commit_message": "Merge pull request from GHSA-vhxv-phmx-g52q\n\n* Prevent OOB read/write when parsing RTCP FB RPSI\n\n* Add log information\n\n* Modification based on comments.", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2022-24786", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. PJSIP versions 2.12 and prior do not parse incoming RTCP feedback RPSI (Reference Picture Selection Indication) packet, but any app that directly uses pjmedia_rtcp_fb_parse_rpsi() will be affected. A patch is available in the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `pjmedia_rtcp_fb_parse_rpsi` is designed to parse an RTCP feedback message of type RPSI (Receiver Packet Status Information), which is part of the RTCP (RTP Control Protocol) feedback mechanism.\n\n2. The function starts by validating input parameters:\n   - `PJ_ASSERT_RETURN(buf && rpsi, PJ_EINVAL);` ensures that both the buffer and output structure are non-null.\n   - `PJ_ASSERT_RETURN(length >= sizeof(pjmedia_rtcp_fb_common), PJ_ETOOSMALL);` ensures the buffer is at least large enough to contain the common RTCP header.\n\n3. It checks the RTCP header fields:\n   - `hdr->rtcp_common.pt != RTCP_PSFB` \u2014 ensures the packet type is RTCP_PSFB (PSFB = Payload-Specific Feedback).\n   - `hdr->rtcp_common.count != 3` \u2014 ensures the FMT (Feedback Message Type) is 3, which is correct for RPSI.\n   - If either check fails, it returns `PJ_ENOTFOUND`, which is appropriate.\n\n4. It checks the RTCP header length:\n   - `if (hdr->rtcp_common.length < 3)` \u2014 ensures the length field is at least 3 (in 32-bit words). This is a valid check to prevent parsing malformed headers.\n\n5. It calculates `rpsi_len`:\n   - `rpsi_len = (pj_ntohs((pj_uint16_t)hdr->rtcp_common.length) - 2) * 4;`\n     - This computes the length of the RPSI payload in bytes.\n     - The subtraction of 2 is because the length field in RTCP is in 32-bit words, and the header itself takes 2 words (common header + FMT-specific header), so the payload length is `(length - 2) * 4`.\n     - This is correct and safe as long as `hdr->rtcp_common.length >= 3`, which is already checked.\n\n6. It checks if the total buffer length is sufficient:\n   - `if (length < rpsi_len + 12)` \u2014 ensures the buffer is large enough to contain the header (12 bytes) plus the RPSI payload.\n   - This is correct: 12 bytes = sizeof(pjmedia_rtcp_fb_common) = 12 bytes (assuming standard RTCP header size).\n\n7. It proceeds to parse the payload:\n   - `p = (pj_uint8_t*)hdr + sizeof(*hdr);` \u2014 points to the start of the payload.\n   - `padlen = *p++;` \u2014 reads the padding length byte.\n   - `if (padlen >= 32)` \u2014 checks that padding is less than 32. This is a reasonable limit, as padding is typically small.\n\n8. It checks the bit length:\n   - `if ((rpsi_len * 8) < (unsigned)(16 + padlen))` \u2014 ensures that the total bit length (rpsi_len * 8) is at least 16 + padlen.\n   - This is a sanity check: the RPSI data must contain at least 16 bits of data (e.g., for the PT field and other fields) plus the padding.\n   - This prevents underflow in the bit length calculation.\n\n9. It parses the PT and bit length:\n   - `rpsi->pt = (*p++ & 0x7F);` \u2014 extracts the 7-bit payload type.\n   - `rpsi->rpsi_bit_len = rpsi_len*8 - 16 - padlen;` \u2014 computes the actual data bit length.\n   - This is safe as long as the previous checks passed.\n\n10. It copies the RPSI data:\n    - `pj_strset(&rpsi->rpsi, (char*)p, (rpsi->rpsi_bit_len + 7)/8);`\n      - This copies the raw data into `rpsi->rpsi`, which is a `pj_str_t` structure.\n      - The size is calculated as `(bit_len + 7)/8` to round up to the nearest byte.\n      - The source pointer `p` is advanced by one byte after reading `padlen`, and then `rpsi_len` bytes are read (but only `rpsi_bit_len` bits are used).\n      - However, note that `rpsi_len` is derived from the RTCP header, and the function has already verified that `length >= rpsi_len + 12`, so the buffer is large enough.\n\n11. Critical observation: The function uses `rpsi_len` to determine how much data to read, but it does not validate that `rpsi_len` is within a safe range relative to the buffer. However, the check `length < rpsi_len + 12` already ensures that the buffer is large enough to contain the payload, so `rpsi_len` cannot exceed `length - 12`.\n\n12. The `pj_strset` function is used to copy data into a string structure. It is safe as long as the source pointer is valid and the size is not too large. The size is `(rpsi->rpsi_bit_len + 7)/8`, which is at most `rpsi_len` (since `rpsi_bit_len <= rpsi_len * 8`), and `rpsi_len` is bounded by `length - 12`, which is safe.\n\n13. There is no use of unsafe functions like `strcpy`, `strcat`, `memcpy` without bounds checking \u2014 all operations are bounded by the length checks.\n\n14. The function performs multiple bounds checks:\n   - Input buffer size\n   - RTCP header fields\n   - Payload length derived from header\n   - Padding length\n   - Bit length sanity\n\n15. All data accesses are within the bounds of the provided buffer, and no integer overflows or underflows are possible due to the checks.\n\nConclusion: The function performs comprehensive input validation and bounds checking. It ensures that all data accesses are within the provided buffer, and it uses safe operations. There are no buffer overflows, out-of-bounds reads, or other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 356170, "project": "firejail", "commit_id": "1884ea22a90d225950d81c804f1771b42ae55f54", "project_url": "https://github.com/netblue30/firejail", "commit_url": "https://github.com/netblue30/firejail/commit/1884ea22a90d225950d81c804f1771b42ae55f54", "commit_message": "CVE-2022-31214: fixing the fix, one more time\n\nthe previous commit \"CVE-2022-31214: fixing the fix\"\nmade private-etc=fonts,fonts and similar commands\nfail with an error\n\nfix that regression by tolerating already existing\ndirectories", "ground_truth": 0, "cwe": ["CWE-94"], "cve": "CVE-2022-31214", "cve_desc": "A Privilege Context Switching issue was discovered in join.c in Firejail 0.9.68. By crafting a bogus Firejail container that is accepted by the Firejail setuid-root program as a join target, a local attacker can enter an environment in which the Linux user namespace is still the initial user namespace, the NO_NEW_PRIVS prctl is not activated, and the entered mount namespace is under the attacker's control. In this way, the filesystem layout can be adjusted to gain root privileges through execution of available setuid-root binaries such as su or sudo.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `build_dirs` is designed to traverse a source path (`src`) and create corresponding directory structure in the destination path (`dst`), preserving directory permissions.\n\n2) The function uses `src_prefix_len` and `dst_prefix_len` to skip prefix parts of the paths, then iterates through the remaining path components.\n\n3) The key logic:\n   - It iterates through the source path starting from `src + src_prefix_len + 1`\n   - For each path component (separated by '/'), it temporarily null-terminates the string at `*p` to isolate the component\n   - It checks if the component exists and is a directory using `stat(src, &s)`\n   - If it exists and is a directory, it creates the corresponding directory in `dst` using `mkdir`\n   - It preserves the directory's mode using `chmod`\n\n4) The critical issue:\n   - The function uses `stat(src, &s)` where `src` is the full path string\n   - However, when the function temporarily null-terminates `*p`, it modifies the `src` string in place\n   - This means that `stat(src, &s)` is called on a modified string that may not represent the original path\n   - For example, if the original path is `/a/b/c/d`, and we're processing the \"b\" component, `*p` is set to '\\0', making `src` effectively `/a\\0b/c/d`\n   - This causes `stat` to check `/a` instead of the full path `/a/b`, which could lead to incorrect behavior\n\n5) More importantly:\n   - The function uses `stat(src, &s)` with the modified `src` string\n   - This creates a time-of-check/time-of-use (TOCTOU) vulnerability\n   - An attacker could manipulate the filesystem between the time `stat` is called and when `mkdir` is called\n   - The `stat` call checks if a directory exists, but the `mkdir` call might create a different directory due to race conditions\n\n6) Additionally:\n   - The function doesn't validate that the path components are safe\n   - It doesn't check for symbolic links or other malicious path constructs\n   - The use of `mkdir` with `0700` permissions could be exploited if the directory structure is manipulated\n\n7) The vulnerability is particularly dangerous because:\n   - It's creating directories based on user-controlled input\n   - The path manipulation through null-termination creates a race condition\n   - An attacker could potentially create directories in unintended locations\n\n(1) YES: A security vulnerability detected."}
{"idx": 241311, "project": "mruby", "commit_id": "b1d0296a937fe278239bdfac840a3fd0e93b3ee9", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/b1d0296a937fe278239bdfac840a3fd0e93b3ee9", "commit_message": "class.c: clear method cache after `remove_method`.", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-1286", "cve_desc": "heap-buffer-overflow in mrb_vm_exec in mruby/mruby in GitHub repository mruby/mruby prior to 3.2. Possible arbitrary code execution if being exploited.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `mrb_remove_method` is designed to remove a method from a class in the MRuby runtime environment. It takes three parameters:\n   - `mrb`: the MRuby state (interpreter context),\n   - `c`: a pointer to a class structure (`struct RClass`),\n   - `mid`: a symbol representing the method name (method ID).\n\n2. The function first calls `MRB_CLASS_ORIGIN(c)` \u2014 this macro is used to ensure that the class is properly initialized and may perform some internal checks or side effects, but it does not appear to be a security concern.\n\n3. It retrieves the method table (`mt_tbl *h`) from the class: `h = c->mt`. This table holds the method definitions for the class.\n\n4. The function checks if `h` is non-null and if `mt_del(mrb, h, mid)` successfully removes the method (i.e., returns true). If so, it calls `mrb_mc_clear_by_class(mrb, c)` to clear any cached method calls for the class \u2014 this is a performance optimization and is safe.\n\n5. If the method is not found (i.e., `mt_del` returns false), the function calls `mrb_name_error(mrb, mid, ...)` to raise a name error with a message indicating that the method is not defined.\n\n6. The key security consideration: \n   - The function operates on internal data structures of the MRuby interpreter.\n   - It does not perform any input validation on `mid` (the method symbol) beyond what is inherent in the `mt_del` function.\n   - However, `mrb_sym` is a type used internally by MRuby to represent symbols (essentially unique identifiers), and it is not user-controllable in a way that would allow arbitrary memory access unless the symbol itself is malformed or invalid.\n   - The `mt_del` function is responsible for safely removing a method from the hash table, and it is assumed to be implemented correctly.\n   - The `mrb_name_error` function is used to report an error in a safe way \u2014 it does not expose internal memory or allow arbitrary code execution.\n\n7. There is no evidence of:\n   - Buffer overflow (no copying of untrusted data into fixed-size buffers),\n   - Use of unsafe string operations,\n   - Memory corruption via invalid pointer access,\n   - Unchecked user input leading to arbitrary code execution.\n\n8. The function is part of a well-designed, type-safe embedded scripting engine (MRuby), and the operations are within the bounds of the interpreter\u2019s internal safety mechanisms.\n\nConclusion: The code does not exhibit any obvious security vulnerabilities. It performs proper checks, uses internal data structures safely, and handles errors appropriately.\n\n(2) NO: No security vulnerability."}
{"idx": 274814, "project": "pjproject", "commit_id": "450baca94f475345542c6953832650c390889202", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/450baca94f475345542c6953832650c390889202", "commit_message": "Merge pull request from GHSA-26j7-ww69-c4qj", "ground_truth": 0, "cwe": ["CWE-787"], "cve": "CVE-2022-31031", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions prior to and including 2.12.1 a stack buffer overflow vulnerability affects PJSIP users that use STUN in their applications, either by: setting a STUN server in their account/media config in PJSUA/PJSUA2 level, or directly using `pjlib-util/stun_simple` API. A patch is available in commit 450baca which should be included in the next release. There are no known workarounds for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `pjstun_parse_msg` parses a STUN (Session Traversal Utilities for NAT) message from a buffer. It takes a buffer (`buf`), its length (`buf_len`), and a pointer to a `pjstun_msg` structure to fill.\n\n2) The function first checks the message type using `pj_ntohs(msg->hdr->type)` and validates it against known STUN message types. Unknown types result in an error return. This is a good security practice to prevent processing malformed or unexpected message types.\n\n3) It then checks the message length (`msg_len`) against the expected length: `buf_len - sizeof(pjstun_msg_hdr)`. If they don't match, it returns an error. This ensures the message length field is consistent with the actual buffer size, preventing potential buffer over-reads.\n\n4) The function then iterates through attributes in the message. It uses a loop that continues while:\n   - `msg_len > 0` (there's still data to process)\n   - `msg->attr_count < attr_max_cnt` (not exceeding the maximum number of attributes)\n\n5) Inside the loop:\n   - It reads the attribute header from the current position (`p_attr`)\n   - It calculates the total length of the attribute including header, rounds it up to a 4-byte boundary using `(len + 3) & ~3`\n   - It checks if the remaining `msg_len` is sufficient for this attribute. If not, it returns an error.\n   - It processes the attribute type, logging a warning for unknown types (but doesn't reject them outright)\n   - It updates `msg_len` and `p_attr` to move to the next attribute\n\n6) The function has a safety check: if `msg->attr_count` reaches `attr_max_cnt`, it logs a warning but continues. This prevents buffer overflow in the `msg->attr` array.\n\n7) The key security consideration: The function uses `pj_ntohs` to convert network byte order to host byte order, which is correct for parsing network data.\n\n8) The function properly bounds checks:\n   - It checks `msg_len` against the attribute length before reading\n   - It limits the number of attributes to `PJ_ARRAY_SIZE(msg->attr)`\n   - It uses `msg_len` to track remaining data\n\n9) The only potential issue is that unknown attribute types are only logged as warnings and not rejected. However, this is not a security vulnerability because:\n   - The function still validates the attribute length\n   - It doesn't execute any code based on unknown attribute types\n   - It doesn't perform any unsafe operations on unknown attributes\n   - The attribute data is simply skipped\n\n10) The function does not have any buffer overflows, out-of-bounds reads, or other classic vulnerabilities. All memory accesses are bounded by the length checks and array size limits.\n\n(2) NO: No security vulnerability."}
{"idx": 404192, "project": "pcre2", "commit_id": "03654e751e7f0700693526b67dfcadda6b42c9d0", "project_url": "https://github.com/PCRE2Project/pcre2", "commit_url": "https://github.com/PCRE2Project/pcre2/commit/03654e751e7f0700693526b67dfcadda6b42c9d0", "commit_message": "Fixed an issue affecting recursions in JIT", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2022-1587", "cve_desc": "An out-of-bounds read vulnerability was discovered in the PCRE2 library in the get_recurse_data_length() function of the pcre2_jit_compile.c file. This issue affects recursions in JIT-compiled regular expressions caused by duplicate data transfers.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose and Context**:\n   - The function `get_recurse_data_length` is part of a PCRE2 (Perl Compatible Regular Expressions) compiler backend, likely used in a JIT (Just-In-Time) compilation context.\n   - It calculates the length of data needed for recursion handling in a compiled regular expression, based on the bytecode (`cc`) and its structure.\n   - It uses `common->recurse_bitset` to track which capture groups or recursion points are used, and updates `length` accordingly.\n\n2. **Input Validation and Bounds Checking**:\n   - The function takes `cc` (current bytecode pointer) and `ccend` (end of bytecode), and iterates while `cc < ccend`.\n   - It uses `SLJIT_ASSERT(cc != NULL)` after `next_opcode`, which ensures that the bytecode pointer remains valid during traversal.\n   - The `switch` statement handles various opcodes (like OP_RECURSE, OP_KET, OP_CBRA, etc.), and each case advances `cc` by appropriate amounts based on opcode size and link fields.\n   - The use of `PRIVATE_DATA(cc)` and `GET(cc, 1)` suggests that the code is parsing variable-length opcodes, but these macros are assumed to be safe and bounds-checked by the surrounding code (as is typical in PCRE2).\n\n3. **Buffer and Memory Safety**:\n   - `memset(common->recurse_bitset, 0, common->recurse_bitset_size);` initializes a bitset used to track recursion state. The size is provided via `common->recurse_bitset_size`, which should be validated earlier in the call chain.\n   - The function does not perform any direct memory writes outside of this bitset, and all accesses to `common->recurse_bitset` are via `recurse_check_bit`, which is assumed to be safe (bounds-checked).\n   - There is no use of unsafe string functions (like `strcpy`, `strcat`, etc.), no direct user input manipulation, and no dynamic memory allocation.\n\n4. **Control Flow and Logic**:\n   - The function uses `SLJIT_ASSERT` statements to verify invariants (e.g., `common->control_head_ptr != 0`, `PRIVATE_DATA(cc) != 0`, `recurse_check_bit` returns true for expected offsets).\n   - These assertions are not runtime checks but debug-time checks. However, in a production build, they are disabled, so the code must be correct even without them.\n   - The logic for updating `length` is based on whether certain recursion or control flow markers are present. This is part of a JIT compilation strategy and is not directly exploitable via input unless the bytecode itself is malformed.\n\n5. **Potential Vulnerability Considerations**:\n   - Could a malformed or maliciously crafted regular expression cause an out-of-bounds access?\n     - The function relies on `cc < ccend` to bound the loop.\n     - Each opcode advances `cc` by a calculated amount (e.g., `1 + LINK_SIZE`, `1 + LINK_SIZE + IMM2_SIZE`, etc.).\n     - The use of `next_opcode(common, cc)` in the `default` case is critical. If this function is not correctly implemented, it could lead to infinite loops or buffer overflows.\n     - However, `next_opcode` is a standard helper in PCRE2 and is known to be safe when the bytecode is valid.\n   - The function does not validate the bytecode structure beyond what is implied by the opcode parsing. But this is not a vulnerability in the function itself \u2014 it's the responsibility of the caller to ensure valid bytecode.\n   - There is no direct user input being processed in this function. The input is bytecode generated from a regex pattern, which is already validated earlier in the compilation process.\n\n6. **Conclusion**:\n   - The function performs careful pointer arithmetic and uses assertions to validate assumptions.\n   - It does not contain any obvious buffer overflows, use-after-free, or unsafe memory operations.\n   - The logic is sound and consistent with safe bytecode interpretation in PCRE2.\n   - While a malformed regex could theoretically cause issues, that would be a vulnerability in the overall regex engine, not in this specific function.\n   - This function is part of a well-established, secure codebase (PCRE2), and no exploitable flaw is evident in the code as presented.\n\n(2) NO: No security vulnerability."}
{"idx": 292205, "project": "hexchat", "commit_id": "4e061a43b3453a9856d34250c3913175c45afe9d", "project_url": "https://github.com/hexchat/hexchat", "commit_url": "https://github.com/hexchat/hexchat/commit/4e061a43b3453a9856d34250c3913175c45afe9d", "commit_message": "Clean up handling CAP LS", "ground_truth": 0, "cwe": ["CWE-22"], "cve": "CVE-2016-2087", "cve_desc": "Directory traversal vulnerability in the client in HexChat 2.11.0 allows remote IRC servers to read or modify arbitrary files via a .. (dot dot) in the server name.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `inbound_cap_ls` processes a string of IRC capability extensions (`extensions_str`) and constructs a CAP REQ message to send to the server.\n\n2. A fixed-size buffer `buffer[256]` is declared to hold the constructed CAP REQ string.\n\n3. The function starts by copying the string \"CAP REQ :\" into the buffer using `strcpy`. This is safe because \"CAP REQ :\" is 8 characters long, and the buffer is 256 bytes, so no overflow occurs here.\n\n4. Then, the function uses `g_strlcat` to append each supported capability to the buffer. `g_strlcat` is a safe string concatenation function that ensures the total length does not exceed the specified size (sizeof(buffer) = 256). It also null-terminates the string properly.\n\n5. The loop iterates over each extension in `extensions_str`, and for each one:\n   - If the extension is \"sasl\" and the conditions for SASL authentication are met, it appends \"sasl \" to the buffer.\n   - Otherwise, it checks if the extension is in the `supported_caps` array. If so, it appends the extension followed by a space.\n\n6. The `g_strlcat` function is used in all cases where strings are appended to `buffer`, and it is called with `sizeof(buffer)` as the size limit. This prevents buffer overflow by ensuring that the total length of the string never exceeds 255 characters (leaving room for null termination).\n\n7. After processing all extensions, the function checks `want_cap`. If true, it emits a signal and sends the CAP REQ message via `tcp_sendf`, using `g_strchomp` to remove trailing whitespace. `g_strchomp` is safe and only removes whitespace from the end.\n\n8. The `tcp_sendf` function is used to send the message. The format string is `%s\\r\\n`, and the argument is the buffer content. Since the buffer is properly null-terminated and its length is bounded by `sizeof(buffer)`, there is no risk of buffer overflow in `tcp_sendf`.\n\n9. The function also handles `CAP END` when SASL is not requested, sending \"CAP END\\r\\n\" via `tcp_send_len`. This is a fixed string and safe.\n\n10. The only potential risk would be if `extensions_str` contains a very long string, but `g_strsplit` is used with a limit of 0 (meaning no limit), which could theoretically lead to a large number of extensions. However, even in that case, `g_strlcat` is used with a size limit, so the buffer cannot overflow.\n\n11. The `supported_caps` array is assumed to be a known, fixed list of valid capabilities, so no injection or arbitrary input is processed without validation.\n\nConclusion: All string operations are performed using safe functions (`g_strlcat`, `g_strchomp`, `g_strsplit`, `g_strfreev`) that respect buffer boundaries and null termination. The fixed-size buffer is properly managed, and no unchecked or unsafe string operations are used.\n\n(2) NO: No security vulnerability."}
{"idx": 267917, "project": "tensorflow", "commit_id": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe", "commit_message": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63e", "ground_truth": 0, "cwe": ["CWE-703"], "cve": "CVE-2021-29552", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Input Validation**:\n   - The function `Compute` takes three inputs: `input`, `segment_id`, and `num_segments_tensor`.\n   - It checks that `num_segments_tensor` is not empty (`NumElements() != 0`), which prevents division by zero or invalid allocation.\n   - It ensures `segment_id` has at least rank 1 (`segment_dims != 0`), which is necessary for meaningful indexing.\n   - It validates that the rank of `segment_id` is not greater than the rank of `input` (`segment_dims <= input_dims`), which is a correct bound check.\n   - It checks that each dimension of `segment_id` matches the corresponding dimension of `input` (`dim_size(i) == input_shape.dim_size(i)`), ensuring shape compatibility.\n\n2. **Output Tensor Allocation**:\n   - The output tensor is allocated using `context->allocate_output`, with a shape derived from `GetOutputShape(...)`. This is safe as long as `GetOutputShape` is correctly implemented and does not produce invalid or overly large sizes.\n\n3. **Flat Tensor Access**:\n   - The code uses `.flat<tstring>()` for `output_tensor`, `segment_id`, and `input`. This assumes that the tensors are contiguous and of the correct type. Since the input types are validated earlier, this is acceptable.\n\n4. **Segment ID Validation**:\n   - The loop over `flat_segment_id.size()` checks that each segment ID is within the valid range: `0 <= flat_segment_id(i) < num_segments`. This prevents out-of-bounds access to the output tensor and is a critical safety check.\n\n5. **Strides and Offsets**:\n   - `GetStrides` and `GetFlattenedRelativeOffsets` are used to compute offsets for flattening multi-dimensional arrays. These functions are assumed to be correctly implemented and return valid strides and offsets.\n\n6. **String Concatenation**:\n   - The nested loops iterate over `start_offset` and `relative_offset_set`, computing indices into the flattened tensors.\n   - It appends `separator_.c_str()` (a string) to `output_flat(output_index)` if it's non-empty, then appends `flat_input(offset)`.\n   - The `append` operation is on `tstring`, which is a string type. The code does not perform any bounds checking on the string content itself, but the indices are validated via the earlier checks.\n\n7. **Potential Security Concerns**:\n   - The main risk would be if `num_segments` is very large, leading to excessive memory allocation or long execution time (DoS via resource exhaustion).\n   - However, `num_segments` comes from `num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()()`, which is validated to be non-zero, but not bounded. If `num_segments` is extremely large (e.g., 2^63), then `output_tensor` allocation could fail or cause memory exhaustion.\n   - But the code uses `context->allocate_output`, which is part of a framework (likely TensorFlow) that typically enforces memory limits and checks for reasonable tensor sizes. So this is more of a resource exhaustion concern than a direct security vulnerability like buffer overflow or injection.\n   - The string operations (`append`) are safe because:\n     - The indices are validated (`flat_segment_id(i) < num_segments` and `>= 0`).\n     - The `flat_input(offset)` is accessed only via valid `offset` computed from `relative_offset_set`, which is derived from `small_stride` and `big_stride`, which are based on valid tensor shapes.\n     - No user-controlled data is directly used in string formatting or concatenation without bounds checking.\n\n8. **Conclusion**:\n   - All critical bounds checks are in place: shape compatibility, segment ID range, and index validity.\n   - The code does not perform unsafe operations like buffer overflows, use of uninitialized memory, or direct string formatting with user input.\n   - While there is a theoretical risk of resource exhaustion (e.g., if `num_segments` is huge), this is not a classic security vulnerability like buffer overflow, injection, or memory corruption. It's more of a denial-of-service risk, but not exploitable in the same way as the examples provided (e.g., buffer overflow, SQLi, XSS).\n   - The code follows safe practices: input validation, bounds checking, and use of safe APIs.\n\n(2) NO: No security vulnerability."}
{"idx": 349251, "project": "squashfs-tools", "commit_id": "e0485802ec72996c20026da320650d8362f555bd", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/e0485802ec72996c20026da320650d8362f555bd", "commit_message": "Unsquashfs: additional write outside destination directory exploit fix\n\nAn issue on github (https://github.com/plougher/squashfs-tools/issues/72)\nshowed how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and '..') can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nSince then it has been shown that specially crafted Squashfs filesystems\nthat contain a symbolic link pointing outside of the destination directory,\ncoupled with an identically named file within the same directory, can\ncause Unsquashfs to write files outside of the destination directory.\n\nSpecifically the symbolic link produces a pathname pointing outside\nof the destination directory, which is then followed when writing the\nduplicate identically named file within the directory.\n\nThis commit fixes this exploit by explictly checking for duplicate\nfilenames within a directory.  As directories in v2.1, v3.x, and v4.0\nfilesystems are sorted, this is achieved by checking for consecutively\nidentical filenames.  Additionally directories are checked to\nensure they are sorted, to avoid attempts to evade the duplicate\ncheck.\n\nVersion 1.x and 2.0 filesystems (where the directories were unsorted)\nare sorted and then the above duplicate filename check is applied.\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 0, "cwe": ["CWE-200"], "cve": "CVE-2021-41072", "cve_desc": "squashfs_opendir in unsquash-2.c in Squashfs-Tools 4.5 allows Directory Traversal, a different vulnerability than CVE-2021-40153. A squashfs filesystem that has been crafted to include a symbolic link and then contents under the same filename in a filesystem can cause unsquashfs to first create the symbolic link pointing outside the expected directory, and then the subsequent write operation will cause the unsquashfs process to write through the symbolic link elsewhere in the filesystem.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its metadata, and building a linked list of directory entries (`struct dir_ent`).\n\n2. The function starts by allocating a buffer `buffer` of size `sizeof(struct squashfs_dir_entry) + SQUASHFS_NAME_LEN + 1`, aligned properly. This buffer is used to read directory entries and their names.\n\n3. The function reads the directory header (`dirh`) and validates that `dir_count` does not exceed `SQUASHFS_DIR_COUNT`. This prevents potential integer overflow or excessive memory allocation.\n\n4. It then loops through each directory entry, reading the `struct squashfs_dir_entry` into the `dire` pointer (which points into the `buffer`), and then reads the name into `dire->name`.\n\n5. A critical check is performed: `if(dire->size >= SQUASHFS_NAME_LEN) { ERROR(\"...\"); goto corrupted; }`. This ensures that the name length is not too long, preventing buffer overflow when copying the name.\n\n6. The name is read with `read_directory_data(dire->name, &start, &offset, dire->size + 1)`. The size passed is `dire->size + 1`, which includes space for the null terminator. This is correct.\n\n7. After reading, the code does: `dire->name[dire->size + 1] = '\\0';`. This is suspicious. The `dire->name` buffer is allocated as part of the `buffer` which is of size `sizeof(struct squashfs_dir_entry) + SQUASHFS_NAME_LEN + 1`. The `dire->size` is checked to be less than `SQUASHFS_NAME_LEN`, so `dire->size + 1` is at most `SQUASHFS_NAME_LEN`. But the buffer is only `SQUASHFS_NAME_LEN + 1` bytes long, so `dire->name` is a pointer into this buffer.\n\n   However, `dire->name` is not a fixed-size array \u2014 it's a pointer to a location within the `buffer`. The `buffer` is large enough to hold the `struct squashfs_dir_entry` and then `SQUASHFS_NAME_LEN + 1` bytes for the name. But the `dire->name` field is likely defined as `char name[1]` or similar (flexible array member), so it's not a separate allocation.\n\n   The key issue: `dire->name[dire->size + 1] = '\\0';` \u2014 this writes one byte beyond the end of the name if `dire->size + 1` is the actual size. But the name is read with `read_directory_data(dire->name, ..., dire->size + 1)`, which reads exactly `dire->size + 1` bytes. So the name is already null-terminated by the read operation. Writing `dire->name[dire->size + 1] = '\\0'` is redundant and potentially dangerous.\n\n   But more importantly: the `buffer` is only `SQUASHFS_NAME_LEN + 1` bytes long. If `dire->size` is close to `SQUASHFS_NAME_LEN`, and the name is read with `dire->size + 1`, then the buffer is exactly sized to hold the name. But `dire->name[dire->size + 1] = '\\0'` attempts to write to index `dire->size + 1`, which is **one past the end** of the buffer if `dire->size + 1 == SQUASHFS_NAME_LEN + 1`. That is, if `dire->size == SQUASHFS_NAME_LEN`, then `dire->name[dire->size + 1]` is at index `SQUASHFS_NAME_LEN + 1`, which is **out of bounds** of the `buffer`.\n\n   However, earlier we have: `if(dire->size >= SQUASHFS_NAME_LEN) { ... goto corrupted; }`. So `dire->size` is strictly less than `SQUASHFS_NAME_LEN`. Therefore, `dire->size + 1 <= SQUASHFS_NAME_LEN`. So `dire->name[dire->size + 1]` is at most `SQUASHFS_NAME_LEN`, which is within the `buffer` of size `SQUASHFS_NAME_LEN + 1`. So the write is safe.\n\n   But wait: `dire->name` is a pointer into the `buffer`, and the `buffer` is `SQUASHFS_NAME_LEN + 1` bytes. The `dire->name` field is placed after the `struct squashfs_dir_entry`, so the offset is `sizeof(struct squashfs_dir_entry)`. The total buffer size is `sizeof(struct squashfs_dir_entry) + SQUASHFS_NAME_LEN + 1`, so the name buffer is `SQUASHFS_NAME_LEN + 1` bytes long.\n\n   Therefore, `dire->name` points to a region of `SQUASHFS_NAME_LEN + 1` bytes. The read operation reads `dire->size + 1` bytes into `dire->name`, and `dire->size < SQUASHFS_NAME_LEN`, so `dire->size + 1 <= SQUASHFS_NAME_LEN`. So the read is safe.\n\n   Then `dire->name[dire->size + 1] = '\\0'` \u2014 this writes to index `dire->size + 1`, which is at most `SQUASHFS_NAME_LEN`. But the buffer is only `SQUASHFS_NAME_LEN + 1` bytes, so index `SQUASHFS_NAME_LEN` is valid (0-based), and `SQUASHFS_NAME_LEN + 1` is out of bounds.\n\n   Wait: `dire->name[dire->size + 1]` \u2014 if `dire->size + 1 == SQUASHFS_NAME_LEN`, then we are writing to index `SQUASHFS_NAME_LEN`, which is the last byte of the buffer (since buffer is `SQUASHFS_NAME_LEN + 1` bytes long). So index `SQUASHFS_NAME_LEN` is valid.\n\n   But the buffer is `SQUASHFS_NAME_LEN + 1` bytes, so indices 0 to `SQUASHFS_NAME_LEN` are valid. So `dire->name[dire->size + 1]` is at index `dire->size + 1`, which is at most `SQUASHFS_NAME_LEN`, so it's valid.\n\n   However, the read operation already read `dire->size + 1` bytes into `dire->name`, so the name is already null-terminated at `dire->name[dire->size]`. Writing `dire->name[dire->size + 1] = '\\0'` is redundant and potentially dangerous if `dire->size + 1` is not the correct offset.\n\n   But the real issue: the `buffer` is only `SQUASHFS_NAME_LEN + 1` bytes long, and `dire->name` is placed at the end of the `struct squashfs_dir_entry`. The `struct squashfs_dir_entry` has a `name` field that is a flexible array member. So the `buffer` is large enough to hold the header and the name.\n\n   However, the `dire->name` is not allocated separately \u2014 it's a pointer into the `buffer`. So when we do `dire->name[dire->size + 1] = '\\0'`, we are writing to a location that is within the `buffer` because `dire->size + 1 <= SQUASHFS_NAME_LEN`, and the buffer has `SQUASHFS_NAME_LEN + 1` bytes for the name.\n\n   So this write is safe.\n\n8. The function then calls `check_name(dire->name, dire->size + 1)` to validate the name. This checks for invalid characters like `/`, `.`, `..`. This is good.\n\n9. The function then allocates a `struct dir_ent` and copies the name with `strdup(dire->name)`. This is safe because `dire->name` is null-terminated and the length is checked.\n\n10. The function builds a linked list of entries and finally calls `check_directory(dir)` to ensure no duplicate names and proper sorting.\n\n11. The function returns `dir` on success, or `NULL` on error.\n\n12. The only potential issue is the redundant null-termination write: `dire->name[dire->size + 1] = '\\0'`. But since the name was already read with `dire->size + 1` bytes, and the read function likely null-terminated it, this is redundant. However, it's not a vulnerability because the buffer is large enough and the index is within bounds.\n\n13. The function uses `read_directory_data` to read data from the filesystem. This function is assumed to be safe and bounds-checked.\n\n14. The function checks `dir_count` and `dire->size` against `SQUASHFS_DIR_COUNT` and `SQUASHFS_NAME_LEN`, respectively, preventing buffer overflows.\n\n15. The `buffer` is allocated on the stack and is of fixed size, so no heap overflow.\n\n16. The `strdup` and `malloc` calls are checked for `NULL`, and `MEM_ERROR()` is called if allocation fails.\n\n17. The `check_directory` function is called to prevent duplicate names and unsorted entries, which is a good security practice.\n\nAfter careful analysis, there is no buffer overflow, no memory corruption, no injection vulnerability, and all input is validated before use. The redundant null-termination write is not a security vulnerability because it is within bounds.\n\n(2) NO: No security vulnerability."}
{"idx": 199836, "project": "pjproject", "commit_id": "077b465c33f0aec05a49cd2ca456f9a1b112e896", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/077b465c33f0aec05a49cd2ca456f9a1b112e896", "commit_message": "Merge pull request from GHSA-7fw8-54cv-r7pm", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-21723", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In versions 2.11.1 and prior, parsing an incoming SIP message that contains a malformed multipart can potentially cause out-of-bound read access. This issue affects all PJSIP users that accept SIP multipart. The patch is available as commit in the `master` branch. There are no known workarounds.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `pj_scan_get_char` is designed to read a character from a scanner's current position (`scanner->curptr`), increment the pointer, and optionally skip whitespace if the next character is a space and `scanner->skip_ws` is enabled.\n\n2. The function first reads the current character into `chr` via `*scanner->curptr`. This is a dereference of a pointer, so we must ensure that `scanner->curptr` is valid and points to a valid memory location.\n\n3. The function checks if `chr` is 0 (i.e., null terminator). If so, it calls `pj_scan_syntax_err(scanner)` and returns 0. This is a valid check to detect end-of-input or null-terminated strings, which is typical in scanner implementations.\n\n4. Then, `scanner->curptr` is incremented. This is a critical point: if `scanner->curptr` was already pointing to the end of the input buffer (e.g., at a null terminator), incrementing it could lead to a buffer overflow or out-of-bounds memory access.\n\n5. However, the function does not validate whether `scanner->curptr` is within bounds before incrementing. It assumes that the input is well-formed and that `curptr` is not at the end of the buffer. But if the input is malformed or the scanner is misused (e.g., `curptr` points to the last valid character and is incremented), this could result in reading past the end of the buffer.\n\n6. The function does not perform any bounds checking on `scanner->curptr` before incrementing it. This is a classic example of a buffer over-read vulnerability, where the code dereferences a pointer after it has been incremented past the end of the buffer, potentially leading to undefined behavior or information disclosure.\n\n7. Although the function checks for `chr == 0` (null) before incrementing, this only prevents the case where the current character is null. It does not prevent the case where `curptr` is already at the last valid position and incrementing it leads to an out-of-bounds access.\n\n8. Therefore, the function is vulnerable to buffer over-read if the input is not properly bounded or if the scanner state is corrupted.\n\n(1) YES: A security vulnerability detected."}
{"idx": 197057, "project": "drogon", "commit_id": "3c785326c63a34aa1799a639ae185bc9453cb447", "project_url": "https://github.com/drogonframework/drogon", "commit_url": "https://github.com/drogonframework/drogon/commit/3c785326c63a34aa1799a639ae185bc9453cb447", "commit_message": "Prevent malformed upload path causing arbitrary write (#1174)", "ground_truth": 1, "cwe": ["CWE-552"], "cve": "CVE-2022-25297", "cve_desc": "This affects the package drogonframework/drogon before 1.7.5. The unsafe handling of file names during upload using HttpFile::save() method may enable attackers to write files to arbitrary locations outside the designated target folder.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `HttpFileImpl::save` takes a `std::string &path` parameter representing the destination path where a file should be saved.\n\n2. The function first asserts that the path is not empty, which is a good defensive check.\n\n3. It checks if `fileName_` is empty \u2014 if so, it returns -1. This prevents saving without a valid file name.\n\n4. The input path is converted to a native path using `utils::toNativePath(path)`, which likely handles platform-specific path separators (e.g., converting forward slashes to backslashes on Windows). This is safe as long as the function doesn't introduce path traversal vulnerabilities.\n\n5. The key logic is in the path normalization and validation:\n   - It checks if the path is not absolute (`!fsPath.is_absolute()`).\n   - Then it checks if the path has no parent path, or if the first component (the root part) is neither \".\" nor \"..\".\n     - This is intended to prevent relative path traversal (e.g., `../` or `./`).\n     - However, note that `fsPath.begin()->string()` only checks the first component of the path. This means that even if the path is relative, it only validates the first segment.\n\n6. Example: Consider a path like `../../etc/passwd`. Even though it starts with `..`, the check `fsPath.begin()->string() != \".\" && fsPath.begin()->string() != \"..\"` would catch the first `..` and reject it. So this check does prevent simple traversal via `..` at the start.\n\n7. However, what if the path is something like `a/../b`? The first component is `a`, which is neither `.` nor `..`, so it passes the check. But `a/../b` resolves to `b` \u2014 which could be used to traverse directories if the path is not properly normalized.\n\n8. The code does not perform full path normalization (e.g., resolving `..` components) before checking. It only checks the first component. This means that a path like `a/../b` would be accepted, and when later combined with `fsUploadPath / fsPath`, it could result in writing to a location outside the intended upload directory.\n\n9. The function then appends `fsFileName` to the path and calls `saveTo(fsPath / fsFileName)`.\n\n10. The critical issue: **The code does not normalize the path after combining it with the upload path.** It relies only on checking the first component of the relative path. This is insufficient to prevent path traversal attacks.\n\n11. For example, an attacker could provide a path like `a/../config.txt`. The first component is `a`, so it passes the check. But when combined with the upload path, it could result in writing to a file in a parent directory of the upload directory \u2014 a classic path traversal vulnerability.\n\n12. Additionally, the code does not validate that the final path is within the upload directory (e.g., using `fsPath.is_relative()` and checking that it's a subpath of `fsUploadPath`). This is a missing security control.\n\n13. Therefore, despite some checks, the code is vulnerable to path traversal attacks due to insufficient path validation and lack of normalization.\n\n(1) YES: A security vulnerability detected."}
{"idx": 201007, "project": "pjproject", "commit_id": "560a1346f87aabe126509bb24930106dea292b00", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/560a1346f87aabe126509bb24930106dea292b00", "commit_message": "Merge pull request from GHSA-f5qg-pqcg-765m", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-24764", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C. Versions 2.12 and prior contain a stack buffer overflow vulnerability that affects PJSUA2 users or users that call the API `pjmedia_sdp_print(), pjmedia_sdp_media_print()`. Applications that do not use PJSUA2 and do not directly call `pjmedia_sdp_print()` or `pjmedia_sdp_media_print()` should not be affected. A patch is available on the `master` branch of the `pjsip/pjproject` GitHub repository. There are currently no known workarounds.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `print_media_desc` is responsible for formatting an SDP (Session Description Protocol) media description into a character buffer `buf` of size `len`.\n\n2) The function first checks if the provided buffer size `len` is sufficient to hold the \"m=\" line (media description), which includes:\n   - The \"m=\" prefix (2 chars)\n   - Media type (m->desc.media.slen)\n   - Port number (variable length, up to ~10 digits)\n   - Port count (if >1, with '/' and digits)\n   - Transport protocol (m->desc.transport.slen)\n   - Format list (m->desc.fmt_count entries, each with their own length)\n   - CRLF at the end\n   - Plus some extra space (12+24) for safety\n\n   The check: `if (len < (pj_size_t)m->desc.media.slen + m->desc.transport.slen + 12 + 24)` is intended to ensure buffer space.\n\n3) The function then proceeds to copy data into the buffer using:\n   - `*p++ = 'm'; *p++ = '=';`\n   - `pj_memcpy(p, m->desc.media.ptr, m->desc.media.slen);`\n   - `pj_utoa(m->desc.port, p);` \u2014 converts integer to string\n   - `pj_memcpy` for transport and format fields\n   - `print_connection_info`, `print_bandw`, `print_attr` \u2014 which are called with `p` and `end-p` (remaining space)\n\n4) The key safety checks:\n   - The initial length check ensures the buffer is large enough for the \"m=\" line.\n   - Each subsequent function call (like `print_connection_info`, `print_bandw`, `print_attr`) is passed the remaining buffer space (`end - p`), and returns the number of bytes written or -1 on error.\n   - The function checks the return value of these calls and returns -1 if any fails, preventing overflow.\n\n5) The `pj_utoa` function is used to convert integers to strings. It is assumed to be safe and not overflow the buffer, as it only writes the digits of the number and the caller ensures there's enough space.\n\n6) The `pj_memcpy` calls are safe because they copy exactly `slen` bytes, and the buffer size was validated upfront.\n\n7) The loop over `m->attr_count`, `m->bandw_count`, and `m->fmt_count` is safe because each call to `print_*` functions returns the number of bytes written, and the function checks for negative return values (error), which would abort the process.\n\n8) The final return is `(int)(p - buf)`, which is the total number of bytes written.\n\n9) There is no direct buffer overflow because:\n   - The initial length check is conservative (12+24 extra space).\n   - All subsequent writes are bounded by the remaining buffer space (`end - p`).\n   - Each function call returns the actual number of bytes written, and the function checks for errors.\n\n10) The only potential risk would be if the length check is insufficient, but the 12+24 buffer is a generous safety margin for port numbers, transport, and format strings.\n\nConclusion: The function uses proper bounds checking, validates buffer size upfront, and uses safe string and memory copy operations with length checks. All functions that write to the buffer are called with the remaining space, and errors are checked.\n\n(2) NO: No security vulnerability."}
{"idx": 210692, "project": "ImageMagick6", "commit_id": "b268ce7a59440972f4476b9fd98104b6a836d971", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/b268ce7a59440972f4476b9fd98104b6a836d971", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1337", "ground_truth": 1, "cwe": ["CWE-835"], "cve": "CVE-2018-18024", "cve_desc": "In ImageMagick 7.0.8-13 Q16, there is an infinite loop in the ReadBMPImage function of the coders/bmp.c file. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted bmp file.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThis is a C function `ReadBMPImage` from the ImageMagick library, responsible for reading BMP (Bitmap) image files. It parses the BMP file header, validates metadata, reads pixel data, and converts it into an internal image representation.\n\nThe function handles various BMP formats (OS/2, Windows, version 5), supports compression (BI_RGB, BI_RLE4, BI_RLE8, BI_BITFIELDS), color palettes, bitfields, and alpha channels.\n\n---\n\n### Step 2: Identify potential security risks\nSecurity vulnerabilities in image parsers typically arise from:\n- Buffer overflows (due to improper bounds checking)\n- Integer overflows or underflows (leading to incorrect memory allocation)\n- Use of untrusted input in arithmetic or memory operations\n- Improper validation of file format fields\n- Use of unsafe functions (e.g., `strcpy`, `memcpy` without bounds)\n\nLet\u2019s examine key areas:\n\n#### A. Input validation and bounds checking\n- The function reads the BMP header and validates:\n  - Magic bytes (`BM`, `CI`)\n  - File size vs. actual blob size\n  - Image dimensions (`width`, `height`) \u2014 checks for \u2264 0\n  - `planes` must be 1\n  - `bits_per_pixel` must be valid (1, 4, 8, 16, 24, 32)\n  - `number_colors` must not exceed `1 << bits_per_pixel` for indexed images\n  - Compression type validation (e.g., BI_RLE4 only allowed with 4 bpp)\n\nThese checks are robust and prevent malformed or maliciously crafted headers from causing invalid memory access.\n\n#### B. Memory allocation and size calculations\n- Memory is allocated using `AcquireVirtualMemory` and `AcquireQuantumMemory`, which are safe functions that check for overflow and return `NULL` on failure.\n- Key size calculations:\n  - `bytes_per_line = 4 * ((image->columns * bmp_info.bits_per_pixel + 31) / 32);`\n    - This is a standard alignment calculation for BMP scanlines (padded to 32-bit boundaries).\n    - The expression uses `+31` to round up, and division by 32 ensures alignment.\n    - This is safe because `image->columns` is validated earlier (positive), and `bits_per_pixel` is limited to 32.\n  - `length = (size_t) bytes_per_line * image->rows;`\n    - This could be a potential overflow point if `bytes_per_line` and `image->rows` are large.\n    - However, the code checks:\n      ```c\n      if (((MagickSizeType) length/8) > GetBlobSize(image))\n        ThrowReaderException(CorruptImageError,\"InsufficientImageDataInFile\");\n      ```\n      This checks whether the expected pixel data size (in bytes) exceeds the file size. Since `length` is cast to `MagickSizeType` (a large unsigned type), and compared to `GetBlobSize(image)`, this prevents overflow issues in the comparison.\n\n  - The use of `MagickSizeType` for size comparisons is a strong indicator of defensive programming against integer overflow.\n\n#### C. Use of `ReadBlob` and `SeekBlob`\n- `ReadBlob` is used to read data into buffers (`magick`, `bmp_colormap`, `pixels`).\n- The function checks return values:\n  ```c\n  count = ReadBlob(image, 2, magick);\n  if (count != 2) ...\n  ```\n  This prevents reading beyond the file boundary.\n\n- `SeekBlob` is used with `start_position + bmp_info.offset_bits`, but the function checks:\n  ```c\n  offset = SeekBlob(image, start_position + bmp_info.offset_bits, SEEK_SET);\n  if (offset < 0) ...\n  ```\n  This ensures the seek is valid.\n\n#### D. Pixel data processing\n- The code processes pixel data in loops, using `p` as a pointer into the `pixels` buffer.\n- For each pixel format (1, 4, 8, 16, 24, 32), the code:\n  - Reads data from `pixels` (allocated via `AcquireVirtualMemory`)\n  - Uses bounds-checked access (e.g., `x < image->columns`)\n  - Uses `QueueAuthenticPixels` and `SyncAuthenticPixels` to safely access image pixel buffers.\n\n- No direct use of unsafe functions like `strcpy`, `memcpy`, or `sprintf`.\n\n#### E. Use of `IsValidColormapIndex`\n- In the 4-bit and 8-bit cases, `IsValidColormapIndex` is called to validate index values before setting them.\n- This prevents out-of-bounds access to the colormap.\n\n#### F. Handling of compression (RLE, bitfields)\n- RLE decoding is handled via `DecodeImage`, which is a separate function that likely performs its own bounds checks.\n- Bitfield masks are used safely with shift and mask operations, and the code validates that the masks are non-zero before shifting.\n\n#### G. Final checks\n- The function checks `EOFBlob(image)` at the end to detect premature EOF.\n- It uses `IsBMP(magick,2)` to detect multiple images in a file, and loops accordingly \u2014 but only if the next 2 bytes are valid BMP magic.\n\n---\n\n### Step 3: Conclusion\nThe code demonstrates strong defensive programming:\n- Input validation at every step\n- Safe memory allocation with overflow checks\n- Bounds checking in loops\n- Use of safe functions (`AcquireVirtualMemory`, `AcquireQuantumMemory`)\n- Size comparisons using `MagickSizeType` to prevent overflow\n- Proper error handling with `ThrowReaderException`\n\nThere are **no obvious buffer overflows, integer overflows, or unsafe memory operations**.\n\nWhile the code is complex and large, **all critical operations are protected by validation and safe memory management**.\n\n---\n\n### Final Answer:\n(2) NO: No security vulnerability."}
{"idx": 200695, "project": "linux", "commit_id": "fc739a058d99c9297ef6bfd923b809d85855b9a9", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9", "commit_message": "misc: fastrpc: prevent memory leak in fastrpc_dma_buf_attach\n\nIn fastrpc_dma_buf_attach if dma_get_sgtable fails the allocated memory\nfor a should be released.\n\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nLink: https://lore.kernel.org/r/20190925152742.16258-1-navid.emamdoost@gmail.com\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>", "ground_truth": 1, "cwe": ["CWE-401"], "cve": "CVE-2019-19069", "cve_desc": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `fastrpc_dma_buf_attach` is responsible for attaching a DMA buffer to a device, creating a new attachment structure (`a`) and linking it to the buffer's list of attachments.\n\n2. The function allocates memory for `a` using `kzalloc` with `GFP_KERNEL`, which is appropriate for kernel space allocations. If allocation fails, it returns `-ENOMEM`, which is correct behavior.\n\n3. It calls `dma_get_sgtable` to get a scatterlist table for the DMA buffer. This function is part of the DMA API and is expected to handle memory mapping correctly. The return value is checked, and if it fails, an error is logged and `-EINVAL` is returned. This is proper error handling.\n\n4. The function sets `a->dev = attachment->dev`, which is safe since `attachment->dev` is provided by the caller and is expected to be valid.\n\n5. It initializes the `a->node` list head with `INIT_LIST_HEAD`, which is correct.\n\n6. It assigns `attachment->priv = a`, which is standard practice for storing private data in a DMA buffer attachment.\n\n7. The function then acquires a mutex (`buffer->lock`) before adding the new attachment to the list (`list_add(&a->node, &buffer->attachments)`), and releases it afterward. This ensures thread safety when modifying the shared list of attachments.\n\n8. The code does not perform any input validation on `dmabuf` or `attachment` beyond checking for null pointers (which is not shown but implied by the function signature and usage). However, since this is a kernel driver function and the parameters are passed from the DMA buffer framework, they are generally trusted and validated earlier in the call chain.\n\n9. There is no use of unsafe string operations, memory copying without bounds checking, or direct user input manipulation.\n\n10. The function does not expose any sensitive data or allow arbitrary memory access. The operations are all within the kernel's DMA buffer management framework, and the use of `kzalloc`, proper error handling, and mutex protection indicates robustness.\n\nConclusion: The code follows secure kernel programming practices. It handles memory allocation, error conditions, and concurrent access properly. There are no obvious buffer overflows, use-after-free, race conditions, or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 195409, "project": "gpac", "commit_id": "64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/64a2e1b799352ac7d7aad1989bc06e7b0f2b01db", "commit_message": "fixed #2092", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-4043", "cve_desc": "NULL Pointer Dereference in GitHub repository gpac/gpac prior to 1.1.0.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `gitn_box_del` is designed to free memory allocated for a `GroupIdToNameBox` structure, which is a type of box in a media file format (likely ISO Base Media File Format or similar).\n\n2. The function starts by casting the input `s` to a `GroupIdToNameBox *` pointer named `ptr`. It then checks if `ptr` is NULL. If it is, the function returns early. This is a safe practice to prevent null pointer dereference.\n\n3. The function then iterates over `ptr->nb_entries`, which represents the number of entries in the `entries` array. For each entry, it checks if `ptr->entries[i].name` is non-NULL, and if so, frees it using `gf_free`. This prevents memory leaks for dynamically allocated names.\n\n4. After freeing all the individual names, it checks if `ptr->entries` is non-NULL and frees it using `gf_free`. This ensures the array of entries is properly deallocated.\n\n5. Finally, it frees the `ptr` itself (the main structure) using `gf_free`.\n\n6. All memory deallocation is done in a safe order: individual name strings are freed first, then the array of entries, then the main structure. The checks for NULL before freeing are present and correct.\n\n7. There are no obvious issues such as double-free, use-after-free, or buffer overflows. The loop bounds are controlled by `ptr->nb_entries`, which is assumed to be a valid count (though not validated in this function, but that would be a separate issue). However, since this is a cleanup function and the structure is assumed to be valid when passed in, this is acceptable.\n\n8. The function does not perform any input validation on `ptr->nb_entries` or `ptr->entries`, but this is not a vulnerability in itself if the caller is responsible for maintaining the integrity of the structure. The function is only responsible for freeing memory safely.\n\n9. No unsafe functions like `strcpy`, `sprintf`, or `gets` are used. No dynamic memory allocation is performed here\u2014only deallocation.\n\nConclusion: The function correctly and safely frees all allocated memory in the correct order, with proper null checks. There are no security vulnerabilities present in this code snippet.\n\n(2) NO: No security vulnerability."}
{"idx": 196790, "project": "tensorflow", "commit_id": "a4e138660270e7599793fa438cd7b2fc2ce215a6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a4e138660270e7599793fa438cd7b2fc2ce215a6", "commit_message": "Add remaining validation to `sdca_internal.cc`\n\nPiperOrigin-RevId: 387738010\nChange-Id: I28eedcfd87a53aaf34deb075acea1f8c95470808", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2021-37672", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can read from outside of bounds of heap allocated data by sending specially crafted illegal arguments to `tf.raw_ops.SdcaOptimizerV2`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/sdca_internal.cc#L320-L353) does not check that the length of `example_labels` is the same as the number of examples. We have patched the issue in GitHub commit a4e138660270e7599793fa438cd7b2fc2ce215a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `Initialize` is part of a TensorFlow OpKernel and processes input tensors for sparse and dense features, example weights, and labels.\n\n2) Input validation is performed for:\n   - `sparse_example_indices_inputs`: size checked against `num_sparse_features`\n   - `sparse_feature_indices_inputs`: size checked against `num_sparse_features`\n   - `sparse_feature_values_inputs`: only checked if `num_sparse_features_with_values > 0`\n   - `example_weights`: size checked against `std::numeric_limits<int>::max()`\n   - `dense_features_inputs`: input list retrieved and size validated implicitly through the loop\n\n3) The function checks if `example_weights.size()` exceeds `std::numeric_limits<int>::max()`, which is a critical safety check to prevent integer overflow when casting to `int` later.\n\n4) The cast `static_cast<int>(example_weights.size())` is safe because the previous check ensures `example_weights.size() < std::numeric_limits<int>::max()`, so the value fits in an `int`.\n\n5) The function uses `resize()` on vectors with `num_examples`, which is derived from `example_weights.size()`, and this is validated.\n\n6) The function uses `TF_RETURN_IF_ERROR` to propagate errors, ensuring that any failure in input processing or internal operations is properly reported.\n\n7) The function does not perform any unsafe memory operations, buffer overflows, or direct string manipulation with user input.\n\n8) All input sizes are validated before being used in loops or memory allocations, and the use of `flat<float>()` is safe as long as the tensor dimensions are correct, which is ensured by TensorFlow's type system and input validation.\n\n9) There are no known vulnerabilities such as buffer overflows, use-after-free, integer overflows, or improper input validation.\n\n10) The code follows safe practices: input validation, bounds checking, and proper error handling.\n\n(2) NO: No security vulnerability."}
{"idx": 211785, "project": "jasper", "commit_id": "4cd52b5daac62b00a0a328451544807ddecf775f", "project_url": "https://github.com/mdadams/jasper", "commit_url": "https://github.com/jasper-software/jasper/commit/4cd52b5daac62b00a0a328451544807ddecf775f", "commit_message": "Avoid maxrlvls more than upper bound to cause heap-buffer-overflow", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2020-27828", "cve_desc": "There's a flaw in jasper's jpc encoder in versions prior to 2.0.23. Crafted input provided to jasper by an attacker could cause an arbitrary out-of-bounds write. This could potentially affect data confidentiality, integrity, or application availability.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - The function `cp_create` allocates memory for `jpc_enc_cp_t` using `jas_malloc`, and for `ccps` using `jas_alloc2`. These are safe if the underlying `jas_malloc` and `jas_alloc2` functions are properly implemented and do not return null on failure (which is handled via `goto error`).\n   - All allocated memory is properly freed in the `error` label using `jas_free` and `jpc_enc_cp_destroy`, so no memory leaks are apparent.\n\n2. **Input Validation via `jas_tvparser`**:\n   - The function parses options from `optstr` using `jas_tvparser_create` and processes them in a loop with `jas_tvparser_next`.\n   - Each option is validated using `jas_taginfo_nonull(jas_taginfos_lookup(...))`, which ensures that only known tags are processed.\n   - For numeric values, `atoi` is used to convert strings to integers. This is a potential risk if the input string is not properly validated, but:\n     - The function checks for invalid tags and logs a warning, but does not crash or allow arbitrary values.\n     - The values are then used in bounds checks later (e.g., `prcwidthexpn > 15`), which prevent out-of-bounds usage.\n\n3. **Use of `atoi` and `jpc_atoaf`**:\n   - `atoi` is used to parse values like `prcwidthexpn`, `prcheightexpn`, `maxrlvls`, etc.\n   - `jpc_atoaf` is used for parsing `ilyrrates`, which returns 0 on failure and logs a warning. The function then checks `numilyrrates > 0` before using the array, so no out-of-bounds access occurs.\n   - While `atoi` can silently fail on malformed input (e.g., non-numeric strings), the code does not use the result unless it passes subsequent validation checks. For example, `prcwidthexpn` is checked against 15, and `cblkwidthexpn` is checked against 2\u201312. So even if `atoi` returns a bad value, it will be rejected later.\n\n4. **Bounds Checking and Validation**:\n   - The code performs extensive validation:\n     - `prcwidthexpn` and `prcheightexpn` are checked to be \u2264 15.\n     - `cblkwidthexpn` and `cblkheightexpn` are checked to be between 2 and 12.\n     - Their sum is checked to not exceed 12 (to prevent excessively large code blocks).\n     - `numlyrs` is capped at 16384.\n     - `maxrlvls` must be \u2265 1.\n     - `numgbits` \u2264 8.\n     - `totalsize` is checked against `rawsize` (with a warning for large values).\n     - Intermediate layer rates are checked for monotonic increase and must be less than the overall rate.\n   - These checks prevent invalid or malicious values from being used in subsequent computations.\n\n5. **Array Access and Indexing**:\n   - The `ilyrrates` array is allocated only if `jpc_atoaf` succeeds, and its size is `numilyrrates`.\n   - The loop `for (i = 0; i < JAS_CAST(int, tcp->numlyrs - 1); ++i)` safely iterates only up to `tcp->numlyrs - 1`, which is guaranteed to be \u2264 `numilyrrates` because `tcp->numlyrs = numilyrrates + 1`.\n   - No out-of-bounds access occurs.\n\n6. **Use of `jpc_dbltofix` and `jpc_fixtodbl`**:\n   - These functions are used to convert between double and fixed-point representations. They are assumed to be safe if implemented correctly.\n\n7. **Error Handling and Cleanup**:\n   - The `error` label ensures that all allocated memory (`ilyrrates`, `tvp`, `cp`) is properly freed.\n   - No resource leaks.\n\n8. **No Use of Dangerous Functions**:\n   - No `strcpy`, `sprintf`, `gets`, or similar unsafe functions are used.\n   - All string parsing is done via `jas_tvparser`, which is designed to be safe.\n\n9. **Potential Concerns**:\n   - `atoi` is used without bounds checking on input. However, since all values are validated later, and invalid values are rejected with error messages, this does not lead to a vulnerability.\n   - The function logs warnings but does not crash on invalid input, which is acceptable for a configuration parser.\n\nConclusion: The code performs thorough input validation, uses safe memory management, and includes comprehensive bounds checks. Even though `atoi` is used, the values are validated before use, and no exploitable behavior (like buffer overflow, integer overflow, or code execution) is possible.\n\n(2) NO: No security vulnerability."}
{"idx": 196587, "project": "tensorflow", "commit_id": "4aacb30888638da75023e6601149415b39763d76", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76", "commit_message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-37642", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "No response from agent"}
{"idx": 197826, "project": "tensorflow", "commit_id": "7731e8dfbe4a56773be5dc94d631611211156659", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/7731e8dfbe4a56773be5dc94d631611211156659", "commit_message": "Don't constant-fold DT_RESOURCE constants.\n\nPiperOrigin-RevId: 391803952\nChange-Id: I0ea3ec31d3e7dfda0f03b4027a237f08d00a3091", "ground_truth": 1, "cwe": ["CWE-824"], "cve": "CVE-2021-41204", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step:\n\n1. The function `IsConstantFoldable` determines whether a given node in a computational graph (likely in a machine learning framework like TensorFlow) can be constant-folded \u2014 i.e., evaluated at compile time rather than runtime.\n\n2. The function performs a series of checks to determine if constant folding is safe or feasible:\n   - It returns `true` immediately if the node is a constant (`n->IsConstant()`).\n   - It checks if the node can have its shape replaced via `MaybeReplaceShapeOp`, and if so, allows constant folding.\n   - It rejects nodes that are stateful (`is_stateful()`), as they may have side effects.\n   - It respects a user-provided `consider` function to filter nodes.\n   - It checks the size of potential output tensors against `max_constant_size_in_bytes`. If any output is too large (fully defined shape and total size exceeds limit), it returns `false`. This is a safety measure to prevent excessive memory usage during constant folding.\n   - It explicitly disallows control flow nodes, send/recv nodes, session handle operations, source/sink nodes, fake parameters, and nodes that are not CPU-compatible (via `KernelDefAvailable`).\n   - It also skips nodes that are marked with a scoped allocator attribute, as constant folding would break the allocation context.\n\n3. All checks are defensive and designed to prevent:\n   - Side effects (via stateful, control flow, send/recv).\n   - Memory exhaustion (via size limit check).\n   - Invalid execution context (e.g., missing CPU kernel, scoped allocator).\n   - Unintended behavior (e.g., source/sink nodes, fake params).\n\n4. There is no use of unsafe functions (like `strcpy`, `strcat`, `memcpy` without bounds), no direct user input manipulation, no dynamic memory allocation without bounds checking, and no string formatting that could lead to injection or overflow.\n\n5. The function is not processing untrusted input in a way that could lead to buffer overflows, memory corruption, or code execution. Instead, it's making decisions based on node properties and metadata in a graph representation.\n\n6. The only potential concern might be the `max_constant_size_in_bytes` check, but this is a well-placed safeguard to prevent excessive memory consumption \u2014 a common and accepted practice in systems like this.\n\n7. No exploitable vulnerabilities (e.g., buffer overflow, use-after-free, integer overflow, injection) are present in the logic or data handling.\n\n(2) NO: No security vulnerability."}
{"idx": 205736, "project": "linux", "commit_id": "775c5033a0d164622d9d10dd0f0a5531639ed3ed", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=775c5033a0d164622d9d10dd0f0a5531639ed3ed", "commit_message": "fuse: fix live lock in fuse_iget()\n\nCommit 5d069dbe8aaf (\"fuse: fix bad inode\") replaced make_bad_inode()\nin fuse_iget() with a private implementation fuse_make_bad().\n\nThe private implementation fails to remove the bad inode from inode\ncache, so the retry loop with iget5_locked() finds the same bad inode\nand marks it bad forever.\n\nkmsg snip:\n\n[ ] rcu: INFO: rcu_sched self-detected stall on CPU\n...\n[ ]  ? bit_wait_io+0x50/0x50\n[ ]  ? fuse_init_file_inode+0x70/0x70\n[ ]  ? find_inode.isra.32+0x60/0xb0\n[ ]  ? fuse_init_file_inode+0x70/0x70\n[ ]  ilookup5_nowait+0x65/0x90\n[ ]  ? fuse_init_file_inode+0x70/0x70\n[ ]  ilookup5.part.36+0x2e/0x80\n[ ]  ? fuse_init_file_inode+0x70/0x70\n[ ]  ? fuse_inode_eq+0x20/0x20\n[ ]  iget5_locked+0x21/0x80\n[ ]  ? fuse_inode_eq+0x20/0x20\n[ ]  fuse_iget+0x96/0x1b0\n\nFixes: 5d069dbe8aaf (\"fuse: fix bad inode\")\nCc: stable@vger.kernel.org # 5.10+\nSigned-off-by: Amir Goldstein <amir73il@gmail.com>\nSigned-off-by: Miklos Szeredi <mszeredi@redhat.com>", "ground_truth": 1, "cwe": ["CWE-834"], "cve": "CVE-2021-28950", "cve_desc": "An issue was discovered in fs/fuse/fuse_i.h in the Linux kernel before 5.11.8. A \"stall on CPU\" can occur because a retry loop continually finds the same bad inode, aka CID-775c5033a0d1.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `fuse_make_bad` is a static inline function that takes a pointer to a struct `inode` as an argument.\n2. It calls `get_fuse_inode(inode)` to retrieve the FUSE-specific inode data associated with the given inode.\n3. It then sets a bit (specifically, the bit at position FUSE_I_BAD) in the `state` field of the FUSE inode using `set_bit()`.\n4. The `set_bit()` macro is a standard low-level operation used to set a specific bit in a bitfield, typically used for flags or state indicators.\n5. The `FUSE_I_BAD` flag is likely used to mark a FUSE inode as \"bad\" or invalid, possibly indicating that the file or inode has encountered an error or is no longer valid.\n6. The function does not perform any input validation on the `inode` pointer itself. However, in kernel code, it is generally assumed that the `inode` pointer passed to such functions is valid and properly managed by the kernel's VFS layer.\n7. Since this is a kernel-level function and the `inode` pointer is expected to be valid (as per kernel conventions), the lack of explicit null pointer checking is not necessarily a vulnerability in this context.\n8. The operation is atomic and safe as long as the `inode` pointer is valid, and the `set_bit()` operation is safe for the `state` field.\n9. There is no user input involved, no memory copying, no string manipulation, and no potential for buffer overflows or injection attacks.\n10. The function is a simple state mutation operation that is part of the FUSE (Filesystem in Userspace) subsystem, and such state-setting functions are common and safe in kernel code when used correctly.\n\nTherefore, this code does not introduce a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 201343, "project": "linux", "commit_id": "a3727a8bac0a9e77c70820655fd8715523ba3db7", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=a3727a8bac0a9e77c70820655fd8715523ba3db7", "commit_message": "selinux,smack: fix subjective/objective credential use mixups\n\nJann Horn reported a problem with commit eb1231f73c4d (\"selinux:\nclarify task subjective and objective credentials\") where some LSM\nhooks were attempting to access the subjective credentials of a task\nother than the current task.  Generally speaking, it is not safe to\naccess another task's subjective credentials and doing so can cause\na number of problems.\n\nFurther, while looking into the problem, I realized that Smack was\nsuffering from a similar problem brought about by a similar commit\n1fb057dcde11 (\"smack: differentiate between subjective and objective\ntask credentials\").\n\nThis patch addresses this problem by restoring the use of the task's\nobjective credentials in those cases where the task is other than the\ncurrent executing task.  Not only does this resolve the problem\nreported by Jann, it is arguably the correct thing to do in these\ncases.\n\nCc: stable@vger.kernel.org\nFixes: eb1231f73c4d (\"selinux: clarify task subjective and objective credentials\")\nFixes: 1fb057dcde11 (\"smack: differentiate between subjective and objective task credentials\")\nReported-by: Jann Horn <jannh@google.com>\nAcked-by: Eric W. Biederman <ebiederm@xmission.com>\nAcked-by: Casey Schaufler <casey@schaufler-ca.com>\nSigned-off-by: Paul Moore <paul@paul-moore.com>", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2021-43057", "cve_desc": "An issue was discovered in the Linux kernel before 5.14.8. A use-after-free in selinux_ptrace_traceme (aka the SELinux handler for PTRACE_TRACEME) could be used by local attackers to cause memory corruption and escalate privileges, aka CID-a3727a8bac0a. This occurs because of an attempt to access the subjective credentials of another task.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `selinux_ptrace_traceme` is a SELinux policy enforcement function that checks whether the current task (child process) can be traced by the parent process via the `ptrace` system call.\n\n2. The function calls `avc_has_perm`, which is the Access Vector Cache (AVC) interface used by SELinux to check permissions. This function evaluates whether the subject (parent process) has the required permission to perform an operation on the object (current process) under the specified security class and permission.\n\n3. The parameters passed to `avc_has_perm` are:\n   - `&selinux_state`: The SELinux state context.\n   - `task_sid_subj(parent)`: The Security Identifier (SID) of the parent process (subject).\n   - `task_sid_obj(current)`: The SID of the current process (object).\n   - `SECCLASS_PROCESS`: The security class, which in this case is \"process\".\n   - `PROCESS__PTRACE`: The specific permission being checked \u2014 whether the parent can trace the child.\n   - `NULL`: No additional audit data is provided.\n\n4. The `avc_has_perm` function is a well-established, secure mechanism in SELinux for enforcing mandatory access control (MAC). It is designed to prevent privilege escalation and unauthorized access by enforcing fine-grained policies.\n\n5. The function does not perform any input validation or manipulation of raw data \u2014 it simply delegates the access decision to the SELinux policy engine. The security decision is based on the configured SELinux policy, which is enforced at the kernel level.\n\n6. There is no evidence of buffer overflows, use-after-free, improper input validation, or any other common programming vulnerabilities. The function is a standard SELinux permission check and is used correctly.\n\n7. The function returns the result of the permission check, which is the correct and secure way to enforce access control in the kernel.\n\nTherefore, this code is correctly implementing SELinux access control and does not contain any security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 207069, "project": "linux", "commit_id": "cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=cc7a0bb058b85ea03db87169c60c7cfdd5d34678", "commit_message": "PCI: rpadlpar: Fix potential drc_name corruption in store functions\n\nBoth add_slot_store() and remove_slot_store() try to fix up the\ndrc_name copied from the store buffer by placing a NUL terminator at\nnbyte + 1 or in place of a '\\n' if present. However, the static buffer\nthat we copy the drc_name data into is not zeroed and can contain\nanything past the n-th byte.\n\nThis is problematic if a '\\n' byte appears in that buffer after nbytes\nand the string copied into the store buffer was not NUL terminated to\nstart with as the strchr() search for a '\\n' byte will mark this\nincorrectly as the end of the drc_name string resulting in a drc_name\nstring that contains garbage data after the n-th byte.\n\nAdditionally it will cause us to overwrite that '\\n' byte on the stack\nwith NUL, potentially corrupting data on the stack.\n\nThe following debugging shows an example of the drmgr utility writing\n\"PHB 4543\" to the add_slot sysfs attribute, but add_slot_store()\nlogging a corrupted string value.\n\n  drmgr: drmgr: -c phb -a -s PHB 4543 -d 1\n  add_slot_store: drc_name = PHB 4543\u00b0|<82>!, rc = -19\n\nFix this by using strscpy() instead of memcpy() to ensure the string\nis NUL terminated when copied into the static drc_name buffer.\nFurther, since the string is now NUL terminated the code only needs to\nchange '\\n' to '\\0' when present.\n\nCc: stable@vger.kernel.org\nSigned-off-by: Tyrel Datwyler <tyreld@linux.ibm.com>\n[mpe: Reformat change log and add mention of possible stack corruption]\nSigned-off-by: Michael Ellerman <mpe@ellerman.id.au>\nLink: https://lore.kernel.org/r/20210315214821.452959-1-tyreld@linux.ibm.com", "ground_truth": 1, "cwe": ["CWE-120"], "cve": "CVE-2021-28972", "cve_desc": "In drivers/pci/hotplug/rpadlpar_sysfs.c in the Linux kernel through 5.11.8, the RPA PCI Hotplug driver has a user-tolerable buffer overflow when writing a new device name to the driver from userspace, allowing userspace to write data to the kernel stack frame directly. This occurs because add_slot_store and remove_slot_store mishandle drc_name '\\0' termination, aka CID-cc7a0bb058b8.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `add_slot_store` is a kernel object attribute store function, typically used in sysfs to handle write operations to a kernel-controlled file.\n\n2. It takes a buffer `buf` containing user input (from sysfs write), and `nbytes` indicating the size of the input.\n\n3. It declares a local buffer `drc_name` of size `MAX_DRC_NAME_LEN`, which is presumably a fixed maximum length for DRC (Dynamic Reconfiguration Connector) names.\n\n4. The function first checks if `nbytes >= MAX_DRC_NAME_LEN`. If so, it returns 0 immediately. This prevents writing more than the buffer can hold, which is good.\n\n5. Then it uses `memcpy(drc_name, buf, nbytes)` to copy the input into `drc_name`. Since the check above ensures `nbytes < MAX_DRC_NAME_LEN`, this copy is safe in terms of buffer overflow.\n\n6. It then searches for a newline character (`\\n`) in `drc_name` using `strchr`. If not found, it sets `end` to point to the end of the copied data (`&drc_name[nbytes]`).\n\n7. It null-terminates the string with `*end = '\\0'`. This ensures the string is null-terminated.\n\n8. The function then calls `dlpar_add_slot(drc_name)`, passing the null-terminated string.\n\n9. The key concern: Is the input properly validated before being passed to `dlpar_add_slot`?\n\n- The function ensures that `nbytes < MAX_DRC_NAME_LEN`, so the `memcpy` cannot overflow.\n- It properly null-terminates the string.\n- However, there is no validation of the content of `drc_name` \u2014 it could contain arbitrary characters, including control characters or potentially malicious DRC names, depending on the `dlpar_add_slot` implementation.\n\n10. But the critical point: `dlpar_add_slot` is a kernel function that likely performs its own validation and sanitization before acting on the DRC name. Since this is a kernel-level function, and the input is bounded and null-terminated, and no further unsafe operations are performed, the function does not introduce a buffer overflow or other classic vulnerability.\n\n11. The function does not perform any unsafe string operations after the null-termination, and the input is bounded by `MAX_DRC_NAME_LEN`.\n\n12. Therefore, while the function does not validate the *semantic* correctness of the DRC name (e.g., whether it's a valid DRC name), it does not introduce a buffer overflow or other exploitable vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 195291, "project": "tensorflow", "commit_id": "ef1d027be116f25e25bb94a60da491c2cf55bd0b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b", "commit_message": "Prevent copying uninitialized data in `AssignOp`.\n\nThis prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.\n\nPiperOrigin-RevId: 408654780\nChange-Id: Iad2ec40d43f5fd7ea016c20283356c12d5ddeab1", "ground_truth": 1, "cwe": ["CWE-908"], "cve": "CVE-2022-23573", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `Compute` is part of an `OpKernelContext` in a TensorFlow-like framework, likely implementing an \"Assign\" operation where the left-hand side (lhs) tensor is updated with the value from the right-hand side (rhs).\n\n2. The code begins by retrieving the `rhs` tensor from input(1), and then immediately forwards the reference input (input 0) to the output (ref output 0), which is a common pattern in TensorFlow for reference semantics.\n\n3. Allocator attributes (`attr`) are set to enforce GPU and NIC compatibility if `relax_constraints_` is false. This is a performance/compatibility setting and not a security issue.\n\n4. The code acquires a mutex lock on `context->input_ref_mutex(0)` to safely access the mutable input (lhs). This is correct for thread safety when modifying shared state.\n\n5. It checks if the shapes of lhs and rhs are the same, and if `validate_shape_` is true, it enforces this with `OP_REQUIRES`, which will fail the operation if shapes don\u2019t match. This prevents invalid memory operations due to shape mismatches.\n\n6. The code attempts to optimize memory usage via two strategies:\n   - Reuse the existing lhs buffer if it's initialized and has the same number of elements as rhs.\n   - Try to reuse the rhs buffer directly via `forward_input`, which avoids allocation and copying.\n\n7. In the first optimization path:\n   - It creates a `reshaped_old_lhs` tensor if the shapes differ, using `CopyFrom` to reshape it.\n   - It then uses `replace_ref_input` to update the reference to point to the reshaped tensor.\n   - If `use_exclusive_lock_` is true, it calls `Copy` to perform the actual data copy.\n\n8. In the second path:\n   - It attempts to forward the rhs tensor directly using `forward_input`, which returns a `std::unique_ptr<Tensor>`.\n   - If successful, it replaces the lhs ref with this forwarded tensor.\n   - This avoids allocation and copying, which is safe only if the rhs tensor is not modified elsewhere.\n\n9. If neither optimization works, it allocates a new tensor (`copy_tensor`) using `allocate_temp`, with the shape of rhs and the specified allocator attributes. It then replaces the lhs ref with this new tensor.\n\n10. After all optimizations, if the copy must be done outside the lock (i.e., when `use_exclusive_lock_` is false), it retrieves the lhs tensor without the lock and performs the copy.\n\nNow, let\u2019s assess for security vulnerabilities:\n\n- There is no use of unsafe functions like `strcpy`, `memcpy` without bounds checks, or direct memory manipulation.\n- All tensor operations are performed through safe, framework-provided APIs (`CopyFrom`, `Copy`, `allocate_temp`, `replace_ref_input`, etc.).\n- Shape validation is enforced with `OP_REQUIRES`, preventing out-of-bounds access.\n- Memory allocation is done via `allocate_temp` with proper attributes and bounds.\n- The use of `mutex_lock` ensures thread safety when accessing shared mutable state.\n- The `forward_input` mechanism is used safely \u2014 it only forwards if the buffer can be reused, and the code checks for `nullptr` return.\n- There is no user-controlled input directly used in memory operations without validation \u2014 all inputs are validated via shape checks and tensor APIs.\n\nNo buffer overflows, use-after-free, null pointer dereferences, or memory corruption vulnerabilities are present.\n\nThe code is well-structured, uses safe abstractions, and includes proper error checking and synchronization.\n\n(2) NO: No security vulnerability."}
{"idx": 211181, "project": "php-src", "commit_id": "a72cd07f2983dc43a6bb35209dc4687852e53c09", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commit;h=a72cd07f2983dc43a6bb35209dc4687852e53c09", "commit_message": "Fixed bug #68665 (Invalid free)", "ground_truth": 1, "cwe": ["CWE-17"], "cve": "CVE-2014-9426", "cve_desc": "The apprentice_load function in libmagic/apprentice.c in the Fileinfo component in PHP through 5.6.4 attempts to perform a free operation on a stack-based character array, which allows remote attackers to cause a denial of service (memory corruption or application crash) or possibly have unspecified other impact via unknown vectors.  NOTE: this is disputed by the vendor because the standard erealloc behavior makes the free operation unreachable", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Path Construction**:\n   - The function `apprentice_load` takes a file path `fn` as input.\n   - It checks if `fn` refers to a directory using `php_sys_stat` and `S_ISDIR`.\n   - If it's a directory, it opens it with `php_stream_opendir`, reads entries with `php_stream_readdir`, and constructs full paths using `snprintf(mfn, sizeof(mfn), \"%s/%s\", fn, d.d_name)`.\n\n2. **Path Length and Buffer Overflow Risk**:\n   - The `snprintf` call uses `sizeof(mfn)` (which is `MAXPATHLEN`) to limit the buffer size.\n   - The condition `(mflen = snprintf(...)) < 0` checks for negative return, which would indicate an error (e.g., buffer overflow), but `snprintf` returns the number of characters that would have been written (not including null), so a negative return is not possible unless there's an error in the format string (which is not the case here).\n   - However, the code checks `mflen > sizeof(mfn) - 1` and uses `estrndup(mfn, ...)` with a limit of `sizeof(mfn) - 1` if needed. This ensures that the copied string is null-terminated and does not overflow the buffer.\n   - So, the path construction is safe from buffer overflow due to proper use of `snprintf` and `estrndup` with bounds checking.\n\n3. **Directory Traversal and Path Validation**:\n   - The code does not perform any validation on the `d.d_name` (filename from directory entry) before using it in `snprintf`.\n   - This could allow an attacker to craft a directory with filenames like `../../etc/passwd` to perform directory traversal, especially if the `fn` path is controlled by an untrusted source.\n   - However, the code does not validate or sanitize the `d.d_name` before using it in path construction. This is a potential security issue.\n\n4. **File Type Filtering**:\n   - After constructing the path, the code calls `stat(mfn, &st)` and checks `S_ISREG(st.st_mode)` to ensure the entry is a regular file.\n   - This prevents processing of directories, symlinks, or special files, which is good.\n   - But it does not prevent access to files outside the intended directory if the path traversal is possible.\n\n5. **Use of `efree` and `estrndup`**:\n   - The code uses `estrndup` to copy the path string, which is safe as long as the input is bounded.\n   - `efree` is used to free memory, and the code properly frees `filearr` and `map` on error or success.\n\n6. **Sorting and Processing**:\n   - The file list is sorted with `qsort` using `cmpstrp`, which is safe.\n   - Files are processed one by one via `load_1`, which presumably parses magic files.\n\n7. **Security Implications of `load_1`**:\n   - The `load_1` function is called with the constructed path. If `load_1` parses the file content without proper validation (e.g., parsing magic rules), and if the file is under attacker control, it could lead to code execution or denial of service.\n   - However, the vulnerability would depend on `load_1`'s internal behavior, which is not shown here. But since the path is constructed from untrusted input (via directory traversal), the risk is present.\n\n8. **Missing Input Sanitization**:\n   - The most critical issue is that the code does not sanitize or validate the `d.d_name` from the directory listing before using it in path construction.\n   - This allows an attacker to place a file named `../../etc/passwd` in a directory that is being scanned, leading to reading arbitrary files on the system.\n\n9. **Conclusion**:\n   - The code is vulnerable to directory traversal attacks because it directly uses `d.d_name` in path construction without sanitization.\n   - This is a classic security vulnerability that can lead to unauthorized file access.\n\n(1) YES: A security vulnerability detected."}
{"idx": 210203, "project": "linux", "commit_id": "8cae8cd89f05f6de223d63e6d15e31c8ba9cf53b", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/8cae8cd89f05f6de223d63e6d15e31c8ba9cf53b", "commit_message": "seq_file: disallow extremely large seq buffer allocations\n\nThere is no reasonable need for a buffer larger than this, and it avoids\nint overflow pitfalls.\n\nFixes: 058504edd026 (\"fs/seq_file: fallback to vmalloc allocation\")\nSuggested-by: Al Viro <viro@zeniv.linux.org.uk>\nReported-by: Qualys Security Advisory <qsa@qualys.com>\nSigned-off-by: Eric Sandeen <sandeen@redhat.com>\nCc: stable@kernel.org\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-33909", "cve_desc": "fs/seq_file.c in the Linux kernel 3.16 through 5.13.x before 5.13.4 does not properly restrict seq buffer allocations, leading to an integer overflow, an Out-of-bounds Write, and escalation to root by an unprivileged user, aka CID-8cae8cd89f05.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `seq_buf_alloc` is declared as `static`, meaning it is only visible within the current translation unit, which is a good practice for limiting scope.\n\n2. The function takes a single parameter `size` of type `unsigned long`, which represents the amount of memory to allocate.\n\n3. It calls `kvmalloc(size, GFP_KERNEL_ACCOUNT)` to allocate memory. Let's break this down:\n   - `kvmalloc` is a kernel memory allocation function that can allocate memory from both regular kernel memory and high memory (if available), and it is suitable for large allocations.\n   - The `GFP_KERNEL_ACCOUNT` flag indicates that the allocation is made in a context where the memory usage should be accounted for (e.g., for memory accounting in the kernel), and it is safe to sleep (since it's used in process context).\n\n4. The function returns the pointer to the allocated memory, or `NULL` if the allocation fails.\n\n5. Key security considerations:\n   - There is no input validation on `size`. The function accepts any `unsigned long` value, including very large values (e.g., near the maximum of `ULONG_MAX`).\n   - If `size` is extremely large, `kvmalloc` may fail and return `NULL`, but the caller is responsible for checking the return value. However, the function itself does not validate the input size.\n   - The lack of bounds checking on `size` could lead to a denial-of-service (DoS) via memory exhaustion if an attacker can control the `size` parameter (e.g., through a user-controlled ioctl or similar interface).\n   - However, `kvmalloc` internally performs checks to prevent allocations that are too large (e.g., beyond system limits), so it is unlikely to cause a buffer overflow or memory corruption directly. But it can still lead to resource exhaustion.\n\n6. Is this a security vulnerability?\n   - While the function does not directly cause buffer overflow or memory corruption, the lack of input validation on `size` could allow an attacker to trigger large memory allocations, leading to system instability or DoS.\n   - In kernel code, such functions are typically called from trusted contexts (e.g., from within a driver or subsystem), and the size is usually validated before calling `seq_buf_alloc`. But if this function is exposed to untrusted input without proper validation upstream, it could be exploited.\n\n7. However, the function itself does not contain a direct exploitable vulnerability like buffer overflow, use-after-free, or improper access control. It is a simple wrapper around `kvmalloc` with no obvious flaws in logic or memory handling.\n\n8. The absence of input validation is a concern, but unless the function is directly exposed to untrusted input without prior validation, it may not constitute a direct security vulnerability.\n\nConclusion: The function does not contain a direct, exploitable security vulnerability such as buffer overflow or memory corruption. While it lacks input validation, the underlying `kvmalloc` function prevents allocation of impossible sizes, and the function is safe as long as the caller ensures the size is reasonable. Therefore, this is not a security vulnerability in the strict sense.\n\n(2) NO: No security vulnerability."}
{"idx": 196846, "project": "tensorflow", "commit_id": "1e206baedf8bef0334cca3eb92bab134ef525a28", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/1e206baedf8bef0334cca3eb92bab134ef525a28", "commit_message": "Prevent a division by 0 in division ops.\n\nPiperOrigin-RevId: 385223169\nChange-Id: Ia4228960b5d2aa44480385f74bdd70d21a3613c3", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-37683", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `Eval` is a TensorFlow Lite kernel evaluation function responsible for performing division operations on tensors. It takes a `TfLiteContext`, a `TfLiteNode`, and handles input and output tensors.\n\n2. The function retrieves the operation parameters (`params`) and user data (`data`) from the node using `reinterpret_cast`, which is safe here as long as the data layout is correct and consistent with the expected types.\n\n3. It uses `GetInputSafe` and `GetOutputSafe` to retrieve input and output tensors. These functions are part of the TensorFlow Lite framework and are designed to safely access tensors while performing bounds and validity checks. The `TF_LITE_ENSURE_OK` macro ensures that any failure in tensor retrieval results in an early return with an error, preventing further execution with invalid data.\n\n4. The function checks the output tensor's type (`output->type`) and dispatches to appropriate implementations:\n   - For `kTfLiteFloat32` and `kTfLiteInt32`, it calls `EvalDiv<kernel_type>`.\n   - For `kTfLiteUInt8` (quantized), it calls `EvalQuantized<kernel_type>`.\n   - For any other type, it reports an error and returns `kTfLiteError`.\n\n5. The type checking is comprehensive and explicitly rejects unsupported types. This prevents the kernel from attempting to process unsupported data types, which could lead to undefined behavior or crashes.\n\n6. The use of `TF_LITE_ENSURE_OK` ensures that any failure in tensor access or validation is caught early and handled gracefully, avoiding potential memory corruption or invalid operations.\n\n7. There is no direct use of user-controlled data in unsafe operations like string concatenation, buffer copying, or dynamic memory allocation without bounds checking. All operations are mediated through the TensorFlow Lite framework's safe APIs.\n\n8. The function does not perform any arithmetic without checking for division by zero or other invalid operations. However, note that the actual division logic is delegated to `EvalDiv` and `EvalQuantized`, which are assumed to be implemented correctly and safely (as part of the standard TensorFlow Lite kernel library). Since the code under review only dispatches based on type and ensures valid tensor access, and since the framework is designed to prevent such issues, we assume the underlying kernels handle edge cases like zero division appropriately.\n\n9. No input validation is performed on the tensor data values (e.g., checking for zero in input2), but this is not the responsibility of the `Eval` function alone \u2014 such checks are typically handled within the kernel implementations (`EvalDiv` and `EvalQuantized`). The `Eval` function correctly validates the tensor types and access, which is the primary security concern at this level.\n\nConclusion: The code performs proper input validation, uses safe tensor access functions, and rejects unsupported types. There are no obvious buffer overflows, use-after-free, or injection vulnerabilities. The design follows secure practices by leveraging the framework's safety mechanisms.\n\n(2) NO: No security vulnerability."}
{"idx": 214003, "project": "libvncserver", "commit_id": "7b1ef0ffc4815cab9a96c7278394152bdc89dc4d", "project_url": "https://github.com/LibVNC/libvncserver", "commit_url": "https://github.com/LibVNC/libvncserver/commit/7b1ef0ffc4815cab9a96c7278394152bdc89dc4d", "commit_message": "LibVNCClient: really fix #250", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2018-20020", "cve_desc": "LibVNC before commit 7b1ef0ffc4815cab9a96c7278394152bdc89dc4d contains heap out-of-bound write vulnerability inside structure in VNC client code that can result remote code execution", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function HandleCoRREBPP processes a RRE (Rectangle Encoding) update from a VNC server. It reads a header, a pixel value, and then a series of subrectangles.\n\n2) The header contains nSubrects, which is read from the server and then swapped for endianness. This value controls the loop that processes subrectangles.\n\n3) The code allocates a buffer of size hdr.nSubrects * (4 + (BPP / 8)) and reads that many bytes from the server into client->buffer.\n\n4) The critical issue is that the code uses hdr.nSubrects directly to calculate the buffer size and to control the loop, but there is no validation that hdr.nSubrects is reasonable or within expected bounds.\n\n5) Since hdr.nSubrects comes from the server (untrusted input), an attacker could send a very large value (e.g., 0xFFFFFFFF) which would cause:\n   - A massive buffer allocation (potentially leading to memory exhaustion or denial of service)\n   - A large number of iterations in the loop\n   - Potential integer overflow in the buffer size calculation\n\n6) The check `hdr.nSubrects * (4 + (BPP / 8)) > RFB_BUFFER_SIZE` is present, but:\n   - RFB_BUFFER_SIZE is likely a fixed constant\n   - If BPP is 8, then (4 + (BPP/8)) = 5, so the maximum allowed nSubrects would be RFB_BUFFER_SIZE / 5\n   - However, if RFB_BUFFER_SIZE is large enough, or if BPP is larger, this check might not be sufficient\n   - More importantly, the multiplication could overflow if hdr.nSubrects is very large, making the check ineffective\n\n7) The loop uses i < hdr.nSubrects, and reads 4 bytes (x, y, w, h) and BPP/8 bytes for the pixel value per subrectangle. If hdr.nSubrects is too large, this could lead to buffer over-reads or excessive processing.\n\n8) There is no validation that hdr.nSubrects is within a reasonable range (e.g., not too large compared to the screen size).\n\n9) This is a classic case of untrusted input being used to control buffer size and loop count without proper bounds checking, which can lead to denial of service (via memory exhaustion) or potentially other vulnerabilities.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195742, "project": "gpac", "commit_id": "37592ad86c6ca934d34740012213e467acc4a3b0", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/37592ad86c6ca934d34740012213e467acc4a3b0", "commit_message": "fixed #2163", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-29340", "cve_desc": "GPAC 2.1-DEV-rev87-g053aae8-master. has a Null Pointer Dereference vulnerability in gf_isom_parse_movie_boxes_internal due to improper return value handling of GF_SKIP_BOX, which causes a Denial of Service. This vulnerability was fixed in commit 37592ad.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThis is a C function `gf_isom_parse_movie_boxes_internal` from the GPAC library, which is a multimedia framework used for handling ISO base media file format (ISOBMFF) files (e.g., MP4, MOV). The function parses top-level boxes (like `moov`, `mdat`, `ftyp`, etc.) in an ISO file.\n\nThe function:\n- Reads from a binary stream (`mov->movieFileMap->bs`).\n- Parses boxes one by one using `gf_isom_parse_root_box`.\n- Handles various box types (e.g., `MOOV`, `MDAT`, `META`, `FTYP`, `MOOF`, `SIDX`, etc.).\n- Manages memory via `gf_isom_box_del` and `gf_list_add`.\n- Supports different modes: read-only, edit, fragment parsing, debug, etc.\n\n---\n\n### Step 2: Look for potential vulnerabilities\n\n#### A. **Buffer overflows / memory corruption**\n- The function uses `gf_bs_get_position()` and `gf_bs_seek()` to manage the stream position.\n- It uses `gf_bs_available()` to check if there is data left.\n- It calls `gf_isom_parse_root_box()` to parse each box, which is expected to handle box size and parsing safely.\n- The function does **not** perform manual buffer copying or string operations that could overflow (e.g., no `strcpy`, `strcat`, `memcpy` with untrusted size).\n- All box parsing is done via a well-defined API (`gf_isom_parse_root_box`), which should validate box size and structure.\n\n\u2705 No evidence of buffer overflow or unsafe memory operations.\n\n#### B. **Use of untrusted input**\n- The input is a binary file (ISO media file), which is untrusted.\n- However, the parser is designed to handle malformed or malicious files gracefully.\n- The function checks for:\n  - Duplicate boxes (e.g., `MOOV`, `META`, `FTYP`) \u2192 returns error if found.\n  - Incomplete files \u2192 returns `GF_ISOM_INCOMPLETE_FILE` or `GF_ISOM_INVALID_FILE`.\n  - Invalid box types \u2192 handled via `case GF_ISOM_BOX_TYPE_UNKNOWN`.\n- The `senc_Parse` function is called only when `sample_encryption` is present, and it's passed a valid stream position and box data.\n\n\u26a0\ufe0f However, note that `senc_Parse` is called **without validating the size of the `sample_encryption` box** before parsing. But this is not a direct vulnerability because:\n- `senc_Parse` is a known safe function in GPAC.\n- The `sample_encryption` box is part of the ISOBMFF specification and is parsed in a controlled way.\n- The function does not use `memcpy` or `strcpy` on untrusted data.\n\n#### C. **Logic errors / state management**\n- The function maintains `mov->current_top_box_start` and adjusts it with `mov->bytes_removed`.\n- It uses `assert(totSize >= mov->bytes_removed)` \u2014 this is safe as long as `bytes_removed` is non-negative and not larger than `totSize`, which is enforced by the logic.\n- The `single_moof_mode` logic is handled correctly: it returns early if `single_moof_state == 2`, preventing further processing.\n\n\u2705 No obvious logic errors that lead to memory corruption or infinite loops.\n\n#### D. **Resource leaks**\n- The function uses `gf_isom_box_del(a)` to free boxes that are not kept.\n- It adds boxes to `mov->TopBoxes` only when needed.\n- It uses `gf_list_add` and checks return values.\n\n\u2705 No resource leaks detected.\n\n#### E. **Information disclosure / side-channel**\n- The function logs debug messages using `GF_LOG(GF_LOG_DEBUG, ...)`, but only when `GF_LOG_DEBUG` is enabled.\n- It logs box types and positions, but this is not sensitive information.\n- No sensitive data (e.g., passwords, keys) is exposed.\n\n\u2705 Not a security issue.\n\n#### F. **Insecure handling of fragmented files**\n- The code has `#ifndef GPAC_DISABLE_ISOM_FRAGMENTS` guards, so it's only active when fragments are enabled.\n- It handles `MOOF`, `SIDX`, `STYP`, `SSIX`, etc., correctly.\n- It deletes temporary boxes (like `root_sidx`, `seg_styp`) after use.\n- It avoids keeping unnecessary boxes in non-debug modes.\n\n\u2705 Proper handling of fragmented files.\n\n#### G. **Use of `gf_list_add` and `gf_isom_box_del`**\n- These are safe list and box management functions in GPAC.\n- The code checks return values (`e = gf_list_add(...)`) and returns early on error.\n\n\u2705 Safe usage.\n\n---\n\n### Step 3: Final assessment\n- The code is well-structured and follows safe practices:\n  - Input validation.\n  - Proper error handling.\n  - Memory management with `gf_isom_box_del`.\n  - Use of safe APIs.\n  - No unsafe string or buffer operations.\n- There are no known vulnerabilities such as:\n  - Buffer overflows.\n  - Use-after-free.\n  - Integer overflows (e.g., `totSize += a->size` \u2014 `a->size` is from the file, but `u64` is used, so overflow is unlikely).\n  - Unchecked pointer dereferences.\n  - Insecure parsing of untrusted input.\n\nEven though the code parses untrusted binary data, it does so in a controlled, validated, and safe manner.\n\n---\n\n### Conclusion\nAfter thorough analysis, no security vulnerability is detected.\n\n(2) NO: No security vulnerability."}
{"idx": 206262, "project": "vim", "commit_id": "c6fdb15d423df22e1776844811d082322475e48a", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/c6fdb15d423df22e1776844811d082322475e48a", "commit_message": "patch 9.0.0025: accessing beyond allocated memory with the cmdline window\n\nProblem:    Accessing beyond allocated memory when using the cmdline window in\n            Ex mode.\nSolution:   Use \"*\" instead of \"'<,'>\" for Visual mode.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-2288", "cve_desc": "Out-of-bounds Write in GitHub repository vim/vim prior to 9.0.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Function Purpose**: The function `parse_command_modifiers` is responsible for parsing command modifiers in Vim (e.g., `:silent`, `:silent!`, `:tab`, `:verbose 2`, etc.) from an input command string (`eap->cmd`). It modifies the `cmdmod_T` structure (`cmod`) to reflect which modifiers were present.\n\n2. **Input Handling**: The function processes the command string (`eap->cmd`) by:\n   - Skipping whitespace, tabs, and colons.\n   - Handling special cases like visual range (`'<,'>`).\n   - Parsing command modifiers one by one using a `switch` statement based on the first character of a token.\n   - Using helper functions like `checkforcmd_noparen`, `skip_range`, `skipwhite`, `skip_vimgrep_pat_ext`, etc.\n\n3. **Buffer and String Manipulation**:\n   - The function uses `mch_memmove` and `STRCPY` to manipulate strings in-place.\n   - It modifies `orig_cmd` (the original command string) when `has_visual_range` is true, moving the `'<,'>` range to after the modifiers.\n   - It uses `STRLEN`, `mch_memmove`, `STRCPY`, and `atoi` safely, but we must check for potential buffer overflows or memory corruption.\n\n4. **Critical Points for Security**:\n   - **Memory Copy Safety**: The function uses `mch_memmove` and `STRCPY` with known lengths (e.g., `STRLEN(cmd_start)`), and the destination is `orig_cmd`, which is the original input buffer. However, `orig_cmd` is not necessarily large enough to hold the modified string (e.g., when inserting `:'<,'>` or `'<,'>+'`).\n   - **Potential Buffer Overflow**: The function does not verify that `orig_cmd` has sufficient space to accommodate the new string after moving `'<,'>` or inserting `+`. If `orig_cmd` is a fixed-size buffer (e.g., from a stack-allocated array), and the modified string is longer than the buffer, this could lead to a buffer overflow.\n   - **Use of `STRCPY` and `mch_memmove`**: These functions are used without bounds checking. For example:\n     ```c\n     STRCPY(orig_cmd + len, \"'<,'>+\");\n     ```\n     If `orig_cmd` is not large enough to hold the original content plus `\"'<,'>+\"`, this will overflow.\n   - **No Size Checks**: There is no check on the length of `orig_cmd` before modifying it. The function assumes `orig_cmd` is large enough, but this is not guaranteed.\n\n5. **Contextual Risk**:\n   - This function is part of Vim's command-line parser, which processes user input.\n   - If an attacker can control the command string (e.g., via a malicious script or input), and if `orig_cmd` is a fixed-size buffer, then a crafted command could cause a buffer overflow when `parse_command_modifiers` modifies it.\n   - The `has_visual_range` block is particularly dangerous because it performs in-place string manipulation without bounds checking.\n\n6. **Conclusion**:\n   - The function performs string manipulation (copying, moving) on `orig_cmd` without verifying that the destination buffer is large enough.\n   - This is a classic case of a **buffer overflow vulnerability** if `orig_cmd` is not sufficiently large.\n   - Even though the function uses `STRCPY` and `mch_memmove`, which are unsafe if the destination is not large enough, there is no validation of buffer size before the copy.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195385, "project": "flatpak", "commit_id": "65cbfac982cb1c83993a9e19aa424daee8e9f042", "project_url": "https://github.com/flatpak/flatpak", "commit_url": "https://github.com/flatpak/flatpak/commit/65cbfac982cb1c83993a9e19aa424daee8e9f042", "commit_message": "Ensure that bundles have metadata on install\n\nIf we have a bundle without metadata we wouldn't properly present\nthe permissions in the transaction.", "ground_truth": 1, "cwe": ["CWE-276"], "cve": "CVE-2021-43860", "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. Prior to versions 1.12.3 and 1.10.6, Flatpak doesn't properly validate that the permissions displayed to the user for an app at install time match the actual permissions granted to the app at runtime, in the case that there's a null byte in the metadata file of an app. Therefore apps can grant themselves permissions without the consent of the user. Flatpak shows permissions to the user during install by reading them from the \"xa.metadata\" key in the commit metadata. This cannot contain a null terminator, because it is an untrusted GVariant. Flatpak compares these permissions to the *actual* metadata, from the \"metadata\" file to ensure it wasn't lied to. However, the actual metadata contents are loaded in several places where they are read as simple C-style strings. That means that, if the metadata file includes a null terminator, only the content of the file from *before* the terminator gets compared to xa.metadata. Thus, any permissions that appear in the metadata file after a null terminator are applied at runtime but not shown to the user. So maliciously crafted apps can give themselves hidden permissions. Users who have Flatpaks installed from untrusted sources are at risk in case the Flatpak has a maliciously crafted metadata file, either initially or in an update. This issue is patched in versions 1.12.3 and 1.10.6. As a workaround, users can manually check the permissions of installed apps by checking the metadata file or the xa.metadata key on the commit metadata.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `flatpak_dir_ensure_bundle_remote` is responsible for ensuring a remote is set up for a Flatpak bundle, either by reusing an existing remote or creating a new one.\n\n2. The function first ensures the repository is available via `flatpak_dir_ensure_repo`, which is a standard safety check.\n\n3. It then loads the bundle using `flatpak_bundle_load`, which parses the bundle file and extracts metadata, ref (reference), origin, checksum, and GPG data. This function is designed to validate the bundle's integrity and structure.\n\n4. The function checks if the bundle is already deployed via `flatpak_dir_get_deploy_data`. If it is, it retrieves the existing remote origin and updates the remote configuration with GPG data if provided. This is done using `flatpak_dir_modify_remote`, which modifies the remote configuration to include the GPG data.\n\n5. If the bundle is not deployed, it creates a new remote using `flatpak_dir_create_origin_remote`, which sets up a new remote with the origin, ID, ref, and GPG data.\n\n6. The GPG data is sourced from either `extra_gpg_data` (provided by the caller) or `included_gpg_data` (embedded in the bundle). This is used to verify the authenticity of the bundle.\n\n7. The function then returns the remote name, ref, checksum, and metadata as output parameters.\n\n8. Security considerations:\n   - The bundle is loaded via `flatpak_bundle_load`, which performs integrity checks (e.g., signature verification) and validates the metadata. This prevents loading malicious or tampered bundles.\n   - GPG data is only used to configure the remote, not to execute arbitrary code. The `flatpak_dir_modify_remote` function is responsible for securely updating the remote configuration.\n   - The function does not perform any unsafe string operations, memory copying, or direct user input handling without validation.\n   - The use of `g_steal_pointer` and `g_autoptr` ensures proper memory management and prevents leaks.\n   - The function does not expose any user-controllable data to unsafe operations like shell commands, dynamic code execution, or unvalidated string interpolation.\n\n9. There is no evidence of buffer overflows, use-after-free, format string vulnerabilities, or injection attacks. The code follows secure patterns for handling external data (bundles) and remote configuration.\n\n10. The function is part of Flatpak, a well-audited system for sandboxed application distribution, and this specific function is designed to be safe by relying on validated bundle metadata and secure remote management.\n\n(2) NO: No security vulnerability."}
{"idx": 210702, "project": "squashfs-tools", "commit_id": "79b5a555058eef4e1e7ff220c344d39f8cd09646", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/79b5a555058eef4e1e7ff220c344d39f8cd09646", "commit_message": "Unsquashfs: fix write outside destination directory exploit\n\nAn issue on Github (https://github.com/plougher/squashfs-tools/issues/72)\nshows how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and ..) can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nThis commit fixes this exploit by checking all names for\nvalidity.\n\nIn doing so I have also added checks for '.' and for names that\nare shorter than they should be (names in the file system should\nnot have '\\0' terminators).\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 1, "cwe": ["CWE-22"], "cve": "CVE-2021-40153", "cve_desc": "squashfs_opendir in unsquash-1.c in Squashfs-Tools 4.5 stores the filename in the directory entry; this is then used by unsquashfs to create the new file during the unsquash. The filename is not validated for traversal outside of the destination directory, and thus allows writing to locations outside of the destination.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its entries, and populating a `struct dir` with metadata about the directory entries.\n\n2. A buffer `buffer` of size `sizeof(struct squashfs_dir_entry) + SQUASHFS_NAME_LEN + 1` is declared and aligned. This buffer is used to hold a single directory entry (`dire`) during processing.\n\n3. The function reads the directory header (`dirh`) and validates that `dir_count` (number of entries) is not greater than `SQUASHFS_DIR_COUNT`. This is a safety check to prevent excessive memory allocation.\n\n4. The function then loops through each directory entry:\n   - It swaps the endianness of the directory entry (`SQUASHFS_SWAP_DIR_ENTRY`) to handle byte order differences.\n   - It checks that `dire->size >= SQUASHFS_NAME_LEN` triggers an error. This is a critical check: if the filename size is equal to or greater than `SQUASHFS_NAME_LEN`, it reports corruption. This prevents overly long filenames from being processed.\n\n5. The key line to analyze:\n   ```c\n   memcpy(dire->name, directory_table + bytes, dire->size + 1);\n   dire->name[dire->size + 1] = '\\0';\n   ```\n   - `dire->size + 1` bytes are copied from `directory_table + bytes` into `dire->name`.\n   - Then, `dire->name[dire->size + 1] = '\\0'` is written \u2014 but `dire->name` is only allocated with size `sizeof(struct squashfs_dir_entry) + SQUASHFS_NAME_LEN + 1`, and `dire->size` is checked to be less than `SQUASHFS_NAME_LEN` (via `if(dire->size >= SQUASHFS_NAME_LEN)`).\n\n   So, if `dire->size` is less than `SQUASHFS_NAME_LEN`, then `dire->size + 1` is at most `SQUASHFS_NAME_LEN`, which fits in the buffer.\n\n   However, the **critical flaw** is in the line:\n   ```c\n   dire->name[dire->size + 1] = '\\0';\n   ```\n   - The buffer `dire->name` is of size `SQUASHFS_NAME_LEN + 1` (to hold the name + null terminator).\n   - `dire->size` is the length of the name (without null).\n   - So, `dire->name[dire->size]` is the last valid byte for the null terminator.\n   - But the code writes to `dire->name[dire->size + 1]`, which is **one byte beyond the buffer**.\n\n   This is a **buffer overflow** in the `dire->name` array.\n\n6. Even though the `dire->size` is checked to be less than `SQUASHFS_NAME_LEN`, the check is not sufficient to prevent the overflow because:\n   - The buffer `dire->name` is of size `SQUASHFS_NAME_LEN + 1`.\n   - The code copies `dire->size + 1` bytes (including the null), so the null should be at `dire->name[dire->size]`.\n   - But the code writes `dire->name[dire->size + 1] = '\\0'`, which is **out-of-bounds**.\n\n7. This is a classic **off-by-one buffer overflow** in a stack-allocated buffer (`buffer`), which can be exploited to corrupt memory or execute arbitrary code if the filesystem is crafted maliciously.\n\n8. The function also uses `strcpy` later to copy `dire->name` into `dir->dirs[dir->dir_count].name`, which is another potential vulnerability if `dire->name` is not null-terminated correctly \u2014 but the real issue is the **out-of-bounds write** in `dire->name[dire->size + 1]`.\n\n9. The `SQUASHFS_NAME_LEN` is likely a constant (e.g., 255), so the buffer is large enough, but the **off-by-one write** still occurs and is exploitable in certain contexts (e.g., if the buffer is near other sensitive data).\n\n(1) YES: A security vulnerability detected."}
{"idx": 211471, "project": "frr", "commit_id": "ff6db1027f8f36df657ff2e5ea167773752537ed", "project_url": "https://github.com/FRRouting/frr", "commit_url": "https://github.com/FRRouting/frr/commit/ff6db1027f8f36df657ff2e5ea167773752537ed", "commit_message": "bgpd: Make sure hdr length is at a minimum of what is expected\n\nEnsure that if the capability length specified is enough data.\n\nSigned-off-by: Donald Sharp <sharpd@nvidia.com>", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-37032", "cve_desc": "An out-of-bounds read in the BGP daemon of FRRouting FRR before 8.4 may lead to a segmentation fault and denial of service. This occurs in bgp_capability_msg_parse in bgpd/bgp_packet.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `bgp_capability_msg_parse` parses BGP capability messages from a peer. It processes a byte stream (`pnt`) of length `length` and extracts capability headers and data.\n\n2. The function starts by setting `end = pnt + length`, which defines the end of the input buffer. This is used to prevent buffer overflows during parsing.\n\n3. A `while` loop iterates over the input data, processing each capability in sequence.\n\n4. Before processing any capability, the code checks:\n   - `if (pnt + 3 > end)` \u2192 ensures at least 3 bytes (action, code, length) are available.\n   - This is a valid bounds check to prevent reading beyond the buffer.\n\n5. Then it checks:\n   - `if ((pnt + hdr->length + 3) > end)` \u2192 ensures the full capability (header + data) fits within the remaining buffer.\n   - This is a critical bounds check: it verifies that the `hdr->length` field (which comes from the input) does not cause a buffer overflow when reading `hdr->length + 3` bytes.\n\n6. The function then uses `memcpy(&mpc, pnt + 3, sizeof(struct capability_mp_data))` to copy the capability data. The size copied is fixed (`sizeof(struct capability_mp_data)`), and the source is validated via the previous bounds check.\n\n7. The `hdr->length` field is used to determine how much data to skip (`pnt += hdr->length + 3`). However, the code does **not** validate that `hdr->length` is within a reasonable range (e.g., not excessively large). But note: the earlier check `if ((pnt + hdr->length + 3) > end)` already ensures that `hdr->length` cannot be so large that it causes a buffer overflow when reading or advancing the pointer.\n\n8. The `memcpy` is safe because:\n   - The source buffer is bounded by `end`.\n   - The size copied is fixed and known (`sizeof(struct capability_mp_data)`), which is a compile-time constant.\n   - The input `hdr->length` is not used to determine the size of the `memcpy` \u2014 only to control how much to skip.\n\n9. The `memcpy` is not vulnerable to heap or stack overflow because:\n   - The destination is a local struct (`mpc`), which is on the stack.\n   - The size copied is fixed and small (known at compile time).\n   - The source is validated via the bounds check.\n\n10. The function also checks `action` for valid values (`CAPABILITY_ACTION_SET` or `CAPABILITY_ACTION_UNSET`) \u2014 this prevents invalid state transitions.\n\n11. The `hdr->code` is checked: if not `CAPABILITY_CODE_MP`, it logs a warning and ignores the capability. No unsafe operations are performed.\n\n12. The `bgp_map_afi_safi_iana2int` function is called with `pkt_afi` and `pkt_safi` from the parsed data. However, this function is assumed to be safe (as it's part of the BGP implementation and typically validates input). Even if it were not, the input comes from a validated source (the `mpc` struct, which was safely copied).\n\n13. The function uses `ntohs(mpc.afi)` \u2014 this is safe because `mpc.afi` is a 16-bit value from the network byte order, and `ntohs` is a standard, safe conversion.\n\n14. The `pnt` pointer is advanced by `hdr->length + 3`, but only after verifying that this does not exceed `end`. This prevents buffer over-reads.\n\n15. The only potential risk would be if `hdr->length` were extremely large (e.g., near `UINT_MAX`), but the check `pnt + hdr->length + 3 > end` prevents this from causing an overflow \u2014 it would fail early and return `BGP_Stop`.\n\n16. The function does not perform any dynamic memory allocation, does not use unsafe string functions, and does not expose user-controlled data to unsafe operations.\n\nConclusion: All input validation and bounds checks are properly implemented. The code safely parses the BGP capability message without any risk of buffer overflow, out-of-bounds access, or other memory safety issues.\n\n(2) NO: No security vulnerability."}
{"idx": 195984, "project": "gpac", "commit_id": "3dbe11b37d65c8472faf0654410068e5500b3adb", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/3dbe11b37d65c8472faf0654410068e5500b3adb", "commit_message": "fixed #2175", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1441", "cve_desc": "MP4Box is a component of GPAC-2.0.0, which is a widely-used third-party package on RPM Fusion. When MP4Box tries to parse a MP4 file, it calls the function `diST_box_read()` to read from video. In this function, it allocates a buffer `str` with fixed length. However, content read from `bs` is controllable by user, so is the length, which causes a buffer overflow.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `diST_box_read` reads data from a bitstream (`bs`) into a character buffer `str` of size 1024.\n2. It reads one byte at a time using `gf_bs_read_u8(bs)` and stores it in `str[i]`, incrementing `i` each time.\n3. The loop continues until a null byte (`\\0`) is read, which acts as a terminator.\n4. The buffer `str` is declared with a fixed size of 1024 bytes.\n5. The function does not check whether `i` exceeds 1023 (the maximum index for a 1024-byte array) before writing to `str[i]`.\n6. If the bitstream contains more than 1023 non-null bytes before a null terminator, the loop will write past the end of the buffer, causing a buffer overflow.\n7. Although the loop stops at the first null byte, there is no guarantee that a null byte appears within the first 1023 bytes. An attacker could craft input with many non-null bytes (e.g., all 0xFF) followed by a null byte only after 2048 bytes, which would overflow the 1024-byte buffer.\n8. The function then uses `gf_strdup(str)` to copy the string, but this is after the potential overflow has already occurred.\n9. The `ISOM_DECREASE_SIZE(p, i)` call is based on `i`, which could be larger than the actual buffer size if overflow occurred, but this does not mitigate the buffer overflow issue.\n\nTherefore, this code is vulnerable to a buffer overflow due to lack of bounds checking on the input size relative to the buffer size.\n\n(1) YES: A security vulnerability detected."}
{"idx": 212414, "project": "linux", "commit_id": "04c2a47ffb13c29778e2a14e414ad4cb5a5db4b5", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/04c2a47ffb13c29778e2a14e414ad4cb5a5db4b5", "commit_message": "net: sched: fix use-after-free in tc_new_tfilter()\n\nWhenever tc_new_tfilter() jumps back to replay: label,\nwe need to make sure @q and @chain local variables are cleared again,\nor risk use-after-free as in [1]\n\nFor consistency, apply the same fix in tc_ctl_chain()\n\nBUG: KASAN: use-after-free in mini_qdisc_pair_swap+0x1b9/0x1f0 net/sched/sch_generic.c:1581\nWrite of size 8 at addr ffff8880985c4b08 by task syz-executor.4/1945\n\nCPU: 0 PID: 1945 Comm: syz-executor.4 Not tainted 5.17.0-rc1-syzkaller-00495-gff58831fa02d #0\nHardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011\nCall Trace:\n <TASK>\n __dump_stack lib/dump_stack.c:88 [inline]\n dump_stack_lvl+0xcd/0x134 lib/dump_stack.c:106\n print_address_description.constprop.0.cold+0x8d/0x336 mm/kasan/report.c:255\n __kasan_report mm/kasan/report.c:442 [inline]\n kasan_report.cold+0x83/0xdf mm/kasan/report.c:459\n mini_qdisc_pair_swap+0x1b9/0x1f0 net/sched/sch_generic.c:1581\n tcf_chain_head_change_item net/sched/cls_api.c:372 [inline]\n tcf_chain0_head_change.isra.0+0xb9/0x120 net/sched/cls_api.c:386\n tcf_chain_tp_insert net/sched/cls_api.c:1657 [inline]\n tcf_chain_tp_insert_unique net/sched/cls_api.c:1707 [inline]\n tc_new_tfilter+0x1e67/0x2350 net/sched/cls_api.c:2086\n rtnetlink_rcv_msg+0x80d/0xb80 net/core/rtnetlink.c:5583\n netlink_rcv_skb+0x153/0x420 net/netlink/af_netlink.c:2494\n netlink_unicast_kernel net/netlink/af_netlink.c:1317 [inline]\n netlink_unicast+0x539/0x7e0 net/netlink/af_netlink.c:1343\n netlink_sendmsg+0x904/0xe00 net/netlink/af_netlink.c:1919\n sock_sendmsg_nosec net/socket.c:705 [inline]\n sock_sendmsg+0xcf/0x120 net/socket.c:725\n ____sys_sendmsg+0x331/0x810 net/socket.c:2413\n ___sys_sendmsg+0xf3/0x170 net/socket.c:2467\n __sys_sendmmsg+0x195/0x470 net/socket.c:2553\n __do_sys_sendmmsg net/socket.c:2582 [inline]\n __se_sys_sendmmsg net/socket.c:2579 [inline]\n __x64_sys_sendmmsg+0x99/0x100 net/socket.c:2579\n do_syscall_x64 arch/x86/entry/common.c:50 [inline]\n do_syscall_64+0x35/0xb0 arch/x86/entry/common.c:80\n entry_SYSCALL_64_after_hwframe+0x44/0xae\nRIP: 0033:0x7f2647172059\nCode: ff ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 b8 ff ff ff f7 d8 64 89 01 48\nRSP: 002b:00007f2645aa5168 EFLAGS: 00000246 ORIG_RAX: 0000000000000133\nRAX: ffffffffffffffda RBX: 00007f2647285100 RCX: 00007f2647172059\nRDX: 040000000000009f RSI: 00000000200002c0 RDI: 0000000000000006\nRBP: 00007f26471cc08d R08: 0000000000000000 R09: 0000000000000000\nR10: 9e00000000000000 R11: 0000000000000246 R12: 0000000000000000\nR13: 00007fffb3f7f02f R14: 00007f2645aa5300 R15: 0000000000022000\n </TASK>\n\nAllocated by task 1944:\n kasan_save_stack+0x1e/0x40 mm/kasan/common.c:38\n kasan_set_track mm/kasan/common.c:45 [inline]\n set_alloc_info mm/kasan/common.c:436 [inline]\n ____kasan_kmalloc mm/kasan/common.c:515 [inline]\n ____kasan_kmalloc mm/kasan/common.c:474 [inline]\n __kasan_kmalloc+0xa9/0xd0 mm/kasan/common.c:524\n kmalloc_node include/linux/slab.h:604 [inline]\n kzalloc_node include/linux/slab.h:726 [inline]\n qdisc_alloc+0xac/0xa10 net/sched/sch_generic.c:941\n qdisc_create.constprop.0+0xce/0x10f0 net/sched/sch_api.c:1211\n tc_modify_qdisc+0x4c5/0x1980 net/sched/sch_api.c:1660\n rtnetlink_rcv_msg+0x413/0xb80 net/core/rtnetlink.c:5592\n netlink_rcv_skb+0x153/0x420 net/netlink/af_netlink.c:2494\n netlink_unicast_kernel net/netlink/af_netlink.c:1317 [inline]\n netlink_unicast+0x539/0x7e0 net/netlink/af_netlink.c:1343\n netlink_sendmsg+0x904/0xe00 net/netlink/af_netlink.c:1919\n sock_sendmsg_nosec net/socket.c:705 [inline]\n sock_sendmsg+0xcf/0x120 net/socket.c:725\n ____sys_sendmsg+0x331/0x810 net/socket.c:2413\n ___sys_sendmsg+0xf3/0x170 net/socket.c:2467\n __sys_sendmmsg+0x195/0x470 net/socket.c:2553\n __do_sys_sendmmsg net/socket.c:2582 [inline]\n __se_sys_sendmmsg net/socket.c:2579 [inline]\n __x64_sys_sendmmsg+0x99/0x100 net/socket.c:2579\n do_syscall_x64 arch/x86/entry/common.c:50 [inline]\n do_syscall_64+0x35/0xb0 arch/x86/entry/common.c:80\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nFreed by task 3609:\n kasan_save_stack+0x1e/0x40 mm/kasan/common.c:38\n kasan_set_track+0x21/0x30 mm/kasan/common.c:45\n kasan_set_free_info+0x20/0x30 mm/kasan/generic.c:370\n ____kasan_slab_free mm/kasan/common.c:366 [inline]\n ____kasan_slab_free+0x130/0x160 mm/kasan/common.c:328\n kasan_slab_free include/linux/kasan.h:236 [inline]\n slab_free_hook mm/slub.c:1728 [inline]\n slab_free_freelist_hook+0x8b/0x1c0 mm/slub.c:1754\n slab_free mm/slub.c:3509 [inline]\n kfree+0xcb/0x280 mm/slub.c:4562\n rcu_do_batch kernel/rcu/tree.c:2527 [inline]\n rcu_core+0x7b8/0x1540 kernel/rcu/tree.c:2778\n __do_softirq+0x29b/0x9c2 kernel/softirq.c:558\n\nLast potentially related work creation:\n kasan_save_stack+0x1e/0x40 mm/kasan/common.c:38\n __kasan_record_aux_stack+0xbe/0xd0 mm/kasan/generic.c:348\n __call_rcu kernel/rcu/tree.c:3026 [inline]\n call_rcu+0xb1/0x740 kernel/rcu/tree.c:3106\n qdisc_put_unlocked+0x6f/0x90 net/sched/sch_generic.c:1109\n tcf_block_release+0x86/0x90 net/sched/cls_api.c:1238\n tc_new_tfilter+0xc0d/0x2350 net/sched/cls_api.c:2148\n rtnetlink_rcv_msg+0x80d/0xb80 net/core/rtnetlink.c:5583\n netlink_rcv_skb+0x153/0x420 net/netlink/af_netlink.c:2494\n netlink_unicast_kernel net/netlink/af_netlink.c:1317 [inline]\n netlink_unicast+0x539/0x7e0 net/netlink/af_netlink.c:1343\n netlink_sendmsg+0x904/0xe00 net/netlink/af_netlink.c:1919\n sock_sendmsg_nosec net/socket.c:705 [inline]\n sock_sendmsg+0xcf/0x120 net/socket.c:725\n ____sys_sendmsg+0x331/0x810 net/socket.c:2413\n ___sys_sendmsg+0xf3/0x170 net/socket.c:2467\n __sys_sendmmsg+0x195/0x470 net/socket.c:2553\n __do_sys_sendmmsg net/socket.c:2582 [inline]\n __se_sys_sendmmsg net/socket.c:2579 [inline]\n __x64_sys_sendmmsg+0x99/0x100 net/socket.c:2579\n do_syscall_x64 arch/x86/entry/common.c:50 [inline]\n do_syscall_64+0x35/0xb0 arch/x86/entry/common.c:80\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nThe buggy address belongs to the object at ffff8880985c4800\n which belongs to the cache kmalloc-1k of size 1024\nThe buggy address is located 776 bytes inside of\n 1024-byte region [ffff8880985c4800, ffff8880985c4c00)\nThe buggy address belongs to the page:\npage:ffffea0002617000 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x985c0\nhead:ffffea0002617000 order:3 compound_mapcount:0 compound_pincount:0\nflags: 0xfff00000010200(slab|head|node=0|zone=1|lastcpupid=0x7ff)\nraw: 00fff00000010200 0000000000000000 dead000000000122 ffff888010c41dc0\nraw: 0000000000000000 0000000000100010 00000001ffffffff 0000000000000000\npage dumped because: kasan: bad access detected\npage_owner tracks the page as allocated\npage last allocated via order 3, migratetype Unmovable, gfp_mask 0x1d20c0(__GFP_IO|__GFP_FS|__GFP_NOWARN|__GFP_NORETRY|__GFP_COMP|__GFP_NOMEMALLOC|__GFP_HARDWALL), pid 1941, ts 1038999441284, free_ts 1033444432829\n prep_new_page mm/page_alloc.c:2434 [inline]\n get_page_from_freelist+0xa72/0x2f50 mm/page_alloc.c:4165\n __alloc_pages+0x1b2/0x500 mm/page_alloc.c:5389\n alloc_pages+0x1aa/0x310 mm/mempolicy.c:2271\n alloc_slab_page mm/slub.c:1799 [inline]\n allocate_slab mm/slub.c:1944 [inline]\n new_slab+0x28a/0x3b0 mm/slub.c:2004\n ___slab_alloc+0x87c/0xe90 mm/slub.c:3018\n __slab_alloc.constprop.0+0x4d/0xa0 mm/slub.c:3105\n slab_alloc_node mm/slub.c:3196 [inline]\n slab_alloc mm/slub.c:3238 [inline]\n __kmalloc+0x2fb/0x340 mm/slub.c:4420\n kmalloc include/linux/slab.h:586 [inline]\n kzalloc include/linux/slab.h:715 [inline]\n __register_sysctl_table+0x112/0x1090 fs/proc/proc_sysctl.c:1335\n neigh_sysctl_register+0x2c8/0x5e0 net/core/neighbour.c:3787\n devinet_sysctl_register+0xb1/0x230 net/ipv4/devinet.c:2618\n inetdev_init+0x286/0x580 net/ipv4/devinet.c:278\n inetdev_event+0xa8a/0x15d0 net/ipv4/devinet.c:1532\n notifier_call_chain+0xb5/0x200 kernel/notifier.c:84\n call_netdevice_notifiers_info+0xb5/0x130 net/core/dev.c:1919\n call_netdevice_notifiers_extack net/core/dev.c:1931 [inline]\n call_netdevice_notifiers net/core/dev.c:1945 [inline]\n register_netdevice+0x1073/0x1500 net/core/dev.c:9698\n veth_newlink+0x59c/0xa90 drivers/net/veth.c:1722\npage last free stack trace:\n reset_page_owner include/linux/page_owner.h:24 [inline]\n free_pages_prepare mm/page_alloc.c:1352 [inline]\n free_pcp_prepare+0x374/0x870 mm/page_alloc.c:1404\n free_unref_page_prepare mm/page_alloc.c:3325 [inline]\n free_unref_page+0x19/0x690 mm/page_alloc.c:3404\n release_pages+0x748/0x1220 mm/swap.c:956\n tlb_batch_pages_flush mm/mmu_gather.c:50 [inline]\n tlb_flush_mmu_free mm/mmu_gather.c:243 [inline]\n tlb_flush_mmu+0xe9/0x6b0 mm/mmu_gather.c:250\n zap_pte_range mm/memory.c:1441 [inline]\n zap_pmd_range mm/memory.c:1490 [inline]\n zap_pud_range mm/memory.c:1519 [inline]\n zap_p4d_range mm/memory.c:1540 [inline]\n unmap_page_range+0x1d1d/0x2a30 mm/memory.c:1561\n unmap_single_vma+0x198/0x310 mm/memory.c:1606\n unmap_vmas+0x16b/0x2f0 mm/memory.c:1638\n exit_mmap+0x201/0x670 mm/mmap.c:3178\n __mmput+0x122/0x4b0 kernel/fork.c:1114\n mmput+0x56/0x60 kernel/fork.c:1135\n exit_mm kernel/exit.c:507 [inline]\n do_exit+0xa3c/0x2a30 kernel/exit.c:793\n do_group_exit+0xd2/0x2f0 kernel/exit.c:935\n __do_sys_exit_group kernel/exit.c:946 [inline]\n __se_sys_exit_group kernel/exit.c:944 [inline]\n __x64_sys_exit_group+0x3a/0x50 kernel/exit.c:944\n do_syscall_x64 arch/x86/entry/common.c:50 [inline]\n do_syscall_64+0x35/0xb0 arch/x86/entry/common.c:80\n entry_SYSCALL_64_after_hwframe+0x44/0xae\n\nMemory state around the buggy address:\n ffff8880985c4a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb\n ffff8880985c4a80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb\n>ffff8880985c4b00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb\n                      ^\n ffff8880985c4b80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb\n ffff8880985c4c00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc\n\nFixes: 470502de5bdb (\"net: sched: unlock rules update API\")\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nCc: Vlad Buslov <vladbu@mellanox.com>\nCc: Jiri Pirko <jiri@mellanox.com>\nCc: Cong Wang <xiyou.wangcong@gmail.com>\nReported-by: syzbot <syzkaller@googlegroups.com>\nLink: https://lore.kernel.org/r/20220131172018.3704490-1-eric.dumazet@gmail.com\nSigned-off-by: Jakub Kicinski <kuba@kernel.org>", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-1055", "cve_desc": "A use-after-free exists in the Linux Kernel in tc_new_tfilter that could allow a local attacker to gain privilege escalation. The exploit requires unprivileged user namespaces. We recommend upgrading past commit 04c2a47ffb13c29778e2a14e414ad4cb5a5db4b5", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n1. **Input Validation and Parsing**:\n   - The function `tc_new_tfilter` processes a Netlink message (`nlmsghdr`) to create or modify a traffic control (TC) filter.\n   - It uses `nlmsg_parse_deprecated` to parse attributes into `tca`, with a policy defined by `rtm_tca_policy`. This is a standard and safe way to validate Netlink attributes.\n   - The function checks for valid `TCA_KIND`, `TCA_CHAIN`, and `tcm_info` (priority and protocol), and validates the `chain_index` against `TC_ACT_EXT_VAL_MASK`. This prevents out-of-bounds access.\n\n2. **Buffer Size and String Handling**:\n   - A local buffer `char name[IFNAMSIZ]` is used to store the filter kind (e.g., \"ingress\", \"htb\"). `IFNAMSIZ` is typically 16 bytes, which is sufficient for interface and filter kind names.\n   - The function calls `tcf_proto_check_kind(tca[TCA_KIND], name)` to validate the length of the kind string. This prevents buffer overflow by ensuring the name is not too long.\n\n3. **Use of `nla_get_u32` and `nla_strcmp`**:\n   - `nla_get_u32` is used to extract `chain_index`, and it is checked against `TC_ACT_EXT_VAL_MASK` (which is 0x3F, or 63). This prevents integer overflow or out-of-range values.\n   - `nla_strcmp` is used to compare the filter kind string with the existing `tp->ops->kind`. This is safe as long as the strings are null-terminated and within bounds \u2014 which is ensured by prior validation.\n\n4. **Use of `__tcf_block_find` and `tcf_chain_get`**:\n   - These functions are used to locate or create a filter chain and block. They return `struct tcf_block *` or `struct tcf_chain *`, and `IS_ERR()` is used to check for errors. This prevents use of invalid pointers.\n\n5. **Use of `tcf_proto_create` and `tcf_chain_tp_insert_unique`**:\n   - These functions are responsible for creating and inserting a new filter protocol. They are called only when `n->nlmsg_flags & NLM_F_CREATE` is set, and only if the filter does not already exist.\n   - The `tcf_proto_create` function is expected to be safe and validate inputs.\n\n6. **Use of `tp->ops->get` and `tp->ops->change`**:\n   - These are function pointers to the specific filter kind's implementation (e.g., for `bpf`, `u32`, etc.).\n   - The `get` function returns a filter handle (`fh`). If `fh` is NULL and `NLM_F_CREATE` is not set, an error is returned \u2014 this prevents creation without proper flags.\n   - The `change` function is called only after proper validation and locking.\n\n7. **Locking and Concurrency**:\n   - The function uses `rtnl_lock()` and `mutex_lock(&chain->filter_chain_lock)` to protect against race conditions.\n   - It checks `chain->flushing` and retries with `goto replay` on `-EAGAIN`, which is a known pattern to handle concurrent chain flushes safely.\n   - The `rtnl_held` flag ensures that the lock is properly released even in error paths.\n\n8. **Error Handling and Cleanup**:\n   - The function has a well-structured error path (`errout`, `errout_locked`, `errout_tp`) that ensures:\n     - Resources are properly released (`tcf_proto_put`, `tcf_chain_put`, `tcf_block_release`).\n     - The `rtnl_unlock()` is called only if `rtnl_held` is true.\n     - `tcf_chain_tp_delete_empty` is called only if `tp_created` is true, preventing memory leaks.\n\n9. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, `gets`, or other unsafe string functions.\n   - All string operations are bounded and validated via `nla_*` functions and `tcf_proto_check_kind`.\n\n10. **No Known Vulnerabilities**:\n    - The code follows kernel security best practices: input validation, proper locking, error handling, and resource cleanup.\n    - The use of `nlmsg_flags` (`NLM_F_CREATE`, `NLM_F_EXCL`, `NLM_F_REPLACE`) ensures that operations are atomic and safe.\n    - The `rtnl_held` logic prevents race conditions during concurrent operations.\n\nConclusion: The code is well-structured, uses safe APIs, performs proper input validation, and handles errors and cleanup correctly. There are no obvious buffer overflows, use-after-free, race conditions, or injection vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 217551, "project": "elfspirit", "commit_id": "c5b0f5a9a24f2451bbeda4751d67633bc375e608", "project_url": "https://github.com/liyansong2018/elfspirit", "commit_url": "https://github.com/liyansong2018/elfspirit/commit/c5b0f5a9a24f2451bbeda4751d67633bc375e608", "commit_message": "Fix #1 about out-of-bounds", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-21711", "cve_desc": "elfspirit is an ELF static analysis and injection framework that parses, manipulates, and camouflages ELF files. When analyzing the ELF file format in versions prior to 1.1, there is an out-of-bounds read bug, which can lead to application crashes or information leakage. By constructing a special format ELF file, the information of any address can be leaked. elfspirit version 1.1 contains a patch for this issue.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Input Handling and File Access\n- The function `parse` takes a `char *elf` parameter, which is the path to an ELF file.\n- It opens the file using `open(elf, O_RDONLY)`, which is safe as long as the path is controlled and validated.\n- The file is then mapped into memory using `mmap(0, st.st_size, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0)`.\n  - `PROT_READ | PROT_WRITE` is used, which allows reading and writing the mapped memory.\n  - However, the code only reads from the ELF file and does not modify it. The write permission is unnecessary and could be a concern if the file is untrusted, but since the code only reads and parses, it's not immediately exploitable.\n\n---\n\n### Step 2: Buffer Overflow Risk \u2013 String Truncation\n- The code uses `strcpy(&name[15 - 6], \"[...]\")` when `strlen(name) > 15`.\n  - This line attempts to truncate the string `name` to 15 characters by overwriting from position `15 - 6 = 9` with `[...]`.\n  - However, this is **dangerous**:\n    - `strcpy` does **not** check bounds.\n    - If `name` is shorter than 9 characters, this will cause a buffer overflow.\n    - Even if `strlen(name) > 15`, the `strcpy` call starts at index 9, but there's no guarantee that `name` has at least 15 characters, or that the buffer is large enough.\n    - The `name` pointer comes from `elf_map + shstrtab.sh_offset + shdr[i].sh_name`, which is a pointer into the ELF file's string table. The size of this string is not validated.\n    - This is a **classic buffer overflow vulnerability** due to unsafe string manipulation.\n\n---\n\n### Step 3: Use of `snprintf` and `memset`\n- The code uses `snprintf(value, 50, \"0x%x\", ...)` and `memset(value, 0, 50)` \u2014 these are safe because they limit the output size.\n- `snprintf` is used correctly with size bounds.\n- `memset` is used safely.\n\n---\n\n### Step 4: Dynamic Section Parsing\n- The code parses `.dynstr` and `.dynamic` sections to extract shared library names and other metadata.\n- It uses `name = elf_map + shdr[dynstr].sh_offset + dyn[i].d_un.d_val` to access strings from `.dynstr`.\n  - This is safe **only if** `dyn[i].d_un.d_val` is within bounds of the `.dynstr` section.\n  - However, the code does **not validate** that `dyn[i].d_un.d_val` is less than `shdr[dynstr].sh_size`.\n  - If an attacker crafts an ELF file with a malicious `d_un.d_val` value (e.g., very large), this could lead to **out-of-bounds memory access** or **buffer overflow** when `snprintf` or `strcpy` is used on the resulting string.\n  - This is a **critical vulnerability** in the context of untrusted input.\n\n---\n\n### Step 5: Memory Mapping and Access\n- The code maps the entire ELF file into memory with `mmap` and then accesses it directly via pointer arithmetic.\n- This is acceptable for parsing, but:\n  - The code assumes the file is a valid ELF file (checked via `get_elf_class`).\n  - However, if the file is malformed or crafted maliciously, the `mmap`-mapped data could be used to trigger out-of-bounds reads or writes.\n  - The code does not validate the ELF header fields (e.g., `e_shoff`, `e_phoff`, `e_shnum`, etc.) before using them to index into the mapped memory.\n  - For example, `shdr = (Elf32_Shdr *)&elf_map[ehdr->e_shoff];` \u2014 if `ehdr->e_shoff` is invalid (e.g., huge or negative), this could cause a crash or memory corruption.\n\n---\n\n### Step 6: Use of `flag` Buffer\n- `char flag[4];` is used and `strcpy(flag, \"   \");` is called.\n- Then `flag2str_sh` and `flag2str` are used to write into `flag`.\n- These functions are not shown, but if they write more than 3 characters into `flag`, it could overflow.\n- However, since `flag` is only 4 bytes, and the string is likely short (e.g., \"RWE\", \"R\", etc.), this is **probably safe** if the functions are well-behaved.\n\n---\n\n### Step 7: Overall Risk Assessment\n- The code is parsing untrusted ELF files.\n- It performs **no validation** of:\n  - ELF header fields (e.g., `e_shoff`, `e_phoff`, `e_shnum`, `e_phnum`).\n  - Section offsets and sizes.\n  - Dynamic entry values (`d_un.d_val`).\n- The use of `strcpy` on `name` with a fixed offset (`&name[9]`) is **unsafe** and can cause buffer overflow.\n- The use of `snprintf` and `memset` is safe, but the **input validation is missing** for critical fields.\n\n---\n\n### Conclusion\nThe code contains **multiple security vulnerabilities**, including:\n- **Buffer overflow** due to unsafe `strcpy` usage on `name`.\n- **Out-of-bounds memory access** due to lack of validation of ELF header fields and dynamic section offsets.\n- **Untrusted input parsing** without bounds checking.\n\nThese vulnerabilities can be exploited by an attacker to cause crashes, memory corruption, or potentially arbitrary code execution.\n\n(1) YES: A security vulnerability detected."}
{"idx": 211126, "project": "libmobi", "commit_id": "612562bc1ea38f1708b044e7a079c47a05b1291d", "project_url": "https://github.com/bfabiszewski/libmobi", "commit_url": "https://github.com/bfabiszewski/libmobi/commit/612562bc1ea38f1708b044e7a079c47a05b1291d", "commit_message": "Fix: index entry label not being zero-terminated with corrupt input", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-1987", "cve_desc": "Buffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function starts by checking if `indx` is NULL, which is a good practice.\n   - It calculates `entry_offset` and `entry_length` based on `idxt.offsets[curr_number]` and `idxt.offsets[curr_number + 1]`. This assumes that `idxt.offsets` is valid and properly sized. However, there is no validation that `curr_number + 1` is within bounds of `idxt.offsets`. If `curr_number` is too large (e.g., equal to `idxt.offsets_count - 1`), accessing `idxt.offsets[curr_number + 1]` would be out of bounds. This is a critical issue: **missing bounds check on `curr_number` relative to `idxt.offsets` array size**.\n   - The code checks `entry_number >= indx->total_entries_count`, which is correct for preventing out-of-bounds access to `indx->entries`, but this check depends on `entry_offset` being valid, which is derived from `indx->entries_count`. If `indx->entries_count` is corrupted or malicious, this could still lead to buffer overflows.\n\n2. **Buffer Overflow Prevention**:\n   - The code uses `mobi_buffer_setpos(buf, idxt.offsets[curr_number])` to set the buffer position. This is safe as long as `idxt.offsets[curr_number]` is within the buffer bounds.\n   - It then checks: `if (buf->offset + entry_length >= buf_maxlen)`, which prevents reading beyond the buffer. This is a good safety check.\n   - It sets `buf->maxlen = buf->offset + entry_length`, which is correct for limiting future reads.\n\n3. **Label Length Handling**:\n   - `label_length = mobi_buffer_get8(buf);` reads a single byte as the label length.\n   - Then it checks: `if (label_length > entry_length)`, which prevents reading more than the entry allows. This is correct.\n   - It uses a fixed-size buffer: `char text[INDX_LABEL_SIZEMAX];`. This is safe as long as `label_length` is less than `INDX_LABEL_SIZEMAX`. However, there is no check that `label_length` is less than `INDX_LABEL_SIZEMAX`. If `label_length` is larger than `INDX_LABEL_SIZEMAX`, this would cause a buffer overflow when copying into `text`.\n   - The function then calls `mobi_getstring_ordt` or `mobi_indx_get_label`, which may read more data into `text`. If `label_length` is larger than `INDX_LABEL_SIZEMAX`, this is a buffer overflow.\n\n4. **Memory Allocation and Copying**:\n   - `indx->entries[entry_number].label = malloc(label_length + 1);` is safe if `label_length` is valid.\n   - `strncpy(indx->entries[entry_number].label, text, label_length + 1);` copies `label_length + 1` bytes. This is safe only if `text` is null-terminated and `label_length + 1` is within bounds. But if `label_length` is larger than `INDX_LABEL_SIZEMAX`, `text` may not be null-terminated, and `strncpy` could write past the buffer.\n\n5. **Tag Parsing and Variable-Length Data**:\n   - The code parses variable-length data using `mobi_buffer_get_varlen`, which is assumed to be safe if the buffer is properly bounded.\n   - However, the `tagvalues` array is declared as `uint32_t tagvalues[INDX_TAGVALUES_MAX];`, and the code checks `tagvalues_count < INDX_TAGVALUES_MAX`. This is a good bound check.\n   - The `memcpy` call uses `arr_size = tagvalues_count * sizeof(*...)`, which is safe as long as `tagvalues_count` is within bounds.\n\n6. **Critical Issue: Missing Bounds Check on `curr_number`**:\n   - The most critical vulnerability is that `idxt.offsets[curr_number + 1]` is accessed without checking if `curr_number + 1` is less than `idxt.offsets_count`. If `curr_number` is equal to `idxt.offsets_count - 1`, then `curr_number + 1` is out of bounds, leading to a buffer overflow or memory corruption.\n\n7. **Other Issues**:\n   - The use of `MOBI_NOTSET` as a sentinel value is questionable, but not inherently a vulnerability unless used in a way that causes undefined behavior.\n   - The `debug_print` calls are safe and do not affect security.\n\nConclusion:\n- The most serious issue is the **missing bounds check on `curr_number`** when accessing `idxt.offsets[curr_number + 1]`. This can lead to out-of-bounds memory access, which is a classic buffer overflow vulnerability.\n- Additionally, there is no check that `label_length` is less than `INDX_LABEL_SIZEMAX`, which could lead to a buffer overflow in the `text` array.\n\n(1) YES: A security vulnerability detected."}
{"idx": 214282, "project": "radare2", "commit_id": "9650e3c352f675687bf6c6f65ff2c4a3d0e288fa", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/9650e3c352f675687bf6c6f65ff2c4a3d0e288fa", "commit_message": "Fix oobread segfault in java arith8.class ##crash\n\n* Reported by Cen Zhang via huntr.dev", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-0518", "cve_desc": "Heap-based Buffer Overflow in GitHub repository radareorg/radare2 prior to 5.6.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose**:  \n   The function `r_bin_java_inner_classes_attr_new` is responsible for parsing the \"InnerClasses\" attribute from a Java class file. This attribute contains metadata about inner classes, including indices into the constant pool for class names, outer class names, and access flags.\n\n2. **Input Validation and Buffer Bounds Checking**:  \n   - The function starts by validating the input buffer and size (`buffer`, `sz`, `buf_offset`).\n   - It uses `offset += 6` after allocating the base attribute, which is likely for the attribute header (attribute_name_index and attribute_length).\n   - Then, it reads `number_of_classes` from the buffer using `R_BIN_JAVA_USHORT`, which is a safe 16-bit unsigned read.\n   - The loop iterates `number_of_classes` times, and for each entry, it checks:\n     ```c\n     if (offset + 8 > sz) {\n         eprintf (\"Invalid amount of inner classes\\n\");\n         break;\n     }\n     ```\n     This is a critical check: it ensures that at least 8 bytes (2 bytes \u00d7 4 fields) are available for each inner class entry. Since each entry is exactly 8 bytes (4 \u00d7 2-byte indices/flags), this check prevents reading beyond the buffer.\n\n3. **Memory Allocation and Initialization**:  \n   - `icattr = R_NEW0(RBinJavaClassesAttribute)` is used to allocate memory for each inner class entry. If allocation fails, the loop breaks and the function continues, but it does not proceed with invalid data.\n   - The function properly initializes fields like `inner_class_info_idx`, `outer_class_info_idx`, `inner_name_idx`, and `inner_class_access_flags` using `R_BIN_JAVA_USHORT`, which safely reads 2-byte values from the buffer.\n\n4. **String Retrieval and Error Handling**:  \n   - The function attempts to retrieve the name of the inner class from the constant pool using `r_bin_java_get_item_from_bin_cp_list` and `r_bin_java_get_item_name_from_bin_cp_list`.\n   - If the name cannot be retrieved, it logs an error and assigns a default string `\"NULL\"`. This is a defensive fallback, but it does not lead to memory corruption or buffer overflow.\n   - The function does not use the retrieved name in any unsafe way (e.g., copying into a fixed-size buffer without bounds checking).\n\n5. **List Management and Memory Safety**:  \n   - The function uses `r_list_append` to add the `icattr` entry to a list. The list is properly initialized with `r_list_newf(r_bin_java_inner_classes_attr_entry_free)`, which ensures proper cleanup.\n   - If allocation fails or a name cannot be retrieved, the function breaks out of the loop and returns the partially constructed `attr` object. This is acceptable behavior for a parser \u2014 it gracefully handles malformed input.\n\n6. **Final Size Assignment**:  \n   - `attr->size = offset;` is set after processing all entries. This reflects the actual number of bytes consumed from the buffer, which is correct.\n\n7. **Potential Issues?**  \n   - There is no direct buffer overflow because:\n     - The loop bounds are based on `number_of_classes`, which is read from the buffer.\n     - The check `offset + 8 > sz` prevents reading beyond the buffer.\n     - All reads are 2-byte values using `R_BIN_JAVA_USHORT`, which is safe.\n   - The function does not perform any unsafe string copying (e.g., `strcpy`, `strcat`) or unbounded memory operations.\n   - Even in error cases (e.g., missing name), the function does not crash or corrupt memory \u2014 it logs and continues.\n\n8. **Conclusion**:  \n   The code performs proper bounds checking, uses safe memory allocation, handles errors gracefully, and avoids unsafe operations. It is designed to parse a structured binary format (Java class file) safely, and the checks prevent buffer overflows or out-of-bounds access.\n\n(2) NO: No security vulnerability."}
{"idx": 195092, "project": "hermes", "commit_id": "55e1b2343f4deb1a1b5726cfe1e23b2068217ff2", "project_url": "https://github.com/facebook/hermes", "commit_url": "https://github.com/facebook/hermes/commit/55e1b2343f4deb1a1b5726cfe1e23b2068217ff2", "commit_message": "Handle typeof applied to empty in InstSimplify\n\nSummary:\nDo not simplify `typeof` if it is applied to an invalid type. This\nhandles a case like the one in the added test, where `typeof` is called\non a literal empty in unreachable code.\n\nReviewed By: kodafb\n\nDifferential Revision: D31000173\n\nfbshipit-source-id: 2d7f69cbcc9c1bb0a916585c07171089444c85dc", "ground_truth": 1, "cwe": ["CWE-843"], "cve": "CVE-2021-24045", "cve_desc": "A type confusion vulnerability could be triggered when resolving the \"typeof\" unary operator in Facebook Hermes prior to v0.10.0. Note that this is only exploitable if the application using Hermes permits evaluation of untrusted JavaScript. Hence, most React Native applications are not affected.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `evalUnaryOperator` is part of a JavaScript engine (likely Hermes, given the namespace) and evaluates unary operators (like -, typeof, !, void) on literal values at compile-time or during evaluation.\n\n2. The function takes a `UnaryOperatorInst::OpKind` (the operator), an `IRBuilder`, and a `Literal *operand` (the value to operate on).\n\n3. The function uses a switch on the operator kind and then a nested switch on the operand's `ValueKind`.\n\n4. For each case:\n   - `MinusKind` (-): Handles negation of numbers, undefined, booleans, and null. It correctly returns:\n     - A negated number via `builder.getLiteralNumber(-literalNum->getValue())`.\n     - `NaN` for `undefined`.\n     - `-1` for `true`, `-0` for `false` or `null`.\n     - This is consistent with JavaScript semantics (e.g., `-true` is `-1`, `-false` is `-0`).\n   - `TypeofKind`: Returns string literals like \"object\", \"undefined\", etc., based on the operand kind. This is standard behavior for `typeof` in JavaScript.\n   - `BangKind` (!): Logical NOT. Returns `false` if operand is truthy, `true` if falsy. Uses `evalIsTrue` and `evalIsFalse` \u2014 these are likely safe checks that correctly evaluate truthiness.\n   - `VoidKind`: Returns `undefined`, as per JavaScript.\n\n5. The function returns `nullptr` only if no case matches, which is acceptable since the function is expected to return a `Literal*` or `nullptr` if unsupported.\n\n6. Key security considerations:\n   - No user input is directly processed without validation \u2014 this is a static evaluator for known literals.\n   - No memory corruption (e.g., buffer overflows, use-after-free) is evident.\n   - No unsafe string or arithmetic operations that could lead to overflow or injection.\n   - The use of `llvh::dyn_cast` is safe because it checks the type before casting.\n   - All return values are constructed via `builder.getLiteralXXX()`, which are likely safe factory methods.\n   - The `llvm_unreachable` is used in a default case that should never be reached due to exhaustive switch on `ValueKind`, which is a good practice.\n\n7. There is no evidence of:\n   - Buffer overflows\n   - Use of unsafe functions\n   - Improper input validation\n   - Type confusion\n   - Memory safety issues\n\n8. The code is well-structured, handles all known literal kinds, and follows safe patterns for a static evaluator.\n\n(2) NO: No security vulnerability."}
{"idx": 195389, "project": "tensorflow", "commit_id": "c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0", "commit_message": "Remove a `DCHECK`-fail, log an error instead.\n\n`DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.\n\nOutside of debug mode, `DCHECK` is a no-op.\n\nA better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.\n\nPiperOrigin-RevId: 408375925\nChange-Id: Id5b3e19c73f3fbe0cc4bba26ca44ff9607bb6356", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2022-23565", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `RepeatedAttrDefEqual` compares two `protobuf::RepeatedPtrField<OpDef::AttrDef>` objects, which are collections of attribute definitions (likely from a protocol buffer schema).\n\n2. It first builds a `std::unordered_map<string, const OpDef::AttrDef*>` from the first collection (`a1`), mapping attribute names to their corresponding `AttrDef` pointers. This ensures that each attribute name in `a1` is unique, as enforced by the `DCHECK` assertion: if a name appears more than once, it will trigger a failure during development/testing.\n\n3. Then, it iterates over the second collection (`a2`). For each `AttrDef` in `a2`, it checks:\n   - Whether the name exists in `a1_set` (i.e., the corresponding attribute exists in `a1`).\n   - If it exists, it compares the two `AttrDef` objects using `AttrDefEqual`.\n   - If the comparison fails, it returns `false`.\n   - It then removes the matched entry from `a1_set` to ensure one-to-one matching.\n\n4. After processing all elements in `a2`, it checks if `a1_set` is empty. If not, it means there are attributes in `a1` that were not matched in `a2`, so it returns `false`.\n\n5. Only if all checks pass does it return `true`.\n\n6. Key security considerations:\n   - The function does not perform any dynamic memory allocation or string manipulation that could lead to buffer overflows or memory corruption.\n   - It uses `std::unordered_map` for O(1) average lookup, which is safe here as long as the input is valid.\n   - The `DCHECK` is only active in debug builds and does not affect runtime behavior in production. However, it ensures internal consistency (no duplicate names), which is important for correctness but not a security vulnerability per se.\n   - There is no user input directly processed in a way that could lead to code injection, arbitrary memory access, or other classic vulnerabilities.\n   - The function is purely a comparison utility for internal schema validation, not handling untrusted data in a dangerous way.\n\n7. The logic is sound: it ensures that both collections have the same set of attribute definitions, with matching names and values, and enforces uniqueness in `a1`.\n\n8. No evidence of buffer overflows, use-after-free, null pointer dereference, or any other exploitable behavior.\n\n(2) NO: No security vulnerability."}
{"idx": 210834, "project": "xserver", "commit_id": "da15c7413916f754708c62c2089265528cd661e2", "project_url": "http://gitweb.freedesktop.org/?p=xorg/xserver", "commit_url": "https://gitlab.freedesktop.org/xorg/xserver/commit/da15c7413916f754708c62c2089265528cd661e2", "commit_message": "LogFilePrep: add a comment to the unsafe format string.\n\nCVE-2018-14665 also made it possible to exploit this to access\nmemory. With -logfile forbidden when running with elevated privileges\nthis is no longer an issue.\n\nSigned-off-by: Matthieu Herrb <matthieu@herrb.eu>\nReviewed-by: Adam Jackson <ajax@redhat.com>\n(cherry picked from commit 248d164eae27f1f310266d78e52f13f64362f81e)", "ground_truth": 1, "cwe": ["CWE-863"], "cve": "CVE-2018-14665", "cve_desc": "A flaw was found in xorg-x11-server before 1.20.3. An incorrect permission check for -modulepath and -logfile options when starting Xorg. X server allows unprivileged users with the ability to log in to the system via physical console to escalate their privileges and run arbitrary code under root privileges.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `LogFilePrep` takes three parameters: `fname` (format string for log file name), `backup` (format string for backup file name), and `idstring` (a string to be inserted into both format strings via `asprintf`).\n\n2) The function uses `asprintf` to construct the log file name using `fname` and `idstring`. This is potentially dangerous if `fname` is controlled by an untrusted source, because `asprintf` uses the format string directly. However, in this case, `fname` is likely a hardcoded format string (e.g., \"/var/log/app/%s.log\"), so this is not inherently vulnerable.\n\n3) The critical issue arises in the backup logic: `asprintf(&suffix, backup, idstring)` and `asprintf(&oldLog, \"%s%s\", logFileName, suffix)`. Here, `backup` is used as a format string in `asprintf`. If `backup` is controlled by an untrusted source (e.g., from user input or configuration), this creates a format string vulnerability.\n\n4) For example, if `backup` is set to \"%x%x%x%x\", then `asprintf` will interpret this as a format string and read arbitrary memory locations, potentially leading to information disclosure or crashes.\n\n5) Even if `backup` is not directly user-controlled, if it comes from an untrusted source (e.g., configuration file, network input), this could still be exploited.\n\n6) The function does not validate or sanitize the `backup` parameter before using it as a format string in `asprintf`, which is a classic security vulnerability.\n\n7) The use of `asprintf` with user-controlled format strings is a well-known vulnerability pattern (format string vulnerability).\n\n(1) YES: A security vulnerability detected."}
{"idx": 212818, "project": "pjproject", "commit_id": "15663e3f37091069b8c98a7fce680dc04bc8e865", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/15663e3f37091069b8c98a7fce680dc04bc8e865", "commit_message": "Merge pull request from GHSA-2qpg-f6wf-w984", "ground_truth": 1, "cwe": ["CWE-191"], "cve": "CVE-2021-37706", "cve_desc": "PJSIP is a free and open source multimedia communication library written in C language implementing standard based protocols such as SIP, SDP, RTP, STUN, TURN, and ICE. In affected versions if the incoming STUN message contains an ERROR-CODE attribute, the header length is not checked before performing a subtraction operation, potentially resulting in an integer underflow scenario. This issue affects all users that use STUN. A malicious actor located within the victim\u2019s network may forge and send a specially crafted UDP (STUN) message that could remotely execute arbitrary code on the victim\u2019s machine. Users are advised to upgrade as soon as possible. There are no known workarounds.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `decode_errcode_attr` is responsible for decoding a STUN error code attribute from a binary buffer (`buf`) into a structured `pj_stun_errcode_attr` object.\n\n2) The function first allocates memory for the attribute using `PJ_POOL_ZALLOC_T`, which is safe in the context of a memory pool.\n\n3) It extracts the header using `GETATTRHDR(buf, &attr->hdr)`, which is a macro likely to read the attribute header (type, length, etc.) from the buffer.\n\n4) The error code is computed as: `attr->err_code = buf[6] * 100 + buf[7]`. This assumes that the error code is encoded as three digits (e.g., 400, 404) in two bytes. This is a reasonable assumption for STUN error codes, and no bounds checking is needed here since the values are directly read from the buffer and used as integers.\n\n5) The function then sets up a `pj_str_t` `value` to point to the reason string:\n   - `value.ptr = ((char*)buf + ATTR_HDR_LEN + 4)`\n   - `value.slen = attr->hdr.length - 4`\n\n   This is critical: the reason string starts 4 bytes after the attribute header, and its length is the attribute length minus 4.\n\n6) The function then calls `pj_strdup(pool, &attr->reason, &value)` to copy the reason string into the pool-allocated `attr->reason`.\n\n7) The key issue: `pj_strdup` copies the string from `value.ptr` to `attr->reason.ptr`, but it does **not** validate whether `value.slen` is within safe bounds or whether the string is null-terminated. However, the `pj_str_t` structure is designed to be length-delimited, so it doesn't require null termination.\n\n8) The real vulnerability lies in the assumption that `attr->hdr.length - 4` is a valid length. If the attribute length is less than 4, then `value.slen` becomes negative (or very large due to unsigned wraparound), which would cause `pj_strdup` to copy an excessive amount of data from the buffer.\n\n9) Since `attr->hdr.length` comes from the STUN message header (which is user-controlled), an attacker can craft a message with a very small `length` field (e.g., 2 or 3), leading to `value.slen = attr->hdr.length - 4` being negative (or a large positive number if `length` is unsigned). This would cause `pj_strdup` to copy potentially many bytes beyond the actual message buffer, leading to a buffer overflow.\n\n10) Even though `pj_strdup` may have internal bounds checks, the `pj_str_t` structure is not null-terminated, and the length is derived from user-controlled input without validation. If the length is too large, it can cause memory corruption.\n\n11) The function does not validate that `attr->hdr.length >= 4` before computing `value.slen`. This is a critical missing check.\n\nTherefore, this code is vulnerable to a buffer overflow due to lack of bounds checking on the attribute length.\n\n(1) YES: A security vulnerability detected."}
{"idx": 214124, "project": "chafa", "commit_id": "e6ce3746cdcf0836b9dae659a5aed15d73a080d8", "project_url": "https://github.com/hpjansson/chafa", "commit_url": "https://github.com/hpjansson/chafa/commit/e6ce3746cdcf0836b9dae659a5aed15d73a080d8", "commit_message": "libnsgif: fix oob in lzw_decode", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-2061", "cve_desc": "Heap-based Buffer Overflow in GitHub repository hpjansson/chafa prior to 1.12.0.", "vuln": 1, "reasoning": "Let's analyze the provided LZW decompression code step by step to identify any potential security vulnerabilities.\n\n1. **Input Validation and Code Handling**:\n   - The function `lzw_decode` reads a new code from the input using `lzw__next_code`, which is expected to validate the input stream and return an error if invalid.\n   - It checks for special codes: `clear_code` (resets the dictionary), `eoi_code` (end of input), and invalid codes (code_new > current_entry).\n   - The check `if (code_new > current_entry)` is correct: it ensures that the code is within the valid range of the current dictionary, preventing out-of-bounds access.\n\n2. **Dictionary Access and Buffer Bounds**:\n   - The code accesses `table[code_new]` when `code_new < current_entry` or in the \"not in table\" case.\n   - The dictionary table is allocated with size `1 << LZW_CODE_MAX`, and `current_entry` is tracked to ensure it does not exceed `1 << LZW_CODE_MAX`.\n   - The condition `if (current_entry < (1 << LZW_CODE_MAX))` ensures that the dictionary is not overfilled when adding a new entry.\n   - The `code_new` value is checked against `current_entry` before accessing the table, so `code_new` is guaranteed to be less than `current_entry` in the valid case, and thus within bounds.\n\n3. **Stack Overflow Protection**:\n   - The function uses a stack (`stack_pos`) to reconstruct the decompressed data.\n   - The stack is initialized to `ctx->stack_base`, which should be a pre-allocated buffer of sufficient size.\n   - The code writes data to `stack_pos` in a loop: `*stack_pos++ = entry->last_value;` until the code chain is fully traversed.\n   - However, there is **no explicit check** on the size of the stack buffer or whether `stack_pos` exceeds `ctx->stack_base + stack_size`.\n   - If the input stream is malicious and contains a very long chain of codes (e.g., a long sequence of dictionary entries that expand into a huge output), the stack could overflow, leading to a buffer overflow.\n\n4. **Potential for Infinite or Excessive Expansion**:\n   - LZW decompression can be vulnerable to \"dictionary explosion\" attacks where a malicious input causes the decompressed output to grow exponentially.\n   - Although the code limits dictionary growth via `current_entry < (1 << LZW_CODE_MAX)`, it does **not** limit the size of the output stack.\n   - The `while (code_out > clear_code)` loop can run many iterations if the code chain is long, and each iteration writes one byte to the stack.\n   - If the stack buffer is not large enough, this can lead to a buffer overflow.\n\n5. **Missing Stack Size Check**:\n   - The function does not verify that `stack_pos` stays within the bounds of the allocated stack buffer.\n   - There is no check like `if (stack_pos >= ctx->stack_top)` before writing to `*stack_pos++`.\n   - This is a critical omission: without such a check, a malicious input could cause a buffer overflow.\n\n6. **Conclusion**:\n   - The code correctly validates input codes and prevents dictionary overflows.\n   - However, it **fails to validate the output stack size**, which can be exploited by an attacker to cause a buffer overflow by crafting a long decompression chain.\n   - This is a known class of vulnerabilities in LZW decompression implementations (e.g., in GIF files).\n\n(1) YES: A security vulnerability detected."}
{"idx": 215038, "project": "gst-plugins-good", "commit_id": "b31c504645a814c59d91d49e4fe218acaf93f4ca", "project_url": "https://github.com/GStreamer/gst-plugins-good", "commit_url": "https://github.com/GStreamer/gst-plugins-good/commit/b31c504645a814c59d91d49e4fe218acaf93f4ca", "commit_message": "flxdec: Don't unref() parent in the chain function\n\nWe don't own the reference here, it is owned by the caller and given to\nus for the scope of this function. Leftover mistake from 0.10 porting.\n\nhttps://bugzilla.gnome.org/show_bug.cgi?id=774897", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2016-9810", "cve_desc": "The gst_decode_chain_free_internal function in the flxdex decoder in gst-plugins-good in GStreamer before 1.10.2 allows remote attackers to cause a denial of service (invalid memory read and crash) via an invalid file, which triggers an incorrect unref call.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Initialization**:\n   - The function `gst_flxdec_chain` takes a `GstBuffer *buf` as input, which is a data buffer from a GStreamer pipeline.\n   - It first checks that `buf` is not NULL using `g_return_val_if_fail`, and returns `GST_FLOW_ERROR` if so. This prevents null pointer dereference.\n   - It then casts `parent` to `GstFlxDec *` and checks that it is not NULL. Again, this is a valid safety check.\n\n2. **Buffer Handling with GstAdapter**:\n   - The buffer is pushed into `flxdec->adapter` using `gst_adapter_push`.\n   - The available data in the adapter is checked with `gst_adapter_available`.\n   - This is a standard and safe way to handle streaming data in GStreamer, and `gst_adapter` is designed to manage dynamic data safely.\n\n3. **Header Parsing (State: GST_FLXDEC_READ_HEADER)**:\n   - When the state is `READ_HEADER`, the code checks if at least `FlxHeaderSize` bytes are available.\n   - It maps the data using `gst_adapter_map`, copies the header into `flxdec->hdr` using `memcpy`, and then unmaps and flushes the adapter.\n   - The header is validated: `flxh->type` must be one of `FLX_MAGICHDR_FLI`, `FLX_MAGICHDR_FLC`, or `FLX_MAGICHDR_FLX`. If not, it goes to `wrong_type` error.\n   - The `memcpy` is used to copy exactly `FlxHeaderSize` bytes, which is a fixed size. Since `FlxHeaderSize` is a compile-time constant (assumed), and the data is read from the adapter only up to that size, this is safe.\n   - The `FLX_HDR_FIX_ENDIANNESS` macro is used to fix endianness \u2014 this is a standard practice and not a vulnerability.\n\n4. **Frame Processing (State: GST_FLXDEC_PLAYING)**:\n   - The code enters a loop while `avail >= FlxFrameChunkSize`.\n   - It maps `FlxFrameChunkSize` bytes from the adapter, copies into `flxfh`, fixes endianness, and unmaps.\n   - It checks if `avail < flxfh.size` \u2014 if not enough data, it jumps to `need_more_data`. This prevents reading beyond available data.\n   - For `FLX_FRAME_TYPE`, it flushes the chunk header, then takes the rest of the frame (`flxfh.size - FlxFrameChunkSize`) using `gst_adapter_take`.\n   - The frame data is then processed:\n     - `flx_decode_chunks` is called with the chunk data and `flxdec->frame_data` (allocated earlier).\n     - `flx_colorspace_convert` is used to convert the frame data to output format.\n     - A new `GstBuffer` is allocated with `gst_buffer_new_and_alloc(flxdec->size * 4)`, which is safe because `flxdec->size` is derived from `flxh->width * flxh->height`, which was validated earlier.\n     - The buffer is mapped, written to, and timestamped.\n     - Finally, it is pushed to the output pad.\n\n5. **Memory Management**:\n   - `g_malloc` is used to allocate `frame_data` and `delta_data` \u2014 these are freed only when the object is destroyed (not shown here, but assumed to be handled).\n   - `g_free(chunk)` is called after use \u2014 correct.\n   - `gst_buffer_new_and_alloc` is used safely \u2014 no buffer overflow risk.\n   - `gst_adapter_take` is used to extract data of size `flxfh.size - FlxFrameChunkSize`, which is only done after checking `avail >= flxfh.size`, so it's safe.\n\n6. **Potential Vulnerabilities?**:\n   - **Buffer Overflows**: No `strcpy`, `strcat`, or unsafe `memcpy` with unbounded sizes. All `memcpy` calls use fixed, known sizes (`FlxHeaderSize`, `FlxFrameChunkSize`, etc.) and are bounded by the adapter's available data.\n   - **Integer Overflows**: The code uses `guint` and `guint` arithmetic. While `flxdec->size = width * height` could theoretically overflow if `width` and `height` are large, this is mitigated by the fact that:\n     - The header is validated before use.\n     - `flxh->width` and `flxh->height` are read from a file header, but the `flx_decode_chunks` function likely validates the data size.\n     - The `gst_buffer_new_and_alloc` call uses `flxdec->size * 4`, which could overflow if `flxdec->size` is huge. However, in practice, `flxdec->size` is derived from `width * height`, and `width` and `height` are typically small (e.g., 320x240). But this is a potential issue if the header is maliciously crafted.\n   - **Untrusted Input**: The input is from a file (FLX format), which is untrusted. However, the code validates the header magic bytes and checks frame sizes before processing. The `avail < flxfh.size` check prevents reading beyond available data.\n   - **Use-After-Free / Dangling Pointers**: No evidence of this. All data is managed via GStreamer's memory management (`GstBuffer`, `gst_adapter`, `g_malloc`).\n   - **Error Handling**: The code has proper error handling with `goto` labels (`wrong_type`, `need_more_data`) and returns appropriate flow results.\n\n7. **Critical Point: Size Calculation and Allocation**:\n   - The line `flxdec->size = ((guint) flxh->width * (guint) flxh->height);` could overflow if `width` and `height` are large (e.g., 65536x65536 \u2192 4GB, which is plausible in a malicious file).\n   - Then `g_malloc(flxdec->size)` could fail or cause memory exhaustion.\n   - But more importantly, `gst_buffer_new_and_alloc(flxdec->size * 4)` could cause integer overflow in `flxdec->size * 4` if `flxdec->size` is large (e.g., > 2^31 / 4).\n   - However, the code does not validate that `width` and `height` are within reasonable bounds (e.g., < 10000). This is a potential **integer overflow** or **resource exhaustion** vulnerability.\n\n8. **Mitigation?**:\n   - The code does not check for excessive `width` or `height` values.\n   - There is no validation that `flxh->width * flxh->height` is within a safe range (e.g., < 100000000).\n   - This could allow a malicious FLX file to cause:\n     - Integer overflow in `flxdec->size * 4` \u2192 `gst_buffer_new_and_alloc` gets a small number due to wraparound \u2192 buffer too small \u2192 memory corruption.\n     - Or, if no overflow, huge memory allocation \u2192 denial of service (DoS).\n\nThis is a **classic integer overflow / resource exhaustion vulnerability** in a media parser.\n\n(1) YES: A security vulnerability detected."}
{"idx": 199841, "project": "radare2", "commit_id": "feaa4e7f7399c51ee6f52deb84dc3f795b4035d6", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/feaa4e7f7399c51ee6f52deb84dc3f795b4035d6", "commit_message": "Fix null deref in xnu.kernelcache ##crash\n\n* Reported by @xshad3 via huntr.dev", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-0419", "cve_desc": "NULL Pointer Dereference in GitHub repository radareorg/radare2 prior to 5.6.0.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `load_buffer` is responsible for loading a Mach-O binary file into a kernel cache object (`RKernelCacheObj`) and setting up various components like rebase information, prelink info, and buffer references.\n\n2. The function uses `r_buf_ref(buf)` to create a reference to the input buffer `buf`. This is safe as long as the buffer is properly managed, and `r_buf_ref` typically increments a reference count, which is correctly handled.\n\n3. A `struct MACH0_(obj_t)` is created via `MACH0_(new_buf)` using the buffer and options. This function is expected to parse the Mach-O file and return a valid object or NULL on failure. The code checks for `!main_mach0` and returns false if so \u2014 this is a proper error check.\n\n4. `r_rebase_info_new_from_mach0` is called to create rebase information from the Mach-O object. This is a legitimate operation and does not appear to involve untrusted input directly.\n\n5. `get_prelink_info_range_from_mach0` retrieves a prelink range from the Mach-O object. If this returns NULL, the function jumps to `beach`, freeing resources and returning false. This is a valid error path.\n\n6. `R_NEW0(RKernelCacheObj)` allocates memory for the kernel cache object. The code checks for NULL and cleans up on failure \u2014 good practice.\n\n7. `r_cf_value_dict_parse` is used to parse prelink information from the buffer at a specific offset and size. This function parses structured data (likely CFPropertyList-like) from the binary. The input to this function comes from `prelink_range->range.offset` and `prelink_range->range.size`, which are derived from the Mach-O file.\n\n   - The key concern: `prelink_range->range.size` is used directly as the size to parse. If this value is maliciously crafted (e.g., extremely large), it could lead to a buffer overflow or excessive memory allocation.\n   - However, the function `r_cf_value_dict_parse` is expected to validate the input data and not read beyond the buffer bounds. But the code does not validate that `prelink_range->range.size` is within the bounds of `fbuf` (the buffer). This is a critical issue.\n\n8. The function uses `fbuf` (a reference to the original buffer) to parse data, but there is no check to ensure that `prelink_range->range.offset + prelink_range->range.size` is within the buffer's length. If the Mach-O file is malformed or crafted to have an oversized `range.size`, this could result in reading past the end of the buffer, leading to a buffer overflow or out-of-bounds read.\n\n9. The `r_cf_value_dict_parse` function may be vulnerable to such attacks if it does not perform bounds checking. Even if it does, the lack of validation in the calling code is a red flag.\n\n10. The `beach` cleanup path correctly frees `prelink_range`, `obj`, and `prelink_info`, and also frees `fbuf` at the end. However, the `fbuf` is freed only in the error path, and the `main_mach0` is freed via `MACH0_(mach0_free)` \u2014 this is correct.\n\n11. The function does not perform any direct string copying or unsafe memory operations, but the use of `prelink_range->range.size` as a length parameter without bounds checking on the buffer is a serious flaw.\n\n12. Since the `prelink_range` is derived from the Mach-O file (untrusted input), and its `size` field is used directly in `r_cf_value_dict_parse`, this creates a potential for a heap-based buffer overflow or denial-of-service via memory exhaustion if the size is extremely large.\n\nConclusion: The code fails to validate that `prelink_range->range.size` is within the bounds of the buffer `fbuf`. This allows an attacker to craft a malicious Mach-O file with an oversized `range.size`, leading to a buffer overflow or excessive memory allocation \u2014 a serious security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 212829, "project": "php-src", "commit_id": "698a691724c0a949295991e5df091ce16f899e02", "project_url": "https://github.com/php/php-src", "commit_url": "https://github.com/php/php-src/commit/698a691724c0a949295991e5df091ce16f899e02?w=1", "commit_message": "Fix bug #72750: wddx_deserialize null dereference", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2016-7130", "cve_desc": "The php_wddx_pop_element function in ext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid base64 binary value, as demonstrated by a wddx_deserialize call that mishandles a binary element in a wddxPacket XML document.", "vuln": 1, "reasoning": "Let's analyze the provided C code step-by-step, focusing on potential security vulnerabilities.\n\n1. **Context and Purpose**:\n   - This function `php_wddx_pop_element` is part of a WDDX (Web Distributed Data eXchange) parser in PHP.\n   - It is called during XML parsing when an element is closed (i.e., when the end tag is encountered).\n   - It manages a stack (`wddx_stack`) to reconstruct PHP data structures (arrays, objects, etc.) from WDDX XML.\n\n2. **Key Operations**:\n   - The function checks the element name (`name`) and performs different actions based on the type (e.g., `EL_STRING`, `EL_OBJECT`, `EL_STRUCT`, etc.).\n   - It retrieves the top of the stack via `wddx_stack_top`.\n   - It handles base64 decoding for `EL_BINARY` elements using `php_base64_decode`, which is safe if properly used.\n   - It calls `__wakeup()` on deserialized objects via `call_user_function_ex`, which is a known attack vector if not properly controlled.\n   - It reconstructs objects using `object_init_ex` and merges properties via `zend_hash_merge`.\n   - It uses `zval_ptr_dtor` and `efree` to clean up memory, which is correct if used properly.\n\n3. **Security Considerations**:\n\n   a. **Untrusted Input Handling**:\n      - The `name` parameter comes from XML input, which is untrusted.\n      - However, the function only compares `name` with known constants (`EL_STRING`, `EL_NUMBER`, etc.) using `!strcmp`. This is safe because it's a whitelist of allowed tags.\n\n   b. **Base64 Decoding**:\n      - `php_base64_decode` is used to decode binary data. The code properly frees the old string (`STR_FREE`) and updates the zval with the decoded data.\n      - No buffer overflow or memory corruption is evident here, assuming `php_base64_decode` is implemented safely.\n\n   c. **Object Injection via `__wakeup()`**:\n      - The most critical part: `call_user_function_ex` is used to invoke `__wakeup()` on deserialized objects.\n      - This is a well-known security risk in PHP: if an attacker can control the object structure (e.g., via malicious WDDX data), they can trigger `__wakeup()` on a crafted object, potentially leading to arbitrary code execution, especially if the class has dangerous logic in `__wakeup()`.\n      - This is a classic **deserialization vulnerability**.\n\n   d. **Object Reconstruction**:\n      - The code uses `object_init_ex` with a class name from the input (`Z_STRVAL_P(ent1->data)`), which is user-controlled.\n      - It performs case-insensitive comparison (`zend_str_tolower`) and checks `EG(class_table)` for existence.\n      - If the class doesn't exist, it uses `PHP_IC_ENTRY` (incomplete class), which is a mitigation.\n      - However, if the class exists and has a `__wakeup()` method, it will be called \u2014 and if that method contains malicious logic (e.g., file inclusion, command execution), this becomes exploitable.\n\n   e. **Memory Management**:\n      - The code uses `zval_ptr_dtor`, `efree`, `MAKE_STD_ZVAL`, etc., correctly.\n      - No obvious use-after-free or double-free issues are visible.\n\n   f. **Input Validation**:\n      - The function validates that `ent1->data` is not null before using it.\n      - It checks `stack->top == 0` at the beginning, preventing stack underflow.\n\n4. **Conclusion**:\n   - The most serious issue is the **unrestricted invocation of `__wakeup()` on user-controlled object types** during deserialization.\n   - This is a known and critical vulnerability in PHP applications that deserialize untrusted data.\n   - Even though the code attempts to handle incomplete classes, it does not prevent the execution of `__wakeup()` on valid, maliciously crafted classes.\n   - This is a textbook example of a **deserialization vulnerability**.\n\n(1) YES: A security vulnerability detected."}
{"idx": 211695, "project": "vim", "commit_id": "4c13e5e6763c6eb36a343a2b8235ea227202e952", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/4c13e5e6763c6eb36a343a2b8235ea227202e952", "commit_message": "patch 8.2.3949: using freed memory with /\\%V\n\nProblem:    Using freed memory with /\\%V.\nSolution:   Get the line again after getvvcol().", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2021-4192", "cve_desc": "vim is vulnerable to Use After Free", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `reg_match_visual()` is designed to check whether a given line (identified by `rex.lnum + rex.reg_firstlnum`) falls within a visual selection in a Vim-like editor environment.\n\n2. The function first checks if the buffer being examined (`rex.reg_buf`) is the current buffer (`curbuf`) and if the visual selection is active (`VIsual.lnum == 0`). If either condition fails, it returns `FALSE`. This is a valid safety check.\n\n3. The function then determines the top and bottom positions of the visual selection:\n   - If `VIsual_active` is true, it uses `VIsual` and `wp->w_cursor` to define the range.\n   - Otherwise, it uses `curbuf->b_visual.vi_start` and `curbuf->b_visual.vi_end`.\n   - It correctly handles the ordering using `LT_POS` to ensure `top` is the earlier position and `bot` is the later one.\n\n4. The line number `lnum` is computed as `rex.lnum + rex.reg_firstlnum`. This is a derived line number from a regex match context.\n\n5. The function checks if `lnum` is within the visual selection range (`top.lnum` to `bot.lnum`). If not, it returns `FALSE`. This is a valid bounds check.\n\n6. For visual mode `'v'` (character-wise visual), it checks whether the column position (`col`) of the input is within the visual selection:\n   - If the line is the top line and the column is before `top.col`, it returns `FALSE`.\n   - If the line is the bottom line and the column is at or beyond `bot.col + (*p_sel != 'e')`, it returns `FALSE`.\n   - The use of `*p_sel != 'e'` adjusts the end column based on the selection mode (e.g., 'e' for exclusive), which is a known Vim behavior.\n\n7. For block-wise visual mode (`Ctrl_V`), it uses `getvvcol()` to get the start and end columns of the visual block at both `top` and `bot` positions. It then computes the effective `start` and `end` column range of the block. It also handles the case where `MAXCOL` is involved (which represents an invalid or unbounded column), and sets `end = MAXCOL` in such cases.\n\n8. It computes `cols` as the column position of the input line using `win_linetabsize()`, which accounts for tabs and display width. Then it checks if `cols` is within the computed `start` to `end` range, adjusting for the selection mode (`*p_sel != 'e'`).\n\n9. All checks are performed using proper comparisons and bounds validation. There is no use of unsafe functions like `strcpy`, `strcat`, or direct buffer manipulation. All variables are of type `pos_T`, `linenr_T`, `colnr_T`, etc., which are well-defined and bounded types in Vim.\n\n10. There is no user input directly copied into a buffer without bounds checking. The input comes from internal state (`rex`, `VIsual`, `curbuf`, `wp`, etc.), which are all controlled by the editor's internal logic and not directly from untrusted external input.\n\n11. The function does not perform any memory allocation, pointer arithmetic, or string operations that could lead to buffer overflows, use-after-free, or other memory safety issues.\n\n12. The logic is defensive: it checks for invalid states (e.g., `curbuf`, `VIsual.lnum == 0`) and returns early when conditions are not met.\n\nConclusion: The code performs proper bounds checking, handles visual selection modes correctly, and uses safe internal state without exposing any known vulnerabilities such as buffer overflows, use-after-free, or improper input validation.\n\n(2) NO: No security vulnerability."}
{"idx": 202677, "project": "qemu", "commit_id": "9302e863aa8baa5d932fc078967050c055fa1a7f", "project_url": "https://github.com/bonzini/qemu", "commit_url": "http://git.qemu.org/?p=qemu.git;a=commit;h=9302e863aa8baa5d932fc078967050c055fa1a7f", "commit_message": "parallels: Sanity check for s->tracks (CVE-2014-0142)\n\nThis avoids a possible division by zero.\n\nConvert s->tracks to unsigned as well because it feels better than\nsurviving just because the results of calculations with s->tracks are\nconverted to unsigned anyway.\n\nSigned-off-by: Kevin Wolf <kwolf@redhat.com>\nReviewed-by: Max Reitz <mreitz@redhat.com>\nSigned-off-by: Stefan Hajnoczi <stefanha@redhat.com>", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2014-0142", "cve_desc": "QEMU, possibly before 2.0.0, allows local users to cause a denial of service (divide-by-zero error and crash) via a zero value in the (1) tracks field to the seek_to_sector function in block/parallels.c or (2) extent_size field in the bochs function in block/bochs.c.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `parallels_open` is responsible for opening a Parallels disk image and initializing the state.\n\n2. The code reads the Parallels header from the file using `bdrv_pread` at offset 0 into a `struct parallels_header ph`. This is a standard way to read metadata.\n\n3. It checks the magic bytes and version to ensure the image is in the correct format. If not, it returns an error. This is a good security practice to prevent processing malformed or malicious images.\n\n4. The total number of sectors is read from the header and stored in `bs->total_sectors`. This value is derived from `ph.nb_sectors`, which is converted from little-endian using `le32_to_cpu`.\n\n5. The `catalog_size` is read from `ph.catalog_entries` and converted using `le32_to_cpu`. Then, there is a check:\n   ```c\n   if (s->catalog_size > INT_MAX / 4) {\n       error_setg(errp, \"Catalog too large\");\n       ret = -EFBIG;\n       goto fail;\n   }\n   ```\n   This check prevents integer overflow when allocating memory for `s->catalog_bitmap` (which is `s->catalog_size * 4` bytes). This is a critical protection against heap overflow via a large catalog size.\n\n6. Memory is allocated using `g_malloc(s->catalog_size * 4)`. The prior check ensures that `s->catalog_size * 4` won't overflow `size_t` or cause an integer overflow, so this allocation is safe.\n\n7. The code then reads the catalog bitmap from the file at offset 64, using `bdrv_pread` with the size `s->catalog_size * 4`. This is a fixed-size read based on the validated `catalog_size`.\n\n8. After reading, it converts each 32-bit value in the bitmap from little-endian to host byte order using `le32_to_cpus(&s->catalog_bitmap[i])`. This is safe because the loop runs exactly `s->catalog_size` times, and the size was validated earlier.\n\n9. The mutex is initialized, and the function returns success.\n\n10. In the `fail` path, `g_free(s->catalog_bitmap)` is called, which is safe even if it was not allocated (since `g_free` handles null pointers).\n\n11. No unbounded loops, no unchecked user input directly used in memory allocation or buffer operations, and all sizes are validated before use.\n\n12. The only potential risk would be if `ph.catalog_entries` were maliciously large, but the check `s->catalog_size > INT_MAX / 4` prevents this from leading to an overflow or excessive memory allocation.\n\nConclusion: All critical memory operations are protected by input validation. The code correctly handles endianness, validates sizes, and avoids buffer overflows or integer overflows.\n\n(2) NO: No security vulnerability."}
{"idx": 204425, "project": "frr", "commit_id": "6d58272b4cf96f0daa846210dd2104877900f921", "project_url": "https://github.com/FRRouting/frr", "commit_url": "https://github.com/FRRouting/frr/commit/6d58272b4cf96f0daa846210dd2104877900f921", "commit_message": "[bgpd] cleanup, compact and consolidate capability parsing code\n\n2007-07-26 Paul Jakma <paul.jakma@sun.com>\n\n\t* (general) Clean up and compact capability parsing slightly.\n\t  Consolidate validation of length and logging of generic TLV, and\n\t  memcpy of capability data, thus removing such from cap specifc\n\t  code (not always present or correct).\n\t* bgp_open.h: Add structures for the generic capability TLV header\n\t  and for the data formats of the various specific capabilities we\n\t  support.  Hence remove the badly named, or else misdefined, struct\n\t  capability.\n\t* bgp_open.c: (bgp_capability_vty_out) Use struct capability_mp_data.\n\t  Do the length checks *before* memcpy()'ing based on that length\n\t  (stored capability - should have been validated anyway on input,\n\t  but..).\n\t  (bgp_afi_safi_valid_indices) new function to validate (afi,safi)\n\t  which is about to be used as index into arrays, consolidates\n\t  several instances of same, at least one of which appeared to be\n\t  incomplete..\n\t  (bgp_capability_mp) Much condensed.\n\t  (bgp_capability_orf_entry) New, process one ORF entry\n\t  (bgp_capability_orf) Condensed. Fixed to process all ORF entries.\n\t  (bgp_capability_restart) Condensed, and fixed to use a\n\t  cap-specific type, rather than abusing capability_mp.\n\t  (struct message capcode_str) added to aid generic logging.\n\t  (size_t cap_minsizes[]) added to aid generic validation of\n\t  capability length field.\n\t  (bgp_capability_parse) Generic logging and validation of TLV\n\t  consolidated here. Code compacted as much as possible.\n\t* bgp_packet.c: (bgp_open_receive) Capability parsers now use\n\t  streams, so no more need here to manually fudge the input stream\n\t  getp.\n\t  (bgp_capability_msg_parse) use struct capability_mp_data. Validate\n\t  lengths /before/ memcpy. Use bgp_afi_safi_valid_indices.\n\t  (bgp_capability_receive) Exported for use by test harness.\n\t* bgp_vty.c: (bgp_show_summary) fix conversion warning\n\t  (bgp_show_peer) ditto\n\t* bgp_debug.h: Fix storage 'extern' after type 'const'.\n        * lib/log.c: (mes_lookup) warning about code not being in\n          same-number array slot should be debug, not warning. E.g. BGP\n          has several discontigious number spaces, allocating from\n          different parts of a space is not uncommon (e.g. IANA\n          assigned versus vendor-assigned code points in some number\n          space).", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-37032", "cve_desc": "An out-of-bounds read in the BGP daemon of FRRouting FRR before 8.4 may lead to a segmentation fault and denial of service. This occurs in bgp_capability_msg_parse in bgpd/bgp_packet.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `bgp_capability_msg_parse` processes a BGP capability message from a peer. It parses a stream of bytes (`pnt`) of length `length` and processes each capability in the message.\n\n2. The function starts by setting `end = pnt + length`, which defines the end of the input buffer. It then enters a while loop that iterates through the message, processing each capability.\n\n3. Before processing any capability, it checks if there are at least 3 bytes remaining (`pnt + 3 > end`). This ensures that the action byte, capability code, and length byte are present. This is a valid bounds check.\n\n4. It then uses `memcpy` to copy `sizeof(struct capability)` bytes starting from `pnt + 1`. The `struct capability` is assumed to be a known structure that includes fields like `code`, `length`, and `mpc` (for MP capability). The size of this structure is fixed and known.\n\n5. The function checks that the `action` is either `CAPABILITY_ACTION_SET` or `CAPABILITY_ACTION_UNSET`. If not, it logs an error and sends a BGP notification, then returns -1. This prevents invalid actions.\n\n6. It then checks if the total length of the capability (including the 3-byte header) exceeds the available buffer: `pnt + (cap.length + 3) > end`. This is a critical bounds check to prevent reading beyond the buffer. If violated, it logs an error and returns -1.\n\n7. For the MP capability (`cap.code == CAPABILITY_CODE_MP`), it extracts `afi` and `safi` from the capability data. It uses `ntohs` on `afi`, which is correct for network byte order conversion.\n\n8. It checks if `afi` is `AFI_IP` or `AFI_IP6` and `safi` is one of the valid values. If so, it proceeds to process the capability.\n\n9. It adjusts `safi` from `BGP_SAFI_VPNV4` to `SAFI_MPLS_VPN`, which is a known mapping.\n\n10. Depending on the `action`, it sets or clears flags in `peer->afc_recv`, `peer->afc_nego`, and triggers route announcements or clears.\n\n11. The loop advances `pnt` by `cap.length + 3`, which is correct because the header is 3 bytes (action, code, length), and the capability data is `cap.length` bytes.\n\n12. The function does not perform any dynamic memory allocation or string operations that could lead to buffer overflows.\n\n13. All buffer accesses are bounded by the `end` pointer, and the checks `pnt + 3 > end` and `pnt + (cap.length + 3) > end` ensure that no out-of-bounds reads occur.\n\n14. The use of `memcpy` is safe because:\n   - The size is `sizeof(struct capability)`, which is fixed and known.\n   - The source is within the valid buffer (ensured by the `pnt + 3 > end` check).\n   - The destination is a local struct, not a fixed-size buffer on the stack that could overflow.\n\n15. There are no unsafe string operations, no format string vulnerabilities, no use of `strcpy`, `strcat`, `sprintf`, etc.\n\n16. The function properly validates all inputs and bounds, and returns early on invalid data.\n\nConclusion: The code performs proper bounds checking, validates input values, and uses safe memory operations. There are no buffer overflows, out-of-bounds reads, or other exploitable vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 195026, "project": "linux", "commit_id": "ab0fc21bc7105b54bafd85bd8b82742f9e68898a", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/ab0fc21bc7105b54bafd85bd8b82742f9e68898a", "commit_message": "Revert \"NFSv4: Handle the special Linux file open access mode\"\n\nThis reverts commit 44942b4e457beda00981f616402a1a791e8c616e.\n\nAfter secondly opening a file with O_ACCMODE|O_DIRECT flags,\nnfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().\n\nReproducer:\n  1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/\n  2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)\n  3. close(fd)\n  4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)\n  5. lseek(fd)\n\nReported-by: Lyu Tao <tao.lyu@epfl.ch>\nSigned-off-by: ChenXiaoSong <chenxiaosong2@huawei.com>\nSigned-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>", "ground_truth": 1, "cwe": ["CWE-909"], "cve": "CVE-2022-24448", "cve_desc": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `nfs4_file_open` is part of the NFSv4 client implementation in the Linux kernel, handling file open operations.\n\n2) The function performs several security-related checks:\n   - Validates file open flags using `nfs_check_flags(openflags)`\n   - Handles O_ACCMODE (read/write/execute) appropriately\n   - Removes O_CREAT and O_EXCL flags since new file creation isn't allowed here\n   - Uses `dget_parent()` to get the parent directory dentry\n   - Allocates an `nfs_open_context` structure with proper validation using `IS_ERR(ctx)`\n   - Sets up `struct iattr` for attributes, including handling O_TRUNC (which sets size to 0 and waits for writeback)\n   - Calls `NFS_PROTO(dir)->open_context()` to perform the actual open operation\n   - Validates the returned inode against the expected dentry inode\n   - Uses proper cleanup with `put_nfs_open_context()` and `dput(parent)`\n\n3) The function properly handles error cases:\n   - Returns appropriate error codes (-ENOENT, -ESTALE, etc.)\n   - Uses `d_drop(dentry)` and returns -EOPENSTALE when stale entries are detected\n   - Ensures proper cleanup with `goto` labels and resource deallocation\n\n4) The code follows kernel security best practices:\n   - Uses proper pointer validation (IS_ERR checks)\n   - Properly manages reference counts (dget_parent, dput)\n   - Uses kernel-provided functions for NFS operations\n   - Handles race conditions by dropping stale dentries and returning -EOPENSTALE\n   - Does not perform unsafe memory operations or string manipulations\n\n5) There are no obvious buffer overflows, use-after-free issues, or improper input validation. The function correctly handles NFS-specific semantics for file opening, including the handling of stale file handles and revalidation.\n\n(2) NO: No security vulnerability."}
{"idx": 201382, "project": "gerbv", "commit_id": "672214abb47a802fc000125996e6e0a46c623a4e", "project_url": "https://github.com/gerbv/gerbv", "commit_url": "https://github.com/gerbv/gerbv/commit/672214abb47a802fc000125996e6e0a46c623a4e", "commit_message": "Add test to demonstrate buffer overrun", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-40391", "cve_desc": "An out-of-bounds write vulnerability exists in the drill format T-code tool number functionality of Gerbv 2.7.0, dev (commit b5f1eacd), and the forked version of Gerbv (commit 71493260). A specially-crafted drill file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Parsing**:\n   - The function `drill_parse_T_code` processes a Gerber drill file, specifically parsing tool definitions (e.g., T1C1.23, T2F, etc.).\n   - It reads characters from the file using `gerb_fgetc(fd)` and `gerb_fgetint(fd, NULL)`, which are custom functions likely designed to handle file parsing safely.\n   - The function checks for valid characters after 'T' (e.g., digits, '+', '-', 'C', 'F', 'S') and handles malformed input with error messages.\n\n2. **Buffer and Memory Safety**:\n   - The function uses `g_new0(gerbv_aperture_t, 1)` to allocate memory for aperture structures. This is safe as it initializes memory to zero.\n   - It checks for `NULL` returns from `g_new0` and calls `GERB_FATAL_ERROR` if allocation fails \u2014 this prevents use-after-free or null-pointer dereference.\n   - The function uses `g_strdup_printf` to create strings for statistics, which is safe as it uses glib's memory management.\n\n3. **String and Format Handling**:\n   - The function uses `g_strdup_printf` to format strings for error and statistics output. This is safe because it uses glib's safe string formatting.\n   - The `read_double` function is used to parse floating-point values. While not shown, it's assumed to be safe (e.g., not using `sscanf` with unbounded format strings).\n   - The function does not use `strcpy`, `sprintf`, or other unsafe string functions. All string operations use safe glib equivalents.\n\n4. **Input Validation**:\n   - The function validates that the character after 'T' is a digit, '+', '-', or one of 'C', 'F', 'S'. Invalid characters trigger an error and return early.\n   - It checks for out-of-bounds tool numbers (`tool_num < TOOL_MIN || tool_num >= TOOL_MAX`) and reports errors.\n   - It validates that the size is within reasonable bounds (`size <= 0. || size >= 10000.`) and issues warnings or errors accordingly.\n\n5. **Potential Issues**:\n   - The function uses `gerb_fgetint(fd, NULL)` to read integers. If this function internally uses `sscanf` or similar without bounds checking, it could be vulnerable. However, given the context and the fact that it's part of a well-maintained Gerber parser, it's likely safe.\n   - The function uses `gerb_ungetc(fd)` to push back characters. This is safe as long as the underlying implementation handles it correctly (which is standard in C file streams).\n   - The function does not perform any dynamic memory allocation based on untrusted input without bounds checking. All allocations are for fixed-size structures.\n\n6. **Error Handling and Logging**:\n   - The function uses `gerbv_stats_printf` to log errors and warnings. This is safe and does not involve user-controlled format strings (no `printf` with user input).\n   - The function returns early on invalid input, preventing further processing.\n\n7. **No Obvious Vulnerabilities**:\n   - No buffer overflows (no `strcpy`, `gets`, `sprintf`, etc.).\n   - No format string vulnerabilities (no `printf` with user-controlled format string).\n   - No command injection (no system calls with user input).\n   - No use of unsafe functions like `strcat`, `gets`, `sprintf`, etc.\n   - All input is validated before processing.\n\nConclusion: The code performs thorough input validation, uses safe memory allocation and string handling (via glib), and avoids unsafe functions. It handles edge cases (like EOF, invalid characters, out-of-bounds tool numbers) gracefully.\n\n(2) NO: No security vulnerability."}
{"idx": 213037, "project": "php-src", "commit_id": "2bcbc95f033c31b00595ed39f79c3a99b4ed0501", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commit;h=2bcbc95f033c31b00595ed39f79c3a99b4ed0501", "commit_message": "Fix bug #79037 (global buffer-overflow in `mbfl_filt_conv_big5_wchar`)", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2020-7060", "cve_desc": "When using certain mbstring functions to convert multibyte encodings, in PHP versions 7.2.x below 7.2.27, 7.3.x below 7.3.14 and 7.4.x below 7.4.2 it is possible to supply data that will cause function mbfl_filt_conv_big5_wchar to read past the allocated buffer. This may lead to information disclosure or crash.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Understand the function\nThe function `mbfl_filt_conv_big5_wchar` is a character encoding conversion filter, likely part of a multibyte character set (like Big5 or CP950) to Unicode (UCS) converter. It processes input bytes (`c`) and converts them into Unicode code points, using a state machine via `filter->status`.\n\n- `filter->status` tracks the state: 0 (initial), 1 (expecting second byte of a DBCS character), or default (reset).\n- `filter->cache` stores the first byte of a DBCS sequence.\n- `filter->output_function` is called to output the resulting Unicode code point.\n- The function uses `CK(...)` macro, which is typically a wrapper for checking return values (e.g., error handling), but we assume it doesn't affect security directly.\n\n---\n\n### Step 2: Analyze state 0 (initial state)\n- If `c` is in 0x00\u20130x80: treated as Latin (single-byte), output directly.\n- If `c == 0xff`: outputs `0xf8f8` (a special placeholder, possibly for error or control).\n- If `c > c1` and `c < 0xff`: assumes it's a DBCS lead byte \u2192 sets `status = 1`, caches `c`.\n- Otherwise: applies `w = c & MBFL_WCSGROUP_MASK | MBFL_WCSGROUP_THROUGH`, then outputs `w`.\n\nNote: `c1` is set to 0x80 for CP950, 0xA0 otherwise. So valid DBCS lead bytes are:\n- For CP950: 0x80 < c < 0xFF \u2192 but 0x80 is excluded, so starts at 0x81.\n- For others: 0xA0 < c < 0xFF.\n\nThis is consistent with Big5/CP950 encoding rules (lead bytes in 0xA1\u20130xFE for Big5, 0x81\u20130xFE for CP950).\n\nSo far, no obvious buffer overflow or injection.\n\n---\n\n### Step 3: Analyze state 1 (second byte of DBCS)\n- `c1 = filter->cache` (the lead byte).\n- Checks if `c` is in valid second byte ranges:\n  - `(c > 0x39 && c < 0x7f)` \u2192 0x3A to 0x7E\n  - OR `(c > 0xa0 && c < 0xff)` \u2192 0xA1 to 0xFE\n\nThis is correct for Big5/CP950: second bytes are in 0x40\u20130x7E and 0xA1\u20130xFE (excluding 0x7F, 0xFF).\n\nIf `c` is valid:\n- Computes `w` using a formula based on `c1` and `c`.\n- Looks up `w` in `big5_ucs_table` (if valid index).\n- Then checks for CP950-specific PUA (Private Use Area) mappings:\n  - Uses `cp950_pua_tbl` to map certain byte pairs to Unicode.\n  - The loop iterates over `sizeof(cp950_pua_tbl)/(sizeof(unsigned short)*4)` entries.\n  - **Critical point**: The loop uses `k` as an index, but **no bounds check** on `k` after the loop.\n\nAfter the loop:\n```c\nif ((cp950_pua_tbl[k][2] & 0xff) == 0x40) {\n    ...\n} else {\n    ...\n}\n```\nBut if the loop doesn't find a match, `k` will be equal to the number of entries (i.e., `sizeof(...) / ...`), which is **out of bounds** for the array.\n\nThis leads to **undefined behavior** when accessing `cp950_pua_tbl[k][2]` and `cp950_pua_tbl[k][0]`.\n\nThis is a **classic out-of-bounds array access**.\n\nEven if the array is static and the bounds are known, the code does not check whether `k` is within bounds before accessing `cp950_pua_tbl[k][...]`.\n\nThis is a **security vulnerability** because:\n- It can lead to memory corruption.\n- It may allow arbitrary code execution if the array is in a writable memory region and the access triggers a use-after-free or heap corruption.\n- It's exploitable via crafted input that causes the lookup to fail (e.g., invalid DBCS sequence), leading to out-of-bounds access.\n\n---\n\n### Step 4: Other cases in state 1\n- If `c` is a control character (0\u20130x20 or 0x7F): output directly.\n- Otherwise: treat as invalid DBCS \u2192 output `(c1 << 8) | c` masked with `MBFL_WCSGROUP_MASK | MBFL_WCSGROUP_THROUGH`.\n\nThis is a fallback for invalid sequences, which is acceptable.\n\nBut the **critical flaw is in the PUA handling loop**.\n\n---\n\n### Step 5: Conclusion\nThe code has a **buffer overflow / out-of-bounds array access** in the CP950 PUA handling logic. The loop variable `k` is used without checking if it is within the valid range of the `cp950_pua_tbl` array. This can lead to memory corruption and is exploitable.\n\nThis is a **security vulnerability**.\n\n(1) YES: A security vulnerability detected."}
{"idx": 211700, "project": "linux", "commit_id": "4fbcc1a4cb20fe26ad0225679c536c80f1648221", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/4fbcc1a4cb20fe26ad0225679c536c80f1648221", "commit_message": "nfc: st21nfca: Fix potential buffer overflows in EVT_TRANSACTION\n\nIt appears that there are some buffer overflows in EVT_TRANSACTION.\nThis happens because the length parameters that are passed to memcpy\ncome directly from skb->data and are not guarded in any way.\n\nSigned-off-by: Jordy Zomer <jordy@pwning.systems>\nReviewed-by: Krzysztof Kozlowski <krzysztof.kozlowski@canonical.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 1, "cwe": ["CWE-120"], "cve": "CVE-2022-26490", "cve_desc": "st21nfca_connectivity_event_received in drivers/nfc/st21nfca/se.c in the Linux kernel through 5.16.12 has EVT_TRANSACTION buffer overflows because of untrusted length parameters.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `st21nfca_connectivity_event_received` handles NFC connectivity events, specifically for two types: ST21NFCA_EVT_CONNECTIVITY and ST21NFCA_EVT_TRANSACTION.\n\n2. For ST21NFCA_EVT_CONNECTIVITY, it simply calls `nfc_se_connectivity()` with the host parameter. This is straightforward and does not involve untrusted data processing.\n\n3. For ST21NFCA_EVT_TRANSACTION, the code processes a received skb (socket buffer) containing structured data:\n   - It first checks if the skb length is at least `NFC_MIN_AID_LENGTH + 2` and if the first byte is the expected AID tag (0x81). This prevents processing malformed packets.\n   - It allocates memory for a `struct nfc_evt_transaction` using `devm_kzalloc`, with size `skb->len - 2`. This is correct because the first two bytes are the AID tag and length.\n   - It copies the AID data from `skb->data[2]` to `transaction->aid`, with length `skb->data[1]`.\n   - Then it checks if the byte after the AID data is the PARAMETERS tag (0x82). This is a protocol-level validation.\n   - It reads the parameters length and copies the parameters data.\n\n4. The key concern is whether the length values (`skb->data[1]` and `skb->data[transaction->aid_len + 3]`) are properly validated against the available buffer size.\n\n5. Let's examine the bounds:\n   - `transaction->aid_len = skb->data[1]` \u2014 this is read from the packet.\n   - The code checks `skb->len < NFC_MIN_AID_LENGTH + 2` \u2014 this ensures the packet is long enough to contain at least the AID tag, length, and minimum AID (5 bytes).\n   - However, there is no check that `transaction->aid_len` is within a reasonable range (e.g., \u2264 16 as per ETSI 102 622), nor is there a check that `transaction->aid_len + 4 + transaction->params_len` exceeds `skb->len`.\n\n6. Specifically:\n   - `memcpy(transaction->aid, &skb->data[2], transaction->aid_len);` \u2014 this is safe only if `transaction->aid_len` is \u2264 `skb->len - 2`, but the code does not verify this.\n   - Later: `memcpy(transaction->params, skb->data + transaction->aid_len + 4, transaction->params_len);` \u2014 this could read beyond the skb buffer if `transaction->params_len` is too large or if the total length exceeds `skb->len`.\n\n7. The code checks that the PARAMETERS tag is present at `transaction->aid_len + 2`, but it does not verify that `transaction->aid_len + 4 + transaction->params_len <= skb->len`. This means an attacker could craft a packet where:\n   - `transaction->aid_len` is large (e.g., 0xFF), and\n   - `transaction->params_len` is also large,\n   - causing `memcpy` to read beyond the skb buffer, leading to a buffer over-read (information disclosure) or potentially a buffer overflow if the allocated memory is too small.\n\n8. Although `devm_kzalloc(dev, skb->len - 2, GFP_KERNEL)` is used, the size is based on `skb->len - 2`, which may be larger than the actual data being copied. But the real issue is that the code assumes the data lengths in the packet are valid and does not validate them against the total packet length.\n\n9. The lack of bounds checking on `transaction->aid_len` and `transaction->params_len` relative to `skb->len` creates a potential for out-of-bounds memory access.\n\n(1) YES: A security vulnerability detected."}
{"idx": 194998, "project": "tensorflow", "commit_id": "240655511cd3e701155f944a972db71b6c0b1bb6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6", "commit_message": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`\n\nPiperOrigin-RevId: 409166738\nChange-Id: I7f0a3590b8acae3f3e3e2fe636e1f5ef285693cf", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2022-23581", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ConstantFolding::IsSimplifiableReshape` is part of a graph optimization system (likely TensorFlow), responsible for determining whether a Reshape operation can be simplified during constant folding.\n\n2) The function performs several validation checks:\n   - Confirms the node is actually a Reshape node\n   - Ensures the node has at least 2 inputs (which is correct for Reshape: input tensor and shape tensor)\n   - Retrieves the second input (the shape) and checks if it's a \"really constant\" node\n   - Evaluates that constant node to get the actual shape tensor\n   - Validates the output of the evaluation (must be exactly one output)\n   - Retrieves the input properties of the node to get the expected shape\n   - Validates the data type and shape properties\n   - Converts the evaluated shape tensor into a PartialTensorShape\n   - Compares the expected shape with the evaluated shape for compatibility\n\n3) Key security considerations:\n   - The function does not directly handle untrusted user input\n   - It operates on a graph representation that is already validated\n   - The evaluation of the shape node is done through `EvaluateNode`, which is part of a controlled graph execution system\n   - The function only evaluates constant nodes that have already been verified as constants\n   - There is no direct string manipulation, memory copying, or unbounded access\n   - The function returns early on any validation failure, preventing further processing\n   - The use of `TF_CHECK_OK` ensures that any failure in shape construction is caught\n   - The function does not perform any unsafe operations like buffer overflows, format string vulnerabilities, or arbitrary code execution\n\n4) The function is defensive in its approach:\n   - It validates all inputs and dependencies\n   - It checks for null pointers and invalid states\n   - It ensures data types and shapes are valid\n   - It performs compatibility checks before proceeding\n\n5) This is not a security-sensitive function in the traditional sense (like handling user input, file I/O, or network data). It's a compiler/optimizer pass that operates on a validated graph structure.\n\n6) There are no obvious vulnerabilities such as:\n   - Buffer overflows\n   - Use-after-free\n   - Integer overflows\n   - Format string vulnerabilities\n   - Insecure memory operations\n   - Unvalidated input processing\n\nThe function is well-structured, defensive, and follows proper validation patterns. It's designed to be safe within the context of a graph optimization system.\n\n(2) NO: No security vulnerability."}
{"idx": 216654, "project": "core", "commit_id": "2c3f37672277b1f73f84722802aaa0ab1ab3e413", "project_url": "https://github.com/LibreOffice/core", "commit_url": "https://github.com/dovecot/core/commit/2c3f37672277b1f73f84722802aaa0ab1ab3e413", "commit_message": "auth: Don't crash expanding %variables when username isn't set.\n\nThis continues the auth-policy fix in\nc3d3faa4f72a676e183f34be960cff13a5a725ae", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2016-8652", "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Function Overview**:\n   - The function `auth_request_get_var_expand_table_full` constructs a `var_expand_table` array (`tab`) that contains key-value pairs for variable expansion during authentication processing.\n   - It dynamically allocates memory using `t_malloc` based on the input `*count` and the number of static entries (`auth_count = N_ELEMENTS(auth_request_var_expand_static_tab)`).\n   - The function populates the table with various fields from the `auth_request` struct, including user, service, IP addresses, ports, session IDs, etc.\n   - The `escape_func` is used to escape values before storing them in the table. If `escape_func` is NULL, it defaults to `escape_none`.\n\n2. **Memory Allocation and Bounds**:\n   - Memory is allocated as: `t_malloc((*count + auth_count) * sizeof(*tab))`.\n   - Then, `tab` is advanced by `*count` positions: `tab += *count;`.\n   - After that, `*count += auth_count;` \u2014 this updates the count to reflect the total number of entries.\n   - The static table (`auth_request_var_expand_static_tab`) is copied into the newly allocated space using `memcpy(tab, ..., auth_count * sizeof(*tab))`.\n   - This is correct: the memory is allocated for `*count + auth_count` entries, and the static table is placed at the end of the allocated block, after the initial `*count` entries.\n\n3. **Value Assignment and Escaping**:\n   - All string values are assigned via `tab[i].value = ...`.\n   - The `escape_func` is used for most values, including user, service, session ID, mechanism name, and others.\n   - For values that are not strings (e.g., `net_ip2addr`, `dec2str`), they return dynamically allocated strings (likely from `t_strcut` or `t_strdup`), which are safe as long as they are properly managed.\n   - The only potential issue is when `escape_func` is `escape_none` \u2014 but even then, the function is not doing anything dangerous unless the data is later used in a context that interprets it as code (e.g., shell command, SQL, etc.). However, the function itself does not execute or interpret the data \u2014 it only prepares it for later use.\n\n4. **Null Pointer Handling**:\n   - The function checks for `escape_func == NULL` and defaults to `escape_none`, which is safe.\n   - For fields like `auth_request->userdb`, `passdb`, `session_id`, etc., it checks for `NULL` and assigns `\"\"` or `NULL` appropriately.\n   - `tab[4]` is commented as \"we have no home dir\" \u2014 but no value is assigned. This is a **critical issue**.\n\n5. **Critical Bug: Uninitialized Table Entry**:\n   - The code assigns values to `tab[0]` through `tab[33]`, but `tab[4]` is **not assigned**.\n   - The comment says: `/* tab[4] = we have no home dir */`, but no assignment is made.\n   - This means `tab[4].value` is uninitialized \u2014 it contains garbage (uninitialized memory).\n   - Later, when this table is used (e.g., in string expansion), this uninitialized value could be dereferenced, leading to undefined behavior, crashes, or potentially information disclosure (if the garbage contains sensitive data).\n   - This is a **buffer use-after-free or uninitialized memory access** vulnerability.\n\n6. **Is this a security vulnerability?**\n   - Yes. Uninitialized memory being used in a data structure that is later exposed (e.g., in logs, responses, or string expansion) can lead to:\n     - Information disclosure (leaking stack or heap contents).\n     - Crashes (if the garbage is invalid pointer or invalid string).\n     - Potential exploitation in contexts where the data is used in sensitive operations.\n   - Even though the function doesn't directly execute the data, the uninitialized value is part of a public-facing data structure, making it a security risk.\n\n7. **Conclusion**:\n   - The function fails to initialize `tab[4]`, which is a critical oversight.\n   - This is a clear example of uninitialized memory usage, which is a known security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 198499, "project": "micro-ecc", "commit_id": "1b5f5cea5145c96dd8791b9b2c41424fc74c2172", "project_url": "https://github.com/kmackay/micro-ecc", "commit_url": "https://github.com/kmackay/micro-ecc/commit/1b5f5cea5145c96dd8791b9b2c41424fc74c2172", "commit_message": "Fix for #168", "ground_truth": 1, "cwe": ["CWE-415"], "cve": "CVE-2020-27209", "cve_desc": "The ECDSA operation of the micro-ecc library 1.0 is vulnerable to simple power analysis attacks which allows an adversary to extract the private ECC key.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose and Context**:\n   - This function `uECC_sign_with_k` is part of a cryptographic library (uECC) for ECDSA signing.\n   - It signs a message hash using a private key and a provided value `k` (the ephemeral private key).\n   - The function is designed to be secure against side-channel attacks by using blinding techniques.\n\n2. **Input Validation**:\n   - The function checks that `k` is non-zero and less than `curve->n` (the order of the curve). This is correct and necessary to prevent invalid or weak signatures.\n   - If `k` is invalid, it returns 0 (failure), which is appropriate.\n\n3. **Side-Channel Mitigation**:\n   - The function uses `regularize_k` to normalize `k` into a canonical form, which helps prevent timing side-channel leaks.\n   - It uses a random number `tmp` (generated via `uECC_generate_random_int` if RNG is available) to blind the computation of `k` via:\n     - `k' = rand * k`\n     - `k = 1 / k'`\n     - `k = 1 / k' * rand` \u2192 effectively `k = 1 / k` (but with randomization)\n   - This blinding technique is intended to prevent side-channel analysis of the modular inverse operation, which could leak information about `k` or the private key.\n\n4. **Use of Random Number Generator (RNG)**:\n   - If `g_rng_function` is not set, it sets `tmp[0] = 1` (i.e., uses a constant \"random\" value). This is a **critical flaw**.\n   - Using a constant value (1) instead of a true random number defeats the purpose of blinding. An attacker could potentially correlate the timing or power consumption of the modular inverse operation across multiple signatures and recover `k` or the private key.\n   - This is a **known vulnerability** in cryptographic implementations: deterministic blinding with a constant value is insecure.\n\n5. **Blinding Effectiveness**:\n   - The blinding is only effective if `tmp` is unpredictable. But when `g_rng_function` is not available, `tmp` is set to 1, making the blinding predictable and thus ineffective.\n   - This creates a **side-channel attack vector** when the RNG is not available.\n\n6. **Other Code Paths**:\n   - The rest of the code correctly computes the ECDSA signature components `r` and `s` using standard ECDSA formulae.\n   - The use of `uECC_vli_modMult`, `uECC_vli_modAdd`, and `uECC_vli_modInv` with proper bounds checking appears correct.\n   - The `bits2int` and `uECC_vli_nativeToBytes` functions are used appropriately for conversion between bit/byte and word representations.\n\n7. **Conclusion**:\n   - The core cryptographic logic is sound.\n   - However, the **failure to use a random value when RNG is not available** (i.e., using `tmp[0] = 1`) **completely undermines the side-channel protection**.\n   - This is a **security vulnerability** because it allows an attacker to perform side-channel attacks (e.g., timing or power analysis) to recover the private key or `k`.\n\n(1) YES: A security vulnerability detected."}
{"idx": 210278, "project": "unicorn", "commit_id": "3d3deac5e6d38602b689c4fef5dac004f07a2e63", "project_url": "https://github.com/unicorn-engine/unicorn", "commit_url": "https://github.com/unicorn-engine/unicorn/commit/3d3deac5e6d38602b689c4fef5dac004f07a2e63", "commit_message": "Fix crash when mapping a big memory and calling uc_close", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-29694", "cve_desc": "Unicorn Engine v2.0.0-rc7 and below was discovered to contain a NULL pointer dereference via qemu_ram_free.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `qemu_ram_free` is responsible for freeing a RAM block in the QEMU user-mode emulation context (`uc`). It takes two parameters: `uc` (the QEMU context) and `block` (the RAMBlock to be freed).\n\n2. The function first checks if `block` is NULL. If so, it returns early. This is a safe practice to prevent null pointer dereference.\n\n3. The code then removes the `block` from a linked list using `QLIST_REMOVE(block, next)`. This is a standard operation for removing an element from a queue list (likely a doubly linked list managed by QEMU's memory management system). This operation is safe as long as the list structure is properly maintained and the `next` field is valid.\n\n4. The line `uc->ram_list.mru_block = NULL;` resets the most recently used (MRU) block pointer. This is a reasonable operation when removing a block from the list, as it ensures the MRU state is consistent.\n\n5. The commented-out lines suggest that there were previously intended operations:\n   - `ram_block_notify_remove(block->host, block->max_length);` \u2014 This would notify a subsystem about the removal of a RAM block, possibly for memory accounting or monitoring.\n   - `smp_wmb();` \u2014 A memory barrier to ensure ordering of writes across CPUs (important in SMP systems).\n   - `call_rcu(block, reclaim_ramblock, rcu);` \u2014 This would schedule a deferred free via RCU (Read-Copy-Update), a mechanism used in kernel code to safely remove data structures in a concurrent environment.\n\n6. However, the actual code calls `reclaim_ramblock(uc, block);` directly. This function is likely responsible for actually freeing the memory associated with the block.\n\n7. The key concern is whether `reclaim_ramblock` is safe to call directly without RCU or memory barriers. In a concurrent environment (e.g., multiple threads accessing the RAM list), removing a block from the list and immediately freeing it without proper synchronization could lead to use-after-free or data races.\n\n8. The absence of RCU or memory barriers (which were commented out) suggests that the code may be assuming a single-threaded context or that `reclaim_ramblock` performs its own synchronization. However, in a real-world QEMU environment, especially in user-mode emulation with potential concurrency, this could be dangerous.\n\n9. More critically, if `reclaim_ramblock` is called directly without ensuring that no other thread is accessing the block (e.g., via RCU), it could result in a use-after-free vulnerability if another thread still holds a reference to the block.\n\n10. The fact that the RCU mechanism was previously used and is now commented out indicates a potential regression in safety. RCU is specifically designed to handle such scenarios safely in concurrent systems.\n\n11. Therefore, the direct call to `reclaim_ramblock` without proper synchronization (like RCU or locks) in a potentially concurrent environment constitutes a security vulnerability, as it may allow use-after-free or data races.\n\n(1) YES: A security vulnerability detected."}
{"idx": 200895, "project": "vim", "commit_id": "d6c67629ed05aae436164eec474832daf8ba7420", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/d6c67629ed05aae436164eec474832daf8ba7420", "commit_message": "patch 9.0.0260: using freed memory when using 'quickfixtextfunc' recursively\n\nProblem:    Using freed memory when using 'quickfixtextfunc' recursively.\nSolution:   Do not allow for recursion.", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-2982", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0260.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `call_qftf_func` is responsible for calling a user-defined callback function (`quickfixtextfunc`) to retrieve text to display in a quickfix window. It uses a callback mechanism with a `callback_T` structure.\n\n2) The function first checks if a custom callback is set in the `qfl->qf_qftf_cb` structure. If so, it uses that instead of the default `qftf_cb`.\n\n3) It then creates a dictionary (`d`) containing several parameters:\n   - \"quickfix\": boolean indicating if it's a quickfix list\n   - \"winid\": window ID\n   - \"id\": quickfix list ID\n   - \"start_idx\": starting index\n   - \"end_idx\": ending index\n\n4) This dictionary is passed as an argument to the callback function via `call_callback()`, which invokes the user-supplied function.\n\n5) The function then checks the return value of the callback and handles the result if it's a list.\n\n6) Key security considerations:\n   - The function properly validates the callback structure before calling it.\n   - The dictionary is properly allocated with `dict_alloc_lock(VAR_FIXED)` and reference counting is managed correctly.\n   - The dictionary is properly cleaned up with `dict_unref(d)` after use.\n   - The callback is only called if the callback name is not NULL, preventing null pointer dereference.\n   - The function checks the return type of the callback and only accepts VAR_LIST, preventing type confusion.\n   - The `call_callback` function is assumed to be a safe wrapper that handles the execution of user-defined functions.\n\n7) There are no obvious buffer overflows, use-after-free issues, or improper memory management. The reference counting for the dictionary and list is handled correctly.\n\n8) The function does not directly expose user input to dangerous operations like string formatting or system calls. The callback is invoked in a controlled manner with properly validated parameters.\n\n9) The function appears to follow safe coding practices for callback invocation in the Vim codebase, with proper validation and cleanup.\n\n(2) NO: No security vulnerability."}
{"idx": 197111, "project": "tinyexr", "commit_id": "a685e3332f61cd4e59324bf3f669d36973d64270", "project_url": "https://github.com/syoyo/tinyexr", "commit_url": "https://github.com/syoyo/tinyexr/commit/a685e3332f61cd4e59324bf3f669d36973d64270", "commit_message": "Make line_no with too large value(2**20) invalid. Fixes #124", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2020-19490", "cve_desc": "tinyexr 0.9.5 has a integer overflow over-write in tinyexr::DecodePixelData in tinyexr.h, related to OpenEXR code.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `DecodeChunk` takes several inputs: `exr_header`, `offsets`, `head`, `size`, and `err`.\n   - It validates `data_width` and `data_height` to ensure they are non-negative. If not, it returns an error.\n   - It applies a heuristic threshold (1024 * 8192 = 8,388,608) to prevent excessively large dimensions, which helps avoid resource exhaustion or integer overflow issues.\n   - For tiled data, it checks that `offsets[tile_idx] + sizeof(int)*5 <= size` before accessing data, preventing buffer over-reads.\n   - For scanline data, it checks `offsets[y_idx] + sizeof(int)*2 <= size` before reading, again preventing buffer over-reads.\n\n2. **Integer Overflow and Underflow Protection**:\n   - The code uses `size_t` for sizes and indices, which is appropriate for memory operations.\n   - It checks for overflow in `total_data_len = data_width * data_height * num_channels` by comparing against a large threshold (0x4000000000, or 256 GB) when `sizeof(void*) == 8`. This prevents integer overflow in size calculations.\n   - It also checks `total_data_len == 0` to avoid zero-sized allocations, which could lead to undefined behavior.\n\n3. **Buffer Access and Memory Safety**:\n   - All memory accesses are bounded by checks on `offsets` and `size`. For example:\n     - `if (offsets[tile_idx] + sizeof(int)*5 > size)` \u2192 prevents reading beyond the buffer.\n     - `if (size_t(data_len) > data_size)` \u2192 ensures data length does not exceed available data.\n   - The use of `memcpy` is safe because it is bounded by the size checks.\n   - The `tinyexr::DecodeTiledPixelData` and `tinyexr::DecodePixelData` functions are called with validated parameters, and the code does not pass untrusted data directly to unsafe functions.\n\n4. **Use of `static_cast<size_t>` and `size_t`**:\n   - The code carefully casts signed integers (like `int`) to `size_t` only after ensuring they are non-negative (e.g., `line_no -= exr_header->data_window[1];` is checked for negative values).\n   - The `lno` overflow check uses `tinyexr_int64` to detect potential overflow before casting to `int`, which is a good defensive practice.\n\n5. **Error Handling and `err` String**:\n   - The function appends error messages to `*err` only when `err` is non-null, and uses `std::stringstream` safely.\n   - No format string vulnerabilities or unsafe string operations are present.\n\n6. **Parallelization with OpenMP**:\n   - The `#pragma omp parallel for` is used safely, with each thread operating on independent data (different scanlines or tiles), and no shared state is modified without proper synchronization (though the comment notes a TODO for MT safety, this is not a vulnerability in this context since the `invalid_data` flag is only set and not read in a race condition\u2014though it's a potential race condition, it's not exploitable in a way that leads to memory corruption or code execution).\n\n7. **No Use of Unsafe Functions**:\n   - No `strcpy`, `sprintf`, `gets`, or similar functions are used.\n   - All memory allocation uses `calloc` and `AllocateImage`, which are safe when bounds are checked.\n\n8. **No Direct User Input to Untrusted Functions**:\n   - All user-provided data (from `head`, `offsets`, `exr_header`) is validated before use.\n   - The `compression_type`, `tile_size`, `data_window`, etc., are all checked for validity.\n\n9. **Potential Race Condition**:\n   - The `invalid_data` flag is shared across threads in the `#pragma omp parallel for` block. This is a race condition: multiple threads can write to `invalid_data` simultaneously. However, this is a **race condition**, not a **security vulnerability** in the traditional sense (e.g., buffer overflow, code execution, memory corruption). It may lead to incorrect error reporting but not to arbitrary code execution or memory corruption.\n\n10. **Conclusion**:\n    - The code performs comprehensive bounds checking, input validation, and overflow protection.\n    - All memory accesses are within safe bounds.\n    - No exploitable vulnerabilities such as buffer overflows, use-after-free, or injection attacks are present.\n    - The race condition in `invalid_data` is a concurrency issue, not a security vulnerability that can be exploited to compromise the system.\n\n(2) NO: No security vulnerability."}
{"idx": 195083, "project": "tensorflow", "commit_id": "5b491cd5e41ad63735161cec9c2a568172c8b6a3", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b491cd5e41ad63735161cec9c2a568172c8b6a3", "commit_message": "Validate `proto.dtype()` before calling `set_dtype()`.\n\nThis prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.\n\nPiperOrigin-RevId: 408369083\nChange-Id: Ia21a3e3d62a90d642a4561f08f3b543e5ad00c46", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2022-23571", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `Tensor::FromProto` is responsible for constructing a Tensor from a `TensorProto` message, using an allocator `a`.\n\n2. The function first checks that the allocator `a` is not null using `CHECK_NOTNULL(a)`. This is a defensive programming practice and not a vulnerability.\n\n3. It validates the tensor shape using `TensorShape::IsValid(proto.tensor_shape())`. If the shape is invalid, it returns false. This prevents malformed shape data from being processed.\n\n4. It checks that the data type (`proto.dtype()`) is not `DT_INVALID`. This is a valid sanity check to prevent processing of invalid data types.\n\n5. It computes the number of elements `N` in the tensor using `shape.num_elements()`. This is necessary for memory allocation and data processing.\n\n6. The function then checks if `N > 0` and `proto.dtype()` is non-zero (though the second condition is likely a typo \u2014 it should probably be `proto.dtype() != DT_INVALID`, but it's already checked above). This condition is used to determine whether to decode data.\n\n7. The function uses `CASES_WITH_DEFAULT` to dispatch based on the data type (`proto.dtype()`). This macro likely expands to a switch statement over `DT_*` enum values, handling each data type appropriately.\n\n8. Two paths are available:\n   - If `proto.tensor_content().empty()` is false, it uses `Helper<T>::Decode(a, content, N)` to decode raw binary data.\n   - Otherwise, it uses `FromProtoField<T>(a, proto, N)` to decode from structured fields (e.g., int32_val, float_val, etc.).\n\n9. Both `Helper<T>::Decode` and `FromProtoField<T>` are templated and likely perform type-specific decoding. The use of `T` suggests that the function is instantiated for specific types, and the `CASES_WITH_DEFAULT` macro ensures that only valid data types are handled.\n\n10. After decoding, it checks if `dtype_error` is true or `p == nullptr`. If so, it returns false. This prevents use of invalid or null buffers.\n\n11. It assigns the decoded buffer to `buf_`, updates the shape and dtype, and properly manages memory with `UnrefIfNonNull(buf_)` and `buf_ = p`.\n\n12. Memory logging is optionally enabled, and if so, it records the allocation. This is for debugging/tracking, not a security issue.\n\n13. The function does not perform any unbounded copying, does not use unsafe string operations, and does not directly expose user-controlled data to execution contexts.\n\n14. The use of `CASES_WITH_DEFAULT` ensures that all known data types are handled, and unknown types result in `dtype_error = true`, which causes the function to return false. This prevents undefined behavior for unknown types.\n\n15. The function does not perform any dynamic memory allocation without bounds checking, and the `N = shape.num_elements()` is validated via `TensorShape::IsValid`, which likely checks for overflow and valid dimensions.\n\n16. There is no evidence of buffer overflows, use-after-free, or injection vulnerabilities. The input is validated at multiple levels: shape, dtype, and content.\n\n17. The function is part of a larger system (likely TensorFlow), and such functions are designed to be safe against malformed protobufs.\n\nConclusion: The code performs proper input validation, uses safe memory management, and avoids unsafe operations. There are no obvious security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 198452, "project": "tensorflow", "commit_id": "a989426ee1346693cc015792f11d715f6944f2b8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a989426ee1346693cc015792f11d715f6944f2b8", "commit_message": "Improve to cover scale value greater than one\n\nPiperOrigin-RevId: 433050921", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-29212", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, certain TFLite models that were created using TFLite model converter would crash when loaded in the TFLite interpreter. The culprit is that during quantization the scale of values could be greater than 1 but code was always assuming sub-unit scaling. Thus, since code was calling `QuantizeMultiplierSmallerThanOneExp`, the `TFLITE_CHECK_LT` assertion would trigger and abort the process. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ComparisonQuantized` is designed to perform a comparison operation between two quantized tensors (input1 and input2), with output stored in a boolean tensor. It supports quantized types (UInt8 and Int8).\n\n2) The function first checks if the input tensor types are UInt8 or Int8, and if so, proceeds with quantized operations.\n\n3) It computes offsets based on zero_point values: `input1_offset = -input1->params.zero_point`, and similarly for input2. This is standard for quantized arithmetic.\n\n4) It calculates quantization multipliers and shifts using `QuantizeMultiplierSmallerThanOneExp`, which is a well-known function used to represent scaling factors in fixed-point arithmetic. This is a correct and safe way to handle quantized data.\n\n5) The function constructs a `ComparisonParams` struct with all necessary parameters (shifts, offsets, multipliers) and passes them to either `BroadcastComparison4DSlowWithScaling` or `ComparisonWithScaling`, depending on whether broadcasting is required.\n\n6) The actual data access is done via:\n   - `GetTensorShape(input1)` and `GetTensorShape(input2)` \u2013 these are assumed to be safe and return valid shapes.\n   - `GetTensorData<input_dtype>(input1)` \u2013 this retrieves the raw data pointer for the input tensor.\n\n7) The key point: the function does not perform any bounds checking on the tensor shapes or data pointers. However, in the context of TensorFlow Lite (TFLite), these tensor access functions are typically part of a trusted runtime environment where the input tensors are validated before reaching this function. The function itself is not responsible for validating tensor metadata (like shape, size, or data pointer validity), which is assumed to be done earlier in the execution pipeline.\n\n8) The function uses template parameters (`input_dtype`, `opname`) which are likely resolved at compile time and are not user-controlled in a way that would lead to code injection or memory corruption.\n\n9) There is no dynamic memory allocation, no string concatenation, no direct user input processing, and no unsafe memory operations (like buffer overflows or use-after-free). The operations are all fixed-point arithmetic and comparisons on quantized data.\n\n10) The use of `reference_ops::ComparisonWithScaling` and `BroadcastComparison4DSlowWithScaling` are reference implementations that are well-tested and do not contain known vulnerabilities in this context.\n\n11) The function does not expose any direct interface to untrusted input in a way that could lead to memory corruption, integer overflow, or other exploitable conditions. The only potential risk would be if the input tensors were malformed (e.g., invalid shape, null data pointer), but that would be a precondition violation, not a vulnerability in this function.\n\nConclusion: The function correctly handles quantized tensor comparison with proper scaling and offset adjustments. It uses safe, well-defined operations and relies on the TFLite runtime to ensure input validity. There are no exploitable security vulnerabilities in this code snippet.\n\n(2) NO: No security vulnerability."}
{"idx": 209955, "project": "linux", "commit_id": "8188a18ee2e48c9a7461139838048363bfce3fef", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8188a18ee2e48c9a7461139838048363bfce3fef", "commit_message": "iwlwifi: pcie: fix rb_allocator workqueue allocation\n\nWe don't handle failures in the rb_allocator workqueue allocation\ncorrectly. To fix that, move the code earlier so the cleanup is\neasier and we don't have to undo all the interrupt allocations in\nthis case.\n\nSigned-off-by: Johannes Berg <johannes.berg@intel.com>\nSigned-off-by: Luca Coelho <luciano.coelho@intel.com>", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2019-16234", "cve_desc": "drivers/net/wireless/intel/iwlwifi/pcie/trans.c in the Linux kernel 5.2.14 does not check the alloc_workqueue return value, leading to a NULL pointer dereference.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - The function `iwl_trans_pcie_alloc` allocates memory for a PCIe transport structure using `iwl_trans_alloc`, which is a safe wrapper for memory allocation.\n   - It initializes various locks (`spin_lock_init`, `mutex_init`, `init_waitqueue_head`) and sets up per-CPU memory for TSO headers using `alloc_percpu`. This is standard and safe for kernel code.\n\n2. **PCI Device Setup**:\n   - `pcim_enable_device(pdev)` enables the PCI device. This is a standard and safe operation.\n   - `pci_set_master(pdev)` allows the device to initiate DMA transactions. This is required and safe when done correctly.\n   - `pci_set_dma_mask` and `pci_set_consistent_dma_mask` are used to set DMA capabilities. The code attempts 64-bit DMA first, then falls back to 32-bit if needed. This is a robust and secure practice to ensure DMA compatibility without assuming 64-bit support.\n\n3. **Memory Mapping**:\n   - `pcim_iomap_regions_request_all(pdev, BIT(0), DRV_NAME)` maps the device's memory region. The function checks for failure and handles cleanup appropriately.\n   - `pcim_iomap_table(pdev)[0]` is used to get the mapped base address. The code checks for null and handles errors properly.\n\n4. **Hardware Register Access**:\n   - `pci_write_config_byte(pdev, PCI_CFG_RETRY_TIMEOUT, 0x00)` disables the retry timeout register to prevent interference with CPU C3 state. This is a known workaround and not a security issue.\n   - `iwl_read32(trans, CSR_HW_REV)` reads the hardware revision. The code checks for the invalid value `0xFFFFFFFF`, which indicates a potential PCI communication issue. This is a valid error check.\n\n5. **Error Handling and Cleanup**:\n   - The code uses a structured error handling pattern with labeled cleanup sections (`out_no_pci`, `out_free_ict`).\n   - All allocated resources (per-CPU memory, IRQ, workqueue, etc.) are properly freed in the error paths.\n   - `iwl_trans_free(trans)` is called in `out_no_pci`, and `iwl_pcie_free_ict(trans)` in `out_free_ict`, ensuring no resource leaks.\n\n6. **Interrupt Handling**:\n   - The code sets up either MSI-X or legacy interrupts via `devm_request_threaded_irq`. The use of `devm_` ensures automatic cleanup on driver unload.\n   - The interrupt handler functions (`iwl_pcie_isr`, `iwl_pcie_irq_handler`) are properly registered.\n\n7. **Workqueue and DebugFS**:\n   - A high-priority, unbound workqueue is created for RX allocation.\n   - DebugFS support is conditionally compiled (`#ifdef CONFIG_IWLWIFI_DEBUGFS`) and properly initialized with mutexes.\n\n8. **No User Input or Untrusted Data**:\n   - The function operates on kernel-level PCI device structures and configuration parameters passed from the driver core.\n   - There is no direct handling of user input, string concatenation, or dynamic memory copying from untrusted sources.\n   - All data comes from the PCI device, configuration tables, or kernel APIs, which are trusted.\n\n9. **No Buffer Overflows, Use-After-Free, or Memory Corruption**:\n   - All memory allocations are checked for success.\n   - All cleanup paths are consistent and prevent resource leaks.\n   - No unsafe functions like `strcpy`, `strcat`, or `memcpy` without bounds are used.\n\n10. **No Injection or Code Execution Risks**:\n   - No dynamic code generation, no SQL, no shell commands, no format string vulnerabilities.\n   - The code does not interpret or execute any data from the device that could be manipulated by an attacker.\n\nConclusion: The code follows secure kernel programming practices. It performs proper error checking, uses safe memory allocation and cleanup, handles device configuration securely, and avoids any known vulnerability patterns.\n\n(2) NO: No security vulnerability."}
{"idx": 208912, "project": "vim", "commit_id": "1c3dd8ddcba63c1af5112e567215b3cec2de11d0", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/1c3dd8ddcba63c1af5112e567215b3cec2de11d0", "commit_message": "patch 9.0.0490: using freed memory with cmdwin and BufEnter autocmd\n\nProblem:    Using freed memory with cmdwin and BufEnter autocmd.\nSolution:   Make sure pointer to b_p_iminsert is still valid.", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-3235", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0490.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `getcmdline_int` is part of the Vim editor's command-line input handling system. It is responsible for:\n- Reading user input from the command line (e.g., `:`, `/`, `?`, `@`).\n- Handling keypresses, including special keys (arrows, Ctrl, ESC, etc.).\n- Supporting features like:\n  - Command history.\n  - Wildcard completion (`Ctrl-N`, `Ctrl-P`, `wildchar`).\n  - Abbreviations.\n  - Input method support (e.g., for non-Latin scripts).\n  - Incremental search.\n  - Autocommands (`CmdlineEnter`, `CmdlineChanged`, `CmdlineLeave`).\n  - Mouse and GUI interactions.\n\nThis is a core part of Vim\u2019s user interface and input processing.\n\n---\n\n### Step 2: Look for potential security vulnerabilities\n\nWe need to check for common vulnerabilities such as:\n- Buffer overflows.\n- Use-after-free.\n- Improper input validation.\n- Code injection (e.g., via command execution).\n- Unsafe memory handling.\n- Unchecked user input leading to arbitrary code execution.\n\n#### A. Buffer handling\n- The function uses `ccline.cmdbuff` to store the command line input.\n- It checks `ccline.cmdbuff != NULL` and saves/restore it when recursive calls occur.\n- It uses `ExpandInit(&xpc)` and `ExpandCleanup(&xpc)` to manage expansion state.\n- `put_on_cmdline()` is used to insert characters into the command line buffer.\n- The function ensures that `ccline.cmdlen` is updated correctly and that `ccline.cmdbuff` is null-terminated.\n\nThere is no direct use of unsafe functions like `strcpy`, `strcat`, or `gets`. All string operations are done via safe wrappers (`put_on_cmdline`, `mb_char2bytes`, etc.) that respect buffer bounds.\n\n\u2705 No buffer overflow risk.\n\n#### B. Input validation and sanitization\n- The function processes input via `safe_vgetc()`, which is designed to safely read input from the user.\n- Special keys (like `K_LEFT`, `K_RIGHT`, `Ctrl_C`, `ESC`) are handled explicitly.\n- `IS_SPECIAL(c)` checks are used to distinguish special keys from regular characters.\n- `mod_mask` is used to track modifier keys (Shift, Ctrl, etc.), and is reset appropriately.\n- `get_literal()` and `get_digraph()` are used for special input (e.g., `Ctrl-V`), and they are handled safely.\n\nNo raw user input is directly passed to system calls or shell commands without validation.\n\n\u2705 No injection vector (e.g., shell injection, command injection).\n\n#### C. Recursive calls and stack depth\n- The function maintains a static `depth` counter.\n- If `depth == 50`, it emits an error: `emsg(_(e_command_too_recursive));` and returns.\n- This prevents infinite recursion.\n\n\u2705 Safe recursion limit.\n\n#### D. Memory management\n- `ccline.cmdbuff` is managed via `save_cmdline()` and `restore_cmdline()` when recursive calls occur.\n- `VIM_CLEAR(lookfor)` is used to free memory when appropriate.\n- `ExpandCleanup(&xpc)` is called at the end.\n- `vim_free(new_last_cmdline)` is used when needed.\n\nAll dynamically allocated memory is properly freed.\n\n\u2705 No memory leaks or use-after-free.\n\n#### E. Command execution\n- The function does not directly execute user input.\n- It only builds a command string (`ccline.cmdbuff`) and later passes it to `do_cmdline()` (not shown here).\n- The actual execution happens elsewhere, and the input is validated and sanitized before execution.\n\n\u2705 No direct command execution from untrusted input.\n\n#### F. Special features (e.g., `Ctrl-V`, `Ctrl-R`, `@`, `:`, `=`, `!`)\n- `Ctrl-V` allows literal insertion \u2014 handled via `get_literal()` and `putcmdline()`, which are safe.\n- `Ctrl-R` inserts register contents \u2014 but only if the register is valid and accessible.\n- `@` is used for executing macros \u2014 but only if the macro is valid and not maliciously crafted.\n- However, **Vim does not execute arbitrary code from command-line input unless explicitly invoked via `:execute` or similar**.\n\nThe function itself does not execute code \u2014 it only collects input.\n\n\u2705 No code execution in this function.\n\n#### G. Autocommands and side effects\n- The function triggers autocommands (`CmdlineEnter`, `CmdlineChanged`, `CmdlineLeave`).\n- These are user-defined and could be malicious if the user has a malicious `.vimrc`.\n- However, **this is not a vulnerability in the function itself** \u2014 it's a known behavior of Vim\u2019s extensibility.\n- The function does not execute arbitrary code; it only triggers events.\n\n\u2705 Not a security vulnerability \u2014 it's a design feature.\n\n#### H. Mouse and GUI handling\n- Mouse events are ignored unless preceded by a mouse-down event.\n- `K_MIDDLEMOUSE`, `K_LEFTMOUSE`, etc., are handled safely.\n- `cmdline_paste()` is used, but only with proper checks (`clip_star.available`, etc.).\n\n\u2705 No unsafe GUI or mouse handling.\n\n---\n\n### Step 3: Conclusion\n\nAfter a thorough analysis:\n- The function handles user input safely.\n- It uses bounds-checked operations and proper memory management.\n- It does not execute arbitrary code or pass untrusted input to system calls.\n- It prevents infinite recursion.\n- It does not contain buffer overflows, use-after-free, or injection vulnerabilities.\n\nWhile Vim as a whole may have security issues in other parts (e.g., in `:execute`, `:system`, or `:source`), **this specific function (`getcmdline_int`) does not contain a security vulnerability**.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 215262, "project": "qemu", "commit_id": "e73adfbeec9d4e008630c814759052ed945c3fed", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://git.qemu.org/?p=qemu.git;a=commit;h=e73adfbeec9d4e008630c814759052ed945c3fed", "commit_message": "cadence_gem: switch to use qemu_receive_packet() for loopback\n\nThis patch switches to use qemu_receive_packet() which can detect\nreentrancy and return early.\n\nThis is intended to address CVE-2021-3416.\n\nCc: Prasad J Pandit <ppandit@redhat.com>\nCc: qemu-stable@nongnu.org\nReviewed-by: Philippe Mathieu-Daud\u00e9 <philmd@redhat.com>\nSigned-off-by: Alexander Bulekov <alxndr@bu.edu>\nSigned-off-by: Jason Wang <jasowang@redhat.com>", "ground_truth": 1, "cwe": ["CWE-835"], "cve": "CVE-2021-3416", "cve_desc": "A potential stack overflow via infinite loop issue was found in various NIC emulators of QEMU in versions up to and including 5.2.0. The issue occurs in loopback mode of a NIC wherein reentrant DMA checks get bypassed. A guest user/process may use this flaw to consume CPU cycles or crash the QEMU process on the host resulting in DoS scenario.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - `gem_transmit` is a function in a QEMU device model (likely for a Cadence GEM Ethernet controller).\n   - It handles transmission of network packets from hardware descriptors to the guest or host network stack.\n   - It reads transmit descriptors from DMA memory, gathers fragmented packet data into a contiguous buffer (`s->tx_packet`), and forwards the packet via QEMU's networking stack.\n\n2. **Buffer Handling**:\n   - A fixed-size buffer `s->tx_packet` is used to gather packet fragments.\n   - The function checks the available space before copying data:\n     ```c\n     if (tx_desc_get_length(desc) > gem_get_max_buf_len(s, true) -\n                                        (p - s->tx_packet)) {\n         qemu_log_mask(LOG_GUEST_ERROR, \"TX descriptor @ 0x%\" HWADDR_PRIx \" too large: size 0x%x space 0x%zx\\n\",\n                       packet_desc_addr, tx_desc_get_length(desc),\n                       gem_get_max_buf_len(s, true) - (p - s->tx_packet));\n         gem_set_isr(s, q, GEM_INT_AMBA_ERR);\n         break;\n     }\n     ```\n     This check ensures that the current descriptor\u2019s length does not exceed the remaining space in `s->tx_packet`. If it does, an error is logged and the processing stops.\n\n   - The buffer `s->tx_packet` is assumed to be large enough to hold the maximum possible packet size (e.g., Ethernet MTU + headers), and the check prevents overflow.\n\n3. **Input Validation**:\n   - The function validates that the buffer address and length in the descriptor are non-zero:\n     ```c\n     if ((tx_desc_get_buffer(s, desc) == 0) ||\n         (tx_desc_get_length(desc) == 0)) {\n         DB_PRINT(\"Invalid TX descriptor @ 0x%\" HWADDR_PRIx \"\\n\", packet_desc_addr);\n         break;\n     }\n     ```\n     This prevents processing of malformed descriptors.\n\n4. **Memory Access Safety**:\n   - All reads from DMA memory are done via `address_space_read`, which is QEMU\u2019s safe interface for accessing device memory. It performs bounds checking and handles memory mapping correctly.\n   - The `desc` array is of fixed size (`DESC_MAX_NUM_WORDS`), and the size read is determined by `gem_get_desc_len(s, false)`, which is derived from hardware configuration and should be bounded.\n\n5. **No Unbounded Loops or Buffer Overflows**:\n   - The loop over descriptors is controlled by the hardware\u2019s descriptor chain and the `tx_desc_get_used()` flag.\n   - The `p += tx_desc_get_length(desc)` and `total_bytes += ...` updates are safe because they are bounded by the earlier check against `gem_get_max_buf_len(s, true)`.\n   - The `s->tx_packet` buffer is reset after each complete packet, so no accumulation beyond the limit occurs.\n\n6. **No Use of Unsafe String Functions**:\n   - No `strcpy`, `strcat`, `sprintf`, etc., are used.\n   - All data copying is done with explicit length checks and safe memory access via `address_space_read`.\n\n7. **No Injection or Code Execution Risks**:\n   - The code does not interpret user input as code or execute it.\n   - It only reads and forwards raw packet data, which is standard behavior for a network device model.\n\n8. **Error Handling and Logging**:\n   - Invalid descriptors are detected and logged with `qemu_log_mask(LOG_GUEST_ERROR)`, which is appropriate for debugging and security monitoring.\n\n9. **Conclusion**:\n   - All critical operations are bounded and validated.\n   - There is no risk of buffer overflow, use-after-free, or memory corruption.\n   - The code follows safe practices for device emulation in QEMU.\n\n(2) NO: No security vulnerability."}
{"idx": 200323, "project": "vim", "commit_id": "156d3911952d73b03d7420dc3540215247db0fe8", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/156d3911952d73b03d7420dc3540215247db0fe8", "commit_message": "patch 8.2.5123: using invalid index when looking for spell suggestions\n\nProblem:    Using invalid index when looking for spell suggestions.\nSolution:   Do not decrement the index when it is zero.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-2126", "cve_desc": "Out-of-bounds Read in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `suggest_trie_walk` is part of a spell-checking system (likely Vim or a similar editor). It performs a depth-first traversal of a trie (prefix tree) to generate spelling suggestions for a misspelled word (`fword`). The function explores various edit operations (substitution, deletion, insertion, swapping, replacement, etc.) to find valid words that are close to the input word.\n\nKey data structures:\n- `tword[MAXWLEN]`: accumulates the current candidate word being built.\n- `preword[MAXWLEN * 3]`: stores the final suggestion with proper case.\n- `stack[MAXWLEN]`: maintains the state of the traversal (depth, current index, flags, etc.).\n- `fword`: the original bad word being corrected.\n- `byts`, `idxs`: pointers into the trie data (byte and index arrays).\n- `sp`: current state pointer in the stack.\n\nThe function uses a recursive-like depth-first search with manual stack management.\n\n---\n\n### Step 2: Look for buffer overflows\n\nCheck all array accesses and string operations:\n\n- `tword[MAXWLEN]`: size is fixed. The function uses `tword[sp->ts_twordlen++] = c;` to append characters. `ts_twordlen` is incremented only when a character is added. The maximum depth is `MAXWLEN`, and `ts_twordlen` is initialized to 0 and only increased. Since `MAXWLEN` is the size of the array, and the loop condition is `depth >= 0`, the function ensures that `ts_twordlen` never exceeds `MAXWLEN - 1` before null-termination. The code explicitly null-terminates `tword[sp->ts_twordlen] = NUL;` at key points.\n\n- `preword[MAXWLEN * 3]`: This is larger than `tword`, and the function uses `STRCPY`, `STRCAT`, `vim_strncpy`, and `make_case_word`. These functions are used carefully:\n  - `STRCPY(preword + sp->ts_prewordlen, tword + sp->ts_splitoff);` \u2014 only copies up to `sp->ts_twordlen - sp->ts_splitoff`, which is bounded by `MAXWLEN`.\n  - `STRCAT(preword, \" \");` \u2014 appends a space, but only if `preword` is not already full. The size is `MAXWLEN * 3`, which is generous.\n  - `vim_strncpy(preword + sp->ts_prewordlen, tword + sp->ts_splitoff, ...)` \u2014 uses a length limit, so no overflow.\n\n- `changename[MAXWLEN][80]`: used only for debugging. Each string is limited to 80 characters, and `depth` is bounded by `MAXWLEN`, so no overflow.\n\n- `fword` is passed in and used as input. It is not modified in a way that overwrites beyond its bounds.\n\n- `stack` is of size `MAXWLEN`, and `depth` is managed such that it never exceeds `MAXWLEN - 1`. The loop condition is `depth >= 0`, and `depth` is only decremented when going back up.\n\nAll array accesses are bounded by `MAXWLEN` or by the actual length of the data being copied. No unchecked `strcpy`, `strcat`, or `sprintf` without length limits are used.\n\n---\n\n### Step 3: Check for integer overflows or underflows\n\n- `sp->ts_curi` is incremented and used as an index into `byts` and `idxs`. The loop condition `sp->ts_curi > byts[arridx]` ensures it doesn't exceed the node size.\n- `sp->ts_fidx` is incremented and used to index `fword`. It is bounded by `su->su_badlen`, and the function checks `fword[sp->ts_fidx] == NUL` before accessing.\n- `repextra` tracks extra bytes from REP replacements. It is updated with `tl - fl`, but only when `fl != tl`. The value is used to adjust `sp->ts_fidx - repextra`, but since `repextra` is only used in a subtraction and the function checks bounds, no underflow occurs.\n\nNo integer overflows or underflows are evident.\n\n---\n\n### Step 4: Check for use of unsafe functions\n\n- `STRCPY`, `STRCAT`, `vim_strncpy`, `mch_memmove`, `STRMOVE`, `sprintf` are used.\n  - `sprintf` is used only in `#ifdef DEBUG_TRIEWALK`, and the format string is fixed (`\"%.*s-%s: ...\"`), with `sp->ts_twordlen` and `fword + sp->ts_fidx` as inputs. The `.*` ensures no buffer overflow.\n  - `STRMOVE` and `mch_memmove` are safe as long as the source and destination don't overlap incorrectly, but the code uses them carefully (e.g., `STRMOVE(p + tl, p + fl)` \u2014 this is safe if `tl >= fl`, which is true when `tl > fl`).\n  - `vim_strncpy` is used with a length limit, so safe.\n\nNo unsafe string functions are used without bounds checking.\n\n---\n\n### Step 5: Check for logic errors that could lead to memory corruption\n\n- The function uses a manual stack (`stack[MAXWLEN]`) and manages `depth` carefully. It never accesses `stack[depth]` when `depth >= MAXWLEN` because the loop condition is `depth >= 0` and `depth` is only incremented when `depth < MAXWLEN - 1`.\n- The `switch` statement handles all states correctly, and `sp` is always a valid pointer into `stack`.\n- The `PROF_STORE` macro is used for profiling, but it doesn't affect memory safety.\n- `ui_breakcheck()` and `profile_passed_limit()` are called periodically to check for interrupts or timeouts \u2014 safe.\n\nNo logic errors that could lead to memory corruption.\n\n---\n\n### Step 6: Check for potential injection or code execution\n\nThis is a C function that performs string manipulation and trie traversal. It does not:\n- Execute user input as code.\n- Use `system()`, `exec()`, or dynamic loading.\n- Format strings with user input.\n\nNo code injection or execution vulnerabilities.\n\n---\n\n### Step 7: Final assessment\n\nThe code:\n- Uses fixed-size buffers with proper bounds checking.\n- Avoids unsafe string functions.\n- Manages stack depth and indices carefully.\n- Does not perform unchecked memory operations.\n- Is part of a well-established spell-checking system (Vim) that has been audited for years.\n\nNo security vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 195665, "project": "njs", "commit_id": "2e00e95473861846aa8538be87db07699d9f676d", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/2e00e95473861846aa8538be87db07699d9f676d", "commit_message": "Fixed Array.prototype.slice() with slow \"this\" argument.\n\nPreviously, when \"this\" argument was not a fast array, but the \"deleted\" array\nwas a fast array, the \"deleted\" array may be left in uninitialized state if\n\"this\" argument had gaps.\n\nThis fix is to ensure that \"deleted\" is properly initialized.\n\nThis fixes #485 issue on Github.", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-29779", "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_value_own_enumerate at src/njs_value.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - This is a JavaScript engine function `njs_array_prototype_splice` implementing the `Array.prototype.splice` method.\n   - It modifies an array by removing elements and/or adding new ones at a specified index.\n   - The function takes arguments: `args`, `nargs`, and `unused`. It processes the array object (`this`), the `start` index, the number of elements to delete (`delete`), and optional new elements to insert (`items`).\n\n2. **Input Validation**:\n   - The function first checks if `this` is a valid object using `njs_value_to_object`. If not, it returns an error.\n   - It retrieves the array length using `njs_object_length`. This is safe as long as the object is an array.\n   - The `start` index is converted to an integer using `njs_value_to_integer`. This is a critical point: if the input is not a valid integer, the function returns an error. This prevents type confusion or invalid index handling.\n   - The `start` index is normalized: if negative, it's adjusted relative to the array length. This is correct behavior (e.g., -1 means last element).\n   - The `delete` count is validated: it's clamped between 0 and `length - start` using `njs_min` and `njs_max`. This prevents out-of-bounds access.\n\n3. **Length Overflow Check**:\n   - The function checks: `if (njs_slow_path((length + delta) > NJS_MAX_LENGTH))`, where `delta = items - delete`.\n   - This prevents the array from growing beyond a maximum allowed length (`NJS_MAX_LENGTH`), which is a good defense against integer overflow or denial-of-service via extremely large array sizes.\n\n4. **Memory Allocation**:\n   - A new array `deleted` is allocated with size `delete` using `njs_array_alloc`. This is safe because `delete` is bounded by `length - start`, which is at most `length`, and `length` is already validated.\n\n5. **Data Extraction (Deleted Elements)**:\n   - The function copies the elements to be deleted from the original array into the `deleted` array.\n   - For fast arrays, it uses direct memory access (`array->start[i]`), which is efficient and safe as long as bounds are respected.\n   - For non-fast arrays, it uses `njs_value_property_i64` to read each property. This is safe because the index `n` is in bounds (due to prior clamping).\n\n6. **Array Modification (Insert/Remove)**:\n   - For fast arrays:\n     - If `delta > 0`, it expands the array using `njs_array_expand` (safe, with bounds check).\n     - Then uses `njs_array_copy_within` to shift elements \u2014 this function is assumed to be safe and bounds-checked.\n     - Finally, it copies new elements using `memcpy` from `args[3]` onward. The number of elements copied is `items`, which is `nargs - 3`, and this is validated via `nargs > 2`.\n   - For non-fast arrays:\n     - Uses `njs_array_copy_within` with proper delta handling.\n     - Deletes old properties beyond the new length using `njs_value_property_i64_delete`.\n     - Inserts new elements using `njs_value_property_i64_set` \u2014 this is safe as long as the index is valid.\n     - Updates the array length using `njs_object_length_set`.\n\n7. **Return Value**:\n   - The function returns the `deleted` array as the result, which is set via `njs_set_array(&vm->retval, deleted)`.\n\n8. **Potential Vulnerabilities?**:\n   - **Bounds Checking**: All array indices are validated before use. The `start` index is clamped, `delete` is bounded, and `delta` is checked against `NJS_MAX_LENGTH`.\n   - **Memory Safety**: No use of unsafe functions like `strcpy`, `memcpy` without size checks \u2014 `memcpy` is used with `items * sizeof(njs_value_t)`, and `items` is derived from `nargs`, which is controlled by the caller but validated via `nargs > 2` and `items = nargs - 3`. Since `nargs` is passed from the VM, it's assumed to be reasonable (e.g., not huge), and `NJS_MAX_LENGTH` prevents overflow.\n   - **Type Safety**: The function uses `njs_value_t` and proper conversion functions (`njs_value_to_integer`, `njs_value_property_i64`, etc.), which are designed to handle type checks and errors.\n   - **No Direct User Input in Unsafe Contexts**: All operations are within the VM and use safe APIs.\n\n9. **Conclusion**:\n   - The code performs comprehensive input validation, bounds checking, and uses safe memory operations.\n   - There are no known buffer overflows, integer overflows, or use-after-free issues.\n   - The logic correctly implements the `splice` behavior as defined in ECMAScript.\n\n(2) NO: No security vulnerability."}
{"idx": 196276, "project": "lsquic", "commit_id": "a74702c630e108125e71898398737baec8f02238", "project_url": "https://github.com/litespeedtech/lsquic", "commit_url": "https://github.com/litespeedtech/lsquic/commit/a74702c630e108125e71898398737baec8f02238", "commit_message": "Release 3.1.0", "ground_truth": 1, "cwe": ["CWE-269"], "cve": "CVE-2022-30592", "cve_desc": "liblsquic/lsquic_qenc_hdl.c in LiteSpeed QUIC (aka LSQUIC) before 3.1.0 mishandles MAX_TABLE_CAPACITY.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `lsquic_qeh_settings` is responsible for initializing QPACK encoder settings in a QUIC implementation. It takes parameters like `max_table_size`, `dyn_table_size`, `max_risked_streams`, and `server` flag.\n\n2. The function first checks if settings have already been set by verifying the `QEH_HAVE_SETTINGS` flag. If already set, it logs a warning and returns -1. This prevents reinitialization, which is a good defensive practice.\n\n3. It sets up encoding options (`enc_opts`) based on whether the encoder is in server mode. The `LSQPACK_ENC_OPT_STAGE_2` flag is always set, and the server flag is conditionally added. This is a valid configuration pattern.\n\n4. The function calls `lsqpack_enc_init()` to initialize the encoder. The parameters passed include:\n   - A pointer to the encoder context\n   - Connection context (`qeh->qeh_conn`)\n   - `max_table_size`, `dyn_table_size`, `max_risked_streams` \u2014 these are user-provided values\n   - `enc_opts` \u2014 derived from the server flag\n   - `qeh->qeh_tsu_buf` \u2014 a buffer for temporary storage\n   - `&qeh->qeh_tsu_sz` \u2014 a pointer to the size of the buffer\n\n5. The function checks the return value of `lsqpack_enc_init()`. If it fails, it logs an error and returns -1. This is proper error handling.\n\n6. The buffer size `qeh->qeh_tsu_sz` is used as an input/output parameter. The function sets it to `sizeof(qeh->qeh_tsu_buf)` before calling `lsqpack_enc_init()`, and then the function updates it to reflect how much space was actually used. This is a common pattern in encoder/decoder APIs.\n\n7. The function then updates `qeh->qeh_flags` to mark settings as initialized, and computes the maximum header block prefix size using `lsqpack_enc_header_block_prefix_size()`. This is used for header compression.\n\n8. The function logs debug information about the settings, which is safe and non-sensitive.\n\n9. If `qeh->qeh_enc_sm_out` is non-null, it calls `qeh_begin_out()`, which likely starts output processing.\n\n10. The function returns 0 on success.\n\nNow, let's assess for security vulnerabilities:\n\n- Input validation: The function does not validate the values of `max_table_size`, `dyn_table_size`, or `max_risked_streams`. However, these are passed directly to `lsqpack_enc_init()`, which is expected to validate them internally. In the absence of evidence that `lsqpack_enc_init()` performs bounds checking, this could be a concern.\n\n- Buffer handling: The buffer `qeh->qeh_tsu_buf` is used with `sizeof(qeh->qeh_tsu_buf)` as the initial size. The function passes this to `lsqpack_enc_init()`, which may write into it. However, the function does not check whether the buffer is large enough for the encoder's needs. If `lsqpack_enc_init()` writes more than `sizeof(qeh->qeh_tsu_buf)` bytes, it could cause a buffer overflow.\n\n- Critical point: The function sets `qeh->qeh_tsu_sz = sizeof(qeh->qeh_tsu_buf)` before calling `lsqpack_enc_init()`, and then `lsqpack_enc_init()` updates `qeh->qeh_tsu_sz` to reflect the actual size used. But if the encoder needs more space than the buffer provides, and the function does not validate that the returned size is within bounds, this could lead to a buffer overflow.\n\n- However, the function does not perform any bounds checking on the output size returned by `lsqpack_enc_init()`. If the encoder requires more space than `qeh->qeh_tsu_buf` can hold, and the function does not verify that `qeh->qeh_tsu_sz` is less than or equal to `sizeof(qeh->qeh_tsu_buf)`, then a buffer overflow could occur.\n\n- But note: `lsqpack_enc_init()` is expected to be a trusted library function. If it is well-designed, it should not write beyond the provided buffer size. However, the function does not validate the return value of `qeh->qeh_tsu_sz` against the buffer size. This is a potential issue.\n\n- The function does not perform any input validation on the `max_table_size`, `dyn_table_size`, or `max_risked_streams` parameters. If these values are extremely large (e.g., near UINT_MAX), they could cause integer overflows or excessive memory allocation in `lsqpack_enc_init()`. But again, this depends on the implementation of `lsqpack_enc_init()`.\n\n- However, in the absence of evidence that `lsqpack_enc_init()` performs proper bounds checking and input validation, and since the function does not validate the output size against the buffer size, there is a risk of buffer overflow.\n\n- But wait: the function passes `qeh->qeh_tsu_buf` and `&qeh->qeh_tsu_sz` to `lsqpack_enc_init()`. The `qeh->qeh_tsu_sz` is initialized to `sizeof(qeh->qeh_tsu_buf)`, and `lsqpack_enc_init()` is expected to update it to the actual size used. If `lsqpack_enc_init()` is designed to not write beyond the buffer, and the buffer is large enough, then it's safe. But if the encoder needs more space, and the function does not check that `qeh->qeh_tsu_sz` is within bounds, then it could be a problem.\n\n- However, the function does not use the buffer after initialization in a way that could overflow it. The buffer is only used internally by the encoder. The real risk is if `lsqpack_enc_init()` writes beyond the buffer, which would be a bug in that function, not this one.\n\n- But the function does not validate that `qeh->qeh_tsu_sz` after the call is less than or equal to `sizeof(qeh->qeh_tsu_buf)`. This is a missing check. If `lsqpack_enc_init()` were to write more than the buffer size, this would be a buffer overflow.\n\n- Therefore, the function has a potential vulnerability: it does not validate that the encoder did not write beyond the buffer.\n\n- This is a critical issue: if `lsqpack_enc_init()` writes more than `sizeof(qeh->qeh_tsu_buf)` bytes, and the function does not check `qeh->qeh_tsu_sz` against the buffer size, then a buffer overflow occurs.\n\n- Since the function does not perform this check, and the buffer is fixed-size, this is a security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 208505, "project": "tor", "commit_id": "57e35ad3d91724882c345ac709666a551a977f0f", "project_url": "https://github.com/torproject/tor", "commit_url": "https://gitweb.torproject.org/tor.git/commitdiff/57e35ad3d91724882c345ac709666a551a977f0f", "commit_message": "Avoid possible segfault when handling networkstatus vote with bad flavor\n\nFix for 6530; fix on 0.2.2.6-alpha.", "ground_truth": 1, "cwe": ["CWE-399"], "cve": "CVE-2012-3517", "cve_desc": "Use-after-free vulnerability in dns.c in Tor before 0.2.2.38 might allow remote attackers to cause a denial of service (daemon crash) via vectors related to failed DNS requests.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there are any security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Parsing\nThe function `networkstatus_parse_vote_from_string` parses a string representing a Tor network status vote (v3 format). It uses several helper functions like `tokenize_string`, `find_by_keyword`, `parse_iso_time`, `tor_parse_long`, and `base16_decode`.\n\n- The input string `s` is validated with `tor_assert(s)` \u2014 this ensures non-null input.\n- The function uses `smartlist_t` and `memarea_t` for memory management, which helps prevent memory leaks and is a good practice in Tor codebase.\n- All string parsing (e.g., IP addresses via `tor_inet_aton`, digests via `base16_decode`) includes error checks and logs warnings on failure.\n\n---\n\n### Step 2: Buffer and Memory Safety\n- **Fixed-size buffers**: The code uses `char declared_identity[DIGEST_LEN];` and `char id_hexdigest[HEX_DIGEST_LEN + 1];` \u2014 these are fixed-size and properly sized (e.g., `DIGEST_LEN` is 20 for SHA1, `HEX_DIGEST_LEN` is 40). These are safe.\n- **Use of `base16_decode`**: This function is called with known lengths (`HEX_DIGEST_LEN`) and checks return value. It does not write beyond buffer bounds.\n- **Use of `tor_strdup`**: All string copies are done via `tor_strdup`, which allocates memory safely and is used consistently.\n- **Use of `tor_memdup` and `memcpy`**: These are used with known sizes and validated inputs (e.g., `tok->object_size` is checked before use).\n- **Use of `smartlist_add`**: All additions to smartlists are done with dynamically allocated strings or structs, and cleanup is handled in the `err` and `done` blocks.\n\n---\n\n### Step 3: Integer and Range Validation\n- The function uses `tor_parse_long` with strict bounds checking:\n  - `tor_parse_long(..., 10, 0, INT_MAX, &ok, NULL)` \u2014 ensures values are non-negative and within valid integer range.\n  - `tor_parse_long(..., 10, INT32_MIN, INT32_MAX, &ok, NULL)` \u2014 ensures 32-bit signed integer bounds.\n- These checks prevent integer overflow and underflow.\n- The code also checks for `tok->n_args` before accessing `tok->args[i]`, avoiding out-of-bounds access.\n\n---\n\n### Step 4: String and Token Processing\n- `tokenize_string` is used to split the input into tokens. It uses `memarea_t` to manage memory, which is safe and avoids heap fragmentation.\n- The code checks for malformed tokens (e.g., missing `=` in `params`, invalid digest format) and logs warnings, then jumps to `err`.\n- The `SMARTLIST_FOREACH` loops are used safely with proper bounds checks.\n\n---\n\n### Step 5: Signature and Cryptographic Validation\n- The function validates signatures carefully:\n  - Checks `object_type` and `object_size` (ensures it's not too large: `<= 512`).\n  - Validates digest format (hex, correct length).\n  - Uses `tor_memneq` for secure comparison of digests.\n  - For non-consensus votes, it verifies the signature using `check_signature_token` \u2014 this is a critical security check.\n  - For consensus, it stores the raw signature data safely with `tor_memdup` and checks size limits.\n- It prevents duplicate signatures from the same voter and same algorithm, which is a good defense against replay attacks.\n\n---\n\n### Step 6: Order and Consistency Checks\n- The code checks that `known-flags` and `params` are in lexicographic order \u2014 this prevents malformed or maliciously ordered data from being accepted.\n- It checks that routerstatus entries are sorted by identity digest \u2014 prevents potential logic issues.\n\n---\n\n### Step 7: Error Handling and Cleanup\n- The function uses a `goto err` pattern with proper cleanup in the `err` and `done` blocks.\n- All allocated memory (via `tor_malloc`, `tor_strdup`, `memarea_new`, etc.) is freed in the cleanup section.\n- `dump_desc` and `DUMP_AREA` are used for debugging, but they don\u2019t affect security.\n\n---\n\n### Step 8: Potential Issues?\nLet\u2019s look for any red flags:\n- **No buffer overflows**: All string operations use fixed-size buffers or validated lengths.\n- **No format string vulnerabilities**: No `printf`-style functions with user-controlled format strings.\n- **No unsafe memory copying**: All `memcpy` and `strcpy`-like operations are bounded.\n- **No use of `strcat`, `strcpy`, `gets`**: These are avoided.\n- **No unsafe casting**: All casts are safe (e.g., `int` to `uint16_t` with bounds check).\n- **No race conditions**: This is a single-threaded parsing function.\n\n---\n\n### Conclusion\nThe code is well-structured, uses safe memory management, performs rigorous input validation, checks bounds, validates cryptographic data, and handles errors properly. It follows Tor\u2019s security best practices.\n\nThere are **no detectable security vulnerabilities** in this code.\n\n(2) NO: No security vulnerability."}
{"idx": 207461, "project": "autotrace", "commit_id": "e96bffadc25ff0ba0e10745f8012efcc5f920ea9", "project_url": "https://github.com/autotrace/autotrace", "commit_url": "https://github.com/autotrace/autotrace/commit/e96bffadc25ff0ba0e10745f8012efcc5f920ea9", "commit_message": "input-bmp: Increase header buffer in some cases\n\nSigned-off-by: Peter Lemenkov <lemenkov@gmail.com>", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-32323", "cve_desc": "AutoTrace v0.40.0 was discovered to contain a heap overflow via the ReadImage function at input-bmp.c:660.", "vuln": 1, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: File Handling and Input Validation\n- The function opens a file using `fopen(filename, \"rb\")` \u2014 this is safe as long as the filename is validated.\n- The code checks if `fd` is null, and if so, logs an error and calls `at_exception_fatal`. This prevents use of an invalid file descriptor.\n\n\u2705 No immediate vulnerability here.\n\n---\n\n### Step 2: Magic Number Check\n- The code reads the first 2 bytes (`magick`) and checks if they are one of: \"BA\", \"BM\", \"IC\", \"PT\", \"CI\", \"CP\".\n- This is a standard way to validate file type (BMP format).\n- The check uses `strncmp` with `!` (logical NOT), which is correct: `!strncmp(...)` means \"match exactly\".\n\n\u2705 This is a proper file signature check.\n\n---\n\n### Step 3: Loop for \"BA\" Signature\n- There's a `while (!strncmp(magick, \"BA\", 2))` loop that reads 12 bytes and then updates `magick`.\n- This is likely handling a \"BMP\" file with a \"BA\" header (possibly a legacy or extended format).\n- The loop continues until the magic is no longer \"BA\", which is acceptable for nested or extended headers.\n\n\u26a0\ufe0f However, **there is no limit on the number of iterations** of this loop. If the file contains many \"BA\" headers (e.g., maliciously crafted), this could lead to:\n- Infinite loop (if the file never stops with \"BA\")\n- Excessive memory or CPU usage (denial of service)\n\nBut note: `ReadOK(fd, buffer, 12)` and `ReadOK(fd, magick, 2)` are called inside the loop. If the file is truncated or malformed, these will fail and exit via `goto cleanup`.\n\nStill, **if the file is crafted to have many \"BA\" headers (e.g., 1000+), the loop could consume excessive time and memory**.\n\nThis is a **potential denial-of-service (DoS) vulnerability** due to unbounded loop on untrusted input.\n\n---\n\n### Step 4: Reading BMP Headers\n- The code reads various header fields using `ReadOK` and converts them with `ToL`/`ToS` (likely little-endian conversion).\n- It handles multiple BMP header sizes: 12, 40, 56\u201364, 108, 124.\n- Each case reads a variable amount of data based on `biSize`.\n\n\u26a0\ufe0f **Critical issue: The code uses `Bitmap_File_Head.biSize` to determine how much data to read**:\n```c\nif (!ReadOK(fd, buffer, Bitmap_File_Head.biSize - 4))\n```\n- `Bitmap_File_Head.biSize` is read from the file (untrusted input).\n- If an attacker sets `biSize` to a very large value (e.g., 0xFFFFFFFF), then `Bitmap_File_Head.biSize - 4` becomes a large number (e.g., 0xFFFFFFFB), which could cause:\n  - `ReadOK` to try to read a huge amount of data (e.g., 4GB+), leading to:\n    - Memory exhaustion\n    - Denial of Service (DoS)\n    - Potential integer overflow in `ReadOK` if it uses `size_t` or `int`\n\nEven though the code later checks for `biSize >= 56 && biSize <= 64`, it **does not validate that `biSize` is within a reasonable range before using it in `ReadOK`**.\n\nFor example:\n```c\nif (Bitmap_File_Head.biSize == 108 || Bitmap_File_Head.biSize == 124)\n{\n    if (!ReadOK(fd, buffer, Bitmap_File_Head.biSize - 4)) // \u2190 Vulnerable!\n```\nIf `biSize` is 0x100000000 (4GB), this will cause a huge read request.\n\n\u2705 The code does validate `biSize` later (e.g., only 12, 40, 56\u201364, 108, 124 are accepted), but **the read happens before the validation**.\n\nThis is a **critical flaw**: the code uses untrusted input (`biSize`) to determine how much to read, **before validating it**.\n\nThis is a classic **integer overflow / out-of-bounds read vulnerability** that can lead to DoS or memory corruption.\n\n---\n\n### Step 5: Integer Overflow Protection\n- The code includes a check to prevent integer overflow:\n```c\nif (((unsigned long)Bitmap_Head.biWidth) > (unsigned int)0x7fffffff / Bitmap_Head.biBitCnt ||\n    ((unsigned long)Bitmap_Head.biWidth) > ((unsigned int)0x7fffffff /abs(Bitmap_Head.biHeight)) / 4)\n```\n- This is a good attempt to prevent overflow in `width * bitcount` calculations.\n\nBut note: `abs(Bitmap_Head.biHeight)` is used \u2014 but `biHeight` can be negative (as per BMP spec), so this is correct.\n\nHowever, **this check is applied after the `rowbytes` calculation**, and **before the actual image data is read**.\n\nBut the **real problem is that the `biSize` field is used to determine how much to read, and it's not validated before that**.\n\n---\n\n### Step 6: Rowbytes Calculation\n```c\nrowbytes = ((Bitmap_Head.biWidth * Bitmap_Head.biBitCnt - 1) / 32) * 4 + 4;\n```\n- This is a standard formula for BMP row padding.\n- But if `biWidth` or `biBitCnt` are huge, this can overflow.\n\nThe code does **not** validate `biWidth` or `biBitCnt` before this calculation.\n\nEven though there is a later check:\n```c\nif (((unsigned long)Bitmap_Head.biWidth) > (unsigned int)0x7fffffff / Bitmap_Head.biBitCnt || ...)\n```\nThis check is **after** the `rowbytes` calculation.\n\nSo if `biWidth` is large, `rowbytes` could overflow **before** the check.\n\nFor example:\n- `biWidth = 0x10000000`, `biBitCnt = 32`\n- `biWidth * biBitCnt = 0x400000000` \u2192 2^34 \u2192 overflow on 32-bit systems\n- This leads to undefined behavior (wraparound)\n\nThis is a **buffer overflow or memory corruption risk**.\n\n---\n\n### Step 7: Color Map and Image Data Reading\n- `ReadColorMap` and `ReadImage` are called with values derived from untrusted input.\n- `ReadImage` uses `rowbytes`, `biWidth`, `biHeight`, etc. \u2014 all of which are untrusted.\n\nIf `rowbytes` is miscalculated due to overflow, `ReadImage` may read too much data or too little, leading to:\n- Buffer overflow\n- Memory corruption\n- Crash\n\n---\n\n### Step 8: Final Cleanup\n- `fclose(fd)` is called in `cleanup`, which is safe.\n\n---\n\n### Summary of Vulnerabilities\n\n| Issue | Severity | Type |\n|------|----------|------|\n| `biSize` used in `ReadOK` before validation | High | Integer overflow / DoS |\n| `rowbytes` calculated before overflow checks | High | Integer overflow |\n| Unbounded loop on \"BA\" headers | Medium | DoS |\n| No bounds check on `biWidth`, `biHeight`, `biBitCnt` before use | High | Integer overflow |\n\n---\n\n### Conclusion\n\nThe code **fails to validate critical fields (`biSize`, `biWidth`, `biBitCnt`) before using them in memory allocation or read operations**. This allows an attacker to craft a BMP file with malicious values that cause:\n- Integer overflows\n- Excessive memory allocation\n- Denial of Service (DoS)\n- Potential memory corruption\n\nThis is a **serious security vulnerability**.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195308, "project": "flatpak", "commit_id": "462fca2c666e0cd2b60d6d2593a7216a83047aaf", "project_url": "https://github.com/flatpak/flatpak", "commit_url": "https://github.com/flatpak/flatpak/commit/462fca2c666e0cd2b60d6d2593a7216a83047aaf", "commit_message": "run: Don't allow chroot()\n\nIf we don't allow pivot_root() then there seems no reason why we should\nallow chroot().\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2021-41133", "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Purpose of the function**:  \n   The function `setup_seccomp` sets up a seccomp filter for a sandboxed environment (Flatpak's bubblewrap). It uses the libseccomp library to block dangerous system calls and restrict socket families based on runtime flags.\n\n2. **Seccomp Rule Setup**:  \n   - The code defines two main syscall blocklists: `syscall_blocklist` and `syscall_nondevel_blocklist`.  \n   - It blocks a wide range of potentially dangerous syscalls such as `mount`, `unshare`, `setns`, `clone`, `ptrace`, `perf_event_open`, `personality`, `keyctl`, `quotactl`, `modify_ldt`, and others.  \n   - These are all known to be used in privilege escalation, information disclosure, or sandbox escape attacks.  \n   - The use of `SCMP_ACT_ERRNO` with `EPERM` or `ENOSYS` ensures that blocked syscalls return an error, preventing execution.\n\n3. **Architecture Handling**:  \n   - The code adds the requested architecture (e.g., x86_64, aarch64) to the seccomp filter using `seccomp_arch_add`.  \n   - It also adds extra architectures for multiarch support (e.g., x86_64 extra arches).  \n   - This is done carefully, with error checking and handling of `EEXIST` (which is expected if the arch is already present).  \n   - The comment notes that it adds the target arch instead of replacing the native one, which is a known limitation but not a vulnerability in this context.\n\n4. **Socket Family Filtering**:  \n   - The code defines an allowlist of socket families (AF_LOCAL, AF_INET, AF_INET6, AF_NETLINK, etc.).  \n   - It uses `seccomp_rule_add_exact` to block all socket families not in the allowlist.  \n   - It handles gaps between allowed families by blocking intermediate ones.  \n   - The final rule blocks all families >= `last_allowed_family + 1`.  \n   - This is a correct and secure way to restrict socket usage.\n\n5. **Use of `seccomp_rule_add_exact`**:  \n   - The code uses `seccomp_rule_add_exact` for socket filtering to avoid libseccomp's default behavior (which might not be safe).  \n   - This is explicitly mentioned as necessary due to a known libseccomp issue.  \n   - This is a correct and defensive practice.\n\n6. **Error Handling and Input Validation**:  \n   - The function checks for null pointers, validates `run_flags`, and uses `g_return_val_if_fail` to ensure `errnum` is `EPERM` or `ENOSYS`.  \n   - It returns meaningful error messages via `flatpak_fail_error` on failure.  \n   - All `seccomp_rule_add` calls are checked for failure, and `EFAULT` (unknown syscall) is handled appropriately.\n\n7. **Security Best Practices**:  \n   - The blocklist is derived from well-known secure practices (Sandstorm, linux-user-chroot, systemd, Docker).  \n   - The code includes comments encouraging collaboration with other sandbox maintainers, indicating awareness of security best practices.  \n   - The use of `__attribute__((cleanup(cleanup_seccomp)))` ensures proper cleanup of the seccomp context.  \n   - The BPF filter is exported to a temporary file and passed to bubblewrap via `--seccomp`, which is the correct way to apply seccomp filters.\n\n8. **No Obvious Vulnerabilities**:  \n   - No buffer overflows, use-after-free, or unsafe string operations.  \n   - No direct user input manipulation without validation.  \n   - All syscalls are blocked with proper error codes.  \n   - The allowlist for socket families is strict and correctly implemented.  \n   - The code avoids dangerous operations like `execve` or `mmap` in the blocklist, which would be a red flag.\n\nConclusion: The code implements a robust, well-structured seccomp filter with proper error handling, architecture support, and secure filtering of syscalls and socket families. It follows security best practices and is consistent with known secure sandboxing patterns.\n\n(2) NO: No security vulnerability."}
{"idx": 210284, "project": "dpdk", "commit_id": "af74f7db384ed149fe42b21dbd7975f8a54ef227", "project_url": "https://github.com/DPDK/dpdk", "commit_url": "https://github.com/DPDK/dpdk/commit/af74f7db384ed149fe42b21dbd7975f8a54ef227", "commit_message": "vhost: fix FD leak with inflight messages\n\nEven if unlikely, a buggy vhost-user master might attach fds to inflight\nmessages. Add checks like for other types of vhost-user messages.\n\nFixes: d87f1a1cb7b6 (\"vhost: support inflight info sharing\")\nCc: stable@dpdk.org\n\nSigned-off-by: David Marchand <david.marchand@redhat.com>\nReviewed-by: Maxime Coquelin <maxime.coquelin@redhat.com>", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-0669", "cve_desc": "A flaw was found in dpdk. This flaw allows a malicious vhost-user master to attach an unexpected number of fds as ancillary data to VHOST_USER_GET_INFLIGHT_FD / VHOST_USER_SET_INFLIGHT_FD messages that are not closed by the vhost-user slave. By sending such messages continuously, the vhost-user master exhausts available fd in the vhost-user slave process, leading to a denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function starts by checking the size of the incoming message: `if (ctx->msg.size != sizeof(ctx->msg.payload.inflight))`. This ensures that the message has the expected size, preventing potential buffer overflows or malformed message handling.\n   - This is a good security practice and prevents issues due to unexpected message formats.\n\n2. **NUMA Node Assignment**:\n   - The code attempts to reuse the NUMA node from the first virtqueue if it exists. This is a performance optimization and does not introduce a security risk.\n\n3. **Memory Allocation for `inflight_info`**:\n   - `dev->inflight_info` is allocated using `rte_zmalloc_socket`, which is a safe memory allocation function in DPDK. It is zero-initialized and uses the specified NUMA node.\n   - If allocation fails, an error is logged and the function returns early. This prevents use-after-free or uninitialized memory access.\n\n4. **Memory Mapping and File Descriptor Handling**:\n   - The function calls `inflight_mem_alloc` to allocate shared memory (`mmap_size`) and returns a file descriptor (`fd`) for the memory region.\n   - The function checks if `addr` is NULL. If not, it proceeds to zero-initialize the memory with `memset(addr, 0, mmap_size)`. This ensures that no stale data is present in the shared memory region.\n\n5. **Cleanup of Previous Resources**:\n   - Before assigning new values, the function checks if `dev->inflight_info->addr` is non-NULL and calls `munmap` to release the old memory.\n   - Similarly, if `dev->inflight_info->fd >= 0`, it closes the old file descriptor.\n   - This prevents resource leaks and ensures that old mappings are properly cleaned up.\n\n6. **Assignment of New Values**:\n   - The new `addr`, `size`, `fd`, and `mmap_offset` are assigned to `dev->inflight_info` and the response payload (`ctx->msg.payload.inflight`).\n   - The `ctx->fd_num = 1` indicates that one file descriptor is being sent back to the guest.\n\n7. **Initialization of Shared Memory (Packed Queue Case)**:\n   - If the virtqueue is packed, the function initializes the `rte_vhost_inflight_info_packed` structure:\n     - `used_wrap_counter` and `old_used_wrap_counter` are set to 1.\n     - A ring-like structure is initialized: `desc[j].next = j + 1` for each descriptor.\n   - This is a valid initialization pattern for a ring buffer and does not involve unbounded loops or unsafe indexing.\n\n8. **Logging and Return**:\n   - The function logs the `mmap_size`, `mmap_offset`, and `fd` for debugging purposes.\n   - It returns `RTE_VHOST_MSG_RESULT_REPLY`, indicating a successful response.\n\n9. **Potential Security Concerns**:\n   - **Untrusted Input**: The `num_queues` and `queue_size` come from the message payload (`ctx->msg.payload.inflight`). These values are used to compute `mmap_size = num_queues * pervq_inflight_size`.\n     - However, `pervq_inflight_size` is derived from `get_pervq_shm_size_packed` or `get_pervq_shm_size_split`, which are likely bounded functions based on `queue_size`.\n     - The `queue_size` is assumed to be reasonable (e.g., not extremely large), and since `get_pervq_shm_size_*` functions are likely bounded (e.g., based on known queue size limits), the total `mmap_size` is unlikely to be exploitable.\n     - There is no explicit check for integer overflow in `num_queues * pervq_inflight_size`, but in practice, `num_queues` is typically small (e.g., \u2264 16), and `pervq_inflight_size` is proportional to `queue_size`, which is also bounded by the device configuration.\n     - However, if `num_queues` or `queue_size` were maliciously large, this could lead to a large memory allocation or integer overflow.\n     - But note: `ctx->msg.payload.inflight.num_queues` and `queue_size` are read from a message that was already validated for size (`sizeof(ctx->msg.payload.inflight)`), and the fields are likely defined as `uint16_t` or similar. This limits their maximum values (e.g., 65535), and even multiplied, the result is bounded by DPDK's memory limits.\n     - Furthermore, `inflight_mem_alloc` likely checks for valid size and returns NULL on failure, which is handled correctly.\n\n10. **File Descriptor Handling**:\n    - The file descriptor `fd` is obtained from `inflight_mem_alloc` and assigned to `ctx->fds[0]`.\n    - The function ensures that old file descriptors are closed and memory is unmapped before reuse.\n    - No file descriptor leak occurs.\n\n11. **No Use of Untrusted Data in Unsafe Functions**:\n    - There is no use of `strcpy`, `sprintf`, `strcat`, or similar unsafe string functions.\n    - No direct use of user input in system calls without validation.\n    - The only data from the guest is used in bounded arithmetic and memory allocation, which is handled safely.\n\nConclusion:\n- The code performs proper input validation.\n- It handles memory and file descriptor lifecycle correctly.\n- It avoids common vulnerabilities like buffer overflows, use-after-free, or resource leaks.\n- While there is a theoretical risk of integer overflow in `mmap_size = num_queues * pervq_inflight_size`, the data types and context (DPDK, virtio, known limits) make this highly unlikely to be exploitable in practice.\n- The code follows safe patterns and includes defensive programming.\n\n(2) NO: No security vulnerability."}
{"idx": 216126, "project": "openssl", "commit_id": "cca1cd9a3447dd067503e4a85ebd1679ee78a48e", "project_url": "https://github.com/openssl/openssl", "commit_url": "https://github.com/openssl/openssl/commit/cca1cd9a3447dd067503e4a85ebd1679ee78a48e", "commit_message": "Submitted by: Tomas Hoger <thoger@redhat.com>\n\nFix for CVE-2010-0433 where some kerberos enabled versions of OpenSSL\ncould be crashed if the relevant tables were not present (e.g. chrooted).", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2010-0433", "cve_desc": "The kssl_keytab_is_available function in ssl/kssl.c in OpenSSL before 0.9.8n, when Kerberos is enabled but Kerberos configuration files cannot be opened, does not check a certain return value, which allows remote attackers to cause a denial of service (NULL pointer dereference and daemon crash) via SSL cipher negotiation, as demonstrated by a chroot installation of Dovecot or stunnel without Kerberos configuration files inside the chroot.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `kssl_keytab_is_available` checks whether a Kerberos keytab is available and contains a specific service principal entry.\n\n2. It initializes a Kerberos context using `krb5_init_context`, which is correct and safe.\n\n3. It determines which keytab to use:\n   - If `kssl_ctx->keytab_file` is provided, it uses `krb5_kt_resolve` to open that specific keytab.\n   - Otherwise, it uses `krb5_kt_default` to get the default keytab.\n   Both functions are part of the MIT Kerberos library and are designed to safely resolve keytab locations.\n\n4. It constructs a principal name using `krb5_sname_to_principal`, which takes the service name (from `kssl_ctx->service_name`) and the service type `KRB5_NT_SRV_HST`. This is a standard way to generate a host principal name.\n\n5. It attempts to retrieve a keytab entry using `krb5_kt_get_entry` for the constructed principal, with version number and encryption type ignored (0). This is appropriate for checking existence.\n\n6. The function checks for `KRB5_KT_NOTFOUND` \u2014 if the entry is not found, it sets `rc = 1` (meaning \"available\") and exits. Wait \u2014 this is critical: the function returns `rc = 1` when the keytab entry is *not found*, which contradicts the function name.\n\n   But let's clarify: the function is named `kssl_keytab_is_available`, and it returns 1 if the keytab is available and contains the expected entry. However, in the code:\n   - If `krb5rc == KRB5_KT_NOTFOUND`, it sets `rc = 1` and exits.\n   - But `KRB5_KT_NOTFOUND` means the entry was not found \u2014 so the keytab does *not* contain the expected entry.\n\n   This is a logic error: returning 1 (true) when the keytab does *not* contain the expected entry. This is a bug, but is it a security vulnerability?\n\n7. However, the function is not directly handling untrusted input in a way that could lead to buffer overflows, injection, or memory corruption. The inputs (`kssl_ctx->keytab_file`, `kssl_ctx->service_name`) are used in standard Kerberos library calls that are designed to be safe.\n\n8. The Kerberos library functions (`krb5_kt_resolve`, `krb5_kt_default`, `krb5_sname_to_principal`, `krb5_kt_get_entry`) are well-tested and do not perform unsafe operations like string concatenation or buffer copying without bounds checking.\n\n9. The function properly cleans up resources: it closes the keytab, frees the principal, and frees the context \u2014 even in error paths via the `exit` label.\n\n10. The only issue is a logical flaw: returning 1 (available) when the keytab entry is *not found*. This could lead to incorrect behavior (e.g., assuming a keytab is available when it isn't), but it does not lead to memory corruption, privilege escalation, or code execution.\n\n11. This is a functional bug, not a security vulnerability, because:\n   - No untrusted input is directly manipulated in a dangerous way.\n   - No unsafe functions are used.\n   - No memory safety issues are present.\n   - The logic error does not open a path for exploitation.\n\nTherefore, despite the logical flaw in the return value, there is no security vulnerability in the code as written.\n\n(2) NO: No security vulnerability."}
{"idx": 214909, "project": "linux", "commit_id": "c8c2a057fdc7de1cd16f4baa51425b932a42eb39", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/c8c2a057fdc7de1cd16f4baa51425b932a42eb39", "commit_message": "net/mlx5: prevent memory leak in mlx5_fpga_conn_create_cq\n\nIn mlx5_fpga_conn_create_cq if mlx5_vector2eqn fails the allocated\nmemory should be released.\n\nFixes: 537a50574175 (\"net/mlx5: FPGA, Add high-speed connection routines\")\nSigned-off-by: Navid Emamdoost <navid.emamdoost@gmail.com>\nSigned-off-by: Saeed Mahameed <saeedm@mellanox.com>", "ground_truth": 1, "cwe": ["CWE-401"], "cve": "CVE-2019-19045", "cve_desc": "A memory leak in the mlx5_fpga_conn_create_cq() function in drivers/net/ethernet/mellanox/mlx5/core/fpga/conn.c in the Linux kernel before 5.3.11 allows attackers to cause a denial of service (memory consumption) by triggering mlx5_vector2eqn() failures, aka CID-c8c2a057fdc7.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `mlx5_fpga_conn_create_cq` is responsible for creating a Completion Queue (CQ) in an FPGA-connected Mellanox device context.\n\n2. The function starts by setting up the CQ size using `roundup_pow_of_two(cq_size)`, which ensures the size is a power of two. This is a common and safe practice for circular buffer implementations.\n\n3. It initializes a temporary CQC (CQ Context) structure with `temp_cqc`, setting `log_cq_size` based on the rounded-up size. This is done via `MLX5_SET(cqc, temp_cqc, log_cq_size, ilog2(cq_size))`, which is correct and safe because `ilog2` of a power of two gives the correct log value.\n\n4. The `mlx5_cqwq_create` function is called to create the CQ work queue. This function is part of the Mellanox driver and is known to perform proper validation and memory allocation. If it fails, the function returns early.\n\n5. The code then initializes each CQE (Completion Queue Entry) in the WQ (Work Queue) by setting `op_own` to an invalid state. This is a standard initialization pattern to ensure no stale CQEs are processed.\n\n6. Memory for the `create_cq_in` input buffer is allocated using `kvzalloc` with `GFP_KERNEL`. This is safe and zero-initialized, which is good for security.\n\n7. The function maps the vector to an EQN (Event Queue Number) and IRQ number using `mlx5_vector2eqn`. This is a standard way to assign interrupts and is not vulnerable to input manipulation since it uses the current CPU (smp_processor_id()) and the driver's internal mapping.\n\n8. The `create_cq_in` structure is populated with:\n   - `log_cq_size` (correctly set via `ilog2`)\n   - `c_eqn` (from EQN mapping)\n   - `uar_page` (from device's UAR index)\n   - `log_page_size` (based on buffer page shift)\n   - `dbr_addr` (DMA address of doorbell)\n   - `pas` (page address list) filled via `mlx5_fill_page_frag_array`\n\n   All of these values are derived from internal device state or validated parameters. The `mlx5_fill_page_frag_array` function is part of the driver and is responsible for correctly setting up the page list for the CQ buffer.\n\n9. The `mlx5_core_create_cq` function is called with the input buffer. This is the actual hardware CQ creation call. The driver ensures that the input is properly formatted and validated before passing to the hardware.\n\n10. After successful creation, the CQ is configured with:\n    - CQE size (64 bytes)\n    - Doorbell addresses\n    - Vector, completion, and event callbacks\n    - IRQ number\n    - UAR\n    - Tasklet initialization\n\n11. The function logs the CQN (CQ Number) using `mlx5_fpga_dbg`.\n\n12. Error handling is properly implemented with `err_cqwq` label that destroys the WQ if creation fails.\n\nKey security considerations:\n- No user input is directly used in the CQ creation process. All parameters are derived from internal device state, configuration, or validated values.\n- The `create_cq_in` buffer is zero-initialized and filled with known-safe values.\n- The `mlx5_fill_page_frag_array` function is trusted and used correctly.\n- No buffer overflows or unsafe string operations are present.\n- All memory allocations are checked (`kvzalloc` and `goto` on failure).\n- The function does not perform any dynamic memory copying without bounds checking.\n\nConclusion: The code follows secure coding practices. It properly validates and initializes all data structures, uses safe memory allocation, and avoids any direct user input manipulation. The CQ creation process is well-structured and error-handled.\n\n(2) NO: No security vulnerability."}
{"idx": 205823, "project": "ovs", "commit_id": "803ed12e31b0377c37d7aa8c94b3b92f2081e349", "project_url": "https://github.com/openvswitch/ovs", "commit_url": "https://github.com/openvswitch/ovs/commit/803ed12e31b0377c37d7aa8c94b3b92f2081e349", "commit_message": "ipf: release unhandled packets from the batch\n\nSince 640d4db788ed (\"ipf: Fix a use-after-free error, ...\") the ipf\nframework unconditionally allocates a new dp_packet to track\nindividual fragments.  This prevents a use-after-free.  However, an\nadditional issue was present - even when the packet buffer is cloned,\nif the ip fragment handling code keeps it, the original buffer is\nleaked during the refill loop.  Even in the original processing code,\nthe hardcoded dnsteal branches would always leak a packet buffer from\nthe refill loop.\n\nThis can be confirmed with valgrind:\n\n==717566== 16,672 (4,480 direct, 12,192 indirect) bytes in 8 blocks are definitely lost in loss record 390 of 390\n==717566==    at 0x484086F: malloc (vg_replace_malloc.c:380)\n==717566==    by 0x537BFD: xmalloc__ (util.c:137)\n==717566==    by 0x537BFD: xmalloc (util.c:172)\n==717566==    by 0x46DDD4: dp_packet_new (dp-packet.c:153)\n==717566==    by 0x46DDD4: dp_packet_new_with_headroom (dp-packet.c:163)\n==717566==    by 0x550AA6: netdev_linux_batch_rxq_recv_sock.constprop.0 (netdev-linux.c:1262)\n==717566==    by 0x5512AF: netdev_linux_rxq_recv (netdev-linux.c:1511)\n==717566==    by 0x4AB7E0: netdev_rxq_recv (netdev.c:727)\n==717566==    by 0x47F00D: dp_netdev_process_rxq_port (dpif-netdev.c:4699)\n==717566==    by 0x47FD13: dpif_netdev_run (dpif-netdev.c:5957)\n==717566==    by 0x4331D2: type_run (ofproto-dpif.c:370)\n==717566==    by 0x41DFD8: ofproto_type_run (ofproto.c:1768)\n==717566==    by 0x40A7FB: bridge_run__ (bridge.c:3245)\n==717566==    by 0x411269: bridge_run (bridge.c:3310)\n==717566==    by 0x406E6C: main (ovs-vswitchd.c:127)\n\nThe fix is to delete the original packet when it isn't able to be\nreinserted into the packet batch.  Subsequent valgrind runs show that\nthe packets are not leaked from the batch any longer.\n\nFixes: 640d4db788ed (\"ipf: Fix a use-after-free error, and remove the 'do_not_steal' flag.\")\nFixes: 4ea96698f667 (\"Userspace datapath: Add fragmentation handling.\")\nReported-by: Wan Junjie <wanjunjie@bytedance.com>\nReported-at: https://github.com/openvswitch/ovs-issues/issues/226\nSigned-off-by: Aaron Conole <aconole@redhat.com>\nReviewed-by: David Marchand <david.marchand@redhat.com>\nTested-by: Wan Junjie <wanjunjie@bytedance.com>\nSigned-off-by: Alin-Gabriel Serdean <aserdean@ovn.org>", "ground_truth": 1, "cwe": ["CWE-401"], "cve": "CVE-2021-3905", "cve_desc": "A memory leak was found in Open vSwitch (OVS) during userspace IP fragmentation processing. An attacker could use this flaw to potentially exhaust available memory by keeping sending packet fragments.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ipf_extract_frags_from_batch` processes a batch of packets (`dp_packet_batch`) and checks whether each packet is a valid IP fragment (IPv4 or IPv6) using `ipf_is_valid_v4_frag` or `ipf_is_valid_v6_frag`.\n\n2) If the packet is a valid fragment, it acquires a mutex (`ovs_mutex_lock(&ipf->ipf_lock)`), calls `ipf_handle_frag` to process the fragment, and then conditionally calls `dp_packet_batch_refill` based on the return value of `ipf_handle_frag`.\n\n3) If the packet is not a valid fragment, it directly calls `dp_packet_batch_refill` without holding the mutex.\n\n4) The key observation is that `dp_packet_batch_refill` is called in both branches of the if-else statement, but only inside the mutex-protected block when the packet is a valid fragment.\n\n5) However, `dp_packet_batch_refill` is a function that may modify the internal state of the packet batch, such as updating pointers or indices. If this function is called outside the mutex (in the else branch), and also inside the mutex (in the if branch), but the logic is not symmetric, this could lead to race conditions.\n\n6) More critically, the function calls `dp_packet_batch_refill` unconditionally in both branches, but the mutex is only held during the `ipf_handle_frag` call and the refill in the if branch. In the else branch, `dp_packet_batch_refill` is called without the mutex.\n\n7) If `dp_packet_batch_refill` modifies shared state (e.g., batch metadata, packet pointers, or indices), and if this function is not thread-safe, then calling it from multiple threads without proper synchronization could lead to data races.\n\n8) However, the function is called within a loop (`DP_PACKET_BATCH_REFILL_FOR_EACH`) that likely runs in a single thread context (e.g., a single flow processing thread), so the risk of concurrent access is low.\n\n9) But more importantly, the function `ipf_handle_frag` may itself be responsible for handling fragment reassembly, and if it fails (returns false), the packet is refilled. The refill operation is safe only if it's not modifying shared state in a way that conflicts with other operations.\n\n10) The real issue: `dp_packet_batch_refill` is called both inside and outside the mutex. If `dp_packet_batch_refill` modifies shared state (e.g., batch metadata), and if the batch is shared across threads, then calling it without the mutex in the else branch could lead to a race condition.\n\n11) However, in typical OVS (Open vSwitch) code, `dp_packet_batch_refill` is designed to be safe in a single-threaded context, and the `DP_PACKET_BATCH_REFILL_FOR_EACH` macro is used in a single-threaded flow. Therefore, the lack of mutex around the else branch's `dp_packet_batch_refill` may not be a vulnerability if the batch is not shared across threads.\n\n12) But the function is called with `ovs_mutex_lock` only around `ipf_handle_frag`, which is a critical section. The `dp_packet_batch_refill` in the else branch is not protected, but if the batch is not shared, this is not a problem.\n\n13) However, the real vulnerability lies in the fact that `ipf_handle_frag` may fail and return false, and then the packet is refilled. But if `ipf_handle_frag` modifies state that `dp_packet_batch_refill` depends on, and if `dp_packet_batch_refill` is not reentrant or not safe to call without the mutex, then this could be a problem.\n\n14) But the more critical point: the function does not check whether `ipf_handle_frag` returns false and then refills the packet. This is correct behavior \u2014 if fragment handling fails, the packet is refilled for later processing.\n\n15) However, the mutex is held only during `ipf_handle_frag`, and `dp_packet_batch_refill` is called after the mutex is released in the if branch, but in the else branch it's called without the mutex.\n\n16) Since `dp_packet_batch_refill` is likely a lightweight operation that only updates local batch state (e.g., pointer arithmetic), and since the batch is processed in a single thread, this is not a security vulnerability.\n\n17) There is no evidence of buffer overflow, use-after-free, null pointer dereference, or any other classic vulnerability.\n\n18) The code appears to be correctly handling the packet batch and mutex usage, even if the `dp_packet_batch_refill` call in the else branch is outside the mutex.\n\n19) Given that the function is part of a single-threaded packet processing path (typical in OVS datapath), and that `dp_packet_batch_refill` is not known to be unsafe in this context, no security vulnerability is present.\n\n(2) NO: No security vulnerability."}
{"idx": 197247, "project": "tensorflow", "commit_id": "ee119d4a498979525046fba1c3dd3f13a039fbb1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ee119d4a498979525046fba1c3dd3f13a039fbb1", "commit_message": "Fix segmentation fault in shape inference logic.\n\nWhen running shape functions, some functions (such as `MutableHashTableShape`)\nproduce extra output information in the form of a `ShapeAndType` struct.  The\nshapes embedded in this struct are owned by an inference context that is\ncleaned up almost immediately; if the upstream code attempts to access this\nshape information, it can trigger a segfault.\n\n`ShapeRefiner` is mitigating this for normal output shapes by cloning them\n(and thus putting the newly created shape under ownership of an inference\ncontext that will not die), but we were not doing the same for shapes and\ntypes.  This commit fixes that by doing similar logic on output shapes and\ntypes.\n\nPiperOrigin-RevId: 384761124\nChange-Id: I07c0c42d29dfbb55bfa13ec1f09ef825fb0a1a1d", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-37690", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions when running shape functions, some functions (such as `MutableHashTableShape`) produce extra output information in the form of a `ShapeAndType` struct. The shapes embedded in this struct are owned by an inference context that is cleaned up almost immediately; if the upstream code attempts to access this shape information, it can trigger a segfault. `ShapeRefiner` is mitigating this for normal output shapes by cloning them (and thus putting the newly created shape under ownership of an inference context that will not die), but we were not doing the same for shapes and types. This commit fixes that by doing similar logic on output shapes and types. We have patched the issue in GitHub commit ee119d4a498979525046fba1c3dd3f13a039fbb1. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `InferShapesForFunctionSubNode` is part of a TensorFlow-like system for shape inference in computational graphs, specifically handling function subnodes (like `Arg` and `Retval` operations).\n\n2) The function first calls `AddNodeInternal` and retrieves a context for the node. It then checks the node type:\n   - If it's an `Arg` node (function input), it retrieves the input index from attributes.\n   - If it's a `Retval` node (function output), it retrieves the output index from attributes.\n\n3) For both node types, the code validates the index:\n   - Checks that index >= 0\n   - Checks that index < num_inputs (for Arg) or index < num_outputs (for Retval)\n   - Returns an error if invalid\n\n4) The index validation is correct and bounds-checked:\n   - For Arg: `index < 0 || outer_context->num_inputs() <= index` \u2192 ensures index is in [0, num_inputs)\n   - For Retval: `index < 0 || outer_context->num_outputs() <= index` \u2192 ensures index is in [0, num_outputs)\n\n5) The code then:\n   - For Arg: sets the output shape from the outer context's input shape (or unknown if not set)\n   - For Retval: converts the input shape from the node context to a proto, creates a new shape handle in the outer context, and sets it as the output\n\n6) The code uses `TF_RETURN_IF_ERROR` for error handling, which is safe and prevents further execution on error.\n\n7) There are no buffer overflows, use-after-free, null pointer dereferences, or unsafe memory operations.\n\n8) The index validation is correct and prevents out-of-bounds access.\n\n9) The use of `ShapeHandle`, `TensorShapeProto`, and proper context management appears safe.\n\n10) No user-controlled data is directly used in a way that could lead to memory corruption, injection, or other security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 198983, "project": "swtpm", "commit_id": "9f740868fc36761de27df3935513bdebf8852d19", "project_url": "https://github.com/stefanberger/swtpm", "commit_url": "https://github.com/stefanberger/swtpm/commit/9f740868fc36761de27df3935513bdebf8852d19", "commit_message": "swtpm: Check header size indicator against expected size (CID 375869)\n\nThis fix addresses Coverity issue CID 375869.\n\nCheck the header size indicated in the header of the state against the\nexpected size and return an error code in case the header size indicator\nis different. There was only one header size so far since blobheader was\nintroduced, so we don't need to deal with different sizes.\n\nWithout this fix a specially craft header could have cause out-of-bounds\naccesses on the byte array containing the swtpm's state.\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-23645", "cve_desc": "swtpm is a libtpms-based TPM emulator with socket, character device, and Linux CUSE interface. Versions prior to 0.5.3, 0.6.2, and 0.7.1 are vulnerable to out-of-bounds read. A specially crafted header of swtpm's state, where the blobheader's hdrsize indicator has an invalid value, may cause an out-of-bounds access when the byte array representing the state of the TPM is accessed. This will likely crash swtpm or prevent it from starting since the state cannot be understood. Users should upgrade to swtpm v0.5.3, v0.6.2, or v0.7.1 to receive a patch. There are currently no known workarounds.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `SWTPM_NVRAM_CheckHeader` is designed to validate a header in a binary blob (`data`) of size `length`. It casts the `data` pointer to a `blobheader *` type, which implies the data is expected to start with a specific header structure.\n\n2. The first check is `if (length < sizeof(bh))`. Here, `sizeof(bh)` is the size of a pointer, not the size of the `blobheader` structure. This is a critical mistake. In C, `sizeof(bh)` where `bh` is a pointer (`blobheader *`) returns the size of a pointer (typically 4 or 8 bytes), not the size of the `blobheader` struct. Therefore, this check is comparing the actual data length against a pointer size, which is almost certainly too small. For example, if the `blobheader` struct is 32 bytes, this check will pass even if `length` is only 8 bytes, leading to a buffer under-read.\n\n3. Because of this incorrect use of `sizeof(bh)` instead of `sizeof(*bh)` or `sizeof(blobheader)`, the function may proceed to access `bh->totlen`, `bh->min_version`, etc., from an incomplete or invalid memory region. This can result in reading uninitialized or arbitrary memory, potentially leading to undefined behavior, crashes, or information disclosure.\n\n4. Even though the function later checks `ntohl(bh->totlen) != length`, this check is only valid if the header is actually read correctly. But due to the earlier buffer size check being incorrect, the function may access memory beyond the provided `data` buffer, leading to a buffer over-read (a type of memory safety vulnerability).\n\n5. The use of `ntohl`, `ntohs`, and `htonl` suggests the code is handling network-byte-order data, which is correct for cross-platform compatibility. However, the fundamental issue is the incorrect size check, which undermines the entire validation.\n\n6. The function does not perform any input validation beyond this flawed check, and the incorrect `sizeof(bh)` leads to a critical security flaw: reading past the end of the buffer or accessing uninitialized memory.\n\n(1) YES: A security vulnerability detected."}
{"idx": 207990, "project": "pcre2", "commit_id": "03654e751e7f0700693526b67dfcadda6b42c9d0", "project_url": "https://github.com/PCRE2Project/pcre2", "commit_url": "https://github.com/PCRE2Project/pcre2/commit/03654e751e7f0700693526b67dfcadda6b42c9d0", "commit_message": "Fixed an issue affecting recursions in JIT", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1587", "cve_desc": "An out-of-bounds read vulnerability was discovered in the PCRE2 library in the get_recurse_data_length() function of the pcre2_jit_compile.c file. This issue affects recursions in JIT-compiled regular expressions caused by duplicate data transfers.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `get_recurse_data_length` is part of a PCRE2 (Perl Compatible Regular Expressions) compiler backend, likely used in a JIT (Just-In-Time) compilation context.\n   - It calculates the required length of private data (e.g., for recursion, control flow, capture groups, etc.) based on the compiled bytecode (`cc`), which is a sequence of opcodes.\n   - The function traverses the bytecode (`cc` to `ccend`) and accumulates a length value (`length`) based on opcode types and conditions.\n\n2. **Input Validation and Bounds Checking**:\n   - The function starts with a `while (cc < ccend)` loop, ensuring that the pointer `cc` does not go beyond the end of the bytecode.\n   - Each opcode is processed using a `switch` statement, and the `cc` pointer is advanced appropriately based on the opcode size.\n   - The `next_opcode` function is used in the `default` case, and it is asserted to return a non-NULL value, ensuring forward progress.\n   - The final `SLJIT_ASSERT(cc == ccend);` confirms that the entire bytecode was processed without overrun.\n\n3. **Use of `PRIVATE_DATA` and `GET` Macros**:\n   - `PRIVATE_DATA(cc)` is used to access private data associated with an opcode. This is a macro that likely reads a size or offset from the bytecode.\n   - `GET(cc, 1)` and `GET2(cc, 1 + LINK_SIZE)` are used to extract link sizes or other values. These are standard in PCRE2 and are designed to be safe as long as the bytecode is valid and properly formatted.\n   - The code checks `PRIVATE_DATA(cc) != 0` before using it, which prevents dereferencing null pointers.\n\n4. **Potential for Buffer Overrun or Integer Overflow**:\n   - The `length` variable is incremented based on opcode types (e.g., `length += 2`, `length++`).\n   - The `get_class_iterator_size` function is called, but it is not shown here. However, it is assumed to be safe and bounded by the input data.\n   - There is no direct use of unsafe functions like `strcpy`, `strcat`, or `memcpy` that could lead to buffer overflows.\n   - The `cc` pointer is advanced using known sizes (`LINK_SIZE`, `IMM2_SIZE`, etc.), which are constants defined in the PCRE2 codebase and are safe.\n\n5. **Use of `SLJIT_ASSERT`**:\n   - The code uses `SLJIT_ASSERT` extensively to verify assumptions (e.g., `common->control_head_ptr != 0`, `PRIVATE_DATA(cc) != 0`, `cc != NULL`).\n   - These assertions are used for debugging and internal consistency checks. In release builds, they are typically disabled, but the logic is still safe because the conditions are checked before use.\n\n6. **Security Implications**:\n   - The function does not directly handle user input. Instead, it processes compiled bytecode, which is generated from a regular expression pattern.\n   - The input to this function is assumed to be valid bytecode from a trusted source (i.e., the PCRE2 compiler itself).\n   - There is no evidence of untrusted input being processed without validation.\n   - The function does not perform any memory allocation or copying that could be exploited via integer overflow or underflow.\n   - The use of `PRIVATE_DATA` and `GET` macros is consistent with PCRE2\u2019s internal design and is not known to be vulnerable.\n\n7. **Conclusion**:\n   - The code is carefully written with bounds checking, pointer arithmetic that respects opcode sizes, and assertions to catch internal inconsistencies.\n   - There are no obvious buffer overflows, use-after-free, integer overflows, or other classic security vulnerabilities.\n   - The function operates on compiled bytecode, which is not directly user-controllable in a way that would allow exploitation.\n\n(2) NO: No security vulnerability."}
{"idx": 206417, "project": "vim", "commit_id": "0971c7a4e537ea120a6bb2195960be8d0815e97b", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/0971c7a4e537ea120a6bb2195960be8d0815e97b", "commit_message": "patch 8.2.5162: reading before the start of the line with BS in Replace mode\n\nProblem:    Reading before the start of the line with BS in Replace mode.\nSolution:   Check the cursor column is more than zero.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-2207", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `ins_bs` is part of a text editor (likely Vim or a derivative) and handles backspace operations.\n   - It manages cursor movement, deletion of characters, handling of indentation, virtual editing, undo/redo, and various editing modes (replace, visual, etc.).\n   - The function is responsible for deleting characters before the cursor based on the mode (BACKSPACE_CHAR, BACKSPACE_WORD, BACKSPACE_LINE), and it interacts with buffers, cursor positions, and undo/redo state.\n\n2. **Input Validation and Buffer Handling**:\n   - The function receives parameters: `c` (the key pressed, likely ASCII), `mode` (how to backspace), and `inserted_space_p` (a flag indicating if a space was inserted).\n   - It uses `curwin->w_cursor` to track the current cursor position (line and column).\n   - It accesses memory via `ml_get_cursor()`, `ml_get_buf()`, and `gchar_cursor()`, which are safe functions in the context of Vim\u2019s internal buffer management.\n   - The code checks for buffer emptiness (`BUFEMPTY()`), cursor position bounds, and uses `u_save()` for undo state \u2014 all standard and safe practices.\n\n3. **Memory Safety and Buffer Overflows**:\n   - The function uses `ml_get_cursor()` and `ml_get_buf()` to access line data. These are internal Vim functions that are designed to be safe and bounds-checked.\n   - There is no use of unsafe string functions like `strcpy`, `strcat`, or `sprintf` that could lead to buffer overflows.\n   - The `cpc[MAX_MCO]` array is used to store composing characters for UTF-8, but it is a fixed-size array with a reasonable limit (`MAX_MCO`), and the code only writes to it via `utfc_ptr2char`, which is safe.\n   - The `del_char(FALSE)` function is used to delete a character, and it is part of Vim\u2019s safe character deletion mechanism.\n\n4. **Use of User Input**:\n   - The only user input is the `c` parameter (the key pressed), which is used only to append to the redo buffer via `AppendCharToRedobuff(c)`. This is a standard, safe operation in Vim.\n   - The `mode` parameter is an integer that controls behavior and is validated via `can_bs()` checks, which are internal and safe.\n   - There is no direct string concatenation or dynamic command execution based on user input.\n\n5. **Potential Vulnerabilities**:\n   - **Off-by-one or bounds errors?** The code carefully checks `curwin->w_cursor.col > mincol`, `curwin->w_cursor.lnum != Insstart_orig.lnum`, and similar conditions. These are used to prevent invalid cursor movement and are well-structured.\n   - **Integer overflows?** The code uses `colnr_T`, `linenr_T`, and `int` types, but all operations are within safe ranges (e.g., `--curwin->w_cursor.lnum` only if not at the first line).\n   - **Use after free or dangling pointers?** No such issues are present. All memory access is through well-defined Vim internal APIs.\n   - **Race conditions?** This is a single-threaded function (Vim is not multi-threaded), so no race conditions.\n\n6. **Security Best Practices**:\n   - The code uses safe functions (`ml_get_cursor`, `gchar_cursor`, `del_char`, `u_save`).\n   - It validates cursor positions and buffer states before accessing data.\n   - It handles UTF-8 and combining characters correctly.\n   - It properly manages undo/redo state and cursor position.\n\n7. **Conclusion**:\n   - The function is part of a mature, well-audited codebase (Vim).\n   - It performs careful bounds checking, uses safe internal APIs, and avoids unsafe operations.\n   - There are no signs of buffer overflows, use-after-free, integer overflows, or injection vulnerabilities.\n   - The only potential concern is the use of `AppendCharToRedobuff(c)`, but this is a standard, safe operation in Vim\u2019s redo buffer system.\n\n(2) NO: No security vulnerability."}
{"idx": 195309, "project": "squid", "commit_id": "5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9", "project_url": "https://github.com/squid-cache/squid", "commit_url": "https://github.com/squid-cache/squid/commit/5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9", "commit_message": "Improve handling of Gopher responses (#1022)", "ground_truth": 1, "cwe": ["CWE-400"], "cve": "CVE-2021-46784", "cve_desc": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Buffer Management and Overflow Prevention**:\n   - The function uses `LOCAL_ARRAY(char, line, TEMP_BUF_SIZE)` and `LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE)` to allocate fixed-size buffers on the stack. These are used to hold temporary data during processing.\n   - The code checks `if (gopherState->len + llen >= TEMP_BUF_SIZE)` before copying data into `gopherState->buf`. If the buffer would overflow, it truncates the length and logs a warning. This is a defensive measure against buffer overflow.\n   - The `snprintf` calls use `TEMP_BUF_SIZE` as the buffer size, which prevents buffer overflow in those cases.\n   - The `memcpy` operations are bounded by `llen`, which is derived from `memchr` and adjusted to avoid overflow.\n\n2. **Input Validation and Parsing**:\n   - The function parses lines from `inbuf` using `memchr` to locate newline characters. It handles partial lines by copying them to `gopherState->buf` and resuming later.\n   - The parsing logic for Gopher protocol lines (e.g., extracting `gtype`, `name`, `selector`, `host`, `port`) uses `strchr` and `strtok`, but all of these are used in a controlled way with proper null-termination and bounds checking via `llen` and `TEMP_BUF_SIZE`.\n\n3. **String Escaping and Output Sanitization**:\n   - The function uses `html_quote()` to escape user-provided strings (e.g., `name`, `result`) before inserting them into HTML output. This prevents XSS by escaping special HTML characters.\n   - `rfc1738_escape_part()` and `rfc1738_escape_unescaped()` are used to escape URLs, which helps prevent injection in URLs.\n   - `xstrdup(rfc1738_escape_part(selector))` ensures that the selector is properly escaped before being used in a URL.\n\n4. **Use of `snprintf` with Size Limits**:\n   - All `snprintf` calls use `TEMP_BUF_SIZE` as the buffer size, which prevents buffer overflow in the `tmpbuf` buffer.\n   - The `outbuf.append(tmpbuf)` is safe because `tmpbuf` is properly null-terminated and bounded.\n\n5. **Memory Management**:\n   - `safe_free(escaped_selector)` is used after `xstrdup`, which is correct and prevents memory leaks.\n   - `outbuf.clean()` is called at the end, which is good practice.\n\n6. **No Direct User Input in Unsanitized Output**:\n   - All user-provided data (from `inbuf`) is processed through `html_quote`, `rfc1738_escape_part`, or similar functions before being inserted into HTML output.\n   - There is no direct use of `strcpy`, `strcat`, or `sprintf` without size limits.\n\n7. **Edge Cases**:\n   - The code handles incomplete lines by storing them in `gopherState->buf` and resuming later. This is safe because the buffer size is checked and truncated if needed.\n   - The `memset(line, '\\0', TEMP_BUF_SIZE)` is used after processing to clear the buffer, preventing information leakage.\n\n8. **No Known Vulnerabilities**:\n   - No buffer overflows, no format string vulnerabilities, no XSS due to proper escaping.\n   - All dynamic output is properly sanitized.\n\n(2) NO: No security vulnerability."}
{"idx": 195056, "project": "tensorflow", "commit_id": "8c6f391a2282684a25cbfec7687bd5d35261a209", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209", "commit_message": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check\n\nPiperOrigin-RevId: 416383645\nChange-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2022-23557", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Function Purpose**: The function `BiasAndClamp` applies a bias to each element of `array_data` using `bias_data`, then clamps the result between `clamp_min` and `clamp_max`. It is designed to handle vectorized operations using NEON intrinsics for performance on ARM architectures.\n\n2. **Input Validation**:\n   - `TFLITE_DCHECK_EQ((array_size % bias_size), 0);` ensures that `array_size` is divisible by `bias_size`. This is critical because the loop assumes that the data is processed in chunks of size `bias_size`. If this condition fails, the function will trigger a debug assertion (in debug builds), preventing undefined behavior. In release builds, this check is typically disabled, but the function relies on correct input.\n\n3. **NEON Code Path**:\n   - The NEON version uses vectorized operations (`vld1q_f32`, `vaddq_f32`, `vmaxq_f32`, `vminq_f32`, `vst1q_f32`) to process 4 floats at a time (128-bit vectors).\n   - The outer loop iterates over `array_data` in chunks of `bias_size`, and the inner loops process `bias_data` in 16-element (4x4) and 4-element blocks.\n   - The code uses `vaddq_f32` to add bias to array values, then applies `vmaxq_f32` and `vminq_f32` to clamp the values.\n   - The final scalar loop handles any remaining elements (less than 4) using `ActivationFunctionWithMinMax`.\n\n4. **Potential Issues**:\n   - **Buffer Overrun Risk?** The code uses `array_ptr += bias_size` and processes `array_ptr + i` where `i` goes up to `bias_size`. However, the outer loop condition is `array_ptr != array_end_ptr`, and `array_end_ptr = array_ptr + array_size`. Since `array_size` is a multiple of `bias_size`, and each iteration processes exactly `bias_size` elements, the loop bounds are correct.\n   - **Index Bounds**: The inner loops use `i <= bias_size - 16` and `i <= bias_size - 4`, which are safe because `bias_size` is the chunk size, and the loop only accesses `bias_data + i` up to `bias_size - 1`. The final loop handles `i < bias_size`, so no out-of-bounds access occurs.\n   - **Use of `ActivationFunctionWithMinMax`**: This function is called only in the final scalar loop. It is assumed to be safe and correctly implemented (not shown here), but if it had undefined behavior (e.g., floating-point overflow), that would be a separate issue. However, the function is not directly involved in buffer access.\n\n5. **Security Considerations**:\n   - No dynamic memory allocation or user input directly used in array indexing.\n   - All array accesses are bounded by `bias_size` and `array_size`, which are passed as parameters.\n   - The `TFLITE_DCHECK_EQ` ensures that `array_size` is a multiple of `bias_size`, preventing misalignment or overruns in the vectorized loop.\n   - The NEON intrinsics are used correctly with proper alignment (assumed by the compiler and runtime).\n   - No use of unsafe functions like `strcpy`, `sprintf`, or direct pointer arithmetic without bounds checks.\n\n6. **Conclusion**:\n   - The code is carefully written with bounds checking via `TFLITE_DCHECK_EQ`, and the loop indices are properly bounded by `bias_size` and `array_size`.\n   - The NEON vector operations are used safely, with no out-of-bounds memory access.\n   - No evidence of buffer overflow, use-after-free, or other classic security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 203902, "project": "vim", "commit_id": "4748c4bd64610cf943a431d215bb1aad51f8d0b4", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/4748c4bd64610cf943a431d215bb1aad51f8d0b4", "commit_message": "patch 8.2.4974: \":so\" command may read after end of buffer\n\nProblem:    \":so\" command may read after end of buffer.\nSolution:   Compute length of text properly.", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1769", "cve_desc": "Buffer Over-read in GitHub repository vim/vim prior to 8.2.4974.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Function Purpose**:  \n   The function `get_one_sourceline` reads a single line from a source file or buffer (used in Vim for sourcing scripts). It uses a growable array (`garray_T`) to accumulate the line content, handling different line endings (Unix, DOS, etc.) and escape sequences (like `^V`).\n\n2. **Buffer Management**:  \n   - A `garray_T` (`ga`) is initialized with a starting size of 1 and a maximum growth step of 250 (`ga_init2(&ga, 1, 250)`).  \n   - The function uses `ga_grow(&ga, 120)` to ensure space for at least 120 more characters before reading.  \n   - The buffer is grown dynamically, and the `ga` structure manages memory safely via its internal `ga_data`, `ga_len`, and `ga_maxlen` fields.\n\n3. **Input Source**:  \n   - The input comes from either a buffer (`sp->source_from_buf`) or a file (`sp->fp`).  \n   - When reading from a file, `fgets` is used:  \n     ```c\n     fgets((char *)buf + ga.ga_len, ga.ga_maxlen - ga.ga_len, sp->fp)\n     ```\n     This is **safe** because `fgets` stops reading at either:\n     - The newline character,\n     - The buffer size minus one (to leave room for null termination),\n     - Or end-of-file.\n\n     The buffer size is controlled by `ga.ga_maxlen - ga.ga_len`, which ensures that `fgets` will not write beyond the allocated space.\n\n4. **Null Termination**:  \n   After reading, the code explicitly null-terminates the buffer:\n   ```c\n   buf = (char_u *)ga.ga_data;\n   buf[ga.ga_len++] = NUL;\n   ```\n   This is done only after `ga_grow` ensures space, and `ga.ga_len` is updated correctly.\n\n5. **Line Ending Handling**:  \n   - The code handles DOS (`\\r\\n`) and Unix (`\\n`) line endings.\n   - It checks for `Ctrl_Z` (0x1A) at the end of a line in DOS mode and removes it.\n   - It also handles escaped newlines via `^V` (Control-V), which is a known Vim feature: an odd number of `^V`s before a newline means the newline is escaped and should be read as part of the line.\n\n6. **Security Considerations**:\n   - **No buffer overflow**: The use of `ga_grow` and `fgets` with size limits prevents buffer overflows.\n   - **No unsafe string functions**: The code does not use `strcpy`, `strcat`, or `sprintf` without bounds checking.\n   - **Input validation**: The function does not directly process untrusted input in a way that could lead to code execution, but it does handle line content that may come from a user-sourced file.\n   - **No injection risk**: Since this is not parsing or executing code directly (it's just reading lines), and the input is not passed to `eval` or `system`, there is no risk of command injection or code execution.\n   - **Escape handling**: The `^V` escaping is handled correctly and safely \u2014 it's a known feature of Vim's sourcing mechanism and is not exploitable in this context.\n\n7. **Memory Safety**:\n   - The `ga` structure is used correctly: `ga_grow` ensures space, `ga_len` is managed, and `vim_free` is called on `ga.ga_data` if no data was read.\n   - No memory leaks or use-after-free issues are apparent.\n\n8. **Conclusion**:  \n   The code uses safe, bounded input reading (`fgets` with size limits), dynamic buffer management via `garray_T`, and proper null termination. It handles edge cases (like line endings and escaped newlines) safely. There are no known vulnerabilities such as buffer overflows, format string issues, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 197395, "project": "tensorflow", "commit_id": "4071d8e2f6c45c1955a811fee757ca2adbe462c1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4071d8e2f6c45c1955a811fee757ca2adbe462c1", "commit_message": "Fix FPE issue with `tf.raw_ops.Reverse`.\n\nPiperOrigin-RevId: 371176973\nChange-Id: Ic6d483bfc95313ec2299c2d1c956cfe96c96626c", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-29556", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.Reverse`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/36229ea9e9451dac14a8b1f4711c435a1d84a594/tensorflow/core/kernels/reverse_op.cc#L75-L76) performs a division based on the first dimension of the tensor argument. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a method in a TensorFlow OpKernel that computes a reverse operation on a tensor based on a \"dims\" input.\n\n2) The function first checks if the input tensor is scalar. If so, it directly returns the input as output.\n\n3) For non-scalar inputs, it validates:\n   - That the \"dims\" tensor is a vector (1D)\n   - That the number of elements in \"dims\" matches the number of dimensions in the input tensor\n   - That the input tensor has at most 8 dimensions (with a hard limit)\n\n4) The code then allocates output tensor with the same shape as input.\n\n5) The switch statement uses a macro (HANDLE_REVERSE) to dispatch to a template function based on the number of dimensions (0-8).\n\n6) The key security consideration: The code validates the dimensions of the input and dims tensors before processing. It checks that:\n   - dims is a vector\n   - dims has the correct number of elements\n   - input has at most 8 dimensions\n\n7) The input validation prevents out-of-bounds access to the dims vector (since it checks dims.dim_size(0) against input_dims).\n\n8) The code uses OP_REQUIRES and OP_REQUIRES_OK macros which are TensorFlow's way of checking conditions and returning errors if they fail.\n\n9) The switch statement is bounded (0-8 dimensions) and the code explicitly handles each case, so there's no risk of infinite loops or unbounded memory allocation.\n\n10) The code does not perform any unsafe memory operations, does not use unsafe string functions, and does not have any obvious buffer overflows or injection vulnerabilities.\n\n11) The only potential concern would be if the dims vector contained invalid values, but the code only uses dims.vec<bool>() which is safe as long as the vector has the correct size (which is validated).\n\n12) All input validation is performed before any processing occurs, and the code has explicit bounds checking.\n\n(2) NO: No security vulnerability."}
{"idx": 200305, "project": "ghostpdl", "commit_id": "2793769ff107d8d22dadd30c6e68cd781b569550", "project_url": "https://github.com/ArtifexSoftware/ghostpdl", "commit_url": "https://git.ghostscript.com/?p=ghostpdl.git;a=commitdiff;h=2793769ff107d8d22dadd30c6e68cd781b569550", "commit_message": "Bug 701819: fixed ordering in if expression to avoid out-of-bounds access.\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r965 -sOutputFile=tmp -sDEVICE=pcx16 ../bug-701819.pdf", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2020-16305", "cve_desc": "A buffer overflow vulnerability in pcx_write_rle() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `pcx_write_rle` is responsible for writing run-length encoded data to a file in PCX format. It processes data in chunks of `step` bytes, and attempts to compress runs of identical bytes.\n\n2. The constant `MAX_RUN_COUNT` is defined as 15, which limits the maximum run length that can be encoded in a single RLE packet (0xc0 + run_count). This is done to ensure compatibility with some PCX readers that cannot handle run counts greater than 15.\n\n3. The variable `max_run` is calculated as `step * MAX_RUN_COUNT`. This determines the maximum number of bytes (in terms of step-sized units) that can be encoded in a single RLE packet.\n\n4. The function processes the input data in a loop:\n   - It reads a byte `data` from `from`.\n   - It then checks if the next byte (after `step`) is different or if we've reached the end.\n   - If the next byte is different or we're at the end, it writes a single byte (possibly preceded by a 0xc1 if data >= 0xc0).\n   - Otherwise, it enters a loop to find the full run length.\n\n5. The key part is the run-length encoding loop:\n   - It computes the run length as `(from - start) / step`.\n   - It then loops while the remaining run length is greater than or equal to `max_run`, emitting packets of size `MAX_RUN_COUNT`.\n   - Finally, it emits the remainder with a run count of `(from - start) / step + 0xc1`.\n\n6. Now, consider the potential issue: the expression `(from - start) / step` is used to compute the run length. Since `from` and `start` are pointers incremented by `step`, the difference is a multiple of `step`. However, the division by `step` is safe only if `step` is non-zero and the difference is divisible by `step`.\n\n7. But what if `step` is 0? The function does not validate `step` before using it in `max_run = step * MAX_RUN_COUNT`. If `step` is 0, then `max_run` becomes 0, and the loop condition `from - start >= max_run` becomes `from - start >= 0`, which is always true (since `from >= start`). This leads to an infinite loop because `from` is never advanced beyond `start` in the inner loop (since `step` is 0, `from += step` does nothing), and `from - start` remains constant.\n\n8. Furthermore, if `step` is 0, the loop `while ((from < end) && (*from == data)) from += step;` will never advance `from`, so the loop will run indefinitely, causing a denial of service (infinite loop) or crash due to stack overflow or resource exhaustion.\n\n9. The function does not check for `step == 0` before using it in arithmetic or pointer arithmetic. This is a critical flaw.\n\n10. Therefore, if an attacker can control the `step` parameter (e.g., via a malformed input file or crafted data), they can cause the function to enter an infinite loop, leading to a denial of service.\n\n(1) YES: A security vulnerability detected."}
{"idx": 196894, "project": "cryptopp", "commit_id": "9425e16437439e68c7d96abef922167d68fafaff", "project_url": "https://github.com/weidai11/cryptopp", "commit_url": "https://github.com/weidai11/cryptopp/commit/9425e16437439e68c7d96abef922167d68fafaff", "commit_message": "Fix for CVE-2015-2141. Thanks to Evgeny Sidorov for reporting. Squaring to satisfy Jacobi requirements suggested by JPM.", "ground_truth": 1, "cwe": ["CWE-399"], "cve": "CVE-2015-2141", "cve_desc": "The InvertibleRWFunction::CalculateInverse function in rw.cpp in libcrypt++ 5.6.2 does not properly blind private key operations for the Rabin-Williams digital signature algorithm, which allows remote attackers to obtain private keys via a timing attack.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Function Purpose**: This function computes the inverse of a value `x` under a specific cryptographic function (likely related to the Rabin-Williams cryptosystem), using modular arithmetic, random blinding, and the Chinese Remainder Theorem (CRT).\n\n2. **Input Validation and Sanitization**:\n   - `DoQuickSanityCheck()` is called \u2014 this likely checks internal consistency of the object (e.g., valid modulus, private key components), which is good practice.\n   - The function uses `m_n`, `m_p`, `m_q`, and `m_u` \u2014 standard parameters in Rabin-Williams (where `n = p*q`, and `u` is the CRT coefficient).\n   - `r` is randomly chosen from the range `[1, m_n - 1]`, which is correct for blinding (ensuring `r` is invertible modulo `n`).\n   - The loop ensures `rInv` is not zero \u2014 this is necessary because the multiplicative inverse of `r` must exist (i.e., `gcd(r, n) = 1`). The loop retries if `r` is not coprime to `n`, which is a valid mitigation for bad random choices.\n\n3. **Blinding**:\n   - `re = modn.Square(r) * x` \u2014 this is standard blinding in Rabin-Williams: the input `x` is blinded by multiplying with `r\u00b2` to prevent side-channel attacks (e.g., timing or power analysis) during square root computation.\n\n4. **Jacobi Symbol Check**:\n   - The code computes `Jacobi(cp, m_p)` and `Jacobi(cq, m_q)` and checks if their product is 1.\n   - This is a correctness check: for a number to be a quadratic residue modulo `p` and `q`, the Jacobi symbol must be 1. If not, the number is not a quadratic residue, and the square root cannot exist.\n   - The code then adjusts `cp` and `cq` by halving them (if odd, add `m_p` or `m_q` and then shift right) \u2014 this is a known technique to reduce the value modulo 2, effectively computing `cp mod 2` and adjusting to ensure the value is in the correct residue class for square root extraction. This is a valid step in some implementations of Rabin-Williams to handle the sign ambiguity.\n\n5. **Parallel Computation of Square Roots**:\n   - The use of OpenMP to compute square roots modulo `p` and `q` in parallel is efficient and safe, provided the `ModularSquareRoot` function is implemented securely (e.g., constant-time, no side-channel leakage). The code does not show the implementation of `ModularSquareRoot`, but assuming it's secure, this is acceptable.\n\n6. **CRT and Unblinding**:\n   - `CRT(cq, m_q, cp, m_p, m_u)` reconstructs the solution modulo `n` using the Chinese Remainder Theorem.\n   - Then `y = modn.Multiply(y, rInv)` unblinds the result \u2014 this is correct and necessary.\n   - `y = STDMIN(y, m_n - y)` selects the smaller of `y` and `n - y`, which is a common way to pick a canonical representative (since both `y` and `-y` are square roots).\n\n7. **Final Check**:\n   - `ApplyFunction(y) != x` \u2014 this checks that the computed inverse is correct. If not, it throws an exception. This is a critical safety check to detect computational errors (e.g., due to incorrect CRT, bad square roots, or implementation bugs). This prevents returning incorrect results silently.\n\n8. **Security Considerations**:\n   - **Blinding**: The use of random `r` and blinding prevents side-channel attacks on the private key operation.\n   - **Randomness**: `r.Randomize(rng, One(), m_n - One())` ensures randomness in the blinding factor, which is essential for security.\n   - **No Information Leakage**: The function does not expose intermediate values (like `r`, `rInv`, `re`, `cp`, `cq`) to the outside, and the final result is validated.\n   - **No Buffer Overflows or Memory Corruption**: The code uses `Integer` class (likely from Crypto++), which handles arbitrary precision integers safely.\n   - **No Use of Unsafe Functions**: No `strcpy`, `sprintf`, or similar functions are used.\n   - **No Direct User Input Exposure**: The function is part of a cryptographic operation, and `x` is assumed to be a valid input (e.g., a valid ciphertext or message).\n\n9. **Potential Risks**:\n   - The only potential concern is the `Jacobi` symbol check and adjustment step. If `cp` or `cq` is not a quadratic residue, the square root does not exist. However, the code adjusts them by halving (which is equivalent to dividing by 2 modulo `p` or `q`), but this is only valid if the original value is odd. The code checks `IsOdd()` and adjusts accordingly \u2014 this is a known technique in Rabin-Williams to handle the sign ambiguity and ensure the value is in the correct residue class for square root extraction.\n   - However, if the input `x` is not a valid quadratic residue modulo `n`, the function will fail (throw an exception), which is acceptable behavior \u2014 it should not return an incorrect result.\n\n10. **Conclusion**:\n    - The code implements a secure, well-known cryptographic algorithm (Rabin-Williams inverse) with proper blinding, CRT, and validation.\n    - All steps are designed to prevent side-channel attacks and ensure correctness.\n    - No obvious vulnerabilities (e.g., buffer overflows, injection, unsafe memory access, or information leakage) are present.\n    - The use of `STDMIN` and final validation ensures correctness.\n\n(2) NO: No security vulnerability."}
{"idx": 198566, "project": "libmobi", "commit_id": "eafc415bc6067e72577f70d6dd5acbf057ce6e6f", "project_url": "https://github.com/bfabiszewski/libmobi", "commit_url": "https://github.com/bfabiszewski/libmobi/commit/eafc415bc6067e72577f70d6dd5acbf057ce6e6f", "commit_message": "Fix wrong boundary checks in inflections parser resulting in stack buffer over-read with corrupt input", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-1533", "cve_desc": "Buffer Over-read in GitHub repository bfabiszewski/libmobi prior to 0.11. This vulnerability is capable of arbitrary code execution.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `mobi_decode_infl` decodes data using a rule stream (`rule`) and modifies a buffer (`decoded`) in place, with `decoded_size` tracking the current size.\n\n2. The function processes each byte in the `rule` array until it encounters a zero byte (null terminator).\n\n3. The logic involves:\n   - Setting `mod` ('i' for insert, 'd' for delete) based on the value of `c`.\n   - Setting `dir` ('<' for left, '>' for right) based on bit 1 of `c`.\n   - Updating `pos` (current position in the buffer) based on `mod`, `dir`, and `c`.\n   - Performing insert or delete operations using `memmove` and adjusting `*decoded_size`.\n\n4. Critical checks:\n   - Before `memmove` in both insert and delete cases, the code checks:\n     ```c\n     if (l < 0 || d + l > decoded + INDX_INFLBUF_SIZEMAX)\n     ```\n     This checks that the destination buffer (`d`) plus the length `l` does not exceed the maximum allowed buffer size (`INDX_INFLBUF_SIZEMAX`). This is a good defensive check.\n\n   - The `l` is computed as `*decoded_size - pos`, which is the number of bytes from `pos` to the end of the buffer.\n\n   - The `memmove` operation is performed on `l` bytes, and the destination is `d = decoded + pos` (for delete) or `d = decoded + pos + 1` (for insert).\n\n5. Potential issue:\n   - The `l` variable is computed as `*decoded_size - pos`. This is correct for the number of bytes to move.\n   - However, in the insert case:\n     ```c\n     const unsigned char *s = decoded + pos;\n     unsigned char *d = decoded + pos + 1;\n     const int l = *decoded_size - pos;\n     ```\n     Then `memmove(d, s, (size_t) l);` \u2014 this moves `l` bytes from `pos` to `pos+1`, which is correct for insertion.\n\n   - But note: `*decoded_size` is incremented after the `memmove`, so the buffer size is updated only after the move.\n\n   - The check `d + l > decoded + INDX_INFLBUF_SIZEMAX` is equivalent to:\n     `(decoded + pos + 1) + (*decoded_size - pos) > decoded + INDX_INFLBUF_SIZEMAX`\n     \u2192 `decoded + 1 + *decoded_size > decoded + INDX_INFLBUF_SIZEMAX`\n     \u2192 `*decoded_size + 1 > INDX_INFLBUF_SIZEMAX`\n\n     So the check ensures that after insertion, the buffer does not exceed `INDX_INFLBUF_SIZEMAX`.\n\n   - Similarly, in the delete case:\n     ```c\n     const unsigned char *s = decoded + pos + 1;\n     unsigned char *d = decoded + pos;\n     const int l = *decoded_size - pos;\n     ```\n     Then `memmove(d, s, (size_t) l);` \u2014 this moves `l` bytes from `pos+1` to `pos`.\n\n     The check is:\n     `d + l > decoded + INDX_INFLBUF_SIZEMAX` \u2192 `(decoded + pos) + (*decoded_size - pos) > decoded + INDX_INFLBUF_SIZEMAX` \u2192 `*decoded_size > INDX_INFLBUF_SIZEMAX`\n\n     So the check ensures that the total number of bytes being moved (from `pos` onward) does not exceed the buffer limit.\n\n6. However, there is a subtle but critical issue:\n   - The `l` is computed as `*decoded_size - pos`, which is the number of bytes from `pos` to the end of the buffer.\n   - But `*decoded_size` is the current size, and `pos` is the current position.\n   - The check `d + l > decoded + INDX_INFLBUF_SIZEMAX` is correct only if `*decoded_size` is not greater than `INDX_INFLBUF_SIZEMAX` already.\n\n   - But what if `*decoded_size` is already at or near `INDX_INFLBUF_SIZEMAX`? The check `d + l > decoded + INDX_INFLBUF_SIZEMAX` is equivalent to `*decoded_size > INDX_INFLBUF_SIZEMAX` in the delete case, and `*decoded_size + 1 > INDX_INFLBUF_SIZEMAX` in the insert case.\n\n   - So the check is actually sufficient to prevent buffer overflow, because it ensures that the total number of bytes being moved (from `pos` to the end) does not exceed the buffer size.\n\n7. However, there is a **critical flaw in the logic of the `pos` update**:\n   - In the `c <= 4` case, the code sets:\n     ```c\n     if (olddir != dir && olddir) {\n         pos = (c & 2) ? *decoded_size : 0;\n     }\n     ```\n     This resets `pos` to `*decoded_size` (if `c & 2` is true) or `0` (if false), but only if `olddir` is not zero and changed.\n\n   - But `*decoded_size` is the current size of the buffer, and `pos` is being set to `*decoded_size` \u2014 which is **one past the last valid index**.\n\n   - Then, in the insert case, `pos` is used as the insertion point. If `pos` is set to `*decoded_size`, and `*decoded_size` is the current size, then `decoded + pos` is the end of the buffer.\n\n   - But in the insert case, the code does:\n     ```c\n     const unsigned char *s = decoded + pos;\n     unsigned char *d = decoded + pos + 1;\n     ```\n     So `s` points to `decoded + *decoded_size`, which is **one past the end** of the buffer.\n\n   - This is **undefined behavior** because `decoded + pos` is `decoded + *decoded_size`, which is out of bounds.\n\n   - Even though the `memmove` is only copying `l = *decoded_size - pos = 0` bytes in this case (since `pos = *decoded_size`), the code still accesses `decoded + pos` (i.e., `decoded + *decoded_size`), which is **out of bounds**.\n\n   - This is a **buffer overflow** in the sense of accessing memory beyond the allocated buffer.\n\n   - The `l` is `*decoded_size - pos = 0`, so `memmove` does nothing, but the pointer arithmetic `decoded + pos` is still invalid.\n\n   - This is a **security vulnerability** because it allows reading from memory beyond the buffer, which could lead to information disclosure or crash.\n\n8. Additionally, in the `else if (c > 10 && c < 20)` block:\n   - `pos -= c - 10;`\n   - Then checks `if (pos < 0 || pos > *decoded_size)`\n   - But `pos` is used as an index into `decoded` in the insert/delete logic, so if `pos` is negative or greater than `*decoded_size`, it's invalid.\n\n   - However, the check is correct here.\n\n9. The main vulnerability is in the `c <= 4` block: when `pos` is set to `*decoded_size`, the code later uses `decoded + pos` (which is `decoded + *decoded_size`) in pointer arithmetic, which is **out of bounds**.\n\n   - Even though `l` is zero and `memmove` does nothing, the pointer access is still invalid.\n\n   - This is a **buffer overflow** in the form of out-of-bounds memory access.\n\n10. Therefore, this code contains a **security vulnerability** due to out-of-bounds memory access.\n\n(1) YES: A security vulnerability detected."}
{"idx": 207520, "project": "rizin", "commit_id": "aa6917772d2f32e5a7daab25a46c72df0b5ea406", "project_url": "https://github.com/rizinorg/rizin", "commit_url": "https://github.com/rizinorg/rizin/commit/aa6917772d2f32e5a7daab25a46c72df0b5ea406", "commit_message": "Fix oob write for dwarf with abbrev with count 0 (Fix #2083) (#2086)", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-43814", "cve_desc": "Rizin is a UNIX-like reverse engineering framework and command-line toolset. In versions up to and including 0.3.1 there is a heap-based out of bounds write in parse_die() when reversing an AMD64 ELF binary with DWARF debug info. When a malicious AMD64 ELF binary is opened by a victim user, Rizin may crash or execute unintended actions. No workaround are known and users are advised to upgrade.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `parse_die` processes DWARF debugging information, parsing attributes from a binary buffer (`buf`) into a `RzBinDwarfDie` structure.\n\n2. The function iterates over the abbreviations (`abbrev->count - 1`) and parses each attribute value using `parse_attr_value`, storing results in `die->attr_values[i]`.\n\n3. Two key attributes are checked:\n   - `DW_AT_comp_dir`: If present and of form `DW_FORM_strp` or `DW_FORM_string`, its value is stored in `comp_dir`.\n   - `DW_AT_stmt_list`: If present, its value (either a constant or a reference) is stored in `line_info_offset`.\n\n4. After parsing, if both `comp_dir` is non-null and `line_info_offset` is not `UT64_MAX`, the code:\n   - Duplicates the `comp_dir` string using `strdup`.\n   - Inserts the duplicated string into a hash table (`info->line_info_offset_comp_dir`) using `line_info_offset` as the key.\n\n5. The use of `strdup` is safe as long as `comp_dir` is a valid null-terminated string. However, `comp_dir` comes from `attribute->string.content`, which is derived from `debug_str` (a debug string section). This data is untrusted and comes from the binary file being analyzed.\n\n6. The `debug_str` data is not validated for proper null-termination or bounds. If `attribute->string.content` points to malformed or oversized data (e.g., no null terminator, or very long string), `strdup` could still work (since it stops at the first null), but the risk lies in the fact that the string content is not validated for length or format.\n\n7. However, the critical issue is not in `strdup` itself, but in the use of `ht_up_insert` to insert the string into a hash table. The hash table is keyed by `line_info_offset`, which is derived from `attribute->uconstant` or `attribute->reference`. These values come from the DWARF debug info and are not validated for being within bounds of the actual `debug_str` section.\n\n8. But more importantly: the `debug_str` buffer is passed in with `debug_str_len`, and `parse_attr_value` is expected to respect bounds. If `parse_attr_value` correctly validates the string offset and length (e.g., checks that `strp` points within `debug_str` and is null-terminated), then `attribute->string.content` is safe.\n\n9. However, the code does not validate that `attribute->string.content` is actually a valid C string (null-terminated) before passing it to `strdup`. If the string is not null-terminated, `strdup` will read past the buffer, potentially causing undefined behavior or memory corruption.\n\n10. Furthermore, `debug_str` is a raw buffer from the binary, and if the DWARF data is malformed (e.g., a `DW_FORM_strp` pointing to an offset beyond `debug_str_len` or to a non-null-terminated string), `parse_attr_value` may return a pointer to invalid memory, leading to `strdup` reading arbitrary data.\n\n11. The function `parse_attr_value` is not shown, but if it does not validate that the string offset is within bounds and that the string is null-terminated, then this function is vulnerable to buffer over-reads.\n\n12. Since the code uses `attribute->string.content` directly in `strdup` without validating that it points to a valid null-terminated string within the `debug_str` buffer, this creates a potential for reading beyond the bounds of `debug_str`, which is a classic buffer over-read vulnerability.\n\n13. This is particularly dangerous in a binary analysis tool like Radare2, where malformed debug information could be used to trigger crashes or potentially execute arbitrary code.\n\n(1) YES: A security vulnerability detected."}
{"idx": 196860, "project": "gpac", "commit_id": "a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/a51f951b878c2b73c1d8e2f1518c7cdc5fb82c3f", "commit_message": "fixed #1782 (fuzz)", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-33361", "cve_desc": "Memory leak in the afra_box_read function in MP4Box in GPAC 1.0.1 allows attackers to read memory via a crafted file.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `afra_box_read` reads data from a bitstream (`GF_BitStream *bs`) into a box structure (`GF_AdobeFragRandomAccessBox *s`). This is part of a parser for a media file format (likely ISO Base Media File Format, such as MP4).\n\n2) The function first reads several flags and values:\n   - `ptr->long_ids`, `ptr->long_offsets`, `ptr->global_entries`, `ptr->reserved`, and `ptr->time_scale`.\n   - Then it reads `ptr->entry_count` (number of local entries).\n\n3) There is a critical check:\n   ```c\n   if (ptr->size / ( (ptr->long_offsets ? 16 : 12) ) < ptr->entry_count)\n       return GF_ISOM_INVALID_FILE;\n   ```\n   This checks whether the total size of the box is sufficient to hold `entry_count` entries, assuming each entry is either 12 or 16 bytes depending on `long_offsets`. This is a valid bounds check to prevent reading beyond the box size.\n\n4) The function then loops `entry_count` times to read local entries:\n   - Allocates memory for `GF_AfraEntry` using `gf_malloc`.\n   - Reads `time` (8 bytes) and `offset` (8 or 4 bytes depending on `long_offsets`).\n   - Inserts into a list using `gf_list_insert`.\n\n5) If `ptr->global_entries` is set, it reads `ptr->global_entry_count` and processes global entries:\n   - Allocates `GF_GlobalAfraEntry`.\n   - Reads `time` (8 bytes), then `segment` and `fragment` (4 or 2 bytes each depending on `long_ids`), and finally `afra_offset` and `offset_from_afra` (8 or 4 bytes each depending on `long_offsets`).\n   - Inserts into another list.\n\n6) The use of `ISOM_DECREASE_SIZE(ptr, N)` macro is critical. This macro is typically used to track how much data remains in the box. It ensures that the parser does not read beyond the declared size of the box.\n\n7) The key security consideration: Are there any unchecked bounds on the number of entries? The check `ptr->size / (16 or 12) < ptr->entry_count` prevents reading more entries than the box size allows. This is a proper validation.\n\n8) Memory allocation is checked (`if (!ae) return GF_OUT_OF_MEM;`), so no buffer overflow from allocation failure.\n\n9) All reads are from the bitstream with fixed sizes (u32, u64, etc.), and the size of each field is known and validated by the size check.\n\n10) There is no use of unsafe string functions, no direct user input into memory without bounds checking, and no format string vulnerabilities.\n\n11) The parser is designed to read structured binary data with size validation and proper memory management.\n\nConclusion: The code includes proper bounds checking based on the box size, validates entry counts against available space, uses safe memory allocation with error checking, and reads fixed-size fields. There are no obvious buffer overflows, integer overflows, or out-of-bounds reads.\n\n(2) NO: No security vulnerability."}
{"idx": 208522, "project": "unbound", "commit_id": "02080f6b180232f43b77f403d0c038e9360a460f", "project_url": "https://github.com/NLnetLabs/unbound", "commit_url": "https://github.com/NLnetLabs/unbound/commit/02080f6b180232f43b77f403d0c038e9360a460f", "commit_message": "- Fix Integer Overflows in Size Calculations,\n  reported by X41 D-Sec.", "ground_truth": 1, "cwe": ["CWE-190"], "cve": "CVE-2019-25038", "cve_desc": "Unbound before 1.9.5 allows an integer overflow in a size calculation in dnscrypt/dnscrypt.c. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `dnsc_load_local_data` is responsible for loading DNSCrypt local zone and local data entries based on signed certificates.\n\n2. First, it inserts a local-zone entry for the provider name with \"deny\" policy. This is safe because it uses `strdup` to copy the provider name, and the string is not user-controlled in a way that would allow injection (it's a fixed provider name from the environment).\n\n3. Then, it iterates over `dnscenv->signed_certs_count` certificates and processes each one.\n\n4. For each certificate:\n   - It checks if the certificate is in the `rotated_certs` list. If so, it skips it. This is a valid safety check.\n   - It calculates the required buffer size for the `rr` string, which includes:\n     - The provider name\n     - The fixed string \" 86400 IN TXT \\\"\"\n     - The raw bytes of the `SignedCert` struct (up to 4 * sizeof(struct SignedCert), which is a worst-case estimate)\n     - A trailing double quote\n     - A null terminator (implied by the allocation)\n   - It allocates memory for `rr` using `malloc(rrlen)`, and checks for failure.\n\n5. The core of the logic is in the `snprintf` loop that writes the certificate data into `rr`:\n   - It iterates over each byte of the `SignedCert` struct.\n   - For each byte:\n     - If the byte is printable and not a double quote or backslash, it is appended directly.\n     - Otherwise, it is escaped as `\\ddd` (three-digit octal).\n   - This is a proper escaping mechanism for the `TXT` record format, which requires that special characters be escaped.\n\n6. After the loop, it appends a closing double quote with `snprintf(rr + strlen(rr), ... , \"\\\"\")`.\n\n7. Then it inserts the resulting string into `cfg->local_data` using `strdup(rr)`.\n\n8. Finally, it frees the `rr` buffer.\n\nNow, let's assess for security vulnerabilities:\n\n- The `rrlen` calculation is conservative (worst-case), and the code uses `snprintf` with `rrlen - 1` to avoid buffer overflow. This is safe.\n- The escaping of non-printable and special characters (like `\"` and `\\`) is done correctly using `\\ddd` format, which is standard for DNS TXT records.\n- The `snprintf` calls are used with proper bounds checking: `rrlen - 1 - strlen(rr)` ensures that there is always space for the null terminator.\n- The `strdup` is used to copy strings safely.\n- The `rotated_cert` check prevents publishing outdated certificates.\n- The `local-zone` entry is safe and not subject to injection.\n\nNo buffer overflows, no injection vulnerabilities (SQL, command, or DNS), no format string issues, and no unsafe string operations.\n\n(2) NO: No security vulnerability."}
{"idx": 196689, "project": "tensorflow", "commit_id": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb", "commit_message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-29195", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function Compute is an override of an OpKernelContext method, likely part of a TensorFlow or similar ML framework kernel.\n\n2) The code retrieves a Buffer object via GetBuffer(ctx, def(), &buf), which is then scoped with ScopedUnref to ensure proper cleanup.\n\n3) It reads an index from the first input tensor using ctx->input(0).scalar<int>()(), which extracts the scalar integer value from the input tensor.\n\n4) It then calls buf->Peek(index, &tuple) to retrieve a tuple from the buffer at the specified index.\n\n5) The code checks if the size of the returned tuple matches the number of outputs expected by the kernel (ctx->num_outputs()).\n\n6) Finally, it sets each output tensor to the corresponding element in the tuple.\n\nNow, let's analyze for security vulnerabilities:\n\n- The index is read from user-controlled input (ctx->input(0)), which is a tensor provided by the user.\n- The index is used directly in buf->Peek(index, &tuple) without any bounds checking.\n- There is no validation that index is within the valid range of the buffer (e.g., index < buf->size()).\n- If the index is out of bounds (either negative or too large), this could lead to memory corruption, buffer overflow, or arbitrary memory access.\n- The OP_REQUIRES_OK and OP_REQUIRES checks only validate the return status of operations, not the validity of the index itself.\n- The tuple.size() check only ensures the tuple size matches the number of outputs, but does not validate that the index is valid for the buffer.\n\nThis is a classic out-of-bounds access vulnerability. An attacker could provide a maliciously large or negative index to access memory outside the buffer's bounds, potentially leading to information disclosure, denial of service, or code execution.\n\n(1) YES: A security vulnerability detected."}
{"idx": 204535, "project": "admesh", "commit_id": "e84d8353f1347e1f26f0a95770d92ba14e6ede38", "project_url": "https://github.com/admesh/admesh", "commit_url": "https://github.com/admesh/admesh/commit/e84d8353f1347e1f26f0a95770d92ba14e6ede38", "commit_message": "Fix heap buffer overflow in stl_update_connects_remove_1\n\n\n- Add argument value check to the stl_update_connects_remove_1\n- Add neighbor value check in stl_remove_degenerate\n\nFixes https://github.com/admesh/admesh/issues/28\nMerges https://github.com/admesh/admesh/pull/55", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2018-25033", "cve_desc": "ADMesh through 0.98.4 has a heap-based buffer over-read in stl_update_connects_remove_1 (called from stl_remove_degenerate) in connect.c in libadmesh.a.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `stl_update_connects_remove_1` takes two parameters: a pointer to an `stl_file` structure (`stl`) and an integer `facet_num` representing a facet index.\n\n2. The function first checks if `stl->error` is non-zero. If so, it returns early. This is a valid error-checking mechanism to prevent further processing when an error state exists.\n\n3. The function then calculates `j`, which counts how many of the three neighbors of the facet at index `facet_num` are set to -1 (indicating no neighbor). This is done using a sum of boolean expressions:\n   - `(stl->neighbors_start[facet_num].neighbor[0] == -1)` \u2192 1 if no neighbor, 0 otherwise\n   - Similarly for indices 1 and 2\n   - So `j` will be 0, 1, 2, or 3.\n\n4. The function then uses `j` to determine how many neighbors the facet has:\n   - `j == 0` \u2192 3 neighbors \u2192 decrement `connected_facets_3_edge`\n   - `j == 1` \u2192 2 neighbors \u2192 decrement `connected_facets_2_edge`\n   - `j == 2` \u2192 1 neighbor \u2192 decrement `connected_facets_1_edge`\n   - Note: `j == 3` is not handled explicitly.\n\n5. The critical issue: if `j == 3`, meaning all three neighbors are -1 (i.e., the facet has no neighbors), the function does nothing. This is a logic flaw, but not necessarily a security vulnerability in itself.\n\n6. However, the real concern is: **is `facet_num` validated before being used as an index into `stl->neighbors_start`?**\n\n   - The code uses `stl->neighbors_start[facet_num]` without checking whether `facet_num` is within the valid range of the array.\n   - If `facet_num` is out of bounds (e.g., negative or greater than or equal to the number of facets), this leads to **out-of-bounds memory access**, which is a classic buffer overflow or memory corruption vulnerability.\n\n7. There is no bounds check on `facet_num` before accessing `stl->neighbors_start[facet_num]`. This is a serious issue because:\n   - `facet_num` is an untrusted input (likely from user or file data).\n   - Accessing memory outside the allocated array can lead to crashes, data corruption, or even arbitrary code execution.\n\n8. The function does not validate that `facet_num` is within the valid range of the `neighbors_start` array. This is a clear security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 198259, "project": "tensorflow", "commit_id": "a2b743f6017d7b97af1fe49087ae15f0ac634373", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a2b743f6017d7b97af1fe49087ae15f0ac634373", "commit_message": "Fix heap OOB in `tf.raw_ops.RaggedGather`\n\nPiperOrigin-RevId: 388355464\nChange-Id: If14d96231d1cd7aad7c4d1c22c1bab1576b75717", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-37641", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions if the arguments to `tf.raw_ops.RaggedGather` don't determine a valid ragged tensor code can trigger a read from outside of bounds of heap allocated buffers. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/ragged_gather_op.cc#L70) directly reads the first dimension of a tensor shape before checking that said tensor has rank of at least 1 (i.e., it is not a scalar). Furthermore, the implementation does not check that the list given by `params_nested_splits` is not an empty list of tensors. We have patched the issue in GitHub commit a2b743f6017d7b97af1fe49087ae15f0ac634373. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of an OpKernel implementation in TensorFlow (likely C++), which processes input tensors and produces output tensors.\n\n2) Input validation:\n   - It retrieves input tensors using context->input_list and context->input.\n   - It validates that params_nested_splits_in is not empty (via DCHECK_GT, which is a debug assertion).\n   - It validates that indices_in is valid via ValidateIndices().\n   - It checks that params_dense_values_in has at least one dimension (non-zero rank).\n   - It uses OP_REQUIRES_OK and OP_REQUIRES for error checking, which ensures proper error propagation.\n\n3) Data processing:\n   - It calculates num_params from the first splits tensor.\n   - It calls MakeSplits() which processes the indices and splits to compute output splits and value slices.\n   - It then writes the output splits and values using WriteSplits and WriteValues.\n\n4) Security considerations:\n   - All input sizes are validated before use.\n   - The code uses proper bounds checking via OP_REQUIRES and OP_REQUIRES_OK macros.\n   - The indices and splits are validated through dedicated functions (ValidateIndices, MakeSplits).\n   - The code does not perform any unsafe memory operations, buffer copies, or direct string manipulation.\n   - All tensor access is through TensorFlow's safe tensor interface with dimension checks.\n\n5) No evidence of:\n   - Buffer overflows\n   - Out-of-bounds memory access\n   - Unchecked array indexing\n   - Use of unsafe functions\n   - Improper input validation\n   - Memory corruption risks\n\n6) The code follows TensorFlow's best practices for kernel implementation with proper error checking and input validation.\n\n(2) NO: No security vulnerability."}
{"idx": 195082, "project": "linux", "commit_id": "c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/c7dfa4009965a9b2d7b329ee970eb8da0d32f0bc", "commit_message": "KVM: nSVM: always intercept VMLOAD/VMSAVE when nested (CVE-2021-3656)\n\nIf L1 disables VMLOAD/VMSAVE intercepts, and doesn't enable\nVirtual VMLOAD/VMSAVE (currently not supported for the nested hypervisor),\nthen VMLOAD/VMSAVE must operate on the L1 physical memory, which is only\npossible by making L0 intercept these instructions.\n\nFailure to do so allowed the nested guest to run VMLOAD/VMSAVE unintercepted,\nand thus read/write portions of the host physical memory.\n\nFixes: 89c8a4984fc9 (\"KVM: SVM: Enable Virtual VMLOAD VMSAVE feature\")\n\nSuggested-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Maxim Levitsky <mlevitsk@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>", "ground_truth": 1, "cwe": ["CWE-862"], "cve": "CVE-2021-3656", "cve_desc": "A flaw was found in the KVM's AMD code for supporting SVM nested virtualization. The flaw occurs when processing the VMCB (virtual machine control block) provided by the L1 guest to spawn/handle a nested guest (L2). Due to improper validation of the \"virt_ext\" field, this issue could allow a malicious L1 to disable both VMLOAD/VMSAVE intercepts and VLS (Virtual VMLOAD/VMSAVE) for the L2 guest. As a result, the L2 guest would be allowed to read/write physical pages of the host, resulting in a crash of the entire system, leak of sensitive data or potential guest-to-host escape.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `recalc_intercepts` is responsible for recalculating intercepts in a nested virtualization environment (SVM - Secure Virtual Machine) for AMD processors.\n\n2) The function first marks the VMCB (Virtual Machine Control Block) as dirty for intercepts, which is a standard practice to ensure changes are reflected in the hardware.\n\n3) It checks if the current mode is guest mode using `is_guest_mode(&svm->vcpu)`. If not in guest mode, it returns early. This is a valid safety check.\n\n4) The function then copies intercepts from the L1 (host) VMCB (`h->intercepts`) to the L2 (nested guest) VMCB (`c->intercepts`). This is correct for nested virtualization.\n\n5) When the nested guest has interrupt masking enabled (`g->int_ctl & V_INTR_MASKING_MASK`), it clears several intercepts:\n   - CR8 read/write intercepts\n   - VINTR (virtual interrupt) intercept\n   This is correct behavior because when interrupt masking is active, the guest's EFLAGS.IF doesn't affect interrupt delivery, so L0 doesn't need to handle interrupt window VM-exits.\n\n6) It explicitly clears the VMMCALL intercept, which is correct because nested guests should not be allowed to make VMMCALLs directly to the host hypervisor.\n\n7) Then it performs a bitwise OR of the nested guest's intercepts (`g->intercepts`) with the current intercepts. This combines the L1 intercepts with the L2 intercepts.\n\n8) Finally, if `intercept_smi` is false, it clears the SMI (System Management Interrupt) intercept. This is a conditional check that prevents SMI interception if not desired.\n\n9) The code uses `vmcb_clr_intercept` and `vmcb_mark_dirty` functions which are likely well-defined and safe. The loop over `MAX_INTERCEPT` is bounded and safe.\n\n10) There are no buffer overflows, use-after-free, null pointer dereferences, or other classic vulnerabilities. The logic is sound for nested virtualization, and all operations are within bounds.\n\n11) The function correctly handles the complex interaction between L0, L1, and L2 intercepts in a nested virtualization scenario.\n\n(2) NO: No security vulnerability."}
{"idx": 196801, "project": "gpac", "commit_id": "f5a038e6893019ee471b6a57490cf7a495673816", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/f5a038e6893019ee471b6a57490cf7a495673816", "commit_message": "fixed #1885", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2021-40567", "cve_desc": "Segmentation fault vulnerability exists in Gpac through 1.0.1 via the gf_odf_size_descriptor function in desc_private.c when using mp4box, which causes a denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Buffer Size and String Formatting\nThe code uses several fixed-size character arrays:\n- `char buf64[5000]`\n- `char sdpLine[5100]`\n\nThese are used with `sprintf` to format strings that are later passed to `gf_isom_sdp_add_line`.\n\n#### Key usage:\n- `sprintf(buf64, \"b=AS:%d\", bandwidth);` \u2192 `buf64` is 5000 bytes, `bandwidth` is `u32` (32-bit), so maximum value is ~4.3 billion \u2192 `sprintf` will write at most ~10 digits + 5 chars \u2192 safe.\n- `sprintf(buf64, \"a=x-copyright: %s\", ...)` \u2192 The string is either a fixed literal or `gf_gpac_version()` and `gf_gpac_copyright()`. These are internal functions returning static strings. The total length is bounded by the fixed buffer size (5000), and the format string is controlled by the code, not user input.\n- `sprintf(sdpLine, \"data:application/mpeg4-od-au;base64,%s\", buf64)` \u2192 `buf64` contains base64-encoded data. The base64 encoding is limited to 2000 bytes via `gf_base64_encode(..., buf64, 2000)`, so `buf64` is at most 2000 bytes. The resulting `sdpLine` will be:\n  - Fixed prefix: `\"data:application/mpeg4-od-au;base64,\"` \u2192 ~40 chars\n  - Base64 data: up to 2000 bytes \u2192 base64 encoding increases size by ~33%, so ~2666 chars\n  - Total: ~2706 chars \u2192 well under `sdpLine[5100]` \u2192 safe.\n\nSimilarly, for the BIFS and IOD parts, the same pattern is used:\n- `gf_base64_encode(..., buf64, 2000)` \u2192 limits output to 2000 bytes\n- `sprintf(sdpLine, \"data:application/mpeg4-bifs-au;base64,%s\", buf64)` \u2192 same logic, safe\n- `sprintf(sdpLine, \"a=mpeg4-iod:\\\"data:application/mpeg4-iod;base64,%s\\\"\", buf64)` \u2192 same, safe\n\nSo **no buffer overflow** from `sprintf` due to unbounded input.\n\n---\n\n### Step 2: Use of `strcpy` and `strlen`\nThe code uses:\n```c\nesd->URLString = (char*)gf_malloc(sizeof(char) * (strlen(sdpLine)+1));\nstrcpy(esd->URLString, sdpLine);\n```\nThis is **safe** because:\n- `strlen(sdpLine)` is computed after `sprintf`, which is bounded by the buffer size.\n- The buffer `sdpLine` is 5100 bytes, and the `sprintf` calls are all within bounds (as shown above).\n- `strlen(sdpLine)` will be less than 5100, so `gf_malloc` allocates enough space.\n- `strcpy` copies exactly the string content, no overflow.\n\nNo risk of buffer overflow here.\n\n---\n\n### Step 3: Base64 Encoding\nThe function `gf_base64_encode` is called with a buffer size limit of 2000:\n```c\nsize64 = gf_base64_encode(samp->data, samp->dataLength, buf64, 2000);\nbuf64[size64] = 0;\n```\nThis ensures that the output is **never longer than 2000 bytes**, and the null terminator is explicitly set. This is a **safe** usage.\n\n---\n\n### Step 4: Input Sources\nAll data used in `sprintf` and `strcpy` comes from:\n- Internal constants (e.g., `\"MP4/3GP File hinted with GPAC\"`)\n- Version/copyright strings from `gf_gpac_version()` and `gf_gpac_copyright()` \u2014 these are static, controlled strings\n- `bandwidth` \u2014 a numeric parameter\n- `gf_isom_get_sample` \u2014 returns data from the file, but this is **not user-controlled input** in the context of this function; it's part of the file being processed, and the code checks size and validity before processing.\n\nThe function is not directly processing untrusted user input. It's processing a media file (e.g., MP4/3GP) that may be user-provided, but the **code itself does not expose untrusted data to unsafe string operations**.\n\n---\n\n### Step 5: Memory Management\n- `gf_free(buffer)` is called after `gf_odf_desc_write` \u2192 safe.\n- `gf_isom_sample_del(&samp)` is called \u2192 safe.\n- `gf_odf_desc_del((GF_Descriptor *)esd)` is called \u2192 safe.\n\nNo memory leaks or dangling pointers.\n\n---\n\n### Step 6: Security Implications\n- No use of `gets`, `strcpy`, `strcat`, `sprintf` with untrusted input.\n- All string formatting uses bounded buffers and controlled inputs.\n- Base64 encoding is limited to 2000 bytes.\n- No dynamic memory allocation without bounds checking.\n\nEven though the function processes media files (which could be malicious), the **code does not have any exploitable vulnerabilities** like buffer overflows, format string vulnerabilities, or unsafe string operations.\n\n---\n\n### Conclusion\nAfter thorough analysis:\n- All string operations are bounded.\n- No unsafe functions are used with untrusted input.\n- Memory management is correct.\n- No exploitable vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 207703, "project": "EternalTerminal", "commit_id": "900348bb8bc96e1c7ba4888ac8480f643c43d3c3", "project_url": "https://github.com/MisterTea/EternalTerminal", "commit_url": "https://github.com/MisterTea/EternalTerminal/commit/900348bb8bc96e1c7ba4888ac8480f643c43d3c3", "commit_message": "red fixes (#468)\n\n* red fixes\n\n* remove magic number", "ground_truth": 1, "cwe": ["CWE-362"], "cve": "CVE-2022-24950", "cve_desc": "A race condition exists in Eternal Terminal prior to version 6.2.0 that allows an authenticated attacker to hijack other users' SSH authorization socket, enabling the attacker to login to other systems as the targeted users. The bug is in UserTerminalRouter::getInfoForId().", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1. The function `listen` is part of a Unix domain socket server setup, using `AF_UNIX` sockets with `sockaddr_un` for local communication.\n\n2. The function first acquires a lock via `lock_guard<std::recursive_mutex> guard(globalMutex);`, which ensures thread safety when accessing shared data (`pipeServerSockets`), preventing race conditions.\n\n3. It checks if a socket is already listening on the given `pipePath`. If so, it throws an exception \u2014 this prevents duplicate binding, which is good practice.\n\n4. It creates a Unix domain socket using `socket(AF_UNIX, SOCK_STREAM, 0)`, which is correct for Unix domain sockets.\n\n5. `FATAL_FAIL(fd)` is used to ensure the socket creation succeeded \u2014 this is a safety check.\n\n6. `initServerSocket(fd)` is called \u2014 this likely sets socket options like `SO_REUSEADDR`, which is standard and safe.\n\n7. The `sockaddr_un` structure is initialized:\n   - `local.sun_family = AF_UNIX` \u2014 correct.\n   - `strcpy(local.sun_path, pipePath.c_str())` \u2014 this is the critical point.\n\n8. The `strcpy` call copies `pipePath.c_str()` into `local.sun_path`. However, `local.sun_path` is a fixed-size array (typically 108 bytes in Linux, but can vary). If `pipePath` is longer than `sizeof(local.sun_path) - 1`, this will cause a buffer overflow.\n\n9. The code does **not** validate the length of `pipePath` before copying it into `local.sun_path`. Since `pipePath` comes from user input (via `SocketEndpoint& endpoint`), an attacker could provide a path longer than the buffer size, leading to a buffer overflow.\n\n10. Although `unlink(local.sun_path)` is called before `bind`, this does not prevent the overflow \u2014 the overflow occurs during `strcpy`, which happens before `unlink`.\n\n11. The `unlink` call is intended to remove any stale socket file, but it's not a defense against buffer overflow.\n\n12. The `chmod` call is only on non-Windows systems and is not a security issue in itself.\n\n13. The `pipeServerSockets` map stores the file descriptor, but the vulnerability is in the `strcpy` call, which is unsafe.\n\nConclusion: The use of `strcpy` without bounds checking on a user-controlled string (`pipePath`) into a fixed-size buffer (`local.sun_path`) is a classic buffer overflow vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 205630, "project": "linux", "commit_id": "32452a3eb8b64e01e2be717f518c0be046975b9d", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/32452a3eb8b64e01e2be717f518c0be046975b9d", "commit_message": "io_uring: fix uninitialized field in rw io_kiocb\n\nio_rw_init_file does not initialize kiocb->private, so when iocb_bio_iopoll\nreads kiocb->private it can contain uninitialized data.\n\nFixes: 3e08773c3841 (\"block: switch polling to be bio based\")\nSigned-off-by: Joseph Ravichandran <jravi@mit.edu>\nSigned-off-by: Jens Axboe <axboe@kernel.dk>", "ground_truth": 1, "cwe": ["CWE-94"], "cve": "CVE-2022-29968", "cve_desc": "An issue was discovered in the Linux kernel through 5.17.5. io_rw_init_file in fs/io_uring.c lacks initialization of kiocb->private.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `io_rw_init_file` is responsible for initializing a read/write I/O request in the io_uring subsystem. It takes a request structure (`req`), and a file mode (`mode`) as input.\n\n2. The function first checks if the file pointer is valid and if the file has the required mode (via `f_mode & mode`). If not, it returns -EBADF. This is a proper validation to prevent use of invalid or unauthorized file descriptors.\n\n3. It then checks if the request has a file flag set via `io_req_ffs_set(req)`. If not, it sets the request flags based on the file's flags using `io_file_get_flags(file)`. This is a legitimate mechanism to propagate file-level flags to the request.\n\n4. The function sets `kiocb->ki_flags` using `iocb_flags(file)`, which is a standard way to initialize I/O control block flags based on the file's properties.\n\n5. It calls `kiocb_set_rw_flags(kiocb, req->rw.flags)` to set read/write-specific flags. If this returns a non-zero value (error), it returns immediately. This is a proper error check.\n\n6. The next block handles the `IOCB_NOWAIT` and `O_NONBLOCK` logic:\n   - If `IOCB_NOWAIT` is set, or if the file is `O_NONBLOCK` but does not support `nowait`, the request is marked with `REQ_F_NOWAIT`.\n   - This logic is intended to prevent retries for non-blocking I/O when it's not supported, which is a reasonable and safe design.\n\n7. The function then checks if `IORING_SETUP_IOPOLL` is enabled:\n   - If so, it verifies that the I/O is direct (`IOCB_DIRECT`) and that the file's operations support `iopoll`. If not, it returns -EOPNOTSUPP.\n   - It sets `IOCB_HIPRI` and `IOCB_ALLOC_CACHE`, and assigns a custom completion handler `io_complete_rw_iopoll`.\n   - This is a valid check to ensure that iopoll is only used with supported configurations.\n\n8. If `IORING_SETUP_IOPOLL` is not set:\n   - It checks if `IOCB_HIPRI` is set and returns -EINVAL if so. This prevents misuse of high-priority I/O in non-iopoll mode.\n   - It sets the completion handler to `io_complete_rw`.\n\n9. The function returns 0 on success.\n\nNow, let\u2019s assess for security vulnerabilities:\n\n- All input validation is done properly: null checks, mode checks, flag checks.\n- There is no use of unsafe memory operations (e.g., buffer overflows, unsafe string copies).\n- The code does not directly handle user input in a way that could lead to injection or memory corruption.\n- The logic around `IOCB_NOWAIT`, `O_NONBLOCK`, and `iopoll` is sound and prevents misuse.\n- The use of `kiocb->ki_flags` and `req->flags` is controlled and validated.\n- No arbitrary memory access or privilege escalation vectors are present.\n\nThe code is part of the Linux kernel's io_uring subsystem, which is designed with security in mind. The checks are thorough and prevent invalid or unsafe configurations.\n\n(2) NO: No security vulnerability."}
{"idx": 197998, "project": "tensorflow", "commit_id": "704866eabe03a9aeda044ec91a8d0c83fc1ebdbe", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe", "commit_message": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.\n\nPiperOrigin-RevId: 370766155\nChange-Id: I33e7c6626224e1060a8a4ab51ad5d861c6d4c63e", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2021-29552", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. **Input Validation**:\n   - The function `Compute` takes three inputs: `input`, `segment_id`, and `num_segments_tensor`.\n   - It checks that `segment_id` has non-zero rank (`segment_dims != 0`), which is correct to avoid invalid indexing.\n   - It ensures that `segment_id`'s rank is not greater than `input`'s rank (`segment_dims <= input_dims`), which prevents dimension mismatch.\n   - It validates that each dimension of `segment_id` matches the corresponding dimension of `input` (`segment_id_shape.dim_size(i) == input_shape.dim_size(i)`), ensuring alignment.\n\n2. **Output Tensor Allocation**:\n   - The output tensor is allocated using `context->allocate_output`, with shape derived from `GetOutputShape(...)`. This is safe as long as `GetOutputShape` is correctly implemented and does not produce invalid or overly large shapes.\n\n3. **Flat Tensor Access**:\n   - The code uses `.flat<tstring>()` to access the underlying data of `output_tensor`, `segment_id`, and `input`. This is valid as long as the tensors are properly shaped and the data types match.\n\n4. **Segment ID Validation**:\n   - The loop checks that each value in `flat_segment_id` is within the valid range: `0 <= flat_segment_id(i) < num_segments`. This is a critical safety check to prevent out-of-bounds access to the output tensor.\n\n5. **Indexing and Data Copying**:\n   - The code computes strides and relative offsets using `GetStrides` and `GetFlattenedRelativeOffsets`, which are assumed to be correctly implemented.\n   - It then iterates over `start_offset` and `relative_offset_set`, computing `output_index` and `offset` into the flat arrays.\n   - The key operation is:\n     ```cpp\n     if (output_flat(output_index).length() != 0)\n       output_flat(output_index).append(separator_.c_str());\n     output_flat(output_index).append(flat_input(offset));\n     ```\n     This appends the input string to the output string at `output_index`, with a separator if the output is non-empty.\n\n6. **Potential Security Concerns**:\n   - The use of `tstring` (a string type) and `append` operations is safe as long as the input strings are not maliciously crafted to cause memory exhaustion or buffer overflows.\n   - However, the code does **not** validate the length of the input strings (`flat_input(offset)`) or the output strings (`output_flat(output_index)`). If the input strings are extremely long (e.g., gigabytes), this could lead to memory exhaustion (a denial-of-service condition).\n   - More critically, the code does **not** check whether `num_segments` is valid or bounded. If `num_segments` is extremely large (e.g., 2^64), then `flat_segment_id(i) < num_segments` could be true for many values, but the output tensor size is determined by `GetOutputShape(...)`, which may not scale appropriately. If `GetOutputShape` does not cap the output size based on `num_segments`, this could lead to allocating an enormous output tensor, causing memory exhaustion.\n   - Additionally, the `GetOutputShape` function is not shown, but if it depends on `num_segments` without bounds checking, it could result in an unbounded output tensor size.\n\n7. **Conclusion**:\n   - While the code performs strong validation on `segment_id` values and dimensions, it **does not** validate the magnitude of `num_segments` or the size of input strings.\n   - This could allow an attacker to supply a very large `num_segments` or very long input strings, leading to excessive memory allocation and potential denial-of-service (DoS).\n   - This is a **resource exhaustion vulnerability**, which is a security vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 198695, "project": "MilkyTracker", "commit_id": "fd607a3439fcdd0992e5efded3c16fc79c804e34", "project_url": "https://github.com/milkytracker/MilkyTracker", "commit_url": "https://github.com/milkytracker/MilkyTracker/commit/fd607a3439fcdd0992e5efded3c16fc79c804e34", "commit_message": "Fix #184: Heap overflow in S3M loader", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2019-14464", "cve_desc": "XMFile::read in XMFile.cpp in milkyplay in MilkyTracker 1.02.00 has a heap-based buffer overflow.", "vuln": 1, "reasoning": "Let's analyze the provided C++ code step-by-step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Memory Allocation and Management\nThe code dynamically allocates several buffers using `new`:\n- `orders` (size: `header->ordnum`)\n- `insParaPtrs` (size: `header->insnum`)\n- `patParaPtrs` (size: `header->patnum`)\n- `samplePtrs` (size: `header->insnum`)\n- `pattern` (size: `64*32*5 = 9600` bytes)\n\nAll allocations are checked for `NULL` before use, and if any fail, the function returns `MP_OUT_OF_MEMORY` and cleans up previously allocated memory (via `delete[]`). This is good practice and prevents memory leaks.\n\n> \u2705 No buffer overflow from allocation failure.\n\n---\n\n### Step 2: Input Validation from File\nThe function reads data from a file (`XMFileBase& f`) that is assumed to be a S3M (ScreamTracker 3) module file. The code performs several checks:\n- Checks for `f.readByte() == 16` to verify it's a valid ST3 module.\n- Reads `header->ordnum`, `header->insnum`, `header->patnum` from the file.\n- Uses these values to allocate arrays.\n\nHowever, **the values read from the file are not validated for reasonableness**. For example:\n- `header->ordnum` is read from the file and used to allocate `orders` array.\n- `header->insnum` and `header->patnum` are used to allocate `insParaPtrs` and `patParaPtrs`.\n\nIf an attacker crafts a malicious S3M file with extremely large values (e.g., `header->ordnum = 0xFFFFFFFF`), this would cause:\n- `new mp_ubyte[0xFFFFFFFF]` \u2192 allocation of ~4GB, which may crash the program or cause denial of service (DoS).\n- Similarly, `patParaPtrs` and `insParaPtrs` could be allocated with huge sizes.\n\nEven though the code checks for `NULL` after `new`, **this does not prevent DoS via resource exhaustion**. The allocation size is directly derived from untrusted input without bounds checking.\n\n> \u26a0\ufe0f This is a **classic resource exhaustion vulnerability** (a form of DoS), which is a security vulnerability.\n\n---\n\n### Step 3: Buffer Overflows in Data Copy\nThe code uses `f.read(...)` to copy data into fixed-size buffers:\n- `f.read(&header->name, 1, 28)` \u2192 safe, since `header->name` is 28 bytes.\n- `f.read(smp[s].name, 1, 12)` \u2192 safe, `name` is 12 bytes.\n- `f.read(instr[i].name, 1, 28)` \u2192 safe, `name` is 28 bytes.\n- `f.read(channelSettings, 1, 32)` \u2192 safe, buffer is 32 bytes.\n\nAll these `f.read` calls use a fixed size that matches the destination buffer. No buffer overflow here.\n\nHowever, later in the pattern loading:\n```cpp\nmp_ubyte* packed = new mp_ubyte[size+5];\n...\nf.read(packed, 1, size);\n```\nHere, `size` is read from the file (`f.readWord()`), and used to allocate `packed`. If `size` is very large (e.g., 0xFFFFFFFF), this again causes a massive allocation, leading to DoS.\n\nAlso, the `safeRead` function is used in a loop:\n```cpp\nmp_ubyte pi = safeRead(packed, index, size);\n```\nBut `safeRead` is not defined in the code. However, assuming it performs bounds checking (as the name suggests), it may prevent out-of-bounds access. But **the real issue is the unbounded `size` from the file**, which leads to excessive memory allocation.\n\n---\n\n### Step 4: Use of `f.readWord()` and `f.readDword()` on Untrusted Input\nThe code reads `header->ordnum`, `header->insnum`, `header->patnum`, and `size` directly from the file. These values are used to determine allocation sizes. Since these are **untrusted inputs**, and no bounds are enforced (e.g., max 256 patterns, 128 instruments, etc.), an attacker can cause:\n- Memory exhaustion (DoS)\n- Potential integer overflow (if `size` is large and used in arithmetic)\n\nFor example:\n```cpp\nmp_uint32 patOffs = patParaPtrs[i]*16;\n```\nIf `patParaPtrs[i]` is huge, `patOffs` could wrap around or cause invalid seeks.\n\nAlso:\n```cpp\nf.seekWithBaseOffset(patOffs);\n```\nIf `patOffs` is larger than the file size, this could lead to undefined behavior or crashes.\n\n> \u26a0\ufe0f This is a **critical vulnerability**: untrusted input used to determine memory allocation and file offsets without bounds checking.\n\n---\n\n### Step 5: Final Checks and Cleanup\nThe code deletes all allocated memory on return, and checks for `NULL` after `new`. This prevents memory leaks but **does not prevent DoS via resource exhaustion**.\n\n---\n\n### Conclusion\nThe code reads untrusted data from a file and uses it directly to:\n- Allocate large amounts of memory (`new` with size from file)\n- Perform file seeks with offsets from file\n\nThis allows an attacker to craft a malicious S3M file that causes:\n- Denial of Service (DoS) via memory exhaustion\n- Potential crashes or system instability\n\nThis is a **security vulnerability**, specifically a **resource exhaustion vulnerability** due to lack of input validation on file metadata.\n\n---\n\n(1) YES: A security vulnerability detected."}
{"idx": 198692, "project": "ipsec", "commit_id": "7bab09631c2a303f87a7eb7e3d69e888673b9b7e", "project_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec", "commit_url": "https://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec.git/commit/?id=7bab09631c2a303f87a7eb7e3d69e888673b9b7e", "commit_message": "xfrm: policy: check policy direction value\n\nThe 'dir' parameter in xfrm_migrate() is a user-controlled byte which is used\nas an array index. This can lead to an out-of-bound access, kernel lockup and\nDoS. Add a check for the 'dir' value.\n\nThis fixes CVE-2017-11600.\n\nReferences: https://bugzilla.redhat.com/show_bug.cgi?id=1474928\nFixes: 80c9abaabf42 (\"[XFRM]: Extension for dynamic update of endpoint address(es)\")\nCc: <stable@vger.kernel.org> # v2.6.21-rc1\nReported-by: \"bo Zhang\" <zhangbo5891001@gmail.com>\nSigned-off-by: Vladis Dronov <vdronov@redhat.com>\nSigned-off-by: Steffen Klassert <steffen.klassert@secunet.com>", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2017-11600", "cve_desc": "net/xfrm/xfrm_policy.c in the Linux kernel through 4.12.3, when CONFIG_XFRM_MIGRATE is enabled, does not ensure that the dir value of xfrm_userpolicy_id is XFRM_POLICY_MAX or less, which allows local users to cause a denial of service (out-of-bounds access) or possibly have unspecified other impact via an XFRM_MSG_MIGRATE xfrm Netlink message.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `xfrm_migrate` is part of the Linux kernel's XFRM (eXtensible FrameWork for Routing and Mobility) subsystem, which handles IPsec security associations and policies.\n\n2) The function takes several parameters including:\n   - `sel`: a selector for matching traffic\n   - `dir`: direction of the policy (inbound/outbound)\n   - `type`: type of policy\n   - `m`: array of migration specifications\n   - `num_migrate`: number of migration entries\n   - `k`: key management address information\n   - `net`: network namespace context\n   - `encap`: encapsulation template\n\n3) The function performs a multi-stage operation:\n   - Stage 1: Validates the migration data with `xfrm_migrate_check()`\n   - Stage 2: Finds existing security states and migrates them to new ones\n   - Stage 3: Updates the policy to reflect the migration\n   - Stage 4: Deletes old states\n   - Stage 5: Announces the migration\n\n4) Key security considerations:\n   - The function validates input with `xfrm_migrate_check()` before proceeding\n   - It uses proper error handling with cleanup paths in both `out` and `restore_state` labels\n   - The `xfrm_state_migrate()` function is responsible for creating new states, which should handle validation\n   - The function properly releases resources in error paths (pol, x_cur, x_new)\n   - The `xfrm_states_put()` and `xfrm_states_delete()` functions are used appropriately to manage reference counts and cleanup\n\n5) The code follows the principle of least privilege and proper error handling:\n   - All error paths properly clean up allocated resources\n   - The function does not perform any direct user input processing or string manipulation that could lead to buffer overflows\n   - All operations are within the kernel's security context with proper access controls\n\n6) There are no obvious issues with:\n   - Buffer overflows (no fixed-size buffers with unsafe copying)\n   - Use-after-free (proper reference counting with xfrm_states_put)\n   - NULL pointer dereferences (all pointers are checked before use)\n   - Integer overflows (no unsafe arithmetic operations)\n   - Improper input validation (input is validated by xfrm_migrate_check)\n\n7) The function appears to be well-structured with proper error handling and resource management.\n\n(2) NO: No security vulnerability."}
{"idx": 195691, "project": "mruby", "commit_id": "a4d97934d51cb88954cc49161dc1d151f64afb6b", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/a4d97934d51cb88954cc49161dc1d151f64afb6b", "commit_message": "vm.c: check if target_class is NULL (when prepended).", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1427", "cve_desc": "Out-of-bounds Read in mrb_obj_is_kind_of in in GitHub repository mruby/mruby prior to 3.2. # Impact: Possible arbitrary code execution if being exploited.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step.\n\n---\n\n### Step 1: Understand the context\nThe function `mrb_vm_exec` is part of the mruby virtual machine interpreter. It executes bytecode instructions (`mrb_code`) in a loop, dispatching to various opcodes (like `OP_ADD`, `OP_SEND`, `OP_LOADI`, etc.) based on the current instruction pointer (`pc`). The function is responsible for interpreting Ruby-like bytecode in a safe and controlled environment.\n\nThis is a core component of a scripting engine (mruby), and its correctness and security are critical.\n\n---\n\n### Step 2: Identify potential security concerns\nWe are looking for:\n- Buffer overflows\n- Use-after-free\n- Integer overflows/underflows\n- Unchecked array accesses\n- Improper bounds checking\n- Memory corruption\n- Unsafe type handling\n- Input validation issues (especially from bytecode)\n\nLet\u2019s examine key aspects:\n\n#### A. **Stack and register management**\n- The function uses `regs` (stack) as an array of `mrb_value`.\n- `mrb_stack_extend(mrb, nregs)` is called to extend the stack when needed.\n- `stack_clear` is used to initialize unused stack slots.\n- `mrb_gc_arena_save/restore` is used to protect values from garbage collection during execution.\n\n\u2705 These are good practices: stack is managed safely, and memory is protected from GC during execution.\n\n#### B. **Array and string operations**\n- Functions like `mrb_ary_new_from_values`, `mrb_str_concat`, `mrb_hash_set`, etc., are used.\n- These functions perform bounds checks and type validation internally.\n- For example, `mrb_ary_push` checks if the value is an array before pushing.\n\n\u2705 Safe usage: no direct buffer copying without bounds checks.\n\n#### C. **Integer arithmetic and overflow handling**\n- The code includes explicit overflow checks:\n  - `mrb_int_add_overflow`, `mrb_int_sub_overflow`, etc.\n  - If overflow occurs, it jumps to `L_INT_OVERFLOW`, which raises a `RangeError`.\n- This prevents integer overflow leading to memory corruption.\n\n\u2705 This is a strong security measure.\n\n#### D. **String and symbol handling**\n- `mrb_intern_str`, `mrb_str_new`, `mrb_symbol_value` are used.\n- The code checks for valid string types before operations.\n- `mrb_assert(mrb_string_p(...))` is used before string operations.\n\n\u2705 Safe: type checks are in place.\n\n#### E. **Bytecode validation**\n- The bytecode is loaded from `irep->iseq`, which is compiled and validated at load time (not shown here).\n- The interpreter does not directly parse untrusted input \u2014 it runs pre-compiled bytecode.\n- The `irep` structure is trusted because it comes from a prior compilation phase.\n\n\u2705 This is a standard and secure design: untrusted code is compiled to bytecode, which is then interpreted safely.\n\n#### F. **Memory safety and GC**\n- `mrb_gc_arena_save/restore` is used to protect values from being collected during execution.\n- `mrb_write_barrier` is used when modifying objects.\n- `mrb_assert` is used in many places to catch invalid states.\n\n\u2705 These are standard and correct practices in a garbage-collected VM.\n\n#### G. **Control flow and exception handling**\n- The code uses `MRB_TRY`/`MRB_CATCH` for exception handling.\n- `mrb->jmp` is set to `&c_jmp` for longjmp-based error recovery.\n- `cipop`, `cipush`, and `mrb_vm_ci_proc_set` manage call stack safely.\n\n\u2705 Proper exception handling with stack unwinding.\n\n#### H. **No direct user input in critical paths**\n- The function does not read user input directly.\n- All data comes from compiled bytecode, which is assumed to be trusted or validated at compile time.\n\n\u2705 No direct injection vector.\n\n---\n\n### Step 3: Look for any known vulnerabilities\n- This code is part of mruby, a well-maintained, minimal Ruby implementation.\n- The codebase has been audited and is known to be secure for its intended use.\n- No obvious buffer overflows, use-after-free, or integer overflows are present.\n- All array accesses are bounded by `nregs`, `nlocals`, or `irep->ilen`.\n- The `CASE` statements use `a`, `b`, `c` as indices, but they are derived from bytecode, which is validated at compile time.\n\n\u2705 No exploitable vulnerabilities found.\n\n---\n\n### Step 4: Final assessment\nThe code is a core interpreter function in a safe, garbage-collected VM. It includes:\n- Proper bounds checking\n- Overflow protection\n- Memory safety via GC and arena management\n- Type safety\n- Secure exception handling\n- No direct user input manipulation\n\nAll operations are performed on validated bytecode, and the interpreter enforces safety at runtime.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 215073, "project": "linux", "commit_id": "24f6008564183aa120d07c03d9289519c2fe02af", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/24f6008564183aa120d07c03d9289519c2fe02af", "commit_message": "cgroup-v1: Require capabilities to set release_agent\n\nThe cgroup release_agent is called with call_usermodehelper.  The function\ncall_usermodehelper starts the release_agent with a full set fo capabilities.\nTherefore require capabilities when setting the release_agaent.\n\nReported-by: Tabitha Sable <tabitha.c.sable@gmail.com>\nTested-by: Tabitha Sable <tabitha.c.sable@gmail.com>\nFixes: 81a6a5cdd2c5 (\"Task Control Groups: automatic userspace notification of idle cgroups\")\nCc: stable@vger.kernel.org # v2.6.24+\nSigned-off-by: \"Eric W. Biederman\" <ebiederm@xmission.com>\nSigned-off-by: Tejun Heo <tj@kernel.org>", "ground_truth": 1, "cwe": ["CWE-269"], "cve": "CVE-2022-0492", "cve_desc": "A vulnerability was found in the Linux kernel\u2019s cgroup_release_agent_write in the kernel/cgroup/cgroup-v1.c function. This flaw, under certain circumstances, allows the use of the cgroups v1 release_agent feature to escalate privileges and bypass the namespace isolation unexpectedly.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `cgroup_release_agent_write` is responsible for writing a release agent path to a cgroup's root structure. It is called when a user writes to a specific kernel filesystem (kernfs) file associated with cgroup release agent configuration.\n\n2. The function first checks for a compile-time assertion using `BUILD_BUG_ON` to ensure that `cgrp->root->release_agent_path` is at least `PATH_MAX` in size. This is a good defensive measure to prevent buffer overflow due to insufficient buffer size.\n\n3. It then locks the cgroup using `cgroup_kn_lock_live`, ensuring that the cgroup structure is valid and not being freed during the operation. This prevents use-after-free issues.\n\n4. The function acquires `release_agent_path_lock` to protect concurrent access to the `release_agent_path` field.\n\n5. It uses `strstrip(buf)` to remove leading and trailing whitespace from the input buffer `buf`. This is a good practice to avoid unintended whitespace in the path.\n\n6. Then it uses `strlcpy` to copy the stripped buffer into `cgrp->root->release_agent_path`. The `strlcpy` function is safe because it takes a size parameter and ensures null termination, preventing buffer overflow. The size used is `sizeof(cgrp->root->release_agent_path)`, which was validated at compile time to be at least `PATH_MAX`.\n\n7. After copying, the function releases the lock and unlocks the cgroup.\n\n8. The function returns `nbytes`, which is the number of bytes written.\n\nKey security considerations:\n- `strlcpy` is used with a known, safe size (validated at compile time).\n- Input is stripped of whitespace.\n- The buffer size is guaranteed to be large enough via `BUILD_BUG_ON`.\n- Proper locking is used to prevent race conditions.\n- No dynamic allocation or unsafe string operations are used.\n\nThere is no evidence of buffer overflow, race condition, or injection vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 207700, "project": "EternalTerminal", "commit_id": "900348bb8bc96e1c7ba4888ac8480f643c43d3c3", "project_url": "https://github.com/MisterTea/EternalTerminal", "commit_url": "https://github.com/MisterTea/EternalTerminal/commit/900348bb8bc96e1c7ba4888ac8480f643c43d3c3", "commit_message": "red fixes (#468)\n\n* red fixes\n\n* remove magic number", "ground_truth": 1, "cwe": ["CWE-362"], "cve": "CVE-2022-24950", "cve_desc": "A race condition exists in Eternal Terminal prior to version 6.2.0 that allows an authenticated attacker to hijack other users' SSH authorization socket, enabling the attacker to login to other systems as the targeted users. The bug is in UserTerminalRouter::getInfoForId().", "vuln": 0, "reasoning": "Let's think step-by-step. This code defines a method `getInfoForId` that takes a string `id` and looks up the corresponding `TerminalUserInfo` in a map called `idInfoMap`. If the `id` is not found in the map (i.e., `it == idInfoMap.end()`), the code logs a fatal error using `STFATAL` and presumably terminates the program.\n\nKey points to consider:\n- The function returns `it->second` only when the `id` is found. If not found, it triggers a fatal error and does not return a value (which would cause undefined behavior if the function is not declared to return void or if the caller expects a return value).\n- However, the function is declared to return `TerminalUserInfo`, which is a value type. If the `id` is not found, the function calls `STFATAL` and likely exits the program, but there is no explicit return statement after the `if` block. This leads to undefined behavior because the function does not return a value in the case where the `id` is not found.\n- The use of `STFATAL` suggests that the program is designed to crash in this case, which may be acceptable if the absence of an ID is a critical error and not exploitable by an attacker.\n- However, the real issue is not a direct security vulnerability like buffer overflow, injection, or memory corruption, but rather a logical flaw: the function does not return a value in all control paths, which is a programming error that could lead to crashes or undefined behavior.\n- But from a security perspective, this is not a vulnerability per se unless the missing `return` leads to memory corruption or information disclosure. Since the function crashes on invalid input and does not expose sensitive data or allow arbitrary code execution, it does not introduce a direct security risk.\n- The function is not processing untrusted input in a dangerous way (e.g., no string manipulation that could overflow, no dynamic code execution, no unsafe memory access). The `id` is used as a key in a map lookup, which is safe.\n\nTherefore, while the code has a bug (missing return in error path), it does not constitute a security vulnerability in the traditional sense (e.g., buffer overflow, injection, etc.). The crash on invalid input is a defensive behavior, not an exploitable flaw.\n\n(2) NO: No security vulnerability."}
{"idx": 211506, "project": "zlib", "commit_id": "eff308af425b67093bab25f80f1ae950166bece1", "project_url": "https://github.com/madler/zlib", "commit_url": "https://github.com/madler/zlib/commit/eff308af425b67093bab25f80f1ae950166bece1", "commit_message": "Fix a bug when getting a gzip header extra field with inflate().\n\nIf the extra field was larger than the space the user provided with\ninflateGetHeader(), and if multiple calls of inflate() delivered\nthe extra header data, then there could be a buffer overflow of the\nprovided space. This commit assures that provided space is not\nexceeded.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-37434", "cve_desc": "zlib through 1.2.12 has a heap-based buffer over-read or buffer overflow in inflate in inflate.c via a large gzip header extra field. NOTE: only applications that call inflateGetHeader are affected. Some common applications bundle the affected zlib source code but may be unable to call inflateGetHeader (e.g., see the nodejs/node reference).", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step.\n\nThe code is a part of the zlib library's `inflate` function, which decompresses data compressed using the DEFLATE algorithm. This is a well-established, widely used, and heavily audited compression/decompression library. The function handles various states of the decompression process, including parsing headers (gzip/zlib), decoding Huffman codes, managing the sliding window, and validating checksums.\n\nKey aspects to evaluate for security vulnerabilities:\n\n1. **Input Validation**:\n   - The function begins with `inflateStateCheck(strm)` and checks for null pointers (`strm->next_out == Z_NULL`, `strm->next_in == Z_NULL && strm->avail_in != 0`), returning `Z_STREAM_ERROR` if invalid. This prevents null pointer dereferences.\n   - It validates the zlib/gzip header (magic number, compression method, window size), ensuring the input is a valid compressed stream.\n   - It checks for invalid block types, invalid code lengths, and invalid distance references.\n\n2. **Buffer Management**:\n   - The function uses `zmemcpy` to copy data from input to output, but only within bounds checked by `have` (available input) and `left` (available output).\n   - The `copy` variable is limited by `have` and `left`, preventing buffer overflows.\n   - The `MATCH` state carefully checks whether the offset is within the window bounds. If the offset is too far back, it checks `state->offset > state->dmax` (in `INFLATE_STRICT` mode), and if not, it uses a fallback path (`INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR`) that still limits the copy to `left` and `state->length`, preventing out-of-bounds writes.\n\n3. **Bounds Checking in Loops and State Transitions**:\n   - All loops (e.g., reading code lengths, decoding Huffman codes) are bounded by known values (`state->nlen`, `state->ndist`, `state->ncode`), which are derived from the input and validated early.\n   - The `lens` array is initialized with `order` and filled only up to `19` entries, and the `inflate_table` function ensures the code lengths are valid.\n\n4. **Checksum and Integrity Verification**:\n   - The function computes and verifies both Adler-32 and CRC-32 checksums (depending on the format), which prevents tampering with the compressed data.\n   - If the checksums don\u2019t match, it returns `Z_DATA_ERROR`, indicating corrupted data.\n\n5. **Use of `PULLBYTE()` and `NEEDBITS()`**:\n   - These macros are used to safely read bits from the input stream, ensuring that `have` is sufficient before accessing `next`. If not, the function exits to `inf_leave` or waits for more input.\n\n6. **Memory Safety**:\n   - The `updatewindow` function is called to manage the sliding window, and it returns `Z_MEM_ERROR` on failure, which is properly handled.\n   - The `state->window` is allocated with `state->wsize`, and all accesses are bounded by `state->wsize` and `state->wnext`.\n\n7. **No Use of Dangerous Functions**:\n   - No `strcpy`, `sprintf`, `gets`, or similar unsafe functions are used.\n   - All memory copies use `zmemcpy` with explicit length limits.\n\n8. **State Machine Design**:\n   - The state machine ensures that each state transition is guarded by proper checks, and invalid transitions lead to `BAD` state or error return.\n\n9. **Known Security History**:\n   - The zlib library has been extensively reviewed and has had vulnerabilities in the past (e.g., CVE-2016-9840, CVE-2017-12121), but those were due to specific edge cases in parsing or memory management. However, the current code snippet shows robust bounds checking, especially in the `MATCH` state, which handles distance validation carefully.\n\n10. **No Obvious Vulnerabilities**:\n    - There are no buffer overflows, use-after-free, integer overflows (all sizes are unsigned and checked), or format string vulnerabilities.\n    - The code handles edge cases (e.g., zero-length input, incomplete blocks) gracefully.\n\nConclusion: The code is well-structured, uses safe memory access patterns, performs thorough input validation, and includes proper error handling. It is part of a mature, secure library that has been hardened over years of use and auditing.\n\n(2) NO: No security vulnerability."}
{"idx": 212822, "project": "ghostpdl", "commit_id": "e1134d375e2ca176068e19a2aa9b040baffe1c22", "project_url": "https://github.com/ArtifexSoftware/ghostpdl", "commit_url": "http://git.ghostscript.com/?p=ghostpdl.git;a=commit;h=e1134d375e2ca176068e19a2aa9b040baffe1c22", "commit_message": "Bug 705156(1): Avoid double free of PCL error buffer", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-1350", "cve_desc": "A vulnerability classified as problematic was found in GhostPCL 9.55.0. This vulnerability affects the function chunk_free_object of the file gsmchunk.c. The manipulation with a malicious file leads to a memory corruption. The attack can be initiated remotely but requires user interaction. The exploit has been disclosed to the public as a POC and may be used. It is recommended to apply the patches to fix this issue.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `pcl_status_read` is designed to read data from a circular buffer (`pcs->status.buffer`) managed by a read and write position (`read_pos` and `write_pos`).\n\n2. The variable `count` is calculated as the minimum of:\n   - `max_data`: the maximum number of bytes the caller wants to read.\n   - `pcs->status.write_pos - pcs->status.read_pos`: the number of available bytes in the buffer.\n\n   This ensures that we do not read more data than is available or more than the caller requested.\n\n3. The `memcpy` call copies `count` bytes from `pcs->status.buffer + pcs->status.read_pos` to `data`. Since `count` is bounded by `max_data` and the available data in the buffer, this copy is within bounds \u2014 no buffer overflow is possible here.\n\n4. After copying, `pcs->status.read_pos` is incremented by `count`. This is correct for a circular buffer, as long as the buffer size is properly managed.\n\n5. The condition `if (pcs->status.read_pos == pcs->status.write_pos)` checks if the buffer is now empty. If so, it:\n   - Frees the buffer using `gs_free_object`.\n   - Resets both `read_pos` and `write_pos` to 0.\n\n   This is a critical point: freeing the buffer when it's empty and then resetting the pointers.\n\n6. However, there is a **serious security vulnerability** here: **use-after-free**.\n\n   - The buffer is freed when `read_pos == write_pos`.\n   - But the function does not check whether the buffer is still being used elsewhere (e.g., by other threads or functions).\n   - After freeing, the pointers `pcs->status.buffer` are set to `NULL` (implied by the free), but the function continues to use `pcs->status.buffer` in subsequent calls \u2014 **if the buffer is reallocated later, or if the memory is reused, this could lead to use-after-free**.\n   - More critically, if another thread or function accesses `pcs->status.buffer` after it's freed, it will result in undefined behavior, potentially exploitable.\n\n   Even worse: the function assumes that after freeing, the buffer is no longer used, but there is no synchronization or protection against concurrent access. This is a classic **use-after-free** vulnerability.\n\n7. Additionally, the function does not validate that `pcs->status.buffer` is non-NULL before using it in `memcpy` or `gs_free_object`. If the buffer was already freed and not reallocated, this could lead to a null pointer dereference or use of freed memory.\n\n8. The `min` function is used safely, but the logic around buffer management is flawed due to the premature freeing of the buffer without ensuring no other references exist.\n\nTherefore, this code contains a **use-after-free vulnerability** due to freeing the buffer when it's empty, without ensuring that no other code is still using it.\n\n(1) YES: A security vulnerability detected."}
{"idx": 200163, "project": "linux", "commit_id": "817b8b9c5396d2b2d92311b46719aad5d3339dbe", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/817b8b9c5396d2b2d92311b46719aad5d3339dbe", "commit_message": "HID: elo: fix memory leak in elo_probe\n\nWhen hid_parse() in elo_probe() fails, it forgets to call usb_put_dev to\ndecrease the refcount.\n\nFix this by adding usb_put_dev() in the error handling code of elo_probe().\n\nFixes: fbf42729d0e9 (\"HID: elo: update the reference count of the usb device structure\")\nReported-by: syzkaller <syzkaller@googlegroups.com>\nSigned-off-by: Dongliang Mu <mudongliangabcd@gmail.com>\nSigned-off-by: Jiri Kosina <jkosina@suse.cz>", "ground_truth": 1, "cwe": ["CWE-200"], "cve": "CVE-2022-27950", "cve_desc": "In drivers/hid/hid-elo.c in the Linux kernel before 5.16.11, a memory leak exists for a certain hid_parse error condition.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `elo_probe` is a driver probe function for a HID device, specifically for an Elo touch device. It is responsible for initializing the device and setting up necessary data structures.\n\n2. The function first checks if the device is a USB device using `hid_is_usb(hdev)`. If not, it returns -EINVAL. This is a valid check to ensure the driver only works with USB HID devices.\n\n3. It allocates memory for a private data structure `struct elo_priv` using `kzalloc` with `GFP_KERNEL`. If allocation fails, it returns -ENOMEM. This is a proper error handling pattern.\n\n4. It initializes a delayed work structure (`INIT_DELAYED_WORK`) for handling periodic tasks. This is used later to queue work if a broken firmware is detected.\n\n5. It retrieves the USB device via `interface_to_usbdev(to_usb_interface(hdev->dev.parent))` and gets a reference to it using `usb_get_dev()`. This is a standard way to get a USB device reference in kernel drivers.\n\n6. It sets the driver data for the HID device using `hid_set_drvdata(hdev, priv)`, which associates the private data with the device.\n\n7. It calls `hid_parse(hdev)` to parse the device's report descriptor. If this fails, it logs an error and jumps to `err_free` to clean up.\n\n8. It calls `hid_hw_start(hdev, HID_CONNECT_DEFAULT)` to start the hardware layer. If this fails, it logs an error and jumps to `err_free`.\n\n9. It checks if the firmware is broken using `elo_broken_firmware(priv->usbdev)`. If so, it logs a message and queues a delayed work item using `queue_delayed_work(wq, &priv->work, ELO_PERIODIC_READ_INTERVAL)`.\n\n10. The cleanup path (`err_free`) calls `kfree(priv)` to free the allocated memory and returns the error code.\n\nNow, let's look for potential security vulnerabilities:\n\n- The code does not perform any input validation on user-controlled data (e.g., from the device's report descriptor or USB descriptors), but this is typical for HID drivers \u2014 the HID core handles parsing and validation.\n- The `elo_broken_firmware` function is called with `priv->usbdev`, which is a valid USB device pointer obtained from the kernel's USB subsystem. There is no indication that this function performs unsafe operations or exposes a vulnerability.\n- The `queue_delayed_work` call is safe because it uses a global workqueue (`wq`) and a properly initialized work structure. The delay interval is a constant (`ELO_PERIODIC_READ_INTERVAL`), which is not user-controlled.\n- All memory allocations are checked, and cleanup is performed properly in the error path.\n- There is no use of unsafe string functions, buffer overflows, or direct user input manipulation.\n- The driver does not expose any user-controllable data to unsafe operations.\n\nThe code follows standard kernel driver patterns and includes proper error handling and resource management.\n\n(2) NO: No security vulnerability."}
{"idx": 197242, "project": "tensorflow", "commit_id": "537bc7c723439b9194a358f64d871dd326c18887", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887", "commit_message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385163909\nChange-Id: I2beb8d50649b6542db224c163033fbcbaa49314f", "ground_truth": 1, "cwe": ["CWE-908"], "cve": "CVE-2021-37682", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The function `Prepare` is part of a TensorFlow Lite (TFLite) operator implementation.\n   - It uses `TF_LITE_ENSURE_EQ` and `TF_LITE_ENSURE_OK` macros to validate:\n     - The number of inputs and outputs (5 inputs, 1 output).\n     - The types of input tensors (only float32 or int8).\n     - Tensor dimensions (e.g., matching dimensions between input and weights_feature, correct rank, etc.).\n     - The shape of the state tensor (must be 2D with specific size).\n   - These checks are robust and prevent invalid or malformed tensor configurations from being processed.\n\n2. **Tensor Resizing and Memory Management**:\n   - The output tensor is resized using `context->ResizeTensor` with a size array derived from `batch_size` and `num_units`, both of which are validated from input tensors.\n   - Scratch tensors are allocated via `GetTemporarySafe` and resized using `context->ResizeTensor` with sizes derived from validated inputs.\n   - The `TfLiteIntArray` structures are properly created and managed (e.g., `TfLiteIntArrayCreate`, `TfLiteIntArrayCopy`, `TfLiteIntArrayFree`), and no memory leaks or buffer overflows are evident in the allocation/deallocation pattern.\n\n3. **Type Safety and Quantization Handling**:\n   - The code checks tensor types and handles quantized (int8) vs. floating-point (float32) cases appropriately.\n   - For full integer operations, it computes effective scales using quantization parameters and stores them in `op_data`. This is done safely using `QuantizeMultiplier`, which is a known safe function in TFLite.\n   - The use of `kTfLiteArenaRw` and `kTfLiteArenaRwPersistent` allocation types is standard in TFLite for temporary tensors and ensures memory is managed within the interpreter\u2019s arena.\n\n4. **Indexing and Array Access**:\n   - The code uses `node->temporaries` to manage temporary tensor indices.\n   - It assigns indices like `scratch_tensor_index + 1`, `+2`, etc., but only after ensuring that the `temporaries` array is properly allocated with sufficient size (1, 2, or 6 elements depending on the mode).\n   - The `TfLiteIntArrayCreate` calls are matched with the correct number of elements, and no out-of-bounds access occurs.\n\n5. **No User Input Directly Manipulated**:\n   - All inputs come from the TFLite interpreter and are validated via `GetInputSafe` and `GetOptionalInputTensor`.\n   - There is no direct string concatenation, dynamic memory allocation without bounds checking, or unsafe function calls (like `strcpy`, `sprintf`, etc.).\n   - The code does not perform any unsafe pointer arithmetic or buffer copying without size checks.\n\n6. **No Known Vulnerability Patterns**:\n   - No buffer overflows, use-after-free, integer overflows, or format string vulnerabilities are present.\n   - All tensor sizes are derived from validated input dimensions.\n   - The code follows TFLite\u2019s best practices for operator implementation.\n\nConclusion: The code performs comprehensive input validation, uses safe tensor management APIs, and avoids unsafe operations. It correctly handles different quantization modes and temporary tensor allocation without introducing security risks.\n\n(2) NO: No security vulnerability."}
{"idx": 195388, "project": "postgres", "commit_id": "160c0258802d10b0600d7671b1bbea55d8e17d45", "project_url": "https://github.com/postgres/postgres", "commit_url": "https://github.com/postgres/postgres/commit/160c0258802d10b0600d7671b1bbea55d8e17d45", "commit_message": "libpq: reject extraneous data after SSL or GSS encryption handshake.\n\nlibpq collects up to a bufferload of data whenever it reads data from\nthe socket.  When SSL or GSS encryption is requested during startup,\nany additional data received with the server's yes-or-no reply\nremained in the buffer, and would be treated as already-decrypted data\nonce the encryption handshake completed.  Thus, a man-in-the-middle\nwith the ability to inject data into the TCP connection could stuff\nsome cleartext data into the start of a supposedly encryption-protected\ndatabase session.\n\nThis could probably be abused to inject faked responses to the\nclient's first few queries, although other details of libpq's behavior\nmake that harder than it sounds.  A different line of attack is to\nexfiltrate the client's password, or other sensitive data that might\nbe sent early in the session.  That has been shown to be possible with\na server vulnerable to CVE-2021-23214.\n\nTo fix, throw a protocol-violation error if the internal buffer\nis not empty after the encryption handshake.\n\nOur thanks to Jacob Champion for reporting this problem.\n\nSecurity: CVE-2021-23222", "ground_truth": 1, "cwe": ["CWE-522"], "cve": "CVE-2021-23222", "cve_desc": "A man-in-the-middle attacker can inject false responses to the client's first few queries, despite the use of SSL certificate verification and encryption.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the code context\nThe function `PQconnectPoll` is part of the PostgreSQL libpq library, responsible for managing the asynchronous connection process to a PostgreSQL server. It handles:\n- Non-blocking socket operations\n- Connection state transitions (e.g., `CONNECTION_NEEDED`, `CONNECTION_STARTED`, `CONNECTION_MADE`, etc.)\n- SSL/GSSAPI negotiation\n- Authentication exchange\n- Server type checks (primary, standby, read-only, etc.)\n- Error handling and retry logic across multiple hosts/addresses\n\nThis is a core networking and security-sensitive component of a database client.\n\n---\n\n### Step 2: Look for potential security vulnerabilities\n\n#### A. **Buffer Overflows**\n- The code uses `snprintf(portstr, sizeof(portstr), \"%d\", thisport);` \u2014 this is safe because `portstr` is of size `MAXPGPATH` (typically 1024), and `thisport` is limited to 1\u201365535 (5 digits max), so no overflow.\n- `appendPQExpBuffer` and `appendPQExpBufferStr` are used throughout \u2014 these are safe functions designed to prevent buffer overflows by checking buffer bounds.\n- `getHostaddr` and `UNIXSOCK_PATH` are used with fixed-size buffers, and `strlen(portstr) >= UNIXSOCK_PATH_BUFLEN` is checked before use \u2014 this prevents overflow in Unix socket paths.\n- No use of unsafe functions like `strcpy`, `strcat`, `gets`, or `sprintf`.\n\n\u2705 No buffer overflow vulnerabilities.\n\n#### B. **Input Validation and Sanitization**\n- The `port` parameter is validated via `parse_int_param` and checked to be in range 1\u201365535.\n- Hostname/address resolution uses `pg_getaddrinfo_all`, which is a safe wrapper around `getaddrinfo`.\n- For `CHT_HOST_ADDRESS`, `AI_NUMERICHOST` is used to prevent DNS lookups, reducing risk of DNS rebinding or spoofing.\n- For `CHT_UNIX_SOCKET`, path length is checked against `UNIXSOCK_PATH_BUFLEN` \u2014 prevents path overflow.\n- `gai_strerror(ret)` is used safely with `appendPQExpBuffer`, which is safe.\n\n\u2705 Input validation is robust.\n\n#### C. **Use of `goto` and Control Flow**\n- The code uses `goto keep_going` and `goto error_return` extensively. While this can make code harder to follow, it does not introduce a security vulnerability by itself.\n- All `goto` targets are well-defined and do not bypass safety checks.\n- Error paths properly clean up state and set `conn->status = CONNECTION_BAD`.\n\n\u2705 No control flow hijacking or logic bypass.\n\n#### D. **Authentication and Encryption Handling**\n- SSL and GSSAPI negotiation is handled securely:\n  - `pqsecure_initialize` is called before SSL/GSS usage.\n  - `pqsecure_open_client` and `pqsecure_open_gss` are used for secure handshakes.\n  - `SO_NOSIGPIPE` and `MSG_NOSIGNAL` are used to prevent SIGPIPE issues.\n- The code checks `sslmode`, `gssencmode`, and `requirepeer` to enforce security policies.\n- `requirepeer` is only enforced on Unix sockets, and uses `getpeereid` (on Unix), which is secure.\n\n\u2705 Secure handling of authentication and encryption.\n\n#### E. **Error Message Handling**\n- Error messages are built using `appendPQExpBuffer`, which prevents format string vulnerabilities.\n- No use of `printf` with user-controlled format strings.\n- `libpq_gettext` is used for localization, but no dynamic format injection.\n\n\u2705 No format string vulnerabilities.\n\n#### F. **Memory Management**\n- `free(conn->connip)` is called before `strdup`, preventing memory leaks.\n- `PQclear(res)` is called on `PGresult` objects before returning.\n- `release_conn_addrinfo(conn)` is called when done with address list.\n- `pqDropConnection`, `pqDropServerData`, and `pqClearAsyncResult` are used to clean up state.\n\n\u2705 No memory leaks or dangling pointer issues.\n\n#### G. **Race Conditions or State Management**\n- The function manages a state machine (`conn->status`) and uses flags like `try_next_host`, `try_next_addr`, `reset_connection_state_machine`, etc.\n- These are updated atomically in context of a single-threaded connection process (libpq is not thread-safe by default, but this is expected).\n- No shared state between threads is exposed.\n\n\u2705 No race conditions detected.\n\n#### H. **Potential for Infinite Loops or Denial of Service?**\n- The `keep_going` label allows looping through states.\n- However, the loop is bounded by:\n  - Maximum number of hosts (`conn->nconnhost`)\n  - Maximum number of addresses per host (`ai_next`)\n  - Retry limits (e.g., `sslmode=\"prefer\"` only retries once)\n- The code does not allow infinite retries without progress.\n\n\u2705 No infinite loop or DoS risk.\n\n---\n\n### Step 3: Final Assessment\nThe code is part of a well-maintained, security-critical library (libpq). It:\n- Uses safe string and buffer functions\n- Validates all inputs rigorously\n- Handles encryption and authentication securely\n- Manages memory and state properly\n- Avoids unsafe operations\n- Has no known vulnerabilities in the logic or control flow\n\nThere are no exploitable security flaws in this function.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 196328, "project": "vim", "commit_id": "409510c588b1eec1ae33511ae97a21eb8e110895", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/409510c588b1eec1ae33511ae97a21eb8e110895", "commit_message": "patch 8.2.5050: using freed memory when searching for pattern in path\n\nProblem:    Using freed memory when searching for pattern in path.\nSolution:   Make a copy of the line.", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-1968", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `find_pattern_in_path` is part of a Vim-like editor (likely Vim or Neovim) and is responsible for searching for a pattern in a file and its included files (e.g., via `#include` directives in C). It supports:\n- Searching in the current buffer or included files.\n- Handling nested includes (via a stack of files).\n- Matching patterns with regex, case sensitivity, word boundaries, etc.\n- Actions like showing matches, expanding completions, jumping to matches, etc.\n\nIt uses:\n- Regular expressions via `vim_regcomp` and `vim_regexec`.\n- File I/O via `mch_fopen`, `vim_fgets`, `fclose`.\n- Memory management with `alloc`, `vim_free`, `lalloc_clear`.\n- String manipulation with `STRNCPY`, `skipwhite`, `find_word_start/end`, etc.\n\n---\n\n### Step 2: Identify potential security issues\n\n#### (A) Input validation and buffer handling\n- The function takes `char_u *ptr` (the search pattern) and uses it in `sprintf` to build a regex pattern:\n  ```c\n  pat = alloc(len + 5);\n  if (pat == NULL)\n      goto fpip_end;\n  sprintf((char *)pat, whole ? \"\\\\<%.*s\\\\>\" : \"%.*s\", len, ptr);\n  ```\n  - `len` is the length of `ptr`, and `ptr` is user-controlled.\n  - `sprintf` is used with `%.*s`, which is safe **if** the length is properly bounded.\n  - Since `len` is passed as a parameter and `ptr` is of length `len`, this is **safe** from buffer overflow because `sprintf` will only copy `len` characters.\n  - However, `sprintf` is still risky if the format string is not controlled \u2014 but here it is hardcoded: `\"%.*s\"` or `\"\\\\<%.*s\\\\>\"`.\n\n  \u2705 **No buffer overflow here** due to proper use of `.*` with length.\n\n#### (B) Regular expression compilation\n- The pattern is compiled with `vim_regcomp(pat, magic_isset() ? RE_MAGIC : 0)`.\n- `vim_regcomp` is assumed to be a safe regex engine (like PCRE or Vim's own), and it's not known to have vulnerabilities in this context.\n- No user-controlled regex is directly passed to a system call or interpreted in an unsafe way.\n\n\u2705 **No regex injection vulnerability** \u2014 the pattern is properly sanitized via `sprintf` and `vim_regcomp` handles it safely.\n\n#### (C) File name handling\n- The function uses `find_file_name_in_path` and `file_name_in_line` to extract file names from `#include` lines.\n- These functions are likely designed to extract file paths from lines like:\n  ```c\n  #include \"file.h\"\n  #include <stdio.h>\n  ```\n- The code checks for `\\\\zs` and `\\\\ze` in the `inc_opt` pattern, which are Vim regex constructs for \"start of match\" and \"end of match\".\n- The extracted file name is used in `mch_fopen` and `vim_fgets`.\n\n\u26a0\ufe0f **Potential risk**: If the `inc_opt` pattern (from `curbuf->b_p_inc` or `p_inc`) is user-controlled and contains malicious regex, it could lead to:\n- Path traversal (e.g., `#include \"../malicious.h\"`).\n- Or, if `inc_opt` is used to extract a filename from a line, and the regex is crafted to extract a malicious path, it could lead to reading arbitrary files.\n\nBut:\n- `inc_opt` is a user-configurable option (`'include'`), which is **not** directly user input in the function.\n- The function uses `strstr((char *)inc_opt, \"\\\\zs\")` to detect if `\\zs` is present \u2014 this is a **static check**, not dynamic parsing.\n- The actual file name extraction is done via `find_file_name_in_path` and `file_name_in_line`, which are likely designed to extract valid file names from `#include` lines and **do not allow arbitrary path traversal**.\n\n\u2705 **No path traversal vulnerability** \u2014 the file name extraction is constrained by the context of `#include` lines and uses safe parsing.\n\n#### (D) Memory management\n- The function uses `alloc`, `vim_free`, `lalloc_clear`, and `ALLOC_MULT` \u2014 all standard Vim memory management functions.\n- All allocated memory is freed in `fpip_end` via `vim_free` and `fclose`.\n- No memory leaks are apparent.\n\n\u2705 **No memory corruption or leak**.\n\n#### (E) Use of `vim_fgets` and `file_line`\n- `file_line` is allocated with `alloc(LSIZE)` \u2014 a fixed size.\n- `vim_fgets` is used to read lines from files.\n- `LSIZE` is likely a constant (e.g., 2048), and `vim_fgets` is designed to not overflow the buffer.\n\n\u2705 **No buffer overflow in file reading**.\n\n#### (F) Use of `msg_outtrans_attr` and `msg_home_replace_hl`\n- These functions are used to display file names in the UI.\n- They are not used to execute code or run shell commands.\n- They do not use `sprintf` or `printf` with user-controlled format strings.\n\n\u2705 **No format string vulnerability**.\n\n#### (G) Use of `vim_regexec` and `regmatch`\n- The `regmatch` struct is used to store results of regex matching.\n- No use of `regexec` with untrusted input in a way that could cause denial of service (e.g., catastrophic backtracking) \u2014 but this is a **potential** risk.\n\n\u26a0\ufe0f **Catastrophic backtracking?**\n- If the user provides a malicious regex pattern (e.g., `a+` in a long string), it could cause performance issues.\n- However, this is a **denial-of-service (DoS)** risk, not a **security vulnerability** in the traditional sense (like code execution or data leak).\n- The function does not allow arbitrary regex input from the user \u2014 the pattern is built from `ptr` and `whole`, which are controlled by the user, but the pattern is not directly passed to `vim_regcomp` without sanitization.\n\nBut: `vim_regcomp` is known to be safe against catastrophic backtracking in Vim (it uses a safe engine).\n\n\u2705 **No exploitable DoS** \u2014 the regex engine is robust.\n\n---\n\n### Step 3: Summary of findings\n- No buffer overflows.\n- No format string vulnerabilities.\n- No path traversal or arbitrary file access.\n- No memory leaks or corruption.\n- No unsafe use of `sprintf`, `strcpy`, or similar.\n- Regex handling is safe and bounded.\n- File name extraction is context-aware and does not allow arbitrary paths.\n\nThe function is well-structured and uses safe practices throughout.\n\n---\n\n### Final Decision\n(2) NO: No security vulnerability."}
{"idx": 202943, "project": "lua", "commit_id": "42d40581dd919fb134c07027ca1ce0844c670daf", "project_url": "https://github.com/lua/lua", "commit_url": "https://github.com/lua/lua/commit/42d40581dd919fb134c07027ca1ce0844c670daf", "commit_message": "Save stack space while handling errors\n\nBecause error handling (luaG_errormsg) uses slots from EXTRA_STACK,\nand some errors can recur (e.g., string overflow while creating an\nerror message in 'luaG_runerror', or a C-stack overflow before calling\nthe message handler), the code should use stack slots with parsimony.\n\nThis commit fixes the bug \"Lua-stack overflow when C stack overflows\nwhile handling an error\".", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-33099", "cve_desc": "An issue in the component luaG_runerror of Lua v5.4.4 and below leads to a heap-buffer overflow when a recursive error occurs.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `luaG_runerror` is a Lua runtime error handler that is called when a runtime error occurs in Lua code.\n\n2. The function takes a format string `fmt` and variable arguments (`...`), which are processed using `va_list` and `va_start`/`va_end`.\n\n3. The error message is constructed using `luaO_pushvfstring(L, fmt, argp)`, which is a Lua function that formats a string using the provided format string and arguments, and pushes the result onto the Lua stack.\n\n4. The function then checks if the current call frame (`ci`) is a Lua function (via `isLua(ci)`), and if so, it appends source file and line number information to the error message using `luaG_addinfo`.\n\n5. Finally, it calls `luaG_errormsg(L)`, which presumably terminates the program or throws an error, depending on the Lua runtime behavior.\n\n6. Key security considerations:\n   - The function uses `va_list` and `va_start`/`va_end` correctly, which is standard for variadic functions.\n   - The `luaO_pushvfstring` function is a safe wrapper that handles formatting and memory allocation safely within the Lua VM context.\n   - The format string `fmt` is passed directly to `luaO_pushvfstring`, which is responsible for parsing and formatting the string. However, if the format string itself is controlled by an attacker (e.g., via user input), this could lead to format string vulnerabilities.\n\n7. But here's the critical point: `luaG_runerror` is not intended to be called directly with user-controlled format strings. It is a low-level error handler used internally by the Lua VM. The format strings passed to it are typically hardcoded or derived from internal Lua source code (e.g., \"attempt to call a non-function\", \"bad argument #1 to 'func'\"), not from user input.\n\n8. Furthermore, `luaO_pushvfstring` is designed to be safe: it does not use `printf`-style format specifiers in a way that would allow arbitrary memory access (e.g., it does not use `%n` or other dangerous specifiers in a way that could be exploited), and it operates within the Lua VM's memory management system, which includes garbage collection and stack bounds checking.\n\n9. Therefore, even if an attacker could somehow influence the format string (which is highly unlikely in practice), the Lua VM's internal error handling is not exposed to untrusted input in a way that would allow exploitation.\n\n10. No buffer overflows, format string vulnerabilities, or memory corruption are evident in this code path.\n\n(2) NO: No security vulnerability."}
{"idx": 202688, "project": "ghostpdl", "commit_id": "450da26a76286a8342ec0864b3d113856709f8f6", "project_url": "https://github.com/ArtifexSoftware/ghostpdl", "commit_url": "https://git.ghostscript.com/?p=ghostpdl.git;a=commit;h=450da26a76286a8342ec0864b3d113856709f8f6", "commit_message": "Bug 701785: fixed sanitizer heap-buffer-overflow in lprn_is_black().\n\nIn contrib/lips4/gdevlprn.c:lprn_is_black(), it seems that bpl is not\nnecessarily a multiple of lprn->nBw, so we need to explicitly avoid straying\ninto the next line's data.\n\nThis also avoids accessing beyond our buffer if we are already on the last\nline, and so fixes the sanitizer error.\n\nFixes:\n    ./sanbin/gs -sOutputFile=tmp -sDEVICE=lips2p ../bug-701785.pdf", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2020-16287", "cve_desc": "A buffer overflow vulnerability in lprn_is_black() in contrib/lips4/gdevlprn.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `lprn_is_black` checks whether a block of pixels in a printer device's image buffer is black (i.e., contains non-zero values). It takes parameters:\n   - `pdev`: a pointer to a printer device context.\n   - `r`, `h`: likely row and height parameters (possibly related to positioning).\n   - `bx`: block x-coordinate.\n\n2. The function extracts:\n   - `bh`: block height (from `lprn->nBh`).\n   - `bpl`: bytes per scan line (from `gdev_mem_bytes_per_scan_line(pdev)`).\n   - `maxY`: maximum valid y-coordinate in the image buffer, computed as `(lprn->BlockLine / lprn->nBh) * lprn->nBh`. This suggests the image is divided into blocks of height `nBh`.\n\n3. The key computation is:\n   ```c\n   y0 = (r + h - bh) % maxY;\n   ```\n   This computes the starting y-offset for the block. However, note that `maxY` is derived from `lprn->BlockLine` and `lprn->nBh`. If `maxY` is zero (e.g., if `BlockLine` is zero or `nBh` is zero), then the modulo operation `% maxY` will cause a division by zero, leading to undefined behavior.\n\n4. The function does not validate that `maxY` is non-zero before performing the modulo operation. If `maxY == 0`, then `y0 = (r + h - bh) % 0` is undefined behavior (division by zero), which can lead to crashes or unpredictable results.\n\n5. Additionally, `lprn->nBh` and `lprn->BlockLine` are fields of the `gx_device_lprn` structure, which are user-controlled or externally set. If these values are manipulated (e.g., via malformed input or memory corruption), `maxY` could become zero.\n\n6. The loop then accesses `lprn->ImageBuf` using:\n   ```c\n   p = &lprn->ImageBuf[(y0 + y) * bpl + bx * lprn->nBw];\n   ```\n   If `y0 + y` exceeds the actual height of the image buffer, or if `bx * lprn->nBw` exceeds the buffer bounds, this could result in out-of-bounds memory access.\n\n7. However, the main issue is the modulo operation with `maxY` \u2014 if `maxY == 0`, the modulo is undefined. This is a critical flaw because it can lead to a crash or undefined behavior, which may be exploitable in certain contexts (e.g., denial of service or potentially memory corruption).\n\n8. The function does not check whether `maxY` is zero before using it in the modulo operation. This is a classic case of a division-by-zero vulnerability in a modulo operation.\n\n(1) YES: A security vulnerability detected."}
{"idx": 206043, "project": "gimp", "commit_id": "c57f9dcf1934a9ab0cd67650f2dea18cb0902270", "project_url": "https://github.com/GNOME/gimp", "commit_url": "https://git.gnome.org/browse/gimp/commit/?id=c57f9dcf1934a9ab0cd67650f2dea18cb0902270", "commit_message": "Bug 790784 - (CVE-2017-17784) heap overread in gbr parser / load_image.\n\nWe were assuming the input name was well formed, hence was\nnul-terminated. As any data coming from external input, this has to be\nthorougly checked.\nSimilar to commit 06d24a79af94837d615d0024916bb95a01bf3c59 but adapted\nto older gimp-2-8 code.", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2017-17784", "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer over-read in load_image in plug-ins/common/file-gbr.c in the gbr import parser, related to mishandling of UTF-8 data.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **File Opening and Input Validation**:\n   - The function opens a file using `g_open` with `O_RDONLY | _O_BINARY`, which is appropriate for binary file reading.\n   - It checks if `fd == -1` and returns an error if the file cannot be opened. This prevents use of invalid file descriptors.\n\n2. **Header Reading and Byte Order Handling**:\n   - The code reads a `BrushHeader` structure using `read(fd, &bh, sizeof(BrushHeader))`. This is a fixed-size read, so no buffer overflow occurs here.\n   - The fields of `bh` are converted from network byte order (`g_ntohl`) to host byte order. This is correct for handling endianness in cross-platform binary formats.\n\n3. **Sanitization of Header Fields**:\n   - The code checks:\n     - `bh.width` and `bh.height` are non-zero and \u2264 `GIMP_MAX_IMAGE_SIZE`.\n     - `bh.bytes` is one of: 1, 2, 4, or 18.\n     - The product `G_MAXSIZE / bh.width / bh.height / bh.bytes` must be \u2265 1, which ensures that the total memory size (`size = width * height * bytes`) does not overflow `gsize` (typically `size_t`).\n   - This is a critical check: it prevents integer overflow when computing `size = bh.width * bh.height * bh.bytes`. Without this, an attacker could craft a header with large values that cause overflow, leading to a small allocation and subsequent buffer overflow when reading data.\n\n4. **Version and Magic Number Validation**:\n   - The code checks `bh.version` and `bh.magic_number` to ensure the file is a supported brush format.\n   - For version 1, it adjusts the header size and rewinds the file descriptor using `lseek(fd, -8, SEEK_CUR)`. This is safe because the file is already read up to the header, and the rewind is within the previously read data.\n   - For version 3, it handles a special case where `bh.bytes == 18` is converted to 2 (for compatibility), and otherwise rejects unsupported formats.\n   - The `default` case rejects unknown versions, preventing processing of unknown or malicious formats.\n\n5. **Name Parsing**:\n   - If `bn_size > 0`, it reads a name string of that size into a temporary buffer.\n   - It then converts the string from an unknown encoding to UTF-8 using `gimp_any_to_utf8`, which is safe and handles invalid UTF-8 gracefully by reporting an error.\n   - The name is properly freed if invalid.\n\n6. **Memory Allocation and Data Reading**:\n   - The code computes `size = bh.width * bh.height * bh.bytes` and allocates `g_malloc(size)`.\n   - The earlier check `G_MAXSIZE / bh.width / bh.height / bh.bytes < 1` ensures that this multiplication cannot overflow `gsize`, so the allocation is safe.\n   - It then reads `size` bytes into `brush_buf` using `read(fd, brush_buf, size)`. This is safe because:\n     - The size is validated and bounded.\n     - The read is for exactly `size` bytes, and the function checks `read(...) != size` before proceeding.\n   - If the read fails, it cleans up and returns.\n\n7. **Post-Processing Based on `bh.bytes`**:\n   - For `bh.bytes == 1`: It checks for a legacy pattern header. If found, it reads additional data and converts the format to RGBA (4 bytes per pixel). The code carefully checks the size of the pattern header and uses `lseek` to skip the rest of the pattern data. The `read` calls are bounded by known sizes.\n   - For `bh.bytes == 2`: It converts 16-bit values to 8-bit grayscale. The conversion uses `guint16` and `gfloat`, and the loop is bounded by `bh.width * bh.height`. The `g_malloc` for the new buffer is again validated by the earlier size check.\n   - The `default` case does nothing, which is safe.\n\n8. **Image Creation and Drawing**:\n   - The code creates a new image using `gimp_image_new` with validated dimensions.\n   - It attaches a parasite with the name, which is properly freed.\n   - It creates a layer and uses `gimp_pixel_rgn_set_rect` to copy the pixel data into the drawable.\n   - The `brush_buf` is freed after use.\n\n9. **Final Cleanup and Error Handling**:\n   - All resources (file descriptor, name, buffers) are properly freed on error paths.\n   - The function returns `image_ID` on success, or `-1` on failure.\n\n10. **Potential Risks**:\n    - **Integer Overflow**: The key risk is integer overflow in `size = width * height * bytes`. However, the code explicitly checks:\n      ```c\n      (G_MAXSIZE / bh.width / bh.height / bh.bytes < 1)\n      ```\n      This ensures that the product `width * height * bytes` would exceed `G_MAXSIZE` (which is typically `SIZE_MAX`), so the allocation would be impossible. This check prevents overflow and underflow.\n    - **Untrusted Input**: The file is treated as untrusted, but all size computations are validated before allocation.\n    - **File Descriptor Use**: The file descriptor is closed on all exit paths, including error paths.\n    - **Memory Safety**: All allocations are checked, and all reads are bounded by validated sizes.\n\nConclusion: The code performs comprehensive input validation, especially around size calculations, preventing integer overflow and buffer overflows. It uses safe functions (`g_malloc`, `g_free`, `read`, `lseek`) with proper error checking. All paths clean up resources.\n\n(2) NO: No security vulnerability."}
{"idx": 214364, "project": "php-src", "commit_id": "e6c48213c22ed50b2b987b479fcc1ac709394caa", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commit;h=e6c48213c22ed50b2b987b479fcc1ac709394caa", "commit_message": "Fix bug #72606: heap-buffer-overflow (write) simplestring_addn simplestring.c", "ground_truth": 1, "cwe": ["CWE-119"], "cve": "CVE-2016-6296", "cve_desc": "Integer signedness error in the simplestring_addn function in simplestring.c in xmlrpc-epi through 0.54.2, as used in PHP before 5.5.38, 5.6.x before 5.6.24, and 7.x before 7.0.9, allows remote attackers to cause a denial of service (heap-based buffer overflow) or possibly have unspecified other impact via a long first argument to the PHP xmlrpc_encode_request function.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `simplestring_addn` is designed to append a specified number of characters (`add_len`) from `source` to a `simplestring` object (`target`).\n\n2) Input validation is performed:\n   - Checks if both `target` and `source` are non-null.\n   - Checks if `target->str` is null, and if so, initializes it via `simplestring_init_str()`.\n\n3) Memory reallocation logic:\n   - Checks if the current length plus the new length plus 1 (for null terminator) exceeds the current buffer size.\n   - Calculates a new size: `target->len + add_len + 1`.\n   - Increases the size by doubling the current `target->size` as an increment (`incr = target->size * 2`).\n   - Aligns the new size to multiples of `SIMPLESTRING_INCR` (via `newsize - (newsize % incr) + incr`).\n   - Uses `realloc` to resize the buffer.\n\n4) Data copying:\n   - If `add_len` is non-zero, copies `add_len` bytes from `source` to `target->str + target->len`.\n   - Updates `target->len` and null-terminates the string.\n\n5) Potential issues to consider:\n   - The function uses `memcpy` to copy `add_len` bytes from `source`. However, there is no validation that `source` is null-terminated or that `add_len` is valid (e.g., not negative or larger than actual available data).\n   - The function assumes `source` contains at least `add_len` valid bytes. If `add_len` is larger than the actual data in `source`, this leads to undefined behavior (buffer over-read).\n   - The function does not validate `add_len` for negative values. If `add_len` is negative, the condition `target->len + add_len + 1 > target->size` might be true even if `add_len` is negative, but the `memcpy` call would still attempt to copy a negative number of bytes, which is undefined behavior.\n   - The `memcpy` call with `add_len` bytes could read beyond the bounds of `source` if `add_len` is not properly constrained.\n\n6) Critical flaw:\n   - The function does not validate that `add_len` is non-negative or that `source` has at least `add_len` bytes available.\n   - This allows an attacker to pass a negative `add_len`, which would cause `memcpy` to copy a negative number of bytes (undefined behavior), or a large `add_len` that exceeds the actual data in `source`, leading to buffer over-read (information disclosure or crash).\n\n7) Conclusion:\n   - The function lacks proper bounds checking on `add_len` and assumes `source` is valid for `add_len` bytes.\n   - This is a classic example of a buffer over-read vulnerability due to unvalidated input length.\n\n(1) YES: A security vulnerability detected."}
{"idx": 196705, "project": "tensorflow", "commit_id": "11ced8467eccad9c7cb94867708be8fa5c66c730", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/11ced8467eccad9c7cb94867708be8fa5c66c730", "commit_message": "Fix UB in SparseTensorDenseAdd\n\nAdded more input validation to avoid nullptr dereferencing and array index\nout of bounds issues.\n\nPiperOrigin-RevId: 446192704", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2022-29206", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.SparseTensorDenseAdd` does not fully validate the input arguments. In this case, a reference gets bound to a `nullptr` during kernel execution. This is undefined behavior. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `ValidateInputs` is designed to validate input tensors for a sparse-dense operation, likely in a machine learning framework like TensorFlow.\n\n2. The function checks:\n   - `a_indices` must be a matrix (2D tensor) using `IsMatrix`.\n   - `a_values` and `a_shape` must be vectors (1D tensors) using `IsVector`.\n   - The number of elements in `a_shape` (i.e., the rank of the sparse tensor) must equal the number of dimensions in `b` (the dense tensor).\n   - Each dimension of `a_shape` must exactly match the corresponding dimension of `b` (no broadcasting is allowed).\n\n3. The validation is performed using:\n   - `TensorShapeUtils::IsMatrix` and `IsVector` \u2014 these are likely safe checks that validate tensor rank.\n   - `a_shape->NumElements()` \u2014 returns the number of elements in the `a_shape` vector, which is the rank of the sparse tensor.\n   - `b->dims()` \u2014 returns the number of dimensions of the dense tensor.\n   - `a_shape->flat<Index>()` \u2014 creates a flat view of the `a_shape` tensor, which is then used in a loop to compare each dimension with `b->dim_size(i)`.\n\n4. The loop iterates over `i` from 0 to `b->dims() - 1`, and compares `a_shape_flat(i)` with `b->dim_size(i)`. This is safe because:\n   - The earlier check ensures `a_shape->NumElements() == b->dims()`, so the loop bounds are valid.\n   - `a_shape_flat(i)` accesses the i-th element of the `a_shape` vector, which is guaranteed to exist due to the size check.\n   - No dynamic memory allocation or unsafe string/pointer operations are involved.\n   - All inputs are validated before use, and no untrusted data is directly used in unsafe operations (like string formatting or memory copying without bounds checks).\n\n5. There are no known buffer overflows, use-after-free, null pointer dereferences, or injection vulnerabilities. The function performs strict input validation and returns early on invalid input, which is a good security practice.\n\n6. The function does not perform any unsafe operations such as:\n   - Direct memory copying without bounds checking.\n   - String concatenation with user input.\n   - Unchecked array indexing.\n   - Use of unsafe functions (e.g., `strcpy`, `gets`, etc.).\n\n7. The use of `flat<Index>()` is safe here because the size has already been validated via `NumElements()` and `dims()`.\n\nConclusion: The function performs comprehensive and safe input validation with proper bounds checking and early returns on invalid inputs. No security vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 202276, "project": "vim", "commit_id": "57df9e8a9f9ae1aafdde9b86b10ad907627a87dc", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/57df9e8a9f9ae1aafdde9b86b10ad907627a87dc", "commit_message": "patch 8.2.4151: reading beyond the end of a line\n\nProblem:    Reading beyond the end of a line.\nSolution:   For block insert only use the offset for correcting the length.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-0318", "cve_desc": "Heap-based Buffer Overflow in vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Context and Purpose**:\n   - The function `block_insert` is part of a text editor (likely Vim or a Vim-like editor).\n   - It handles inserting or appending text (`s`) into lines within a specified range (`oap->start.lnum` to `oap->end.lnum`), with considerations for tab expansion, virtual columns, multi-byte characters, and text properties.\n   - It uses `ml_get()` to retrieve line content, `alloc()` to allocate new memory for modified lines, and `ml_replace()` to update the line.\n\n2. **Input Sources**:\n   - The input `s` is a string passed to the function, likely from user input (e.g., from a register or command).\n   - The `oap` (oparg_T) structure contains line numbers and other metadata.\n   - The `bdp` (block_def) structure contains information about the block being inserted (e.g., start/end columns, tab stops, padding).\n\n3. **Memory Management and Buffer Handling**:\n   - The function uses `alloc()` to allocate memory for the new line content:  \n     ```c\n     newp = alloc(STRLEN(oldp) + spaces + s_len + ... + 1);\n     ```\n     The size is computed based on:\n     - Length of the original line (`STRLEN(oldp)`),\n     - Number of spaces to insert (`spaces`),\n     - Length of the input string `s` (`s_len`),\n     - Additional space for tab padding (`ts_val - spaces`), and\n     - `count` (which is derived from tab handling).\n   - The allocation is followed by `mch_memmove` and `vim_memset` to copy and fill data.\n   - The function ensures null termination with `+1` in the allocation.\n\n4. **Potential Vulnerabilities**:\n   - **Buffer Overflow Risk?**:\n     - The allocation size is computed carefully using `STRLEN(oldp)`, `s_len`, and other derived values.\n     - The use of `mch_memmove` and `vim_memset` is bounded by the computed size.\n     - There is no direct use of unsafe functions like `strcpy`, `strcat`, or `sprintf`.\n     - The `count` variable is derived from `ts_val - 1` or `spaces`, but it is used only in `vim_memset` and `STRMOVE` with bounds checked by the allocation size.\n     - The `has_mbyte` block adjusts offsets to avoid multi-byte character boundaries \u2014 this is a good practice.\n   - **Integer Overflow?**:\n     - The allocation size is computed using `unsigned` and `int` types. However, `STRLEN(oldp)` and `s_len` are `unsigned`, and `spaces`, `count`, `ts_val` are `int`. If any of these values are negative, it could cause issues.\n     - But note: `spaces` is clamped to 0 if negative (`if (spaces < 0) spaces = 0;`), and `count` is derived from `ts_val - 1` or `ts_val - spaces`, which are non-negative due to `ts_val` being a column value and `spaces` being non-negative.\n     - `ts_val` is derived from `bdp->start_char_vcols` or `bdp->end_char_vcols`, which are virtual column positions \u2014 these are non-negative.\n     - Therefore, all components of the allocation size are non-negative, and the total size is bounded by the actual data being copied.\n   - **Use of User Input**:\n     - The string `s` is user-provided (likely from a register or command).\n     - However, it is copied using `mch_memmove` with a size equal to `s_len`, which is safe because `s_len` is `STRLEN(s)` and the allocation includes space for it.\n     - There is no string formatting or interpretation of `s` as code or command \u2014 it's treated purely as text to be inserted.\n   - **No Code Injection or Execution**:\n     - The function does not execute any code based on `s`.\n     - It does not use `eval`, `system`, or similar functions.\n     - It does not interpret `s` as a command, script, or format string.\n\n5. **Security Best Practices**:\n   - Proper bounds checking via `alloc` size calculation.\n   - Use of `mch_memmove` and `vim_memset` with size parameters.\n   - Clamping of negative values (`spaces < 0` \u2192 `0`).\n   - Handling of multi-byte characters correctly.\n   - No use of unsafe string functions.\n\n6. **Conclusion**:\n   - The code carefully computes the required memory size based on actual data.\n   - All memory operations are bounded by the allocated size.\n   - There is no evidence of buffer overflow, integer overflow, or code injection.\n   - The function is designed to handle arbitrary text input safely, with proper alignment and multi-byte handling.\n\n(2) NO: No security vulnerability."}
{"idx": 198350, "project": "owntone-server", "commit_id": "246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "project_url": "https://github.com/owntone/owntone-server", "commit_url": "https://github.com/owntone/owntone-server/commit/246d8ae0cef27377e5dfe9ee3ad87e864d6b6266", "commit_message": "[misc] Fix use-after-free in net_bind()\n\nThanks to Ba Jinsheng for reporting this bug", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2021-38383", "cve_desc": "OwnTone (aka owntone-server) through 28.1 has a use-after-free in net_bind() in misc.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Sanitization**:\n   - The function `net_bind` takes a `port` (a `short unsigned *`), `type`, and `log_service_name`.\n   - The port value is read via `*port`, and then formatted into a string using `snprintf(strport, sizeof(strport), \"%hu\", *port);`.\n   - The `strport` buffer is of size 8, which is sufficient to hold any valid port number (0\u201365535), as the maximum string representation of 65535 is 5 characters. So, no buffer overflow here.\n\n2. **Use of `getaddrinfo`**:\n   - The function uses `getaddrinfo(cfgaddr, strport, &hints, &servinfo)` to resolve the address and port.\n   - `cfgaddr` comes from `cfg_getstr(cfg_getsec(cfg, \"general\"), \"bind_address\")`, which is user-configurable.\n   - However, `getaddrinfo` is safe as long as the input strings are properly null-terminated and within bounds. The `strport` is safely formatted with `snprintf` and bounded by `sizeof(strport)`, so no buffer overflow.\n   - The `hints` structure is properly initialized (all zeroed via `{0}`), and `ai_socktype` is filtered using `type & (SOCK_STREAM | SOCK_DGRAM)` to avoid invalid socket types.\n   - `ai_family` is set based on a config option (`ipv6`), which is reasonable and safe as long as the config is trusted.\n\n3. **Socket Creation and Options**:\n   - `socket()` is called with `ptr->ai_family`, `type | SOCK_CLOEXEC`, and `ptr->ai_protocol`. The `SOCK_CLOEXEC` flag is set, which is a good security practice to prevent file descriptor leaks.\n   - `setsockopt` is used for `SO_KEEPALIVE`, `SO_REUSEADDR`, and `IPV6_V6ONLY` (for IPv6). These are standard and safe configurations.\n\n4. **Binding and Address Resolution**:\n   - `bind()` is called with `ptr->ai_addr` and `ptr->ai_addrlen`, which are from `getaddrinfo` and thus validated by the system.\n   - After binding, `getsockname()` is used to retrieve the actual bound address and port. This is safe and correct.\n   - The port is updated via `net_port_get(port, ...)` \u2014 this is likely a safe function that reads the actual port assigned (e.g., if 0 was passed, the OS assigned a random port).\n\n5. **Error Handling and Resource Management**:\n   - The code properly closes file descriptors in error paths (`close(fd)` in `error:` label).\n   - `freeaddrinfo(servinfo)` is called after use, preventing memory leaks.\n   - The loop over `servinfo` uses `ptr->ai_next`, and `fd` is closed before reuse \u2014 no resource leaks.\n\n6. **Potential Security Concerns**:\n   - **Config Injection**: The `cfgaddr` comes from configuration. If the configuration is untrusted or can be manipulated by an attacker, it could lead to binding to unexpected addresses (e.g., `localhost`, `0.0.0.0`, or even malicious hostnames). However, this is not a direct vulnerability in the code itself \u2014 it's a configuration risk, not a code-level flaw.\n   - **Hostname Resolution**: `getaddrinfo` resolves `cfgaddr`, which could be a hostname. If the hostname is controlled by an attacker, it could lead to DNS rebinding or other attacks. However, this is not a vulnerability in the code \u2014 it's a risk of using dynamic DNS in configuration, which is acceptable if the config source is trusted.\n   - **Port Validation**: The code does not validate that `*port` is within a safe range (e.g., 1\u201365535), but `snprintf` and `getaddrinfo` will handle invalid port values (e.g., 0 or >65535) gracefully \u2014 `getaddrinfo` will fail if the port is invalid. So, no buffer overflow or injection here.\n\n7. **No Use of Unsafe Functions**:\n   - No `strcpy`, `sprintf`, `gets`, or similar unsafe functions are used.\n   - All string operations are bounded (`snprintf`, `sizeof` checks).\n   - No direct user input is used in unsafe contexts.\n\n8. **Final Assessment**:\n   - The code uses safe functions (`getaddrinfo`, `snprintf`, `setsockopt`, `bind`, `getsockname`).\n   - All buffers are properly sized and null-terminated.\n   - Error handling is robust.\n   - No exploitable vulnerabilities like buffer overflows, format string issues, or injection attacks are present.\n\n(2) NO: No security vulnerability."}
{"idx": 195399, "project": "tensorflow", "commit_id": "045deec1cbdebb27d817008ad5df94d96a08b1bf", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/045deec1cbdebb27d817008ad5df94d96a08b1bf", "commit_message": "Prevent null pointer dereference in `mutable_graph_view`\n\nPiperOrigin-RevId: 409684472\nChange-Id: I577eb9d9ac470fcec0501423171e739a4ec0cb5c", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `IsIdentityConsumingSwitch` takes a `MutableGraphView` and a `NodeDef` (representing a node in a computational graph, likely from a framework like TensorFlow).\n\n2. It checks if the given node is an Identity node (either a standard Identity or an Identity with a single input) and has at least one input.\n\n3. If the node is an Identity and has an input, it parses the first input using `ParseTensorName`, which extracts the node name and tensor name from a string like \"node_name:tensor_name\".\n\n4. It then checks if the parsed tensor ID is controlling (i.e., represents a control dependency) using `IsTensorIdControlling`. If it is, the function returns `false`.\n\n5. Otherwise, it retrieves the input node from the graph using `graph.GetNode(tensor_id.node())`.\n\n6. Finally, it checks whether that input node is a Switch node using `IsSwitch(*input_node)`.\n\n7. The function returns `true` only if:\n   - The node is an Identity (or IdentityNSingleInput),\n   - It has an input,\n   - The input is not a control dependency,\n   - The input node is a Switch node.\n\n8. Now, consider potential security vulnerabilities:\n   - The function operates on a graph structure and uses `ParseTensorName` to extract node names from input strings.\n   - `ParseTensorName` is typically a safe function that parses tensor names with a known format (e.g., \"node:output\"), and it's unlikely to be vulnerable to buffer overflows or injection if implemented correctly.\n   - The function does not perform any string manipulation that could lead to buffer overflows or code injection.\n   - It does not directly execute user input or interact with external systems.\n   - The `graph.GetNode()` call is safe as long as the graph is internally consistent and the node name is valid \u2014 but this is assumed to be part of the framework's internal graph management.\n   - There is no dynamic code execution, no unsafe string formatting, no memory corruption patterns.\n\n9. The logic is purely about graph structure analysis \u2014 determining whether an Identity node consumes a Switch node as input. This is a static analysis task, not involving untrusted input in a way that could lead to exploitation.\n\n10. No evidence of buffer overflows, use-after-free, null pointer dereferences, or injection vulnerabilities is present. The function performs input validation (checking `node.input_size() > 0`, `IsTensorIdControlling`) and uses safe parsing.\n\n(2) NO: No security vulnerability."}
{"idx": 211567, "project": "clamav-devel", "commit_id": "c6870a6c857dd722dffaf6d37ae52ec259d12492", "project_url": "https://github.com/vrtadmin/clamav-devel", "commit_url": "https://github.com/vrtadmin/clamav-devel/commit/c6870a6c857dd722dffaf6d37ae52ec259d12492", "commit_message": "bb #6808", "ground_truth": 1, "cwe": ["CWE-189"], "cve": "CVE-2013-2020", "cve_desc": "Integer underflow in the cli_scanpe function in pe.c in ClamAV before 0.97.8 allows remote attackers to cause a denial of service (crash) via a skewed offset larger than the size of the PE section in a UPX packed executable, which triggers an out-of-bounds read.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `getsistring` reads a string from a file at a given offset `ptr` with length `len`.\n\n2) The function first checks if `len` is zero, returning NULL if so.\n\n3) It then limits `len` to a maximum of 400 bytes, which is a reasonable safeguard against excessively large allocations.\n\n4) It allocates memory using `cli_malloc(len)` for the string, which is appropriate for the expected size.\n\n5) It seeks to the specified file position with `fseek(f, ptr, SEEK_SET)`.\n\n6) It attempts to read `len` bytes into the allocated buffer with `fread(name, len, 1, f)`. The check `fread(...) != 1` ensures the full block was read.\n\n7) The critical part is the loop: `for (i = 0 ; i < len; i+=2) name[i/2] = name[i];`. This code copies every other byte from the input buffer to a new position, effectively skipping every second byte. This is a byte-shifting operation that reduces the data size by half.\n\n8) After the loop, it null-terminates the result with `name[i/2] = '\\0'`. Since `i` is incremented by 2 each time, when the loop ends, `i` will be the last value such that `i < len`. So `i/2` gives the number of characters copied.\n\n9) However, there's a critical issue: the function assumes that the input data is a sequence of bytes where every other byte is valid data, and the rest are padding or unused. But this is not guaranteed. The function reads `len` bytes from the file, but then only copies half of them (every other byte) into the output string.\n\n10) The problem is that the function does not validate the content of the data being read. It blindly copies every other byte, which could include arbitrary data from the file. If the file contains malicious data, this could lead to unexpected behavior.\n\n11) More importantly, the function does not check whether the data being read contains null bytes. Since the function uses `fread` to read raw bytes, and then copies them with a stride of 2, it's possible that a null byte appears in the middle of the data, which would prematurely terminate the string.\n\n12) However, the function does not use `strlen` or any other function that would be affected by null bytes in the middle of the data. Instead, it uses a loop that copies exactly `len/2` characters (rounded down), and then null-terminates at position `i/2`. This means the function will always produce a null-terminated string of length `len/2` (or less if `len` is odd), regardless of whether there are null bytes in the data.\n\n13) The real vulnerability is in the byte-shifting operation: `name[i/2] = name[i]`. This operation assumes that the input data is structured in a specific way (e.g., UTF-16 or some other format with padding). But if the data is not structured this way, the function could be misinterpreting the data.\n\n14) However, the function does not perform any dangerous operations like buffer overflows, format string vulnerabilities, or unsafe memory management. The memory allocation is bounded (max 400 bytes), and the function properly checks for allocation failure and read errors.\n\n15) The byte-shifting operation is not inherently insecure\u2014it's a deliberate transformation. The function is designed to extract every other byte, which might be intended for a specific format (e.g., converting from UTF-16 to UTF-8, or handling a packed format).\n\n16) The function correctly null-terminates the result, and the length is limited by the input size.\n\n17) There is no buffer overflow because the function only writes `len/2` characters into the allocated buffer of size `len`, and then null-terminates it.\n\n18) The function does not use any unsafe string functions like `strcpy` or `strcat`.\n\n19) The only potential issue is that the function might misinterpret the data format, but this is not a security vulnerability per se\u2014it's a functional issue.\n\n20) Since the function properly bounds the input, checks for errors, and does not introduce any exploitable behavior (like buffer overflows, use-after-free, or format string vulnerabilities), it does not contain a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 198399, "project": "uftpd", "commit_id": "0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd", "project_url": "https://github.com/troglobit/uftpd", "commit_url": "https://github.com/troglobit/uftpd/commit/0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd", "commit_message": "FTP: Fix buffer overflow in PORT parser, reported by Aaron Esau\n\nSigned-off-by: Joachim Nilsson <troglobit@gmail.com>", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2020-20276", "cve_desc": "An unauthenticated stack-based buffer overflow vulnerability in common.c's handle_PORT in uftpd FTP server versions 2.10 and earlier can be abused to cause a crash and could potentially lead to remote code execution.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `handle_PORT` processes a PORT command in a control protocol (likely FTP), where the client specifies an IP address and port for data connection.\n\n2) The input string `str` is parsed using `sscanf` with format \"%d,%d,%d,%d,%d,%d\" to extract six integers: a, b, c, d (for IP address octets), and e, f (for port components).\n\n3) The IP address is reconstructed using `sprintf(addr, \"%d.%d.%d.%d\", a, b, c, d)`.\n\n4) The code then validates the IP address using `inet_aton(addr, &(sin.sin_addr))`. This function checks if the string is a valid IPv4 address.\n\n5) The code stores the IP address in `ctrl->data_address` using `strlcpy`, with a size limit of `sizeof(ctrl->data_address)`.\n\n6) The port is calculated as `e * 256 + f`, which is correct for combining two 8-bit values into a 16-bit port number.\n\n7) The key security consideration: The input parsing via `sscanf` does not validate the range of the integers. The values a, b, c, d, e, f are read as integers without bounds checking. This means:\n   - Each octet (a, b, c, d) could be outside the valid range 0-255 (e.g., -1, 256, 1000)\n   - The port components e and f could be outside 0-255 range\n\n8) Although `inet_aton` will reject invalid IP addresses (e.g., 256.0.0.0), it's possible to construct an IP address that is syntactically valid but semantically incorrect (e.g., 256.0.0.0 is rejected, but 255.255.255.255 is valid). However, the real issue is that `sscanf` does not validate the range of the integers.\n\n9) The `sprintf` call to build the IP string could potentially lead to buffer overflow if the integers are extremely large (e.g., 1000000), but `sprintf` with %d will write the full decimal representation, and `addr` is of size `INET_ADDRSTRLEN` (16 bytes), which is sufficient for any valid IPv4 address (max 15 chars: \"255.255.255.255\").\n\n10) However, the real vulnerability is that `sscanf` does not validate the range of the input integers. For example, if a = 256, `inet_aton` will reject it, but if a = 255, b = 255, c = 255, d = 255, it's valid. But if a = 256, `inet_aton` will fail, so it's caught.\n\n11) The critical issue: `sscanf` does not validate that each octet is in 0-255 range. An attacker could provide values like 256, 257, etc., which `inet_aton` will reject, but the code doesn't validate the input before passing to `inet_aton`. However, since `inet_aton` is used and will reject invalid addresses, the final IP address is validated.\n\n12) The port calculation `e * 256 + f` could overflow if e or f are large, but since e and f are read as int, and the maximum value for a port is 65535, if e > 255 or f > 255, the result could be > 65535, but that's not a security issue per se.\n\n13) The real vulnerability: The code does not validate that the input integers are in the valid range (0-255 for octets, 0-255 for port components). However, `inet_aton` will reject any invalid IP address, so the final address is validated.\n\n14) But there's a subtle issue: `sscanf` with %d will accept negative numbers. For example, if a = -1, `sprintf` will produce \"-1.0.0.0\", which `inet_aton` will reject. So negative values are caught.\n\n15) The code is robust because it uses `inet_aton` to validate the final IP address. Even if the input integers are out of range, `inet_aton` will reject the address.\n\n16) The `strlcpy` is safe because it uses `sizeof(ctrl->data_address)`.\n\n17) The port calculation is correct and within 0-65535 range if e and f are in 0-255, but if they are not, the port could be invalid, but that's not a security vulnerability.\n\n18) The only potential issue is that `sscanf` does not validate the range, but since `inet_aton` is used to validate the final address, and it's a standard function that checks for valid IPv4 addresses, the code is safe.\n\n19) Therefore, despite the lack of explicit range checking on the input integers, the use of `inet_aton` ensures that only valid IPv4 addresses are accepted.\n\n20) The code is secure against buffer overflows and injection attacks because:\n   - `sprintf` is used with %d, which is safe for integers\n   - `strlcpy` is used with size limit\n   - `inet_aton` validates the IP address\n   - No direct string concatenation with user input without validation\n\n(2) NO: No security vulnerability."}
{"idx": 215103, "project": "mongo", "commit_id": "a5e2f9b0a236462a6d1ca129583c617f111367b4", "project_url": "https://github.com/mongodb/mongo", "commit_url": "https://github.com/mongodb/mongo/commit/a5e2f9b0a236462a6d1ca129583c617f111367b4", "commit_message": "SERVER-59071 Treat '$sample' as unsharded when connecting directly to shards\n\n(cherry picked from commit f3604b901d688c194de5e430c7fbab060c9dc8e0)", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2021-32037", "cve_desc": "An authorized user may trigger an invariant which may result in denial of service or server exit if a relevant aggregation request is sent to a shard. Usually, the requests are sent via mongos and special privileges are required in order to know the address of the shards and to log in to the shards of an auth enabled environment.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Context and Purpose**:\n   - The function `createRandomCursorExecutor` is part of a database query execution system (likely MongoDB).\n   - It creates a plan executor for a `$sample` aggregation stage, using a random cursor for efficient sampling.\n   - It uses a `TrialStage` to dynamically choose between an optimized plan (e.g., random cursor or bucket sampling) and a fallback plan (e.g., collection scan), based on early trial results.\n\n2. **Input Validation and Safety Checks**:\n   - The function checks that the operation context holds a collection lock (`invariant(opCtx->lockState()->isCollectionLockedForMode(...))`), which is a correct safety measure to prevent race conditions.\n   - It validates `sampleSize` against `numRecords` using thresholds (`kMaxSampleRatioForRandCursor`, `kCoefficient`, etc.) to avoid inefficient or unsafe sampling strategies.\n   - For time-series collections, it uses `gTimeseriesBucketMaxCount` and `kMinBucketFullness` to ensure that the bucket sampling strategy is only used when buckets are sufficiently full, preventing inefficiency and potential denial-of-service from excessive retries.\n\n3. **Use of `TrialStage`**:\n   - The `TrialStage` is used to run a trial of the optimized plan (e.g., random cursor or `SampleFromTimeseriesBucket`) for up to `kMaxPresampleSize` (100) documents.\n   - If the trial shows that the optimized plan is not performing well (e.g., too many orphaned documents, low bucket fullness), it falls back to a safe plan (e.g., `CollectionScan`).\n   - This is a well-designed safety mechanism to avoid performance degradation or resource exhaustion due to poor plan choices.\n\n4. **Memory and Resource Management**:\n   - The code uses `std::unique_ptr` and `std::make_unique` appropriately, ensuring RAII and preventing memory leaks.\n   - `WorkingSet` is managed correctly via `std::unique_ptr`, and the plan executor is created with proper ownership transfer.\n\n5. **No User Input Directly Manipulated**:\n   - The function does not directly process untrusted user input in a way that could lead to injection, buffer overflow, or code execution.\n   - All inputs (`sampleSize`, `numRecords`, `bucketUnpacker`, etc.) are validated and used in a controlled, bounded manner.\n\n6. **No Known Vulnerabilities**:\n   - There are no calls to unsafe functions (e.g., `strcpy`, `strcat`, `sprintf`).\n   - No use of raw pointers without ownership semantics.\n   - No off-by-one errors, integer overflows, or unchecked array accesses.\n   - The logic for fallback plans is sound and prevents unsafe execution paths.\n\n7. **Security Best Practices Followed**:\n   - Defense in depth via fallback plans.\n   - Input validation with safe thresholds.\n   - Use of safe C++ constructs (smart pointers, RAII).\n   - Proper handling of sharded and time-series collection cases.\n\nConclusion: The code is well-structured, includes proper validation, uses safe patterns, and implements fallback mechanisms to prevent performance degradation or resource exhaustion. There are no exploitable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 197128, "project": "mruby", "commit_id": "f72315575f78a9a773adbce0ee7d3ec33434cb76", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/f72315575f78a9a773adbce0ee7d3ec33434cb76", "commit_message": "codegen.c: fix a argument generation bug in array assignment.", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-0717", "cve_desc": "Out-of-bounds Read in GitHub repository mruby/mruby prior to 3.2.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - This is a code generation function (`gen_assignment`) in a Ruby interpreter (likely mruby) that handles assignment operations to various types of variables (global, local, instance, class, constants, etc.).\n   - It takes a scope (`codegen_scope *s`), a syntax tree node (`node *tree`), a right-hand side expression (`node *rhs`), and stack pointer (`sp`) and value flag (`val`).\n   - The function generates bytecode for assignments based on the type of the left-hand side (LHS) node.\n\n2. **Key Operations**:\n   - The function uses `codegen(s, rhs, VAL)` to generate code for the right-hand side expression and then pops the result.\n   - It uses `gen_setxv`, `gen_move`, `genop_2`, `genop_3`, `genjmp2_0`, `push`, `pop`, `pop_n`, etc., to generate low-level bytecode.\n   - The function handles different node types like `NODE_GVAR`, `NODE_LVAR`, `NODE_IVAR`, `NODE_CVAR`, `NODE_CONST`, `NODE_COLON2`, `NODE_CALL`, `NODE_SCALL`, `NODE_MASGN`, etc.\n   - It correctly manages the stack pointer (`sp`) and uses `cursp()` to get the current stack pointer.\n\n3. **Potential Security Concerns**:\n   - **Stack Management**: The code carefully manages the stack using `push()`, `pop()`, `pop_n()`, and `cursp()`. There is no apparent stack overflow or underflow because:\n     - `push()` is only called when needed (e.g., for return values, temporary storage).\n     - `pop()` and `pop_n()` are used to clean up after operations.\n     - The stack pointer is updated correctly in all branches.\n   - **Input Validation**: The function checks node types via `switch (type)` and handles unknown types with `codegen_error`. This prevents undefined behavior from malformed input.\n   - **No Direct User Input Handling**: This function is part of a compiler/interpreter codegen phase. It does not directly process untrusted user input. Instead, it operates on parsed AST nodes, which are already validated during parsing.\n   - **No Buffer Overflows or Memory Corruption**: There are no calls to unsafe functions like `strcpy`, `memcpy`, or direct memory writes. All operations are through well-defined bytecode generation functions that manage stack and memory safely.\n   - **No Injection Vulnerabilities**: Since this is not a string-based interpreter or template engine, there is no risk of code injection (e.g., via string concatenation or eval).\n   - **Use of `nsym(tree)` and `new_sym`**: These are used to get symbol names from the AST. The interpreter ensures that symbols are valid and interned, so no arbitrary symbol injection is possible.\n\n4. **Critical Checks**:\n   - The function does not perform any unchecked memory access.\n   - It does not use unbounded loops or recursion without depth limits.\n   - It does not expose raw memory or stack to user-controlled data.\n   - All operations are within the bounds of the interpreter\u2019s internal stack and symbol table.\n\n5. **Conclusion**:\n   - The code is part of a safe, statically-typed code generation system in a well-designed interpreter.\n   - It follows proper stack discipline and type checking.\n   - There are no known vulnerabilities such as buffer overflows, use-after-free, or injection attacks.\n   - The only potential issue is a possible logic error in stack management, but the code appears to handle `sp` and `cursp()` correctly in all branches.\n\n(2) NO: No security vulnerability."}
{"idx": 204019, "project": "squashfs-tools", "commit_id": "e0485802ec72996c20026da320650d8362f555bd", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/e0485802ec72996c20026da320650d8362f555bd", "commit_message": "Unsquashfs: additional write outside destination directory exploit fix\n\nAn issue on github (https://github.com/plougher/squashfs-tools/issues/72)\nshowed how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and '..') can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nSince then it has been shown that specially crafted Squashfs filesystems\nthat contain a symbolic link pointing outside of the destination directory,\ncoupled with an identically named file within the same directory, can\ncause Unsquashfs to write files outside of the destination directory.\n\nSpecifically the symbolic link produces a pathname pointing outside\nof the destination directory, which is then followed when writing the\nduplicate identically named file within the directory.\n\nThis commit fixes this exploit by explictly checking for duplicate\nfilenames within a directory.  As directories in v2.1, v3.x, and v4.0\nfilesystems are sorted, this is achieved by checking for consecutively\nidentical filenames.  Additionally directories are checked to\nensure they are sorted, to avoid attempts to evade the duplicate\ncheck.\n\nVersion 1.x and 2.0 filesystems (where the directories were unsorted)\nare sorted and then the above duplicate filename check is applied.\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 1, "cwe": ["CWE-200"], "cve": "CVE-2021-41072", "cve_desc": "squashfs_opendir in unsquash-2.c in Squashfs-Tools 4.5 allows Directory Traversal, a different vulnerability than CVE-2021-40153. A squashfs filesystem that has been crafted to include a symbolic link and then contents under the same filename in a filesystem can cause unsquashfs to first create the symbolic link pointing outside the expected directory, and then the subsequent write operation will cause the unsquashfs process to write through the symbolic link elsewhere in the filesystem.", "vuln": 0, "reasoning": "No response from agent"}
{"idx": 197593, "project": "njs", "commit_id": "ad48705bf1f04b4221a5f5b07715ac48b3160d53", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ad48705bf1f04b4221a5f5b07715ac48b3160d53", "commit_message": "Fixed frame allocation from an awaited frame.\n\nnjs_function_frame_save() is used to save the awaited frame when \"await\"\ninstruction is encountered. The saving was done as a memcpy() of\nexisting runtime frame.\n\nnjs_function_frame_alloc() is used to alloc a new function frame, this\nfunction tries to use a spare preallocated memory from the previous\nframe first.  Previously, this function might result in \"use-after-free\"\nwhen invoked from a restored frame saved with njs_function_frame_save().\nBecause njs_function_frame_save() left pointers to the spare memory of\nthe original frame which may be already free when saved frame is\nrestored.\n\nThe fix is to erase fields for the spare memory from the saved frame.\n\nThis closes #469 issue on Github.", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-27007", "cve_desc": "nginx njs 0.7.2 is affected suffers from Use-after-free in njs_function_frame_alloc() when it try to invoke from a restored frame saved with njs_function_frame_save().", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `njs_function_frame_save` is responsible for saving the current execution frame in a JavaScript VM context. It copies values from the active frame to a new frame structure.\n\n2) Key operations:\n- It calculates the number of values to copy using `njs_function_frame_value_count(active)`\n- It allocates space for values by calculating offsets from the `native` frame structure\n- It copies values from `start` to `end` using a while loop\n- It processes arguments and local variables, ensuring they are valid\n\n3) Critical analysis points:\n- The function uses `njs_function_frame_value_count(active)` to determine how many values to copy\n- The `new` pointer is calculated as `(njs_value_t **) ((u_char *) native + NJS_FRAME_SIZE)`\n- The `value` pointer is calculated as `(njs_value_t *) (new + value_count + function->u.lambda->temp)`\n- The function copies values from `start` to `end` using `*p = *start++` and `*new++ = p++`\n- The loop condition is `start < end`, which is correct for copying values\n- The function ensures that invalid values are set to undefined using `njs_set_undefined(p)`\n\n4) Potential vulnerabilities:\n- The function uses `njs_function_frame_value_count(active)` to determine the number of values to copy\n- The `value_count` is used to calculate the size of the new array\n- The function assumes that `value_count` is valid and that the memory layout is correct\n- The function does not validate the `value_count` against the available memory\n- However, the `value_count` is obtained from `njs_function_frame_value_count(active)`, which is a function that should return a valid count based on the active frame\n- The function uses `njs_is_valid(p)` to check if a value is valid before copying\n- The function ensures that invalid values are set to undefined\n\n5) The function appears to be well-structured and uses proper bounds checking:\n- It uses `start < end` as the loop condition\n- It uses `njs_is_valid()` to check values\n- It sets invalid values to undefined\n- The memory layout calculations are based on known constants and function parameters\n\n6) There is no evidence of buffer overflow, out-of-bounds access, or memory corruption. The function correctly calculates the number of values to copy and uses proper bounds checking.\n\n(2) NO: No security vulnerability."}
{"idx": 195055, "project": "tensorflow", "commit_id": "2b7100d6cdff36aa21010a82269bc05a6d1cc74a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/2b7100d6cdff36aa21010a82269bc05a6d1cc74a", "commit_message": "Cleanup and remove duplicate validation in `SparseCount`.\n\nWe have valdiation that is duplicated, checking different conditions, in different formats and failing to capture all cases. This should fix all the previous bugs.\n\nPiperOrigin-RevId: 414886981\nChange-Id: Ibf0bba0beb057b76d505324bb9487565daf95f01", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-21740", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `SparseCountSparseOutput` is vulnerable to a heap overflow. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function starts by retrieving four inputs: `indices`, `values`, `shape`, and `weights`.\n   - It checks that `indices` is a 2D tensor using `TensorShapeUtils::IsMatrix`, which prevents malformed input shapes.\n   - It checks that `shape` has at least one element (`NumElements() != 0`), which is necessary for valid tensor construction.\n   - It validates that `weights` and `values` have the same shape if `use_weights` is true \u2014 this prevents mismatched dimensions.\n   - It ensures that all elements in `shape` are non-negative, which is critical for valid tensor dimensions.\n\n2. **Bounds Checking on Indices**:\n   - The code extracts `indices_values` as a matrix of `int64_t` and iterates over each index.\n   - For each index, it computes the batch (`batch = indices_values(idx, 0)`), and checks if `batch >= num_batches`.\n   - If so, it uses `OP_REQUIRES` to fail with an error message \u2014 this prevents out-of-bounds access to `per_batch_counts[batch]`.\n   - This is a critical safety check: it ensures that the batch index is within the valid range `[0, num_batches)`.\n\n3. **Value Index Bounds**:\n   - The code checks that `value >= 0` and `value < maxlength_` (if `maxlength_ > 0`).\n   - It also checks `value >= minlength_` implicitly via `GetOutputSize`, but the key point is that `value` is used as an index into `per_batch_counts[batch][value]`.\n   - The condition `value >= 0 && (maxlength_ <= 0 || value < maxlength_)` ensures that `value` is within a valid range before being used as an index.\n   - This prevents out-of-bounds access to the inner array (i.e., `per_batch_counts[batch]`).\n\n4. **Use of `per_batch_counts`**:\n   - `per_batch_counts` is a `BatchedMap<W>` object, which is assumed to be a data structure that manages per-batch mappings.\n   - The code uses `per_batch_counts[batch][value]` to update counts or weights.\n   - The safety of this access depends on the internal implementation of `BatchedMap<W>`, but the code explicitly checks that `batch < num_batches` and `value` is within bounds before accessing it.\n   - Therefore, the access is guarded by prior validation.\n\n5. **No Buffer Overflows or Memory Corruption**:\n   - All array accesses are protected by explicit bounds checks.\n   - The use of `flat<T>()` and `matrix<int64_t>()` is safe because the input tensors are validated to have correct shapes.\n   - There is no use of unsafe functions like `strcpy`, `memcpy`, or direct pointer arithmetic.\n\n6. **No Injection or Code Execution Risks**:\n   - This is not a string manipulation or command execution context.\n   - The inputs are numeric tensors (indices, values, weights, shape), and the operations are mathematical or indexing-based.\n   - There is no dynamic code generation, SQL, or shell command execution.\n\n7. **No Integer Overflow or Underflow**:\n   - The code uses `int64_t` for indices and `T`/`W` for values, which are typically `int64_t` or `float` types.\n   - The checks like `num_values <= indices.shape().dim_size(0)` prevent overflows in loop bounds.\n   - The `maxlength_` and `minlength_` parameters are used to constrain `value`, preventing excessive indexing.\n\n8. **Error Handling and Early Exit**:\n   - The code uses `OP_REQUIRES` and `OP_REQUIRES_OK` to fail early on invalid inputs.\n   - This prevents further execution with malformed or malicious data.\n\nConclusion: All potential attack vectors (buffer overflows, out-of-bounds access, invalid indices, injection) are mitigated by comprehensive input validation and bounds checking. The code is defensively written and does not exhibit any known security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 204016, "project": "squashfs-tools", "commit_id": "e0485802ec72996c20026da320650d8362f555bd", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/e0485802ec72996c20026da320650d8362f555bd", "commit_message": "Unsquashfs: additional write outside destination directory exploit fix\n\nAn issue on github (https://github.com/plougher/squashfs-tools/issues/72)\nshowed how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and '..') can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nSince then it has been shown that specially crafted Squashfs filesystems\nthat contain a symbolic link pointing outside of the destination directory,\ncoupled with an identically named file within the same directory, can\ncause Unsquashfs to write files outside of the destination directory.\n\nSpecifically the symbolic link produces a pathname pointing outside\nof the destination directory, which is then followed when writing the\nduplicate identically named file within the directory.\n\nThis commit fixes this exploit by explictly checking for duplicate\nfilenames within a directory.  As directories in v2.1, v3.x, and v4.0\nfilesystems are sorted, this is achieved by checking for consecutively\nidentical filenames.  Additionally directories are checked to\nensure they are sorted, to avoid attempts to evade the duplicate\ncheck.\n\nVersion 1.x and 2.0 filesystems (where the directories were unsorted)\nare sorted and then the above duplicate filename check is applied.\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 1, "cwe": ["CWE-200"], "cve": "CVE-2021-41072", "cve_desc": "squashfs_opendir in unsquash-2.c in Squashfs-Tools 4.5 allows Directory Traversal, a different vulnerability than CVE-2021-40153. A squashfs filesystem that has been crafted to include a symbolic link and then contents under the same filename in a filesystem can cause unsquashfs to first create the symbolic link pointing outside the expected directory, and then the subsequent write operation will cause the unsquashfs process to write through the symbolic link elsewhere in the filesystem.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its directory entries, and constructing a linked list of directory entries (`struct dir_ent`).\n\n2. The function uses a fixed-size buffer `buffer` of size `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1`, which is aligned. This buffer is used to read directory entries. The size is carefully chosen to hold a directory entry (including the name) plus one extra byte for null termination.\n\n3. The function reads the directory header (`squashfs_dir_header_2`) and then iterates over `dir_count` directory entries. For each entry:\n   - It reads the `squashfs_dir_entry_2` structure using `read_directory_data`.\n   - It checks that `dire->size` is less than `SQUASHFS_NAME_LEN` (which is a safety check to prevent overly long filenames).\n   - It then reads the actual name into `dire->name` using `read_directory_data`, with a length of `dire->size + 1` (to include null terminator).\n   - It null-terminates the name explicitly: `dire->name[dire->size + 1] = '\\0'`.\n\n4. However, here's a critical issue: the buffer `buffer` is declared as:\n   ```c\n   char buffer[sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1]\n       __attribute__((aligned));\n   ```\n   This buffer is used to hold a `squashfs_dir_entry_2` structure and a name. But `squashfs_dir_entry_2` contains a `name` field that is a variable-length array (or pointer), but in this context, it's likely a fixed-size array or a pointer to a dynamically allocated name. However, the code uses `dire` as a pointer to this buffer, and then reads the name into `dire->name` using `read_directory_data(dire->name, ...)`.\n\n   The key problem is: **`dire->name` is a pointer within the `squashfs_dir_entry_2` structure, and it is not a fixed-size array in the buffer.** Instead, it is likely a pointer to a dynamically allocated name or a pointer to a field in the buffer. But the code does not allocate space for the name within the buffer \u2014 it assumes that `dire->name` points to a valid buffer.\n\n   However, in this code, `dire` is a pointer to `buffer`, and `dire->name` is a field within that buffer. But the size of `buffer` is `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1`. This implies that the `name` field is expected to be stored at the end of the `squashfs_dir_entry_2` structure, and the buffer is large enough to hold the entire entry including the name.\n\n   But here's the flaw: the `squashfs_dir_entry_2` structure likely has a `name` field that is a flexible array member or a pointer. If it's a flexible array member, then the buffer must be large enough to hold the structure plus the name. But the code uses `sizeof(squashfs_dir_entry_2)` \u2014 which does not include the flexible array member \u2014 so the buffer is only large enough for the structure, not the name.\n\n   However, the code does:\n   ```c\n   char buffer[sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1]\n   ```\n   This suggests that the `name` field is not part of the structure size, and the buffer is extended to hold the name. But then the code does:\n   ```c\n   res = read_directory_data(dire->name, &start, &offset, dire->size + 1);\n   ```\n   This reads `dire->size + 1` bytes into `dire->name`, which is a pointer within the `buffer`. But if `dire->name` is a pointer that points to a location within the `buffer`, and the buffer is only `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` bytes, then the `name` field must be placed at the end of the structure.\n\n   But the real issue is: **the code assumes that `dire->name` points to a valid buffer of size at least `dire->size + 1`, but it does not verify that the `name` field is actually located within the `buffer` or that the buffer is large enough.**\n\n   However, the buffer is declared as:\n   ```c\n   char buffer[sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1]\n   ```\n   and `dire` is a pointer to this buffer. So if the `squashfs_dir_entry_2` structure has a flexible array member for `name`, then the total size of the structure including the name is `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1`, which matches the buffer size.\n\n   But the code does:\n   ```c\n   res = read_directory_data(dire->name, &start, &offset, dire->size + 1);\n   ```\n   This reads `dire->size + 1` bytes into `dire->name`. But `dire->size` is the length of the name, and it is checked to be less than `SQUASHFS_NAME_LEN`. So `dire->size + 1` is at most `SQUASHFS_NAME_LEN + 1`, which is exactly the size of the buffer beyond the structure.\n\n   So the buffer is large enough to hold the name.\n\n   However, there is a **critical error in the null termination**:\n   ```c\n   dire->name[dire->size + 1] = '\\0';\n   ```\n   This line attempts to null-terminate the name at index `dire->size + 1`. But the name is stored in `dire->name` with length `dire->size`, so the valid indices are `0` to `dire->size`. The null terminator should be at `dire->size`, not `dire->size + 1`.\n\n   This is a **buffer overflow** in the name buffer: writing to `dire->name[dire->size + 1]` is writing one byte beyond the end of the name, which is undefined behavior and could overwrite adjacent memory.\n\n   Moreover, the `dire->name` field is part of the `buffer`, and the buffer is only `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` bytes. If `dire->size` is `SQUASHFS_NAME_LEN`, then `dire->name[dire->size + 1]` is at index `SQUASHFS_NAME_LEN + 1`, which is beyond the buffer (since the buffer is only `SQUASHFS_NAME_LEN + 1` bytes beyond the structure, and the name starts at the end of the structure).\n\n   But wait: the buffer is `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` bytes. The `name` field starts at `sizeof(squashfs_dir_entry_2)` offset. So the valid indices for `dire->name` are `0` to `SQUASHFS_NAME_LEN`. The null terminator should be at `dire->size`, not `dire->size + 1`.\n\n   Therefore, `dire->name[dire->size + 1] = '\\0'` is writing one byte beyond the end of the name buffer, which is a **buffer overflow**.\n\n   This is a classic buffer overflow vulnerability.\n\n5. The function also checks `dire->size >= SQUASHFS_NAME_LEN`, which is a good check, but it doesn't prevent the overflow because the check is only for `>=`, and if `dire->size` is `SQUASHFS_NAME_LEN`, then `dire->name[dire->size + 1]` is out of bounds.\n\n6. The `read_directory_data` function is used to read data into `dire->name`, but it is not clear if it performs bounds checking. However, the code assumes that the buffer is large enough, but the null termination is incorrect.\n\n7. The function also uses `strdup(dire->name)` to copy the name into `ent->name`. This is safe because `dire->name` is null-terminated (if the null termination were correct), but due to the overflow, it may not be.\n\n8. The null termination at `dire->name[dire->size + 1]` is **incorrect** and **overflows** the buffer.\n\nTherefore, this code contains a **buffer overflow vulnerability** due to incorrect null termination.\n\n(1) YES: A security vulnerability detected."}
{"idx": 197223, "project": "njs", "commit_id": "ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/ab1702c7af9959366a5ddc4a75b4357d4e9ebdc1", "commit_message": "Fixed typo while calculating module path length.\n\nThe issue was introduced in 77c398f26d7e (not released yet).", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-29379", "cve_desc": "Nginx NJS v0.7.3 was discovered to contain a stack overflow in the function njs_default_module_loader at /src/njs/src/njs_module.c. NOTE: multiple third parties dispute this report, e.g., the behavior is only found in unreleased development code that was not part of the 0.7.2, 0.7.3, or 0.7.4 release", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `njs_module_path` is responsible for resolving a module path by combining a directory path (`dir`) and a module name (`info->name`), then resolving the absolute path using `realpath`, and finally opening the file.\n\n2) The function uses a fixed-size buffer `src[NJS_MAX_PATH + 1]` to build the path string. The length of the combined path is checked against `NJS_MAX_PATH` using `njs_slow_path(length > NJS_MAX_PATH)`. This is a good defensive check to prevent buffer overflow.\n\n3) The path construction is done in stages:\n   - If `dir` is not NULL, it copies `dir->start` into `src` using `njs_cpymem`, which is a safe memory copy function (presumably bounds-checked).\n   - If the directory path doesn't end with '/', and `trail` is true, it appends a '/'.\n   - Then it appends `info->name.start` using `njs_cpymem` again.\n   - Finally, it null-terminates the string with `*p = '\\0'`.\n\n4) The `realpath` function is used to resolve symbolic links and normalize the path. This is a secure way to resolve paths and prevent path traversal attacks, as it resolves relative components like `..` and `.`.\n\n5) The `open` system call is used to open the file with `O_RDONLY`, and the file descriptor is stored in `info->fd`. The file path is stored in `info->path`.\n\n6) The function does not directly use user input in a dangerous way (e.g., string concatenation without validation). Instead, it uses structured data (`njs_str_t` for strings) and performs length checks before copying.\n\n7) The use of `njs_cpymem` suggests that the function is designed to be safe and avoid buffer overflows. The length checks are performed before any copy operation.\n\n8) The `realpath` function is called on the constructed path, which ensures that any symbolic links or relative path components are resolved safely, preventing path traversal attacks.\n\n9) There is no evidence of unsafe string operations, lack of bounds checking, or direct user input injection into system calls.\n\n10) The function properly validates input lengths and uses safe memory copy functions, and the final path resolution is done via `realpath`, which is a secure function for path normalization.\n\n(2) NO: No security vulnerability."}
{"idx": 195965, "project": "tensorflow", "commit_id": "30721cf564cb029d34535446d6a5a6357bebc8e7", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/30721cf564cb029d34535446d6a5a6357bebc8e7", "commit_message": "Fix tf.raw_ops.EditDistance vulnerability with negative indices.\n\nCheck that indices are non-negative. Fix several identical code sites.\nClean up grammar in error message.\n\nPiperOrigin-RevId: 445442017", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-29208", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.EditDistance` has incomplete validation. Users can pass negative values to cause a segmentation fault based denial of service. In multiple places throughout the code, one may compute an index for a write operation. However, the existing validation only checks against the upper bound of the array. Hence, it is possible to write before the array by massaging the input to generate negative values for `loc`. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Initialization**:\n   - The function `Compute` takes an `OpKernelContext* ctx` and retrieves several input tensors: `hypothesis_indices`, `hypothesis_values`, `hypothesis_shape`, `truth_indices`, `truth_values`, and `truth_shape`.\n   - Each input is validated using `OP_REQUIRES_OK`, which ensures that the input tensors are valid and properly allocated. This prevents null pointer dereferences and invalid tensor access.\n\n2. **Shape Validation**:\n   - The function calls `ValidateShapes` to ensure that the shapes and data of the input tensors are consistent and compatible.\n   - It then uses `TensorShapeUtils::MakeShape` to construct `hypothesis_st_shape` and `truth_st_shape` from the input shape tensors. This is safe as long as the input shape data is valid and within bounds.\n\n3. **Memory Allocation and Buffer Management**:\n   - The output tensor is allocated using `ctx->allocate_output(\"output\", output_shape, &output)`. The `output_shape` is computed based on the maximum dimensions of the hypothesis and truth tensors along each dimension (except the last one).\n   - The code checks that `output_elements > 0` to ensure the output tensor has at least one element, preventing zero-sized allocations.\n   - The output tensor is initialized to zero using `output_t.setZero()`, which is safe and prevents uninitialized memory usage.\n\n4. **Index Calculation and Bounds Checking**:\n   - The code computes `output_strides` to map multi-dimensional indices to linear indices in the output tensor.\n   - For each group (from `hypothesis_grouper` and `truth_grouper`), it computes a linear index `loc` using `std::inner_product` of the group coordinates and the strides.\n   - Crucially, **before writing to `output_t(loc)`**, the code checks:\n     ```cpp\n     OP_REQUIRES(ctx, loc < output_elements, ...)\n     ```\n     This ensures that the computed index `loc` is within the bounds of the output tensor. This is a critical safety check that prevents out-of-bounds memory writes.\n\n5. **Loop Logic and Control Flow**:\n   - The code processes groups from both `hypothesis_grouper` and `truth_grouper` in a merge-like fashion, comparing group keys (`g_truth` vs `g_hypothesis`).\n   - In each branch (equal, truth > hypothesis, hypothesis > truth), the same `loc < output_elements` check is performed before writing to `output_t(loc)`.\n   - The final two `while` loops handle remaining groups from either hypothesis or truth, and again, the bounds check is performed before any write.\n\n6. **No Untrusted Input Directly Used in Unsafe Operations**:\n   - All input data comes from tensors provided by the framework (via `ctx->input`), which are validated and trusted within the context of the computation.\n   - There are no string concatenations, format strings, or direct memory copying without bounds checks.\n   - The use of `std::inner_product` to compute indices is safe because the group coordinates are derived from valid tensor indices, and the bounds check ensures no overflow.\n\n7. **No Known Vulnerabilities**:\n   - No buffer overflows, use-after-free, null pointer dereferences, or integer overflows are present.\n   - All array accesses are protected by bounds checks.\n   - The code follows safe practices: input validation, bounds checking before memory access, and use of safe APIs.\n\n(2) NO: No security vulnerability."}
{"idx": 198374, "project": "tensorflow", "commit_id": "803404044ae7a1efac48ba82d74111fce1ddb09a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/803404044ae7a1efac48ba82d74111fce1ddb09a", "commit_message": "Fix security vulnerability with LSTMBlockCellOp\n\nPiperOrigin-RevId: 446028341", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-29200", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LSTMBlockCell` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate the ranks of any of the arguments to this API call. This results in `CHECK`-failures when the elements of the tensor are accessed. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a kernel implementation (likely for a machine learning framework like TensorFlow) that computes an LSTM (Long Short-Term Memory) block cell forward pass.\n\n2) The function takes multiple input tensors: x, cs_prev, h_prev, w, wci, wcf, wco, b, and computes several output tensors including i, cs, f, o, ci, co, h.\n\n3) The code performs extensive input validation:\n   - It checks that all input tensors are non-null using OP_REQUIRES_OK\n   - It validates tensor dimensions against expected shapes (batch_size, input_size, cell_size)\n   - It ensures that w_tensor has dimensions (input_size + cell_size) x (cell_size * 4)\n   - It ensures that b_tensor has dimension (cell_size * 4)\n   - It validates that cs_prev and h_prev have matching batch_size and cell_size dimensions\n\n4) The code properly allocates output tensors using ctx->allocate_output and ctx->forward_input_or_allocate_output, which are framework-provided functions that handle memory allocation safely.\n\n5) Temporary tensors (xh_tensor and gates_tensor) are allocated using ctx->allocate_temp, which is a safe method for temporary memory allocation within the context of the kernel.\n\n6) The actual computation is performed by a functor (LSTMBlockCellFprop) that operates on the tensor data. The functor is parameterized by device type, data type, and other compile-time flags.\n\n7) All operations are performed on tensors with validated dimensions, and there is no direct user input manipulation or string concatenation that could lead to injection attacks.\n\n8) The code does not perform any unsafe memory operations, buffer overflows, or direct pointer arithmetic. All tensor access is through safe wrapper methods.\n\n9) The validation of tensor shapes ensures that the computation will not access memory outside the allocated bounds.\n\n10) This is a well-structured, validated kernel implementation with proper error checking and memory management.\n\n(2) NO: No security vulnerability."}
{"idx": 206588, "project": "php-src", "commit_id": "feba44546c27b0158f9ac20e72040a224b918c75", "project_url": "https://github.com/php/php-src", "commit_url": "http://git.php.net/?p=php-src.git;a=commitdiff;h=feba44546c27b0158f9ac20e72040a224b918c75", "commit_message": "Fixed bug #22965 (Crash in gd lib's ImageFillToBorder()).", "ground_truth": 1, "cwe": ["CWE-119"], "cve": "CVE-2015-8874", "cve_desc": "Stack consumption vulnerability in GD in PHP before 5.6.12 allows remote attackers to cause a denial of service via a crafted imagefilltoborder call.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `gdImageFillToBorder` is a recursive flood-fill algorithm that fills an area bounded by a specific border color. It starts at a given pixel (x, y) and fills all connected pixels that are not the border color, using a given fill color.\n\n2. The function first scans left from the starting point (x, y) until it hits a pixel equal to the border color, filling all intermediate pixels with the fill color. It records the leftmost filled position in `leftLimit`.\n\n3. Then it scans right from (x, y) until it hits the border color, filling pixels in between and recording the rightmost filled position in `rightLimit`.\n\n4. After filling the horizontal line, it recursively fills pixels above and below the current line, but only if they are not the border or fill color. The recursion is triggered only when a pixel is neither the border nor the fill color.\n\n5. The function uses `gdImageGetPixel` and `gdImageSetPixel` to access and modify pixel values. These functions are assumed to be safe if the image pointer `im` is valid and the coordinates are within bounds.\n\n6. However, the function does not validate the input coordinates (x, y) against the image dimensions (`im->sx`, `im->sy`). Specifically:\n   - There is no check to ensure that `x` is within `[0, im->sx - 1]` or `y` is within `[0, im->sy - 1]`.\n   - If `x` or `y` is out of bounds, `gdImageGetPixel` and `gdImageSetPixel` could access memory outside the image buffer, leading to undefined behavior, memory corruption, or potential exploitation.\n\n7. The function does check `border < 0` and returns early, but this is not sufficient to prevent out-of-bounds access.\n\n8. The recursive calls to `gdImageFillToBorder` use the same unvalidated coordinates. If the initial (x, y) is invalid, the recursion can lead to stack overflow (due to infinite recursion) or memory access violations.\n\n9. This is a classic case of missing input validation for image coordinates, which can lead to buffer overflows or use-after-free scenarios if the image data is manipulated maliciously.\n\n10. Although the function attempts to avoid infinite recursion by checking for border and color, the lack of bounds checking on the initial (x, y) is a critical flaw.\n\n(1) YES: A security vulnerability detected."}
{"idx": 198013, "project": "tensorflow", "commit_id": "3150642acbbe254e3c3c5d2232143fa591855ac9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/3150642acbbe254e3c3c5d2232143fa591855ac9", "commit_message": "Fix tf.raw_ops.LoadAndRemapMatrix vulnerability with invalid `row_remapping`.\n\nCheck that `row_remapping` has the correct dims().\n\nPiperOrigin-RevId: 445522800", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-29199", "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.LoadAndRemapMatrix does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `initializing_values` is a vector but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Input Validation and Bounds Checking**:\n   - The code uses `OP_REQUIRES_OK` and `OP_REQUIRES` extensively to validate inputs from the `OpKernelContext`.\n   - It checks that `row_remapping` and `col_remapping` tensors have the expected sizes (`num_rows_` and `num_cols_` respectively).\n   - It validates that `ckpt_path` and `old_tensor_name` are single-element tensors.\n   - It checks that the tensor type is `DT_FLOAT` and the rank is exactly 2.\n   - These checks prevent invalid or malformed inputs from causing undefined behavior.\n\n2. **Memory Safety and Buffer Overflows**:\n   - The code uses `TensorSlice` to load the tensor in chunks, which helps manage memory usage and avoids loading the entire tensor into memory at once.\n   - The `tensor_slices` are constructed based on `min_old_row` and `max_old_row`, and the slice length is bounded by `max_rows_in_memory_` (or the full remaining range if `max_rows_in_memory_ <= 0`).\n   - The `loaded_tensor_t` is reallocated only when the shape changes, and the shape is derived from `tensor_slice.SliceTensorShape`, which is validated.\n   - The output matrix is allocated with `TensorShape({num_rows_, num_cols_})`, and the code ensures that `new_row` and `new_col` are within bounds before accessing `output_matrix(new_row, new_col)`.\n\n3. **Index Bounds and Null Checks**:\n   - The code uses `gtl::FindOrNull` to look up keys in `old_row_to_new_row_map` and `old_col_to_new_col_map`. If the key is not found, it skips the row or column.\n   - Before accessing `output_matrix`, it checks:\n     ```cpp\n     OP_REQUIRES(context,\n                 new_row < num_rows_ && new_col < num_cols_ &&\n                     new_row >= 0 && new_col >= 0,\n                 errors::Internal(...));\n     ```\n     This is a critical safety check that ensures no out-of-bounds access occurs.\n\n4. **Initialization of Missing Values**:\n   - The code uses `initializing_values` to fill in uninitialized cells (where `row_id_present[i]` or `col_id_present[j]` is false).\n   - It checks that the number of initializing values matches the number of missing cells, preventing buffer overflows or underflows.\n\n5. **No Use of Untrusted Input in Unsafe Operations**:\n   - All user-provided inputs (e.g., `ckpt_path`, `old_tensor_name`, `row_remapping`, `col_remapping`, `initializing_values`) are validated before use.\n   - There is no use of string concatenation, dynamic memory allocation without bounds checking, or unsafe C-style functions.\n   - The `BundleReader` is used to read from a checkpoint file, but the path is validated to be a single-element string, and the tensor name is validated.\n\n6. **No Known Vulnerabilities**:\n   - No buffer overflows, use-after-free, or integer overflows are present.\n   - All array accesses are bounded by size checks and validated indices.\n   - The code is defensive and uses `OP_REQUIRES` to fail early on invalid inputs.\n\nConclusion: The code is well-structured, performs comprehensive input validation, enforces bounds checking, and avoids unsafe operations. There are no exploitable security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 206273, "project": "radare2", "commit_id": "a7ce29647fcb38386d7439696375e16e093d6acb", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/a7ce29647fcb38386d7439696375e16e093d6acb", "commit_message": "Fix UAF in aaaa on arm/thumb switching ##crash\n\n* Reported by @peacock-doris via huntr.dev\n* Reproducer tests_65185\n* This is a logic fix, but not the fully safe as changes in the code\n  can result on UAF again, to properly protect r2 from crashing we\n  need to break the ABI and add refcounting to RRegItem, which can't\n  happen in 5.6.x because of abi-compat rules", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-1031", "cve_desc": "Use After Free in op_is_set_bp in GitHub repository radareorg/radare2 prior to 5.6.6.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Code Overview\nThe function `extract_arg` is part of a disassembler/analysis engine (likely Radare2, given the use of `RAnal`, `RAnalFunction`, `r_num_get`, etc.). It attempts to extract stack-based variable arguments (e.g., function parameters) from an instruction's ESIL (Expression Stack Instruction Language) representation or register operations.\n\nIt:\n- Looks for register references in the instruction's source operands.\n- Uses `op->src[i]->delta` to determine offset from stack pointer (SP) or base pointer (BP).\n- Falls back to parsing ESIL string to extract stack offsets.\n- Uses `r_num_get` to parse numeric values from strings.\n- Determines whether the offset corresponds to a function argument or local variable.\n- Creates or updates `RAnalVar` objects to represent stack variables.\n- Uses `strdup`, `strstr`, `r_strf_var`, and manual string manipulation.\n\n---\n\n### Step 2: Potential Security Issues\n\n#### 1. **Use of `strdup` and `strstr` on Untrusted Input**\n- The function uses `op_esil` (from `r_strbuf_get(&op->esil)`) as input to `strdup` and later string manipulation.\n- `op->esil` is derived from disassembled instructions, which may come from untrusted binary input.\n- However, `strdup` is safe here as long as the input is valid UTF-8 and not excessively long. But:\n  - `r_strf_var (esilexpr, 64, \",%s,%s,\", reg, sign);` creates a fixed-size buffer (64 bytes), so no buffer overflow here.\n  - `strstr(esil_buf, esilexpr)` is safe since `esil_buf` is a copy of `op_esil`, and `strstr` is bounded by the string length.\n\n\u2705 No buffer overflow from `strdup` or `strstr`.\n\n#### 2. **String Parsing with `r_num_get`**\n- The function parses numeric values from strings like `addr` using `r_num_get(NULL, addr)`.\n- `r_num_get` is designed to parse numbers in various formats (hex, decimal, etc.) and is generally safe.\n- However, if `addr` contains a malformed or extremely long number string, it could cause:\n  - Integer overflow (if `st64` is not large enough).\n  - Denial of service via excessive parsing time (unlikely in practice, but possible).\n\nBut:\n- `st64` is a 64-bit signed integer, so it can handle large numbers.\n- The `maxstackframe` check (1024 * 8 = 8192 bytes) limits the valid range of `frame_off` to \u00b18192, so even if `r_num_get` returns a large value, it will be rejected.\n\n\u2705 Safe: `r_num_get` is used in a bounded context.\n\n#### 3. **Use of `r_str_newf` and `r_anal_function_autoname_var`**\n- These functions generate variable names based on `frame_off`, `ptr`, etc.\n- They are used to create symbolic names for stack variables.\n- The format strings are controlled by constants (`ARGPREFIX`, `VARPREFIX`, `pfx`), and the values are `R_ABS(frame_off)` or `ptr`.\n- No user-controlled input is directly used in format strings.\n\n\u2705 No format string vulnerability.\n\n#### 4. **Use of `goto beach` and `free(esil_buf)`**\n- The function uses `goto beach` to jump to cleanup.\n- `esil_buf` is `strdup`'d and must be `free`d.\n- The `free(esil_buf)` is called at the end, even in error paths.\n\n\u2705 No memory leak.\n\n#### 5. **Stack Frame Bounds Check**\n- The code checks:\n  ```c\n  if (maxstackframe != 0 && (frame_off > maxstackframe || frame_off < -maxstackframe)) {\n      goto beach;\n  }\n  ```\n- This prevents processing of stack offsets beyond \u00b18192 bytes, which is a reasonable limit.\n- This protects against:\n  - Out-of-bounds memory access.\n  - Potential DoS via malformed analysis.\n\n\u2705 Good defensive programming.\n\n#### 6. **No Use of Dangerous Functions**\n- No `strcpy`, `sprintf`, `gets`, `system`, `exec`, etc.\n- No direct use of `eval`, `shell`, or dynamic code execution.\n- All string operations are bounded or use safe functions.\n\n\u2705 No obvious exploitable functions.\n\n#### 7. **Input Validation and Error Handling**\n- The function checks for null pointers (`r_return_if_fail`).\n- It validates `op->src`, `op->dst`, `op->esil`, etc.\n- It handles missing or malformed data gracefully.\n\n\u2705 Robust error handling.\n\n---\n\n### Step 3: Final Assessment\nThe function:\n- Handles untrusted input (from disassembled binary) safely.\n- Uses bounded string operations.\n- Performs input validation and bounds checking.\n- Avoids dangerous functions.\n- Properly cleans up memory.\n- Uses safe numeric parsing with bounds checks.\n\nThere is **no evidence of a buffer overflow, integer overflow, format string vulnerability, memory leak, or code injection**.\n\n---\n\n### Conclusion\n(2) NO: No security vulnerability."}
{"idx": 213370, "project": "glib", "commit_id": "d553d92d6e9f53cbe5a34166fcb919ba652c6a8e", "project_url": "https://gitlab.gnome.org/GNOME/glib", "commit_url": "https://gitlab.gnome.org/GNOME/glib/commit/d553d92d6e9f53cbe5a34166fcb919ba652c6a8e", "commit_message": "gsocketclient: Fix criticals\n\nThis ensures the parent GTask is kept alive as long as an enumeration\nis running and trying to connect.\n\nCloses #1646\nCloses #1649", "ground_truth": 1, "cwe": ["CWE-754"], "cve": "CVE-2019-9633", "cve_desc": "gio/gsocketclient.c in GNOME GLib 2.59.2 does not ensure that a parent GTask remains alive during the execution of a connection-attempting enumeration, which allows remote attackers to cause a denial of service (g_socket_client_connected_callback mishandling and application crash) via a crafted web site, as demonstrated by GNOME Web (aka Epiphany).", "vuln": 1, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `g_socket_client_connected_callback` is a callback invoked when a socket connection attempt finishes asynchronously. It handles the result of a connection, manages cleanup, and proceeds with either TLS handshake or proxy negotiation.\n\n2. The function first checks if the task was cancelled using `g_task_return_error_if_cancelled`. If so, it cleans up and returns. This is a correct and safe practice to avoid further processing after cancellation.\n\n3. It cancels any pending timeout source, which prevents resource leaks and ensures that the timeout does not interfere with the current connection state.\n\n4. It calls `g_socket_connection_connect_finish` to complete the connection. If the connection fails, it checks whether the cancellation was due to user cancellation (`g_cancellable_is_cancelled`). If not, it calls `clarify_connect_error` and `set_last_error` to provide meaningful error information. Then it proceeds to clean up the current attempt and continues with the next connection attempt via `enumerator_next_async`, or unrefs the attempt if no data is present. This is a proper error handling pattern.\n\n5. Upon successful connection, it transfers ownership of the socket and connection using `g_steal_pointer`, which is safe and correct.\n\n6. It iterates over `data->connection_attempts`, cancels each associated cancellable, clears the data, and unrefs each attempt. Then it frees the list. This prevents memory leaks and ensures that no stale connection attempts remain.\n\n7. It calls `g_socket_connection_set_cached_remote_address` with `NULL`, which clears the cached remote address. This is safe and may be used to reset state.\n\n8. It emits a `G_SOCKET_CLIENT_CONNECTED` event, which is a standard GLib signal for connection success.\n\n9. The line `g_socket_set_blocking (data->socket, TRUE);` is flagged as \"wrong, but backward compatible\". This is a critical observation. Setting a socket to blocking mode after an asynchronous connection is problematic because:\n   - The socket was created and used in an asynchronous context (non-blocking).\n   - Switching it to blocking mode can cause the application to hang if the socket is not ready for I/O, especially in event-driven environments.\n   - This can lead to denial-of-service (DoS) if the socket is not properly managed, as the thread may block indefinitely.\n   - While this is not a direct vulnerability like buffer overflow or injection, it introduces a **serious reliability and potential DoS risk** in asynchronous code, which is a security concern in the broader sense (e.g., can be exploited in high-load scenarios to exhaust threads or cause unresponsiveness).\n\n10. The code then handles proxy logic:\n    - It checks if a proxy address is set.\n    - It verifies the connection is TCP (using `G_IS_TCP_CONNECTION`), and logs a critical message if not. This is a safety check.\n    - It checks if the protocol is handled by application-specific proxies (`app_proxies`), and if so, completes the connection without TLS handshake \u2014 this is acceptable if the app handles proxy setup.\n    - Otherwise, it tries to get a default proxy for the protocol and initiates `g_proxy_connect_async`, which is the correct way to handle proxy connections asynchronously.\n    - If no proxy is available, it sets an error and continues.\n\n11. The proxy handling is done correctly using asynchronous APIs (`g_proxy_connect_async`), and the callback is properly set. No direct user input is used in a way that could lead to injection or buffer overflow.\n\n12. The only real issue is the `g_socket_set_blocking (data->socket, TRUE);` line. This is explicitly marked as \"wrong\" in the comment. While it may not be exploitable in a traditional sense (like code execution), it breaks the asynchronous model and can lead to:\n    - Thread blocking in an event loop.\n    - Resource exhaustion (e.g., thread pool exhaustion).\n    - Denial of service.\n\nThis is a **security-relevant design flaw** because it undermines the non-blocking nature of the async I/O system, which is a core security and stability feature in networked applications.\n\nTherefore, despite the absence of classic vulnerabilities (like buffer overflows, injection, or improper access control), the intentional use of `g_socket_set_blocking` in an async context is a **known anti-pattern** that can be exploited to cause DoS.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195073, "project": "tensorflow", "commit_id": "e746adbfcfee15e9cfdb391ff746c765b99bdf9b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e746adbfcfee15e9cfdb391ff746c765b99bdf9b", "commit_message": "Prevent use after free in `DecodePng` kernel.\n\nWe are cleaning up the memory in `decode` and then we are using an `OP_REQUIRES` to check an invariant on the `decode` data.\n\nPiperOrigin-RevId: 409299145\nChange-Id: I4eb93aaca52483eb202e89b78df07fbb2f6cb254", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-23584", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a use after free behavior when decoding PNG images. After `png::CommonFreeDecode(&decode)` gets called, the values of `decode.width` and `decode.height` are in an unspecified state. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Input Validation and Initialization**:\n   - The function `DecodePngV2` takes a `StringPiece input` representing the PNG data.\n   - It initializes a `png::DecodeContext` using `png::CommonInitDecode`, which performs basic validation of the PNG header and structure. This is a good first step in preventing malformed input from causing issues.\n\n2. **Size Validation**:\n   - The code checks the width and height of the decoded PNG:\n     - It ensures that `width` and `height` are positive and do not exceed `1 << 27` (134,217,728), which is a reasonable upper bound to prevent integer overflow and excessive memory allocation.\n     - It checks that `total_size = width * height` does not exceed `1 << 29` (536,870,912), which is a further safeguard against excessive memory consumption.\n   - These checks are performed using `int64_t` arithmetic to avoid overflow during the multiplication, and the results are compared against the original `decode.width` and `decode.height` to ensure no truncation occurred during casting to `int`. This is a strong defense against integer overflow and underflow.\n\n3. **Memory Allocation**:\n   - The output tensor is allocated using `context->allocate_output`, with shape based on `height`, `width`, and `channels`.\n   - The allocation is bounded by the previously validated `width` and `height`, so the size of the output tensor is constrained by the same limits.\n   - For `DT_FLOAT`, a temporary `uint16[]` buffer is allocated with size `height * width * decode.channels`, which is again bounded by the same size checks.\n\n4. **Data Processing**:\n   - The `png::CommonFinishDecode` function is used to decode the image data into the output buffer.\n   - The function is called with a buffer pointer and the correct stride (`decode.channels * width * sizeof(type)`), which ensures that the decoder writes only within the allocated space.\n   - For `DT_FLOAT`, the data is first decoded into a `uint16` buffer (lossless), then converted to `float` using Eigen's device-aware tensor operations. This avoids direct memory corruption and ensures safe conversion.\n\n5. **Error Handling and Cleanup**:\n   - If any step fails, the function calls `png::CommonFreeDecode(&decode)` to clean up the decoder context.\n   - The `OP_REQUIRES` macros ensure that errors are propagated correctly and that invalid input leads to early termination.\n\n6. **Security Considerations**:\n   - There is no direct use of unsafe functions like `strcpy`, `memcpy` without bounds, or unbounded memory allocation.\n   - All size checks are performed using `int64_t` to prevent overflow during multiplication.\n   - The input size is validated via `StringPiece`, and the decoder initialization already checks for valid PNG format.\n   - The code does not perform any dynamic memory allocation without bounds checking, and all allocations are based on validated dimensions.\n\n7. **Potential Risks**:\n   - One could argue that the `decode.width` and `decode.height` are read from the PNG file, which is untrusted input. However, the code explicitly checks that these values are within safe bounds (\u2264 1<<27) and that their product is \u2264 1<<29. This prevents denial-of-service via large image sizes.\n   - The use of `reinterpret_cast` is safe here because the buffer is allocated with the correct size and alignment, and the `CommonFinishDecode` function is expected to write exactly the required number of bytes.\n\nConclusion: The code performs comprehensive input validation, uses safe arithmetic with `int64_t`, bounds checks on image dimensions, and proper cleanup. It avoids common vulnerabilities like buffer overflows, integer overflows, and uncontrolled memory allocation.\n\n(2) NO: No security vulnerability."}
{"idx": 197517, "project": "glewlwyd", "commit_id": "0efd112bb62f566877750ad62ee828bff579b4e2", "project_url": "https://github.com/babelouest/glewlwyd", "commit_url": "https://github.com/babelouest/glewlwyd/commit/0efd112bb62f566877750ad62ee828bff579b4e2", "commit_message": "Fix fido2 signature validation bug", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-40818", "cve_desc": "scheme/webauthn.c in Glewlwyd SSO server through 2.5.3 has a buffer overflow during FIDO2 signature validation in webauthn registration.", "vuln": 1, "reasoning": "Let's analyze the provided code step-by-step to identify any potential security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Initialization\n- The function takes multiple inputs: `j_params`, `credential_id`, `cert_x`, `cert_y`, `att_stmt`, `rpid_hash`, `client_data`, etc.\n- It initializes various GnuTLS structures (`gnutls_pubkey_t`, `gnutls_x509_crt_t`) and buffers (`data_signed`, `client_data_hash`, `cert_export`, etc.).\n- All critical resources are initialized with proper error checking (e.g., `gnutls_x509_crt_init`, `gnutls_pubkey_init`), and errors are reported via `json_array_append_new` and `y_log_message`.\n\n\u2705 Good: Proper initialization and error handling at the start.\n\n---\n\n### Step 2: Parsing and Validating `att_stmt` (CBOR Map)\n- The function checks that `att_stmt` is a CBOR map with exactly 2 elements.\n- It iterates over the map keys and validates that they are strings.\n- It checks for two valid keys: `\"x5c\"` and `\"sig\"`, and extracts their corresponding values.\n- If any key is invalid or not a string, it logs an error and breaks.\n\n\u2705 Good: Strict validation of CBOR map structure and key names. Prevents injection via malformed or unexpected keys.\n\n---\n\n### Step 3: Certificate Parsing (`x5c`)\n- The `x5c` value is expected to be a CBOR array of length 1, containing a single DER-encoded certificate.\n- The certificate is imported using `gnutls_x509_crt_import` with `GNUTLS_X509_FMT_DER`.\n\n\u2705 Good: The certificate is parsed from DER format, which is standard and safe when properly validated.\n\n---\n\n### Step 4: Certificate Validation\n- The function checks if a root CA list is provided (`json_object_get(j_params, \"root-ca-list\") != json_null()`).\n- If so, it calls `validate_certificate_from_root()` to verify the certificate chain against trusted CAs.\n\n\u26a0\ufe0f Potential Risk: The function relies on `validate_certificate_from_root()` to perform full certificate chain validation (including revocation, expiration, trust anchors, etc.). However, **if this function is not implemented correctly**, it could allow untrusted or forged certificates to pass.\n\nBut: The code does **not** show the implementation of `validate_certificate_from_root()`, so we must assume it's a trusted, well-implemented function. Since the code explicitly checks for root CA list and uses it, and logs issuer DN on failure, this is a **correct security pattern**.\n\n\u2705 Good: Proper use of certificate trust validation when root CA list is provided.\n\n---\n\n### Step 5: Public Key Import and Signature Verification\n- The certificate is imported into a GnuTLS public key object via `gnutls_pubkey_import_x509`.\n- The function then computes a hash of `client_data` using SHA-256.\n- It constructs a `data_signed` buffer by concatenating:\n  - A leading `0x0` byte\n  - `rpid_hash`\n  - `client_data_hash`\n  - `credential_id`\n  - A `0x04` byte (indicating uncompressed EC point)\n  - `cert_x` and `cert_y` (EC public key coordinates)\n\nThis constructed data is then signed with the ECDSA signature in `sig`.\n\nThe signature is verified using `gnutls_pubkey_verify_data2(pubkey, GNUTLS_SIGN_ECDSA_SHA256, 0, &data, &signature)`.\n\n\u2705 Good: The data to be signed is constructed in a deterministic, well-defined way. The use of `GNUTLS_SIGN_ECDSA_SHA256` ensures proper hashing.\n\n\u26a0\ufe0f Critical Check: Is the `data_signed` buffer properly bounded?\n\n- `data_signed` is declared as `unsigned char data_signed[200]`.\n- The function builds the data by copying:\n  - `rpid_hash` (length `rpid_hash_len`)\n  - `client_data_hash` (32 bytes)\n  - `credential_id` (length `credential_id_len`)\n  - `cert_x` and `cert_y` (lengths `cert_x_len`, `cert_y_len`)\n\nThe total size is:\n```\n1 (leading 0x0) + rpid_hash_len + 32 + credential_id_len + 1 (0x04) + cert_x_len + cert_y_len\n```\n\nThe maximum size depends on input lengths. However, **the function does not validate that this total size fits within `200` bytes**.\n\nFor example:\n- `rpid_hash_len` could be 32 (standard)\n- `credential_id_len` could be up to 64 (common in FIDO U2F)\n- `cert_x_len` and `cert_y_len` could be 32 each (for P-256)\n\nTotal: 1 + 32 + 32 + 64 + 1 + 32 + 32 = **194 bytes** \u2192 still under 200.\n\nBut what if inputs are larger? For example:\n- `credential_id` could be longer than 64? (FIDO U2F spec limits to 64, but not enforced here)\n- `cert_x`/`cert_y` could be larger? (P-384 would be 48 bytes each \u2192 1 + 32 + 32 + 64 + 1 + 48 + 48 = 226 > 200)\n\n\u26a0\ufe0f **This is a critical issue**: The buffer `data_signed[200]` is **not checked** for overflow before copying. If the total length exceeds 200, it will cause a **buffer overflow**.\n\nEven though the FIDO U2F specification limits `credential_id` to 64 bytes and EC keys to 32 or 48 bytes, **the code does not enforce these limits**. It blindly copies data into a fixed-size buffer without bounds checking.\n\nThis is a **classic buffer overflow vulnerability**.\n\n---\n\n### Step 6: Base64 Encoding and Output\n- The certificate key ID is exported and base64-encoded using `o_base64_encode`, which is assumed to be safe (no overflow if buffer is large enough).\n- The output is returned in a JSON object.\n\n\u2705 No issues here, assuming `o_base64_encode` is safe.\n\n---\n\n### Step 7: Error Handling and Resource Management\n- All allocated resources (`pubkey`, `cert`, `att_cert`) are properly deinitialized.\n- `json_decref(j_error)` is called.\n- `o_free(message)` is used where needed.\n\n\u2705 Good: No resource leaks.\n\n---\n\n### Final Assessment\n\nThe **only critical vulnerability** is:\n- **Buffer overflow in `data_signed`** due to lack of bounds checking when copying variable-length inputs into a fixed-size buffer (`[200]`).\n- The function does not validate that the total size of `data_signed` will not exceed 200 bytes.\n- This can be exploited by an attacker providing large `credential_id`, `cert_x`, or `cert_y` values to overflow the buffer and potentially execute arbitrary code.\n\nEven though the FIDO U2F spec defines limits, **the code does not enforce them**, making it vulnerable to malformed or malicious inputs.\n\n---\n\n(1) YES: A security vulnerability detected."}
{"idx": 198662, "project": "vim", "commit_id": "dc5490e2cbc8c16022a23b449b48c1bd0083f366", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/dc5490e2cbc8c16022a23b449b48c1bd0083f366", "commit_message": "patch 8.2.4215: illegal memory access when copying lines in Visual mode\n\nProblem:    Illegal memory access when copying lines in Visual mode.\nSolution:   Adjust the Visual position after copying lines.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-0361", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 8.2.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ex_copy` copies a range of lines from `line1` to `line2` to a destination line `n`.\n\n2) The function uses `u_save(n, n + 1)` to save the undo information for the range starting at line `n` and ending at `n + 1`. This is a standard undo mechanism in Vim.\n\n3) The core copying logic uses `ml_get(line1)` to retrieve the content of a line, `vim_strsave()` to create a copy of the string, and `ml_append()` to insert it at the current cursor position.\n\n4) The function carefully handles the cursor position and line numbers during copying, with special handling for the case where the destination is between the source lines (situation 2).\n\n5) The `vim_strsave()` function is used to safely duplicate the string returned by `ml_get()`, which is appropriate because `ml_get()` returns a pointer to internal buffer data that may be invalidated.\n\n6) The function properly frees the allocated string with `vim_free(p)` after use.\n\n7) The function updates the operation start/end positions in the buffer (`b_op_start`, `b_op_end`) only if the `CMOD_LOCKMARKS` flag is not set.\n\n8) The function calls `appended_lines_mark(n, count)` to mark the newly appended lines, which is correct for maintaining buffer state.\n\n9) The function uses `msgmore()` to display a message about the number of lines copied.\n\n10) There are no obvious buffer overflows, use-after-free issues, or memory corruption vulnerabilities. The string handling is done safely with `vim_strsave()` and `vim_free()`. The line number arithmetic appears correct, and the loop termination condition is properly maintained.\n\n11) The function does not directly handle user input in a way that could lead to injection or overflow vulnerabilities. The parameters are line numbers, which are validated by the calling context.\n\n12) The code follows established Vim coding patterns for line manipulation and undo handling.\n\n(2) NO: No security vulnerability."}
{"idx": 194996, "project": "tensorflow", "commit_id": "4f38b1ac8e42727e18a2f0bde06d3bee8e77b250", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/4f38b1ac8e42727e18a2f0bde06d3bee8e77b250", "commit_message": "Prevent null dereference read in `GetInitOp`.\n\nWe have a map of maps. We test that the key exists in the first map but then we don't have any validation that this also means the second map has the needed key. In the scenarios where this is not the case, we'll dereference a nullptr, if we don't have this check\n\nPiperOrigin-RevId: 408739325\nChange-Id: If9bb7ed759aba1f3b56a34913f209508dbaf65ce", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-23577", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `GetInitOp` is vulnerable to a crash caused by dereferencing a null pointer. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `GetInitOp` is designed to retrieve the name of the initialization operation from a TensorFlow SavedModel's MetaGraphDef. It checks two sources:\n   - First, it looks for a signature definition with the key `kSavedModelInitOpSignatureKey`.\n   - If not found, it checks for a collection definition with either `kSavedModelMainOpKey` or `kSavedModelLegacyInitOpKey`.\n\n2. The function retrieves the operation name from either:\n   - The `signature_def` map, specifically from the output named `kSavedModelInitOpSignatureKey`.\n   - The `collection_def` map, specifically from the `node_list` of the selected collection key.\n\n3. The code performs input validation:\n   - It checks if the `signature_def` map contains the expected key.\n   - It checks if the `collection_def` map contains either of the two expected keys.\n   - It verifies that the `node_list` in the collection has exactly one value (ensuring a single init op).\n\n4. The retrieved operation name is assigned to `*init_op_name` and returned via `Status::OK()`.\n\n5. Security considerations:\n   - The function does not perform any direct string manipulation or memory copying that could lead to buffer overflows.\n   - It does not execute or interpret the retrieved operation name in any way (e.g., it doesn't call `eval`, `execute`, or similar functions).\n   - The operation name is simply extracted from structured metadata (protobufs) and returned as a string.\n   - The input is the `MetaGraphDef`, which is a serialized model representation. The function assumes this is valid and well-formed (as is typical in such contexts).\n   - There is no user-controlled input being directly processed in a dangerous way (e.g., no dynamic code execution, no injection into a command or query).\n   - The function is not vulnerable to injection attacks (like SQL or command injection) because it's not constructing any executable strings.\n\n6. The only potential risk would be if the `MetaGraphDef` itself is maliciously crafted (e.g., containing an extremely long string), but:\n   - The function uses `string` types and `find`, `value_size()`, etc., which are safe in C++ as long as the protobuf is valid.\n   - The `MetaGraphDef` is expected to be a trusted model export (from a known source), and such validation is typically done at load time.\n   - There is no evidence of unbounded memory allocation or string copying without bounds checking.\n\n7. Therefore, the function is correctly extracting a name from structured metadata with proper bounds checking and validation.\n\n(2) NO: No security vulnerability."}
{"idx": 210050, "project": "lua", "commit_id": "1f3c6f4534c6411313361697d98d1145a1f030fa", "project_url": "https://github.com/lua/lua", "commit_url": "https://github.com/lua/lua/commit/1f3c6f4534c6411313361697d98d1145a1f030fa", "commit_message": "Bug: Lua can generate wrong code when _ENV is <const>", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-28805", "cve_desc": "singlevar in lparser.c in Lua from (including) 5.4.0 up to (excluding) 5.4.4 lacks a certain luaK_exp2anyregup call, leading to a heap-based buffer over-read that might affect a system that compiles untrusted Lua code.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `singlevar` is part of a Lua interpreter's parser (likely in the `lparser.c` file), responsible for handling variable references in the source code.\n\n2. It starts by retrieving a variable name using `str_checkname(ls)`, which gets a string representing the variable name from the lexer. This is a standard operation in a parser.\n\n3. It then calls `singlevaraux(fs, varname, var, 1)` to resolve the variable. This function attempts to find the variable in the current scope (local or upvalue). If the variable is not found locally, it returns `VVOID` (indicating it's a global variable).\n\n4. If `var->k == VVOID`, the code assumes the variable is global and proceeds to access it via the environment table (`ls->envn`), which is typically the global environment (e.g., `_G` in Lua).\n\n5. It then:\n   - Calls `singlevaraux` again with `ls->envn` (the environment name) to get the environment table.\n   - Uses `codestring(&key, varname)` to create a string constant for the variable name.\n   - Uses `luaK_indexed(fs, var, &key)` to generate bytecode that accesses `env[varname]`.\n\n6. The key point: The variable name (`varname`) is taken directly from the source code (via `str_checkname`) and used as a key in a table lookup (`env[varname]`). This is a dynamic table access using a user-controlled string.\n\n7. However, in Lua, the environment table (`_G` or `ls->envn`) is typically a global table, and the key is a string derived from the source code. The code does not perform any input validation on the variable name beyond what `str_checkname` does (which ensures it's a valid identifier, i.e., a valid name in Lua syntax).\n\n8. But here's the critical point: **Lua's environment table is user-accessible and can be modified.** However, the code does not perform any sanitization or validation of the variable name beyond ensuring it's a valid identifier. Since the variable name comes from the source code (not from untrusted input), and the parser is designed to handle valid Lua syntax, this is not an injection vulnerability in the traditional sense.\n\n9. The use of `luaK_indexed` with a string key is standard and safe in Lua's implementation. The interpreter is not executing arbitrary code based on the variable name \u2014 it's just doing a table lookup. The variable name is not being used in a string concatenation or command execution context.\n\n10. Furthermore, `str_checkname` ensures that the name is a valid identifier (no special characters, etc.), so there's no risk of injection via malformed names.\n\n11. Therefore, this code is not vulnerable to injection attacks (like code injection or table injection) because:\n    - The variable name is syntactically validated.\n    - The environment is a known table.\n    - The access is a standard table lookup, not a dynamic code execution.\n\n(2) NO: No security vulnerability."}
{"idx": 215921, "project": "grep", "commit_id": "83a95bd8c8561875b948cadd417c653dbe7ef2e2", "project_url": "http://git.savannah.gnu.org/cgit/grep", "commit_url": "http://git.sv.gnu.org/cgit/grep.git/commit/?id=83a95bd8c8561875b948cadd417c653dbe7ef2e2", "commit_message": "grep -F: fix a heap buffer (read) overrun\n\ngrep's read buffer is often filled to its full size, except when\nreading the final buffer of a file.  In that case, the number of\nbytes read may be far less than the size of the buffer.  However, for\ncertain unusual pattern/text combinations, grep -F would mistakenly\nexamine bytes in that uninitialized region of memory when searching\nfor a match.  With carefully chosen inputs, one can cause grep -F to\nread beyond the end of that buffer altogether.  This problem arose via\ncommit v2.18-90-g73893ff with the introduction of a more efficient\nheuristic using what is now the memchr_kwset function. The use of\nthat function in bmexec_trans could leave TP much larger than EP,\nand the subsequent call to bm_delta2_search would mistakenly access\nbeyond end of the main input read buffer.\n\n* src/kwset.c (bmexec_trans): When TP reaches or exceeds EP,\ndo not call bm_delta2_search.\n* tests/kwset-abuse: New file.\n* tests/Makefile.am (TESTS): Add it.\n* THANKS.in: Update.\n* NEWS (Bug fixes): Mention it.\n\nPrior to this patch, this command would trigger a UMR:\n\n  printf %0360db 0 | valgrind src/grep -F $(printf %019dXb 0)\n\n  Use of uninitialised value of size 8\n     at 0x4142BE: bmexec_trans (kwset.c:657)\n     by 0x4143CA: bmexec (kwset.c:678)\n     by 0x414973: kwsexec (kwset.c:848)\n     by 0x414DC4: Fexecute (kwsearch.c:128)\n     by 0x404E2E: grepbuf (grep.c:1238)\n     by 0x4054BF: grep (grep.c:1417)\n     by 0x405CEB: grepdesc (grep.c:1645)\n     by 0x405EC1: grep_command_line_arg (grep.c:1692)\n     by 0x4077D4: main (grep.c:2570)\n\nSee the accompanying test for how to trigger the heap buffer overrun.\n\nThanks to Nima Aghdaii for testing and finding numerous\nways to break early iterations of this patch.", "ground_truth": 1, "cwe": ["CWE-119"], "cve": "CVE-2015-1345", "cve_desc": "The bmexec_trans function in kwset.c in grep 2.19 through 2.21 allows local users to cause a denial of service (out-of-bounds heap read and crash) via crafted input when using the -F option.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `bmexec_trans` is a part of a string matching engine, likely implementing a variant of the Boyer-Moore algorithm with additional optimizations (e.g., delta1 and delta2 tables, character translation, etc.). It searches for a pattern (defined in `kwset`) within a given text.\n\n2. The function takes:\n   - `kwset_t kwset`: a structure containing the pattern, delta tables, translation table, and other metadata.\n   - `char const *text`: the input text to search in.\n   - `size_t size`: the length of the text.\n\n3. Key checks:\n   - `if (len == 0) return 0;` \u2014 handles empty pattern (no match needed).\n   - `if (len > size) return -1;` \u2014 ensures the pattern is not longer than the text.\n   - `if (len == 1)` \u2014 handles single-character case via `memchr_kwset`, which is safe.\n\n4. The main loop uses `d1[U(tp[-1])]` to compute jump distances based on the last character of the current window. The `U()` macro is assumed to be a safe cast (e.g., `unsigned char`), which is important to avoid negative indexing.\n\n5. The loop condition: `tp <= ep`, where `ep = text + size - 11 * len`. This ensures that the loop only runs when there are at least 11 * len characters remaining, which is safe because it prevents accessing beyond the end of the text.\n\n6. Inside the loop:\n   - `tp` is advanced using `d1[U(tp[-1])]`, which is a standard Boyer-Moore delta1 jump.\n   - The loop performs up to 8 delta1 jumps (in 2-step increments) before checking for a potential match.\n   - If the total advance is large enough (\u2265 16 * sizeof(long)), it skips to `big_advance`, which uses `memchr_kwset` to find a potential match location.\n   - Otherwise, it performs a `memchr_kwset` call starting from `tp - 1`, which is safe because it's bounded by `text + size - tp`.\n\n7. The `memchr_kwset` function is used to find a character that could be the last character of the pattern. This is a safe operation as long as the input range is valid.\n\n8. The `bm_delta2_search` function is called to verify a match. It uses the `trans` table and `gc1`, `gc2` for character comparison, and `d1` for delta2 jumps. The function is called with `&tp`, `ep`, and other bounds-checked parameters.\n\n9. The final fallback loop:\n   - `while (d <= ep - tp)` \u2014 ensures that `tp + d` does not exceed `ep`.\n   - `d = d1[U((tp += d)[-1])]` \u2014 advances `tp` by `d`, but only if `d` is within bounds.\n   - The loop continues until `tp` reaches `ep`.\n\n10. All pointer arithmetic is bounded:\n    - The initial loop bounds are set to avoid accessing beyond `text + size`.\n    - The final loop uses `d <= ep - tp` to ensure no out-of-bounds access.\n    - All array accesses use `U()` to avoid negative indexing.\n    - The `memchr_kwset` calls are passed valid ranges.\n\n11. No buffer overflows, use-after-free, or out-of-bounds memory accesses are evident. The code carefully bounds all pointer arithmetic and uses safe jump logic.\n\n12. The function does not perform any dynamic memory allocation, does not use unsafe string functions, and does not rely on untrusted input for control flow without bounds checking.\n\nConclusion: The code is carefully written with bounds checking at every step. It avoids buffer overflows and out-of-bounds access through proper loop conditions and pointer arithmetic. The use of `memchr_kwset` and `bm_delta2_search` is safe due to the bounds enforcement.\n\n(2) NO: No security vulnerability."}
{"idx": 197973, "project": "crun", "commit_id": "1aeeed2e4fdeffb4875c0d0b439915894594c8c6", "project_url": "https://github.com/containers/crun", "commit_url": "https://github.com/containers/crun/commit/1aeeed2e4fdeffb4875c0d0b439915894594c8c6", "commit_message": "exec: --cap do not set inheritable capabilities\n\nCloses: CVE-2022-27650\n\nSigned-off-by: Giuseppe Scrivano <gscrivan@redhat.com>", "ground_truth": 1, "cwe": ["CWE-276"], "cve": "CVE-2022-27650", "cve_desc": "A flaw was found in crun where containers were incorrectly started with non-empty default permissions. A vulnerability was found in Moby (Docker Engine) where containers were started incorrectly with non-empty inheritable Linux process capabilities. This flaw allows an attacker with access to programs with inheritable file capabilities to elevate those capabilities to the permitted set when execve(2) runs.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `crun_command_exec` is responsible for executing a container command with given arguments and options. It uses various input parameters from `argc`, `argv`, and `exec_options` (parsed via `argp_parse`).\n\n2. The function initializes a `libcrun_context_t` structure (`crun_context`) and sets default values, including `preserve_fds = 0` and `listen_fds = 0`.\n\n3. It parses command-line arguments using `argp_parse`, which is a standard argument parser. The `first_arg` is used to determine where the actual command arguments start.\n\n4. The function calls `init_libcrun_context` to initialize the context based on the container specification and global arguments. This function is assumed to be safe if properly implemented.\n\n5. The `exec_opts` structure is initialized with `memset` and `struct_size` set, which is a good practice to avoid uninitialized memory issues.\n\n6. The `exec_options` structure is used to populate `exec_opts` and `crun_context`. The `exec_options.process` field is used to set `exec_opts.path` directly if provided.\n\n7. If `exec_options.process` is not provided, the code dynamically builds a `process` structure:\n   - It allocates memory for `process->args` using `xmalloc0` and `xstrdup` for each argument.\n   - The arguments are copied from `argv[first_arg + i + 1]` (note: `i` starts at 0, and the loop runs for `argc - first_arg` iterations, but the first argument after `first_arg` is `argv[first_arg + 1]`).\n   - This suggests that `argv[first_arg]` is the container name or command, and `argv[first_arg + 1]` onward are the arguments to the process.\n\n8. The `process->args` array is properly null-terminated (`process->args[i] = NULL`), which is correct for C-style argument arrays.\n\n9. The code sets various fields like `cwd`, `terminal`, `env`, `user`, `selinux_label`, `apparmor_profile`, and `capabilities` from `exec_options`. These are all validated or copied safely:\n   - `env` is passed directly from `exec_options.env`, which is assumed to be properly managed.\n   - `capabilities` are duplicated using `dup_array`, which is a safe copy function (assuming it's implemented correctly).\n   - `no_new_privileges` is set based on `exec_options.no_new_privs`.\n\n10. The `exec_opts.cgroup` is set from `exec_options.cgroup`.\n\n11. Finally, the function calls `libcrun_container_exec_with_options` with the context, container name, and execution options.\n\nNow, let's look for potential security issues:\n\n- Input validation: The function uses `argp_parse` to parse arguments, which is a standard and safe way to handle command-line input. The `crun_assert_n_args` ensures the correct number of arguments are provided.\n\n- Memory management: The code uses `xmalloc0`, `xstrdup`, and `dup_array`, which are safe wrappers (assuming they are implemented correctly and do not have bugs). The `process` structure is properly initialized and null-terminated.\n\n- No direct string concatenation or unsafe function calls (like `strcpy`, `sprintf`, etc.) are used.\n\n- The `exec_options.process` is used directly as `exec_opts.path`, but this is only used in the context of a container runtime, and the path is expected to be a valid executable within the container. The runtime is responsible for validating the path.\n\n- The `env` and `args` are copied safely using `xstrdup` and `dup_array`.\n\n- The `capabilities` are duplicated safely using `dup_array`, which is a known safe function in this codebase.\n\n- There is no use of `system()`, `popen()`, or similar unsafe functions.\n\n- The `getenv(\"LISTEN_FDS\")` is read and converted to a number using `strtoll`, which is safe as long as the environment variable contains a valid integer. However, if the environment variable is not a valid number, `strtoll` returns 0, which is safe (no overflow or buffer issues).\n\n- The `exec_opts.process` is set to the dynamically allocated `process` structure only when `exec_options.process` is not provided. This is correct.\n\n- The `process` structure is allocated with `xmalloc0`, which zero-initializes memory, reducing the risk of uninitialized data.\n\n- The `exec_opts` structure is properly initialized with `memset` and `struct_size`, which prevents undefined behavior.\n\nConclusion: The code uses safe memory allocation, proper input validation, and avoids dangerous functions. All user-provided data is copied safely, and no direct execution of untrusted input occurs. The container runtime context ensures that execution is sandboxed.\n\n(2) NO: No security vulnerability."}
{"idx": 206815, "project": "ImageMagick", "commit_id": "c111ed9b035532c2c81ea569f2d22fded9517287", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/c111ed9b035532c2c81ea569f2d22fded9517287", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1540", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2019-11598", "cve_desc": "In ImageMagick 7.0.8-40 Q16, there is a heap-based buffer over-read in the function WritePNMImage of coders/pnm.c, which allows an attacker to cause a denial of service or possibly information disclosure via a crafted image file. This is related to SetGrayscaleImage in MagickCore/quantize.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Initialization**:\n   - The function `SetGrayscaleImage` takes an `Image *image` and `ExceptionInfo *exception` as parameters.\n   - It begins with `assert(image != (Image *) NULL);` and `assert(image->signature == MagickCoreSignature);`, which are defensive checks to ensure the image pointer is valid and the signature matches. These are good practices and do not introduce vulnerabilities.\n\n2. **Colorspace Transformation**:\n   - If the image type is not `GrayscaleType`, it calls `TransformImageColorspace(image, GRAYColorspace, exception);`. This is a legitimate operation to convert the image to grayscale, and it's safe as long as the underlying implementation is secure.\n\n3. **Memory Allocation for colormap_index**:\n   - The code dynamically allocates memory for `colormap_index` using `AcquireQuantumMemory(image->colors+1, sizeof(*colormap_index))` for PseudoClass images, or `MaxColormapSize+1` otherwise.\n   - `AcquireQuantumMemory` is a safe memory allocation function in ImageMagick that checks for overflow and returns NULL on failure. This prevents integer overflow issues during allocation.\n   - If allocation fails, it throws a `ResourceLimitError`, which is appropriate.\n\n4. **Handling of Colormap and Image Data**:\n   - For non-PseudoClass images, it initializes `colormap_index` with `-1` using `memset`, then acquires a colormap of size `MaxColormapSize` using `AcquireImageColormap`.\n   - The use of `GetCacheViewAuthenticPixels` and `SyncCacheViewAuthenticPixels` is standard for image processing and is safe when used correctly.\n   - The code uses `#pragma omp parallel for` for parallel processing, but it includes proper `#pragma omp critical` to protect the critical section where `colormap_index[intensity]` is updated. This prevents race conditions and is correctly implemented.\n\n5. **Pixel Processing Loop**:\n   - The loop iterates over each pixel, scales the red channel to a map index using `ScaleQuantumToMap(GetPixelRed(image,q))`, and checks if that index has been assigned in `colormap_index`.\n   - If not, it assigns a new colormap entry and increments `image->colors`. The `colormap_index` is updated atomically via the critical section.\n   - The `SetPixelIndex` function is used to set the index in the pixel data. This is safe as long as the index is within bounds.\n\n6. **Post-Processing: Deduplication and Sorting**:\n   - After the first pass, the code sorts the colormap using `qsort` with `IntensityCompare`, which is safe.\n   - It then creates a new `colormap` array and deduplicates entries using `IsPixelInfoEquivalent`, which is a safe comparison function.\n   - The `colormap_index` is updated to map old colormap indices to new deduplicated ones.\n   - The old colormap is freed with `RelinquishMagickMemory`, and the new one is assigned.\n\n7. **Second Pass: Index Remapping**:\n   - A second parallel loop remaps the pixel indices using the new `colormap_index` array.\n   - The index is derived from `ScaleQuantumToMap(GetPixelIndex(image,q))`, which is safe because `GetPixelIndex` returns a `Quantum`, and `ScaleQuantumToMap` is a known safe function that maps Quantum values (0\u201365535) to a smaller range (0\u2013MaxColormapSize), but the actual range is bounded by `image->colors`, which is controlled and validated.\n\n8. **Final Steps**:\n   - The image type is set to `GrayscaleType`, and if `SetImageMonochrome` returns `MagickFalse`, it may set the type to `BilevelType`. This is a valid transformation.\n\n9. **Potential Issues**:\n   - **Integer Overflow Risk?** The use of `ssize_t` and `size_t` is consistent. `MaxColormapSize` is a constant (typically 65536), and `image->colors` is limited by the image data. The allocation uses `AcquireQuantumMemory`, which guards against overflow.\n   - **Buffer Overflows?** All array accesses are bounded by `image->colors`, `image->columns`, and `image->rows`, which are derived from the image metadata. These are validated by the ImageMagick core and are not directly user-controlled in a way that would allow overflow.\n   - **Race Conditions?** The use of `#pragma omp critical` in the first loop ensures that only one thread can update `colormap_index[intensity]` at a time, preventing race conditions.\n   - **Memory Safety?** All memory is allocated with safe functions (`AcquireQuantumMemory`) and freed with `RelinquishMagickMemory`. No dangling pointers or double-free issues are apparent.\n\n10. **Conclusion**:\n    - The code follows secure coding practices: input validation, safe memory allocation, proper bounds checking, thread safety via critical sections, and safe use of image data.\n    - There are no obvious buffer overflows, use-after-free, integer overflows, or race conditions.\n    - The image data is processed in a controlled and safe manner, with no direct user input manipulation that could lead to code execution or memory corruption.\n\n(2) NO: No security vulnerability."}
{"idx": 213075, "project": "linux", "commit_id": "d270453a0d9ec10bb8a802a142fb1b3601a83098", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/d270453a0d9ec10bb8a802a142fb1b3601a83098", "commit_message": "nfc: nfcmrvl: main: reorder destructive operations in nfcmrvl_nci_unregister_dev to avoid bugs\n\nThere are destructive operations such as nfcmrvl_fw_dnld_abort and\ngpio_free in nfcmrvl_nci_unregister_dev. The resources such as firmware,\ngpio and so on could be destructed while the upper layer functions such as\nnfcmrvl_fw_dnld_start and nfcmrvl_nci_recv_frame is executing, which leads\nto double-free, use-after-free and null-ptr-deref bugs.\n\nThere are three situations that could lead to double-free bugs.\n\nThe first situation is shown below:\n\n   (Thread 1)                 |      (Thread 2)\nnfcmrvl_fw_dnld_start         |\n ...                          |  nfcmrvl_nci_unregister_dev\n release_firmware()           |   nfcmrvl_fw_dnld_abort\n  kfree(fw) //(1)             |    fw_dnld_over\n                              |     release_firmware\n  ...                         |      kfree(fw) //(2)\n                              |     ...\n\nThe second situation is shown below:\n\n   (Thread 1)                 |      (Thread 2)\nnfcmrvl_fw_dnld_start         |\n ...                          |\n mod_timer                    |\n (wait a time)                |\n fw_dnld_timeout              |  nfcmrvl_nci_unregister_dev\n   fw_dnld_over               |   nfcmrvl_fw_dnld_abort\n    release_firmware          |    fw_dnld_over\n     kfree(fw) //(1)          |     release_firmware\n     ...                      |      kfree(fw) //(2)\n\nThe third situation is shown below:\n\n       (Thread 1)               |       (Thread 2)\nnfcmrvl_nci_recv_frame          |\n if(..->fw_download_in_progress)|\n  nfcmrvl_fw_dnld_recv_frame    |\n   queue_work                   |\n                                |\nfw_dnld_rx_work                 | nfcmrvl_nci_unregister_dev\n fw_dnld_over                   |  nfcmrvl_fw_dnld_abort\n  release_firmware              |   fw_dnld_over\n   kfree(fw) //(1)              |    release_firmware\n                                |     kfree(fw) //(2)\n\nThe firmware struct is deallocated in position (1) and deallocated\nin position (2) again.\n\nThe crash trace triggered by POC is like below:\n\nBUG: KASAN: double-free or invalid-free in fw_dnld_over\nCall Trace:\n  kfree\n  fw_dnld_over\n  nfcmrvl_nci_unregister_dev\n  nci_uart_tty_close\n  tty_ldisc_kill\n  tty_ldisc_hangup\n  __tty_hangup.part.0\n  tty_release\n  ...\n\nWhat's more, there are also use-after-free and null-ptr-deref bugs\nin nfcmrvl_fw_dnld_start. If we deallocate firmware struct, gpio or\nset null to the members of priv->fw_dnld in nfcmrvl_nci_unregister_dev,\nthen, we dereference firmware, gpio or the members of priv->fw_dnld in\nnfcmrvl_fw_dnld_start, the UAF or NPD bugs will happen.\n\nThis patch reorders destructive operations after nci_unregister_device\nin order to synchronize between cleanup routine and firmware download\nroutine.\n\nThe nci_unregister_device is well synchronized. If the device is\ndetaching, the firmware download routine will goto error. If firmware\ndownload routine is executing, nci_unregister_device will wait until\nfirmware download routine is finished.\n\nFixes: 3194c6870158 (\"NFC: nfcmrvl: add firmware download support\")\nSigned-off-by: Duoming Zhou <duoming@zju.edu.cn>\nSigned-off-by: David S. Miller <davem@davemloft.net>", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-1734", "cve_desc": "A flaw in Linux Kernel found in nfcmrvl_nci_unregister_dev() in drivers/nfc/nfcmrvl/main.c can lead to use after free both read or write when non synchronized between cleanup routine and firmware download routine.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `nfcmrvl_nci_unregister_dev` is responsible for unregistering and cleaning up an NFC device instance represented by `priv`, which is a pointer to a `struct nfcmrvl_private`.\n\n2. The function first checks if firmware download is in progress via `priv->ndev->nfc_dev->fw_download_in_progress`. If so, it calls `nfcmrvl_fw_dnld_abort(priv)` to abort the firmware download. This is a good safety measure to prevent race conditions or inconsistent states during cleanup.\n\n3. Next, it calls `nfcmrvl_fw_dnld_deinit(priv)` to deinitialize firmware download state. This is appropriate for cleaning up resources related to firmware operations.\n\n4. It checks if the reset GPIO is valid using `gpio_is_valid(priv->config.reset_n_io)`, and if so, frees it with `gpio_free(priv->config.reset_n_io)`. This is a proper resource cleanup for GPIOs.\n\n5. Then it calls `nci_unregister_device(ndev)` to unregister the NCI device from the NCI subsystem. This is necessary to remove the device from the system's device list.\n\n6. After that, `nci_free_device(ndev)` is called to free the NCI device structure. This is the correct way to release memory allocated for the device.\n\n7. Finally, `kfree(priv)` is called to free the `nfcmrvl_private` structure.\n\nNow, consider potential issues:\n\n- All operations are performed in a logical order: aborting firmware download, deinitializing firmware state, freeing GPIO, unregistering and freeing the NCI device, and finally freeing the private data.\n- There are no obvious use-after-free issues because the `priv` structure is freed only after all device-related cleanup is complete.\n- The function does not perform any input validation on `priv` itself, but since this is a kernel driver function called with a valid `priv` pointer (presumably validated earlier), and the pointer is not used after `kfree`, there is no immediate risk of use-after-free.\n- The function does not involve any user-controlled data that could lead to buffer overflows, memory corruption, or other classic vulnerabilities.\n- All resource cleanup is done in a safe, sequential manner, and no critical operations are performed after freeing memory.\n\nNo obvious security vulnerabilities such as use-after-free, double-free, buffer overflow, or improper access control are present in this code snippet.\n\n(2) NO: No security vulnerability."}
{"idx": 206676, "project": "vim", "commit_id": "777e7c21b7627be80961848ac560cb0a9978ff43", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/777e7c21b7627be80961848ac560cb0a9978ff43", "commit_message": "patch 8.2.3564: invalid memory access when scrolling without valid screen\n\nProblem:    Invalid memory access when scrolling without a valid screen.\nSolution:   Do not set VALID_BOTLINE in w_valid.", "ground_truth": 1, "cwe": ["CWE-122"], "cve": "CVE-2021-3903", "cve_desc": "vim is vulnerable to Heap-based Buffer Overflow", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is any security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `update_topline()` is part of a text editor (likely Vim or a Vim-like editor).\n   - It manages the vertical scrolling of the current window (`curwin`) by updating the `w_topline` (top line displayed) and `w_botline` (bottom line displayed) based on the cursor position, scroll settings (`w_p_so`, `p_so`), and window height.\n   - It handles edge cases such as empty buffers, folding, diff mode, and cursor movement.\n\n2. **Input Sources**:\n   - The function does not directly read user input (e.g., from network, file, or command line).\n   - The only inputs are internal state variables:\n     - `curwin->w_cursor.lnum` (cursor line number)\n     - `curwin->w_topline`, `w_botline`, `w_height`, `w_valid`, etc.\n     - `curwin->w_p_so` (scroll offset setting), `p_so` (global scroll offset)\n     - `curbuf->b_ml.ml_line_count` (number of lines in the buffer)\n   - These are all internal state values that are updated by other parts of the editor based on user actions (e.g., cursor movement, scrolling commands).\n\n3. **Potential Vulnerabilities to Check**:\n   - **Buffer overflows**: No fixed-size buffers are being copied into using unsafe functions like `strcpy`, `strncpy`, `memcpy`, etc. All operations are on integers and pointers, with bounds checks via `ml_line_count` and `w_height`.\n   - **Integer overflows/underflows**: The code uses `long`, `int`, and `linenr_T` (likely a long integer type). There are comparisons like `lnum >= curbuf->b_ml.ml_line_count` and `lnum <= 0`, which prevent out-of-bounds access. The loop conditions (e.g., `lnum < curwin->w_topline + *so_ptr`) are bounded by `ml_line_count` or `w_height`, which are positive and derived from the buffer size. No arithmetic that could overflow is performed without checks.\n   - **Use of uninitialized or untrusted data**: All data used comes from the editor's internal state, which is validated and updated by trusted code paths. There is no direct user input manipulation.\n   - **Logic errors vs. security vulnerabilities**: The code has complex logic for scrolling, folding, and diff handling, but all branches are bounded and use proper checks (e.g., `BUFEMPTY()`, `screen_valid()`, `check_top_offset()`). The use of `validate_botline()` and `redraw_later()` is safe and standard.\n   - **Memory safety**: No dynamic memory allocation or deallocation. No use of unsafe pointer arithmetic. All pointer dereferences are through valid `curwin` and `curbuf` structures that are checked for validity earlier in the function.\n\n4. **Specific Checks**:\n   - `if (!screen_valid(TRUE) || curwin->w_height == 0)` \u2014 safely handles edge cases.\n   - `if (BUFEMPTY())` \u2014 handles empty buffer correctly.\n   - Loops like `for (lnum = curwin->w_cursor.lnum; lnum < curwin->w_topline + *so_ptr; ++lnum)` are bounded by `ml_line_count` or `halfheight`, preventing infinite loops.\n   - `botline_forw(&loff)` is used in a loop with bounds checks.\n   - `hasFolding()` is called with proper parameters and returns early if conditions are not met.\n\n5. **No External Input or Injection**:\n   - There is no string manipulation, no command execution, no SQL, no HTML, no format string, no path traversal, etc.\n   - The function is purely internal state management.\n\n6. **Conclusion**:\n   - The code is well-structured, uses bounds checks, avoids unsafe operations, and handles edge cases safely.\n   - There are no known vulnerabilities such as buffer overflows, integer overflows, use-after-free, or injection attacks.\n   - The function operates on trusted internal state and does not expose any attack surface.\n\n(2) NO: No security vulnerability."}
{"idx": 194989, "project": "ImageMagick6", "commit_id": "450949ed017f009b399c937cf362f0058eacc5fa", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/450949ed017f009b399c937cf362f0058eacc5fa", "commit_message": "Pull request: https://github.com/ImageMagick/ImageMagick/pull/4963", "ground_truth": 1, "cwe": ["CWE-190"], "cve": "CVE-2022-32545", "cve_desc": "A vulnerability was found in ImageMagick, causing an outside the range of representable values of type 'unsigned char' at coders/psd.c, when crafted or untrusted input is processed. This leads to a negative impact to application availability or other problems related to undefined behavior.", "vuln": 1, "reasoning": "Let's think step-by-step:\n\n1) The function `ReadPSDChannelPixels` reads pixel data from a PSD (Photoshop Document) file and writes it into an Image structure. It processes pixel data in a channel-by-channel manner, handling different data types (1-byte, 2-byte, or 4-byte floating point) based on `packet_size`.\n\n2) The function uses `GetAuthenticPixels` to get a pointer to the pixel data in the image. This is a standard way to access pixel data in ImageMagick, and it's properly checked for NULL return.\n\n3) The input parameters include `pixels` (raw pixel data from the file), `image->columns`, `image->depth`, and `packet_size`. The function processes each pixel in a loop over `x` from 0 to `image->columns - 1`.\n\n4) The key concern is the handling of `packet_size`:\n   - If `packet_size == 1`: uses `ScaleCharToQuantum(*p++)` \u2014 safe, reads one byte.\n   - If `packet_size == 2`: uses `PushShortPixel` to read a 16-bit value \u2014 this function should handle endianness and bounds.\n   - If `packet_size == 4`: uses `PushFloatPixel` to read a 32-bit float \u2014 again, should be safe if implemented correctly.\n\n5) The function then calls `SetPSDPixel` to set the pixel value. This function is responsible for writing the pixel data into the image, possibly with channel and type handling.\n\n6) The most critical part is the bit-level handling when `image->depth == 1` (i.e., 1-bit per pixel). In this case:\n   - The code processes up to 8 bits at a time (number_bits = min(8, remaining columns)).\n   - It loops over `bit` from 0 to `number_bits - 1`.\n   - It sets each bit using `(((unsigned char) pixel) & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange`.\n   - Then it does `x++` inside the loop and `x--` after the loop, which effectively skips the next iteration.\n\n7) The issue is in the bit-level processing:\n   - The loop processes `number_bits` bits (up to 8), but then does `x++` for each bit processed.\n   - Then it does `x--` after the loop, which cancels the last increment.\n   - However, if `number_bits < 8`, then `x` is incremented by `number_bits`, then decremented by 1 \u2014 so net effect is `x += (number_bits - 1)`.\n   - But the outer loop is `for (x=0; x < (ssize_t) image->columns; x++)`, so the loop variable `x` is incremented by the loop itself.\n   - This leads to a potential off-by-one or off-by-n error: the inner loop may process more bits than intended, and the `x` variable may be advanced incorrectly.\n\n8) More importantly, the `x++` inside the bit loop and the `x--` after it can cause the outer loop to skip or miscount pixels. For example:\n   - If `image->columns = 10`, and `number_bits = 8`, then `x` becomes 8 after the inner loop, then `x--` makes it 7, then the outer loop increments it to 8.\n   - But if `number_bits = 1`, then `x` becomes 1 after the inner loop, then `x--` makes it 0, then outer loop increments to 1 \u2014 so it's okay.\n   - However, the logic is fragile and could lead to buffer overflows or underflows if the pixel data is malformed.\n\n9) The real danger is that `p` (the input pointer) is advanced by `packet_size` bytes per pixel, but in the 1-bit case, the function processes multiple bits from a single byte. However, the code does not check if `p` is still within bounds when reading multiple bits. If the input data is truncated or malformed, `p` could be read past the end of the buffer.\n\n10) The function does not validate the length of the `pixels` buffer before reading from it. It assumes that `pixels` contains enough data for `image->columns` pixels, but in the 1-bit case, it may read more bits than available.\n\n11) Since `p` is advanced by `packet_size` in the outer loop, but in the 1-bit case, it may read from `p` multiple times (via `*p++`), and if the input data is shorter than expected, this leads to reading beyond the buffer.\n\n12) The function does not check if `p` is within bounds before dereferencing it. This is a classic buffer overflow vulnerability.\n\n13) The `PushShortPixel` and `PushFloatPixel` functions may also have bounds checks, but the code does not verify that the input buffer has enough data for the entire image.\n\n14) The `image->columns` is used as a loop bound, but if the input data is corrupted or truncated, the function may read past the end of the `pixels` buffer.\n\n15) This is a buffer over-read vulnerability: the function reads from `pixels` without ensuring that the buffer is large enough for the number of pixels and the packet size.\n\n(1) YES: A security vulnerability detected."}
{"idx": 210620, "project": "linux", "commit_id": "1680939e9ecf7764fba8689cfb3429c2fe2bb23c", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/1680939e9ecf7764fba8689cfb3429c2fe2bb23c", "commit_message": "rpmsg: virtio: Fix possible double free in rpmsg_virtio_add_ctrl_dev()\n\nvch will be free in virtio_rpmsg_release_device() when\nrpmsg_ctrldev_register_device() fails. There is no need to call\nkfree() again.\n\nFixes: c486682ae1e2 (\"rpmsg: virtio: Register the rpmsg_char device\")\nSigned-off-by: Hangyu Hua <hbh25y@gmail.com>\nTested-by: Arnaud Pouliquen <arnaud.pouliquen@foss.st.com>\nLink: https://lore.kernel.org/r/20220426060536.15594-3-hbh25y@gmail.com\nSigned-off-by: Mathieu Poirier <mathieu.poirier@linaro.org>", "ground_truth": 1, "cwe": ["CWE-415"], "cve": "CVE-2022-34494", "cve_desc": "rpmsg_virtio_add_ctrl_dev in drivers/rpmsg/virtio_rpmsg_bus.c in the Linux kernel before 5.18.4 has a double free.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1. The function `rpmsg_virtio_add_ctrl_dev` is responsible for adding a control device in a virtio-based RPMsg (Remote Processor Messaging) framework.\n\n2. It allocates memory for a `virtio_rpmsg_channel` structure using `kzalloc` with `GFP_KERNEL`, which is appropriate for kernel space allocations. The check for `!vch` and returning `ERR_PTR(-ENOMEM)` is correct and handles allocation failure properly.\n\n3. The `vch->vrp = vrp;` assignment links the channel to the virtual processor information, which is valid and safe as long as `vdev->priv` is properly initialized and trusted.\n\n4. The `rpdev_ctrl` pointer is set to `&vch->rpdev`, which is a member of the allocated `vch` structure. This is a valid pointer assignment.\n\n5. The `rpdev_ctrl->ops = &virtio_rpmsg_ops;` sets the operation callbacks for the RPMsg device. This is a standard pattern and not a vulnerability.\n\n6. The device's parent is set to `&vrp->vdev->dev`, which is a valid device pointer from the virtio device. This is correct for device hierarchy in the kernel.\n\n7. The `release` function is set to `virtio_rpmsg_release_device`, which is a proper cleanup function for the device.\n\n8. The `little_endian` field is set based on `virtio_is_little_endian(vrp->vdev)`, which is a safe and correct way to determine endianness.\n\n9. The function calls `rpmsg_ctrldev_register_device(rpdev_ctrl)` to register the control device. If this fails, it cleans up by calling `kfree(vch)` and returns `ERR_PTR(err)`. This is proper error handling.\n\n10. The function returns `rpdev_ctrl` on success, which is a valid pointer to the registered device.\n\n11. There are no obvious buffer overflows, use-after-free, null pointer dereferences, or improper input validation. All memory allocations are checked, and cleanup is performed on error paths.\n\n12. The code does not directly handle user input or untrusted data. It operates on kernel-internal structures and device state, which are assumed to be trusted in this context.\n\n13. The use of `kzalloc` ensures zero-initialization, which is good for avoiding uninitialized data issues.\n\n14. No unsafe functions like `strcpy`, `sprintf`, or `memcpy` with unbounded sizes are used.\n\n15. The code follows standard kernel device driver patterns and includes proper error handling.\n\nConclusion: The code is well-written, follows kernel security best practices, and does not contain any obvious security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 197565, "project": "wolfMQTT", "commit_id": "84d4b53122e0fa0280c7872350b89d5777dabbb2", "project_url": "https://github.com/wolfSSL/wolfMQTT", "commit_url": "https://github.com/wolfSSL/wolfMQTT/commit/84d4b53122e0fa0280c7872350b89d5777dabbb2", "commit_message": "Fix wolfmqtt-fuzzer: Null-dereference WRITE in MqttProps_Free", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2021-45936", "cve_desc": "wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect (called from MqttClient_DecodePacket and MqttClient_WaitType).", "vuln": 0, "reasoning": "Let's analyze the provided code step-by-step to determine if there are any security vulnerabilities.\n\n1. **Input Validation**:\n   - The function begins with a check for null pointers: `if (client == NULL || packet_obj == NULL) return MQTT_CODE_ERROR_BAD_ARG;`. This is good practice to prevent null pointer dereferences.\n\n2. **Buffer Handling and Memory Safety**:\n   - The function uses `client->rx_buf` and `client->rx_buf_len` to read data from the network. These are assumed to be pre-allocated buffers managed by the client.\n   - The function calls `MqttPacket_Read(client, client->rx_buf, client->rx_buf_len, timeout_ms)` to read data into `client->rx_buf`. The size of the buffer is controlled by `client->rx_buf_len`, which should be validated elsewhere (e.g., during client setup). However, within this function, there is no explicit bounds checking on the data read from the network. If `client->rx_buf_len` is not properly constrained, this could lead to a buffer overflow if the received packet exceeds the buffer size.\n   - However, the function does not directly copy untrusted data into a fixed-size buffer without bounds checking. The `MqttPacket_Read` function is responsible for ensuring that no more than `client->rx_buf_len` bytes are read. If this function is implemented correctly (e.g., using `recv()` with a size limit), then this is safe.\n\n3. **Use of `FALL_THROUGH` and State Machine**:\n   - The function uses a state machine with `*mms_stat` to track the current state. The `switch` statement uses `FALL_THROUGH` to allow fall-through from one case to the next. This is a known pattern in MQTT implementations and is not inherently insecure.\n   - The state transitions are controlled and validated. The function resets the state to `MQTT_MSG_BEGIN` at the end if not continuing (non-blocking case), which prevents stale state issues.\n\n4. **Thread Safety and Synchronization**:\n   - The code uses `wm_SemLock` and `wm_SemUnlock` to protect access to shared data structures (`client->lockClient`, `client->lockRecv`) when `WOLFMQTT_MULTITHREAD` is defined.\n   - The locking is applied correctly: mutexes are acquired before accessing shared data (e.g., `client->resp_list`) and released afterward.\n   - There is no evidence of race conditions or deadlocks in the provided code. The use of semaphores is consistent and safe.\n\n5. **Packet Type and ID Matching**:\n   - The function checks for packet type and ID match using:\n     ```c\n     if ((wait_type == MQTT_PACKET_TYPE_ANY ||\n          wait_type == packet_type ||\n          MqttIsPubRespPacket(packet_type) == MqttIsPubRespPacket(wait_type)) &&\n        (wait_packet_id == 0 || wait_packet_id == packet_id))\n     ```\n     This logic correctly handles both wildcard (`ANY`) and specific packet type/ID matching. It also accounts for publish response equivalence via `MqttIsPubRespPacket`, which is a valid design for MQTT.\n\n6. **Use of `packet_obj` and `use_packet_obj`**:\n   - The function uses `packet_obj` as a user-provided object. It is passed to `MqttClient_HandlePacket` only if a match is found. The function ensures that `use_packet_obj` is either the original `packet_obj` or a default (`&client->msg`) if no match is found.\n   - There is no direct copying of untrusted data into a fixed-size buffer without bounds checking. The `MqttClient_HandlePacket` function is responsible for handling the packet data safely.\n\n7. **Error Handling and Return Codes**:\n   - The function properly handles errors at each step (e.g., `wm_SemLock` failure, `MqttPacket_Read` failure, `MqttClient_DecodePacket` failure).\n   - It returns appropriate error codes and cleans up locks before returning.\n\n8. **No Direct User Input in Unsafe Operations**:\n   - The function does not perform string concatenation, format string operations, or direct memory copying without bounds checking.\n   - All data from the network is processed through well-defined decoding and handling functions.\n\n9. **No Known Vulnerabilities**:\n   - There are no buffer overflows, use-after-free, null pointer dereferences, or injection vulnerabilities.\n   - The code is well-structured, uses proper synchronization, and validates inputs.\n\nConclusion: After a thorough analysis, the code does not exhibit any security vulnerabilities. It follows secure coding practices, uses proper bounds checking (via buffer size limits), handles errors correctly, and ensures thread safety.\n\n(2) NO: No security vulnerability."}
{"idx": 206625, "project": "raptor", "commit_id": "590681e546cd9aa18d57dc2ea1858cb734a3863f", "project_url": "https://github.com/dajobe/raptor", "commit_url": "https://github.com/dajobe/raptor/commit/590681e546cd9aa18d57dc2ea1858cb734a3863f", "commit_message": "Calcualte max nspace declarations correctly for XML writer\n\n(raptor_xml_writer_start_element_common): Calculate max including for\neach attribute a potential name and value.\n\nFixes Issues #0000617 http://bugs.librdf.org/mantis/view.php?id=617\nand #0000618 http://bugs.librdf.org/mantis/view.php?id=618", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2017-18926", "cve_desc": "raptor_xml_writer_start_element_common in raptor_xml_writer.c in Raptor RDF Syntax Library 2.0.15 miscalculates the maximum nspace declarations for the XML writer, leading to heap-based buffer overflows (sometimes seen in raptor_qname_format_as_xml).", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - The function dynamically allocates memory for `nspace_declarations` using `RAPTOR_CALLOC`, with size based on `nspace_max_count`, which is derived from `element->attribute_count`, `element->declared_nspaces`, and `element->xml_language`.\n   - The allocation is checked for failure (`if(!nspace_declarations)`), and the function returns early if allocation fails. This prevents use-after-free or buffer overflow due to insufficient memory.\n\n2. **Namespace and Attribute Handling**:\n   - The code carefully checks whether a namespace is already in scope using `raptor_namespaces_namespace_in_scope(nstack, ...)`, avoiding redundant declarations.\n   - It uses a loop to check for duplicate namespace declarations before adding them, preventing duplicate entries.\n   - For each namespace or attribute, it uses `raptor_namespace_format_as_xml` and `raptor_qname_format_as_xml`, which are expected to be safe functions that properly format XML strings and escape content as needed.\n\n3. **XML Language Attribute Handling**:\n   - The `xml:lang` attribute is handled with a fixed-size buffer (`buf_length = XML_LANG_PREFIX_LEN + lang_len + 1`), and `raptor_xml_escape_string` is used to escape the value before writing it into the buffer.\n   - The buffer is allocated with `RAPTOR_MALLOC`, and the length is correctly calculated to avoid overflow.\n   - The function ensures null termination and uses `memcpy` and `raptor_xml_escape_string` safely.\n\n4. **String Writing and Buffer Safety**:\n   - The function uses `raptor_iostream_write_byte` and `raptor_iostream_counted_string_write` to write data to the output stream. These functions are designed to handle counted strings safely and avoid null-termination issues.\n   - The `qsort` is used to sort namespace declarations into canonical order, but this is not a security issue as it's only for formatting.\n\n5. **Memory Management and Cleanup**:\n   - On success, the function frees `nspace_declarations` at the end if `nstack` is non-null.\n   - On error, it uses a `goto error` label to clean up all allocated `declaration` strings via a loop, then frees the array. This prevents memory leaks.\n   - All dynamically allocated strings are properly freed, and no dangling pointers are left.\n\n6. **Input Validation and Bounds Checking**:\n   - The function checks for null pointers (`if(!dest || !src`) and validates input parameters early.\n   - The use of `raptor_sequence_size` and bounds checks in loops ensures that array access is within valid ranges.\n   - The `for` loops use `i < nspace_declarations_count` and `i < (unsigned int)raptor_sequence_size(...)`, which are safe because `nspace_declarations_count` is capped by `nspace_max_count`, which is derived from known, bounded inputs.\n\n7. **No Use of Unsafe Functions**:\n   - There is no use of `strcpy`, `strcat`, `sprintf`, or other unsafe string functions.\n   - All string operations use counted-length functions or safe escaping functions like `raptor_xml_escape_string`.\n\n8. **No Buffer Overflows or Format String Vulnerabilities**:\n   - All string writes are bounded by length parameters.\n   - The `xml:lang` attribute uses a fixed-size buffer with proper length calculation and null termination.\n   - No format strings are used with user-controlled input.\n\n9. **Security Best Practices**:\n   - The code follows defensive programming: checks for nulls, validates inputs, uses safe string functions, and properly cleans up memory.\n   - It avoids common vulnerabilities like buffer overflows, use-after-free, and memory leaks.\n\nConclusion: After thorough analysis, the code correctly handles dynamic memory allocation, avoids buffer overflows, prevents memory leaks, uses safe string operations, and properly validates inputs. There are no exploitable security vulnerabilities present.\n\n(2) NO: No security vulnerability."}
{"idx": 195720, "project": "mvfst", "commit_id": "a67083ff4b8dcbb7ee2839da6338032030d712b0", "project_url": "https://github.com/facebookincubator/mvfst", "commit_url": "https://github.com/facebookincubator/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0", "commit_message": "Close connection if we derive an extra 1-rtt write cipher\n\nSummary: Fixes CVE-2021-24029\n\nReviewed By: mjoras, lnicco\n\nDifferential Revision: D26613890\n\nfbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2021-24029", "cve_desc": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `updateHandshakeState` is responsible for updating the cryptographic state of a QUIC server connection during the handshake process.\n\n2) The code retrieves various ciphers (zero-RTT, 1-RTT, handshake) from the `handshakeLayer` and conditionally assigns them to the connection's codec or state.\n\n3) Key observations:\n   - The code uses `std::move()` to transfer ownership of cipher objects, which is safe and correct.\n   - All cipher assignments are guarded by null checks (e.g., `if (zeroRttReadCipher)`), preventing use of null pointers.\n   - The `CHECK` statements ensure invariants are maintained (e.g., `CHECK(!conn.oneRttWriteCipher.get())` before assignment).\n   - The `handshakeLayer->isHandshakeDone()` check ensures that the `HandshakeDone` frame is only sent once and only when appropriate.\n   - The `processClientInitialParams` function is called only after valid client transport parameters are retrieved, and it throws an exception if not available.\n   - There is no direct user input manipulation, no string concatenation, no unsafe memory operations, and no use of unsafe functions.\n\n4) The code follows proper cryptographic state management patterns:\n   - Ciphers are only set when they are valid and non-null.\n   - The order of operations respects the QUIC handshake protocol flow.\n   - Logging and tracing are used appropriately without exposing sensitive data.\n   - No buffer overflows, use-after-free, or memory corruption patterns are present.\n\n5) The code does not contain any known security vulnerabilities such as:\n   - Buffer overflows\n   - Use-after-free\n   - Null pointer dereferences\n   - Improper input validation\n   - Insecure cipher usage\n   - Information leakage\n\n6) All critical operations are protected by checks and assertions, and the code adheres to secure coding practices for cryptographic state transitions.\n\n(2) NO: No security vulnerability."}
{"idx": 210866, "project": "xserver", "commit_id": "144849ea27230962227e62a943b399e2ab304787", "project_url": "http://gitweb.freedesktop.org/?p=xorg/xserver", "commit_url": "https://gitlab.freedesktop.org/xorg/xserver/-/commit/144849ea27230962227e62a943b399e2ab304787", "commit_message": "Fix XkbSelectEvents() integer underflow\n\nCVE-2020-14361 ZDI-CAN 11573\n\nThis vulnerability was discovered by:\nJan-Niklas Sohn working with Trend Micro Zero Day Initiative\n\nSigned-off-by: Matthieu Herrb <matthieu@herrb.eu>", "ground_truth": 1, "cwe": ["CWE-191"], "cve": "CVE-2020-14361", "cve_desc": "A flaw was found in X.Org Server before xorg-x11-server 1.20.9. An Integer underflow leading to heap-buffer overflow may lead to a privilege escalation vulnerability. The highest threat from this vulnerability is to data confidentiality and integrity as well as system availability.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `SProcXkbSelectEvents` is a server-side procedure handler for XKB (X Keyboard Extension) events in the X Window System. It processes client requests to select which XKB events the client wants to receive.\n\n2) The function starts by:\n   - Using `REQUEST(xkbSelectEventsReq)` to get the request header\n   - Swapping bytes for network-to-host order using `swaps()` on several fields\n   - Validating the request size with `REQUEST_AT_LEAST_SIZE`\n\n3) The core logic handles event mask processing:\n   - It extracts the `affectWhich` mask and filters out `XkbMapNotifyMask`\n   - It iterates through each bit in the mask using a loop\n   - For each bit that is set and not `XkbMapNotify`, it:\n     - Determines the expected data size (1, 2, or 4 bytes) based on the event type\n     - Checks if there's enough data left (`dataLeft < (size * 2)` \u2192 BadLength)\n     - Swaps the data according to size (swaps for 2 bytes, swapl for 4 bytes)\n     - Advances the pointer and reduces dataLeft\n\n4) Critical checks:\n   - The function checks `dataLeft < (size * 2)` before reading data \u2014 this prevents buffer over-read\n   - It ensures that the total data consumed does not exceed the available data\n   - After processing all event types, it checks `if (dataLeft > 2)` \u2014 any extra data beyond 2 bytes triggers BadLength\n   - The `size` variable is properly validated per event type\n   - The `from.c8` pointer is advanced correctly after each read\n   - The `dataLeft` is decremented appropriately\n\n5) Potential issues:\n   - The `size` variable is set to 2 in the `else` block of the switch statement, but this only happens if `size == 1` (which is not possible since size is 1, 2, or 4). This is a redundant case and could be a bug, but it doesn't lead to buffer overflow because:\n     - The `size` is only used in `dataLeft -= (size * 2)` and `from.c8 += (size * 2)`\n     - The `size` is always 1, 2, or 4, so `size * 2` is 2, 4, or 8 \u2014 all valid\n   - The `dataLeft` check before reading ensures no out-of-bounds access\n   - The final check `dataLeft > 2` ensures no trailing data\n\n6) The function properly validates:\n   - Request size\n   - Data availability\n   - Data alignment\n   - Event type validity\n   - No buffer overflows or underflows\n\n7) The use of `swaps()` and `swapl()` ensures correct byte order handling for network data.\n\nConclusion: The code correctly handles variable-length data from a network request, performs bounds checking, and prevents buffer over-reads. There are no exploitable vulnerabilities in the data processing logic.\n\n(2) NO: No security vulnerability."}
{"idx": 216515, "project": "openssl", "commit_id": "939b4960276b040fc0ed52232238fcc9e2e9ec21", "project_url": "https://github.com/openssl/openssl", "commit_url": "https://github.com/openssl/openssl/commit/939b4960276b040fc0ed52232238fcc9e2e9ec21", "commit_message": "Fix race condition in NewSessionTicket\n\nIf a NewSessionTicket is received by a multi-threaded client when\nattempting to reuse a previous ticket then a race condition can occur\npotentially leading to a double free of the ticket data.\n\nCVE-2015-1791\n\nThis also fixes RT#3808 where a session ID is changed for a session already\nin the client session cache. Since the session ID is the key to the cache\nthis breaks the cache access.\n\nParts of this patch were inspired by this Akamai change:\nhttps://github.com/akamai/openssl/commit/c0bf69a791239ceec64509f9f19fcafb2461b0d3\n\nReviewed-by: Rich Salz <rsalz@openssl.org>\n(cherry picked from commit 27c76b9b8010b536687318739c6f631ce4194688)\n\nConflicts:\n\tssl/ssl.h\n\tssl/ssl_err.c", "ground_truth": 1, "cwe": ["CWE-362"], "cve": "CVE-2015-1791", "cve_desc": "Race condition in the ssl3_get_new_session_ticket function in ssl/s3_clnt.c in OpenSSL before 0.9.8zg, 1.0.0 before 1.0.0s, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b, when used for a multi-threaded client, allows remote attackers to cause a denial of service (double free and application crash) or possibly have unspecified other impact by providing a NewSessionTicket during an attempt to reuse a ticket that had been obtained earlier.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `ssl3_get_new_session_ticket` is responsible for processing a NewSessionTicket message in an SSL/TLS handshake, which is used for session resumption via tickets.\n\n2. The function first calls `s->method->ssl_get_message` to receive the message from the network. It specifies a maximum message size of 16384 bytes, which is a reasonable limit to prevent excessive memory allocation.\n\n3. It checks if the message was received successfully (`ok`), and returns early if not.\n\n4. It verifies that the message length `n` is at least 6 bytes, which is the minimum required to contain `ticket_lifetime_hint` (4 bytes) and `ticket_length` (2 bytes). This prevents reading beyond the buffer.\n\n5. It extracts `ticket_lifetime_hint` and `ticklen` from the message using `n2l` and `n2s`, which are macros that read network-order (big-endian) integers. These are standard and safe when used with proper bounds checking.\n\n6. It then checks that the total length of the message (`n`) equals `ticklen + 6`. This ensures that the entire ticket data is present and that no data is missing or truncated. This is a critical check to prevent buffer over-reads or under-reads.\n\n7. It frees any existing ticket data in `s->session->tlsext_tick` and allocates a new buffer of size `ticklen` using `OPENSSL_malloc`. This is safe because `ticklen` is derived from the message and validated earlier.\n\n8. It copies `ticklen` bytes from the message (`p`) into the newly allocated buffer using `memcpy`. Since `ticklen` is validated to be exactly the remaining data length, this copy is bounded and safe.\n\n9. It computes a session ID as the hash of the ticket data using `EVP_Digest`. The hash is computed over `p` (the ticket data) of length `ticklen`. This is safe because `ticklen` is validated and within bounds.\n\n10. The function returns 1 on success, or -1 on error, with appropriate alert handling.\n\nKey security considerations:\n- All input lengths are validated before use.\n- No unbounded reads or writes occur.\n- Memory allocation is based on validated length (`ticklen`).\n- The use of `memcpy` is bounded by `ticklen`, which is checked against the total message length.\n- The `EVP_Digest` call is over a known, validated length of data.\n\nThere are no buffer overflows, use-after-free, or other classic vulnerabilities. The code follows secure practices: input validation, bounded memory operations, and proper cleanup.\n\n(2) NO: No security vulnerability."}
{"idx": 216027, "project": "tar", "commit_id": "cb07844454d8cc9fb21f53ace75975f91185a120", "project_url": "http://git.savannah.gnu.org/cgit/tar", "commit_url": "http://git.savannah.gnu.org/cgit/tar.git/commit/?id=cb07844454d8cc9fb21f53ace75975f91185a120", "commit_message": "Fix possible NULL dereference (savannah bug #55369)\n\n* src/sparse.c (pax_decode_header): Check return from find_next_block.", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2019-9923", "cve_desc": "pax_decode_header in sparse.c in GNU Tar before 1.32 had a NULL pointer dereference when parsing certain archives that have malformed extended headers.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `pax_decode_header` processes sparse file metadata in a tar archive. It reads numeric values from the archive's block data, which is potentially untrusted input.\n\n2. The `COPY_BUF` macro is used to copy a string (terminated by '\\n') from a block buffer into a local buffer `nbuf`. The macro:\n   - Checks if the destination buffer `nbuf` is about to overflow by comparing `dst` with `buf + UINTMAX_STRSIZE_BOUND - 1`.\n   - If the buffer would overflow, it reports an error and returns false.\n   - It handles multi-block input by switching to the next block when the current one is exhausted (`set_next_block_after` and `find_next_block`).\n\n3. The `nbuf` buffer is of size `UINTMAX_STRSIZE_BOUND`, which is defined as the maximum number of characters needed to represent a `uintmax_t` in decimal (typically 20 for 64-bit integers). This is sufficient to hold any valid number that can be represented in `uintmax_t`.\n\n4. After copying the number string into `nbuf`, the code calls `decode_num(&u, nbuf, TYPE_MAXIMUM(...))` to convert the string to a number. This function:\n   - Validates that the string is a valid number.\n   - Ensures the value does not exceed the specified maximum (e.g., `size_t` or `off_t`).\n   - Returns false on overflow or invalid format.\n\n5. The `sparse_map_size` is read from the archive and used to allocate `xcalloc` memory. However, the value is validated via `decode_num`, which ensures it does not exceed `TYPE_MAXIMUM(size_t)`. This prevents integer overflow or excessively large allocations.\n\n6. The loop that reads `sp_array` entries (offset and numbytes) also uses `decode_num` with `TYPE_MAXIMUM(off_t)`, so the values are bounded and cannot cause integer overflow or out-of-bounds memory access.\n\n7. The `COPY_BUF` macro ensures that `nbuf` is null-terminated and does not overflow, and the `decode_num` function ensures that the parsed number is within safe bounds.\n\n8. There is no direct use of untrusted data in unsafe functions like `strcpy`, `sprintf`, or `strcat`. All string-to-number conversions are done safely via `decode_num`, which includes bounds checking.\n\n9. The use of `xcalloc` with a validated size ensures that memory allocation is safe.\n\n10. The `set_next_block_after` and `find_next_block` logic correctly handles multi-block data, and the `COPY_BUF` macro manages block transitions safely.\n\nConclusion: All input from the archive is validated before being used. The code uses safe string copying with bounds checking, safe numeric parsing with overflow protection, and safe memory allocation. There are no buffer overflows, integer overflows, or unsafe memory operations.\n\n(2) NO: No security vulnerability."}
{"idx": 196629, "project": "tensorflow", "commit_id": "579261dcd446385831fe4f7457d802a59685121d", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/579261dcd446385831fe4f7457d802a59685121d", "commit_message": "Fix crash in MatrixSolve when inputs have different batch dimensions.\n\nBefore, the process would crash or certain elements would be silently ignored. Now an InvalidArgument is raised.\n\nPiperOrigin-RevId: 384844020\nChange-Id: Iba44417e383bdd0e1abc4012bfca83b2377dd335", "ground_truth": 1, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Input Validation**:\n   - The code begins by retrieving inputs `input` and `rhs` from the `OpKernelContext`.\n   - It checks that the input has rank \u2265 2 (`ndims >= 2`), which is a valid dimensionality check.\n   - It ensures that `rhs` has the same rank as `input`.\n   - It validates that the last two dimensions are consistent: `input.dim_size(ndims - 2) == n` (square matrix), and `rhs.dim_size(ndims - 2) == n` (same number of rows).\n   - These checks prevent malformed or inconsistent tensor shapes from being processed, which is good defensive programming.\n\n2. **Memory Allocation and Buffer Management**:\n   - The output tensor is allocated using `forward_input_or_allocate_output`, which safely handles input/output aliasing and ensures proper memory management.\n   - Temporary tensors (`input_copy`, `pivots`, `transposed_rhs`) are allocated using `solver->allocate_scoped_tensor`, which is a safe mechanism that ties the lifetime of the tensor to the solver and the async operation.\n   - The code uses `std::unique_ptr<CudaSolver>` to manage the solver object, ensuring proper cleanup.\n   - Scratch space is allocated via `GetScratchSpace`, which is used for device pointers and is managed safely.\n\n3. **Memory Copy Operations**:\n   - The code uses `device.memcpy` for GPU memory copies, but only after ensuring that the source and destination tensors are valid and properly sized.\n   - The `DoMatrixTranspose` function is used for transposing tensors, and it is called only after validating the input and allocating the output tensor.\n   - All memory operations are bounded by the actual tensor sizes (e.g., `input.NumElements() * sizeof(Scalar)`), so there is no risk of buffer overflow.\n\n4. **Use of cuBLAS/cuSOLVER APIs**:\n   - The code uses `GetrfBatched` and `GetrsBatched` (batched LAPACK routines) or their non-batched counterparts.\n   - These are standard GPU linear algebra libraries, and the code correctly passes the required parameters (e.g., matrix dimensions, pointers, pivots).\n   - The `use_batched_solver` condition is based on a reasonable heuristic (`n <= kMaxMatrixSizeToBatchSizeRatio * batch_size`), which avoids performance pitfalls but does not introduce security risks.\n   - The `dev_info` vector is used to track device LAPACK info, and the `info_checker` callback ensures that any error from the GPU kernels is properly checked and reported.\n\n5. **Error Handling and Callbacks**:\n   - The code uses `OP_REQUIRES_OK_ASYNC` and `OP_REQUIRES_ASYNC` throughout, which ensure that any error in tensor operations or kernel launches is caught and propagated.\n   - The `info_checker` callback checks for singular matrices (via `host_infos[0].data()[i] <= 0`) and maps it to a standard error message, which is safe and consistent.\n   - The callback captures `dev_info` and `solver` via move, and the solver is deleted asynchronously via `CheckLapackInfoAndDeleteSolverAsync`, which is a safe pattern.\n\n6. **No User Input in Untrusted Context**:\n   - The inputs are tensors from a TensorFlow kernel context, which are validated and sanitized by the framework.\n   - There is no direct string manipulation, no dynamic code execution, no unsafe memory access, and no exposure to external input that could be exploited.\n\n7. **No Known Vulnerabilities**:\n   - The code does not use unsafe functions like `strcpy`, `memcpy` without bounds checks, or raw pointer arithmetic.\n   - All memory operations are bounded by tensor dimensions and validated via `OP_REQUIRES`.\n   - The use of `std::unique_ptr` and scoped tensor allocation ensures no memory leaks or dangling pointers.\n\nConclusion: The code is well-structured, uses safe memory management practices, performs thorough input validation, and properly handles GPU operations with error checking. There are no signs of buffer overflows, use-after-free, memory leaks, or other common security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 207780, "project": "radare2", "commit_id": "2b77b277d67ce061ee6ef839e7139ebc2103c1e3", "project_url": "https://github.com/radare/radare2", "commit_url": "https://github.com/radareorg/radare2/commit/2b77b277d67ce061ee6ef839e7139ebc2103c1e3", "commit_message": "Fix oobread in dyldcache ##crash\n\n* Reported by @hdthky via huntr.dev\n* Reproducers: poc1\n* BountyID: 8ae2c61a-2220-47a5-bfe8-fe6d41ab1f82", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1244", "cve_desc": "heap-buffer-overflow in GitHub repository radareorg/radare2 prior to 5.6.8. This vulnerability is capable of inducing denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Memory Allocation and Initialization**:\n   - `bins` is created using `r_list_newf`, which is safe as long as the free function is properly defined (assumed to be correct).\n   - `deps` is allocated with `R_NEWS0(int, cache->hdr->imagesCount)`, which initializes memory to zero. This is safe.\n   - `depArray` and `extras` are allocated conditionally and freed appropriately with `R_FREE` or `ht_pu_free`.\n\n2. **User Input Handling**:\n   - The variable `target_libs` is obtained via `r_sys_getenv(\"R_DYLDCACHE_FILTER\")`, which is environment variable input. This is user-controlled.\n   - `target_lib_names` is created using `r_str_split_list(target_libs, \":\", 0)`, which splits the environment variable by `:`. This is a common pattern, but we must check for potential issues.\n   - The code then uses `r_list_find(target_lib_names, lib_name, string_contains)` to check if a library name is in the filtered list. The `string_contains` function is assumed to be a custom comparator that checks if one string contains another (e.g., substring match). This is **not** a safe way to filter libraries because it allows for **wildcard-like matching** (e.g., filtering on \"lib\" would match \"libobjc.A.dylib\", \"libSystem.B.dylib\", etc.), but more importantly, it's **not a precise or secure way to validate allowed libraries**.\n\n3. **Potential Security Issue: Insecure String Matching**:\n   - The use of `strstr` to check if `lib_name` contains a substring from `target_lib_names` is problematic. For example, if `R_DYLDCACHE_FILTER` is set to `\"lib\"`, then any library name containing \"lib\" will be included, even if it's not intended.\n   - This could lead to **unintended exposure of sensitive binaries** or **bypass of intended filtering** if the filtering logic is meant to be exact or whitelist-based.\n   - However, this is not a direct buffer overflow or memory corruption issue. It's more of a **logic flaw** in filtering, which may allow unintended behavior but not necessarily a direct exploit.\n\n4. **Buffer Handling and String Operations**:\n   - `file` is a fixed-size array of 256 bytes. The code reads up to 256 bytes from the buffer using `r_buf_read_at`, then null-terminates it with `file[255] = 0`. This is safe.\n   - `strrchr` and `strdup` are used to extract the filename from the path. These are safe as long as the input path is valid and null-terminated.\n   - The code checks `last_slash > file` and `*scan == '/'`, which prevents out-of-bounds access.\n   - `strdup` is used to copy the filename, which is safe.\n\n5. **Use of `goto` and Error Handling**:\n   - The code uses `goto next` to skip cleanup and continue the loop on error. This is a common pattern in C and is safe as long as all resources are properly freed before the `goto`.\n   - `R_FREE` is used for `depArray`, `extras`, `img`, `deps`, `target_libs`, and `target_lib_names`, which ensures no memory leaks.\n   - `r_list_free` is used for `bins` and `target_lib_names` when needed.\n\n6. **No Buffer Overflows or Memory Corruption**:\n   - All string operations are bounded (e.g., `file` is 256 bytes, `r_buf_read_at` reads exactly `sizeof(file)` bytes).\n   - No use of unsafe functions like `strcpy`, `gets`, or `sprintf`.\n   - No integer overflows or underflows are evident in the loop bounds or array indexing.\n\n7. **Security Implications of Filtering**:\n   - While the filtering logic is **insecure in design** (substring matching instead of exact match), it does not lead to a direct exploit like buffer overflow, code execution, or memory corruption.\n   - It may allow unintended inclusion of binaries, but this is not a vulnerability in the traditional sense (e.g., no arbitrary code execution, no memory corruption).\n\n8. **Conclusion**:\n   - The code does not contain any exploitable vulnerabilities such as buffer overflows, use-after-free, or unsafe memory operations.\n   - The filtering logic is flawed but not a security vulnerability in the strict sense (it's a design issue, not a bug that can be exploited).\n   - All memory allocations are properly freed, and bounds are respected.\n\n(2) NO: No security vulnerability."}
{"idx": 195626, "project": "qemu", "commit_id": "7882080388be5088e72c425b02223c02e6cb4295", "project_url": "https://github.com/bonzini/qemu", "commit_url": "https://github.com/qemu/qemu/commit/7882080388be5088e72c425b02223c02e6cb4295", "commit_message": "virtio-serial: fix ANY_LAYOUT\n\nDon't assume a specific layout for control messages.\nRequired by virtio 1.\n\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nReviewed-by: Amit Shah <amit.shah@redhat.com>\nReviewed-by: Jason Wang <jasowang@redhat.com>", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2015-5745", "cve_desc": "Buffer overflow in the send_control_msg function in hw/char/virtio-serial-bus.c in QEMU before 2.4.0 allows guest users to cause a denial of service (QEMU process crash) via a crafted virtio control message.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `send_control_msg` is responsible for sending a control message through a VirtIO serial device. It takes a buffer `buf` of size `len` and attempts to send it via a virtqueue (`vq`).\n\n2. The function first checks if the virtqueue is ready using `virtio_queue_ready(vq)`. If not ready, it returns 0 \u2014 this is a valid safety check.\n\n3. It then attempts to pop an element from the virtqueue using `virtqueue_pop(vq, &elem)`. If no element is available, it returns 0. This is also a reasonable check.\n\n4. The key operation is: `memcpy(elem.in_sg[0].iov_base, buf, len);`\n\n   - `elem.in_sg[0].iov_base` is the base address of the first scatter-gather entry in the input descriptor.\n   - The function copies `len` bytes from the user-provided buffer `buf` into this memory location.\n\n5. However, there is **no validation** of the size of `elem.in_sg[0].iov_len` \u2014 the length of the input scatter-gather entry. This means that if the `iov_len` field of the first scatter-gather entry is smaller than `len`, the `memcpy` will write past the end of the allocated buffer, causing a buffer overflow.\n\n6. This is a classic case of a **missing bounds check** on the destination buffer size. The source length (`len`) is controlled by the caller (potentially untrusted), but the destination size (`elem.in_sg[0].iov_len`) is not verified before copying.\n\n7. This vulnerability can lead to memory corruption, potential information disclosure, or even remote code execution if exploited carefully.\n\n8. The function does not perform any validation of the scatter-gather list size before copying, which is a known security anti-pattern in virtio implementations.\n\nTherefore, this code contains a security vulnerability due to a potential buffer overflow.\n\n(1) YES: A security vulnerability detected."}
{"idx": 198703, "project": "LibRaw", "commit_id": "4606c28f494a750892c5c1ac7903e62dd1c6fdb5", "project_url": "https://github.com/LibRaw/LibRaw", "commit_url": "https://github.com/LibRaw/LibRaw/commit/4606c28f494a750892c5c1ac7903e62dd1c6fdb5", "commit_message": "0.16.1: fix for dcraw ljpeg_start() vulnerability", "ground_truth": 1, "cwe": ["CWE-189"], "cve": "CVE-2015-3885", "cve_desc": "Integer overflow in the ljpeg_start function in dcraw 7.00 and earlier allows remote attackers to cause a denial of service (crash) via a crafted image, which triggers a buffer overflow, related to the len variable.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `ljpeg_start` is designed to parse JPEG headers, specifically looking for markers like 0xFFC0 (SOF0), 0xFFC3 (SOF3), 0xFFC4 (DHT), 0xFFDA (SOS), and 0xFFDD (DRI).\n\n2. A buffer `data[0x10000]` (65,536 bytes) is declared. This is a large fixed-size buffer, but it's used to read JPEG markers and their data. The size is chosen to be large enough to hold any reasonable JPEG segment, which is acceptable for JPEG parsing.\n\n3. The function reads data from `ifp` (likely a file stream) using `fread`. The first read is for two bytes (marker), then for the length field (2 bytes), and then for the actual data of length `len`.\n\n4. The length `len` is calculated as `(data[2] << 8 | data[3]) - 2`. This is correct because the length field in JPEG markers includes the two bytes for the length itself, so subtracting 2 gives the payload size.\n\n5. The function then reads `len` bytes into the `data` buffer using `fread(data, 1, len, ifp)`. This is where a potential issue may arise: if `len` is very large (e.g., due to a malformed JPEG with a huge length field), this could lead to a buffer overflow.\n\n6. However, the `data` buffer is 0x10000 bytes (65,536 bytes). If `len` exceeds this size, `fread` will still read up to `len` bytes, but only `0x10000` bytes can be stored in `data`, leading to a buffer overflow.\n\n7. The code does not validate that `len` is less than or equal to `0x10000`. For example, if the length field is set to 0xFFFF (65,535), then `len = 65,535 - 2 = 65,533`, which is still less than 65,536, so it's safe. But if the length field is set to 0xFFFF, then `len = 65,533`, which is acceptable. However, if the length field is set to a value larger than 0xFFFF, it would wrap around due to 16-bit arithmetic, but the code uses `data[2] << 8 | data[3]` which is 16-bit, so it's capped at 65,535. So `len` is at most 65,533.\n\n8. But wait: `len = (data[2] << 8 | data[3]) - 2`. The maximum value of `data[2] << 8 | data[3]` is 0xFFFF = 65,535, so `len` is at most 65,533. Since `data` is 65,536 bytes, and `len` is at most 65,533, the read `fread(data, 1, len, ifp)` will not overflow the buffer.\n\n9. However, there is a critical issue: the code reads `len` bytes into `data`, but `len` is not checked against the buffer size before the read. Even though the maximum `len` is 65,533, which is less than 65,536, the code does not explicitly check this. But since the buffer is exactly 65,536 bytes and `len` is at most 65,533, it is safe.\n\n10. However, there is a subtle issue: the `data` buffer is used for multiple purposes. For example, in the `case 0xffc0` block, it accesses `data[7]`, `data[0]`, etc., assuming that `len >= 8` or more. But if `len` is small (e.g., 0), accessing `data[7]` would be out of bounds.\n\n11. Specifically, in `case 0xffc0`, the code does:\n    ```c\n    jh->bits = data[0];\n    jh->high = data[1] << 8 | data[2];\n    jh->wide = data[3] << 8 | data[4];\n    jh->clrs = data[5] + jh->sraw;\n    ```\n    and then:\n    ```c\n    if (len == 9 && !dng_version) getc(ifp);\n    ```\n    But if `len` is less than 6, accessing `data[5]` would be invalid. The code assumes `len >= 6` for this case, but it does not check.\n\n12. The `len` is read from the marker, and for SOF0 (0xFFC0), the standard length is 8 + 3 * number of components. The minimum length for SOF0 is 8 + 3*1 = 11 bytes. But the code does not validate that `len >= 6` before accessing `data[5]`.\n\n13. If a malformed JPEG has a length field of 5, then `len = 3`, and the code will read 3 bytes into `data`, but then access `data[5]`, which is out of bounds. This is a buffer read overflow.\n\n14. Similarly, in `case 0xffc3`, it accesses `data[7]`, so `len` must be at least 8. But if `len < 8`, this causes a buffer overflow.\n\n15. The code does not validate that `len` is sufficient for the data it accesses in each case. This is a critical flaw.\n\n16. Additionally, in `case 0xffc4`, it does:\n    ```c\n    for (dp = data; dp < data+len && (c = *dp++) < 4; )\n      jh->free[c] = jh->huff[c] = make_decoder_ref (&dp);\n    ```\n    This loop reads from `data` up to `len` bytes, but it assumes `dp < data+len`, which is safe as long as `len` is not negative or too large. But if `len` is negative (due to overflow), it could cause issues. However, `len` is calculated from `data[2] << 8 | data[3] - 2`, which is unsigned, so it's non-negative.\n\n17. But the main issue is that the code accesses `data[7]` in `case 0xffc3` and `data[5]` in `case 0xffc0` without checking that `len` is large enough. This is a classic buffer overflow vulnerability.\n\n18. For example, if a malicious JPEG has a marker with `len = 5`, then `fread(data, 1, 5, ifp)` reads 5 bytes, but the code then accesses `data[7]`, which is beyond the buffer.\n\n19. This is a clear buffer overflow vulnerability.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195740, "project": "libjpeg", "commit_id": "4746b577931e926a49e50de9720a4946de3069a7", "project_url": "https://github.com/thorfdbg/libjpeg", "commit_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7", "commit_message": "Fixed handling of empty JPEG-LS scans.", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-32978", "cve_desc": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `SampleInterleavedLSScan::ParseMCU` is part of a JPEG-like or lossless image decoding system (likely related to JPEG-LS or a similar standard).\n   - It processes a \"Minimum Coded Unit\" (MCU), which is a block of image data, typically 8x8 pixels, and decodes it line by line.\n   - The code uses various helper functions like `GetContext`, `GolombDecode`, `Reconstruct`, `UpdateContext`, etc., which are standard in entropy decoding.\n\n2. **Input Validation and Bounds Checking**:\n   - The function reads `m_ulRemaining[0]` (number of remaining MCU lines) and clamps it to a maximum of 8.\n   - It checks `m_pFrame->HeightOf() == 0` and adjusts `lines` to 8 if so \u2014 this is a defensive fix for a known issue (DNL marker case).\n   - It ensures `lines > 0` via `assert(lines > 0)` and `m_ucCount < 4` via `assert(m_ucCount < 4)`.\n   - The loop over `cx` (from 0 to `m_ucCount`) is bounded by `m_ucCount`, which is validated to be less than 4 \u2014 so no out-of-bounds access to arrays like `line[4]` or `lp[4]` is possible.\n   - The `length` variable is initialized from `m_ulWidth[0]`, and the loop runs `length` times. However, there is no explicit check that `m_ulWidth[0]` is valid or within bounds. But since this is part of a decoder, `m_ulWidth[0]` should be set during frame parsing and validated earlier.\n\n3. **Buffer Access and Pointer Arithmetic**:\n   - The code uses `*lp[cx]++ = ...` to write decoded pixel values into the line buffer.\n   - `lp[cx]` is initialized from `line[cx]->m_pData`, which is assumed to be a valid pointer to a data buffer.\n   - The loop runs `length` times (i.e., number of pixels per line), and `lp[cx]` is incremented each time.\n   - The key concern: **Is there a risk of buffer overflow?**\n     - The buffer size is determined by `m_ulWidth[0]`, and the loop runs exactly `length = m_ulWidth[0]` times.\n     - Since `lp[cx]` starts at `m_pData` and is incremented `length` times, it will write exactly `length` values.\n     - Therefore, **no buffer overflow occurs** as long as `m_pData` points to a buffer of size at least `m_ulWidth[0]` bytes (or elements).\n     - However, the code does **not validate** that `m_pData` is large enough \u2014 this is a potential issue.\n\n4. **Critical Point: Trust in Input Data**:\n   - The function reads from `m_Stream.ByteStreamOf()`, which is likely a bitstream from the input file.\n   - The `GolombDecode` and `DecodeRun` functions are used to decode data from this stream.\n   - If the input stream is malformed (e.g., too short, or contains invalid Golomb codes), these functions could:\n     - Read past the end of the stream (buffer underflow).\n     - Cause infinite loops or invalid memory access.\n   - However, the code **does not check for end-of-stream** or error conditions in `GolombDecode` or `DecodeRun`.\n   - The comment says: `// No error handling strategy. No RST in scans. Bummer!` \u2014 this is a **clear admission of missing error handling**.\n\n5. **Security Implications**:\n   - **Buffer overflow**: Not present in the `*lp[cx]++` writes, because the loop runs exactly `length` times and `length` is derived from `m_ulWidth[0]`, which should be validated earlier.\n   - **Buffer underflow**: A more serious risk. If the input stream is truncated or malformed, `GolombDecode` or `DecodeRun` might attempt to read beyond the end of the stream, leading to undefined behavior or crashes.\n   - **Denial of Service (DoS)**: Malformed input could cause infinite loops or excessive memory consumption (e.g., if `DecodeRun` returns a huge value).\n   - **Undefined Behavior**: The lack of error handling in critical decoding functions means that invalid input can lead to memory corruption or crashes.\n\n6. **Conclusion**:\n   - While there is no direct buffer overflow in the array indexing or pointer arithmetic, the **absence of input validation and error handling** in the decoding process (especially in `GolombDecode`, `DecodeRun`, and stream reading) creates a **critical security vulnerability**.\n   - This is a classic case of **lack of input validation in a parser**, which can be exploited to cause crashes, memory corruption, or DoS via malformed input.\n   - The comment explicitly acknowledges the lack of error handling, which is a red flag.\n\n(1) YES: A security vulnerability detected."}
{"idx": 211915, "project": "jasper", "commit_id": "839b1bcf0450ff036c28e8db40a7abf886e02891", "project_url": "https://github.com/mdadams/jasper", "commit_url": "https://github.com/jasper-software/jasper/commit/839b1bcf0450ff036c28e8db40a7abf886e02891", "commit_message": "jp2_dec: fix `numchans` mixup\n\nWhen iterating over `dec->cdef->data.cdef.ents`, we need to use its\n`numchans` variable, not the one in `jp2_dec_t`.\n\nFixes CVE-2018-19543\nFixes CVE-2017-9782\n\nCloses https://github.com/jasper-maint/jasper/issues/13\nCloses https://github.com/jasper-maint/jasper/issues/18\nCloses https://github.com/mdadams/jasper/issues/140\nCloses https://github.com/mdadams/jasper/issues/182", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2017-9782", "cve_desc": "JasPer 2.0.12 allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) via a crafted image, related to the jp2_decode function in libjasper/jp2/jp2_dec.c.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Stream Processing**:\n   - The function `jp2_decode` takes a `jas_stream_t *in` (input stream) and an optional `optstr` (options string).\n   - The function reads boxes from the input stream using `jp2_box_get(in)`, which parses JP2 (JPEG 2000) file format boxes.\n   - The input stream is not validated for size or content beyond basic box type checks. However, the `jp2_box_get` function is responsible for parsing and validating box headers and lengths, which is a standard practice in image format parsers.\n\n2. **Box Parsing and Validation**:\n   - The code checks for required boxes: JP (signature), FTYP (file type), and JP2C (code stream).\n   - It validates magic numbers (e.g., `JP2_JP_MAGIC`) and box types.\n   - It ensures that critical boxes like IHDR, COLR, and CMAP/PCLR are present or handled appropriately.\n   - These checks are essential and prevent malformed or malicious input from progressing further.\n\n3. **Memory Management and Buffer Safety**:\n   - The code uses `jas_alloc2` for dynamic memory allocation, which is safe as long as the size parameters are valid.\n   - All allocated memory is properly freed in the `error` label via `jp2_dec_destroy` and `jp2_box_destroy`.\n   - There is no use of unsafe functions like `strcpy`, `strcat`, or `sprintf` that could lead to buffer overflows.\n   - The code uses `JAS_CAST(jas_uint, ...)` to cast from `int` to `unsigned int`, which is safe in this context because `jas_image_numcmpts` returns a non-negative value.\n\n4. **Index Bounds Checking**:\n   - The code performs bounds checks when accessing arrays:\n     - `if (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)))` \u2014 checks if component number is valid.\n     - `if (dec->cmap->data.cmap.ents[i].pcol >= dec->pclr->data.pclr.numchans)` \u2014 checks palette index bounds.\n     - `if (dec->cdef->data.cdef.ents[i].channo >= dec->numchans)` \u2014 checks channel number bounds.\n   - These checks prevent out-of-bounds memory access.\n\n5. **Use of `jas_image_depalettize`**:\n   - The function `jas_image_depalettize` is called with `pclrd->numlutents` and `lutents` array.\n   - The `lutents` array is allocated with `jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t))`, and the size is derived from `pclrd->numlutents`, which comes from the PCLR box.\n   - The `numlutents` value is validated via the box parsing process, and the code ensures that `pcol + i * pclrd->numchans` does not exceed the bounds of `lutdata` (via the earlier check on `pcol`).\n   - This prevents buffer overflows during palette expansion.\n\n6. **Use of `jp2_getct` and `fromiccpcs`**:\n   - These functions are used to determine component types and color spaces based on parsed metadata.\n   - They are not directly involved in memory manipulation and are assumed to be safe.\n\n7. **Error Handling and Resource Cleanup**:\n   - The `error` label ensures that all allocated resources (boxes, decoder, image) are properly destroyed.\n   - This prevents memory leaks and ensures that invalid or malformed input does not lead to resource exhaustion.\n\n8. **No Use of Untrusted Input in Unsafe Contexts**:\n   - All user-controlled data (from the input stream) is parsed and validated before being used.\n   - There are no direct string concatenations, format string vulnerabilities, or unsafe function calls.\n\n9. **Potential Concerns**:\n   - The code uses `#if 0` to disable some debugging code, but this does not affect security.\n   - The `jas_eprintf` function is used for logging, but it does not use format strings from user input (it uses literal strings).\n   - The `JAS_DBGLOG` macro is used for debugging, but it is conditionally compiled and does not affect runtime behavior.\n\nConclusion:\nThe code performs comprehensive input validation, bounds checking, and proper memory management. It avoids common vulnerabilities such as buffer overflows, use-after-free, and out-of-bounds access. All user-controlled data is validated before use, and the parser is designed to fail gracefully on malformed input.\n\n(2) NO: No security vulnerability."}
{"idx": 198116, "project": "tensorflow", "commit_id": "87158f43f05f2720a374f3e6d22a7aaa3a33f750", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/87158f43f05f2720a374f3e6d22a7aaa3a33f750", "commit_message": "Prevent heap OOB in sparse reduction ops.\n\nPiperOrigin-RevId: 387934524\nChange-Id: I894aa30f1e454f09b471d565b4a325da49322c1a", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2021-37635", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of sparse reduction operations in TensorFlow can trigger accesses outside of bounds of heap allocated data. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_reduce_op.cc#L217-L228) fails to validate that each reduction group does not overflow and that each corresponding index does not point to outside the bounds of the input tensor. We have patched the issue in GitHub commit 87158f43f05f2720a374f3e6d22a7aaa3a33f750. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a kernel implementation (likely for a machine learning framework like TensorFlow) that processes sparse tensors. It takes input indices, values, shape, and reduction axes, and computes a reduced sparse tensor.\n\n2) The code performs several input validations:\n   - Uses OP_REQUIRES_OK to check for valid inputs\n   - Calls ValidateInputs() on shape_t and reduction_axes_t\n   - Uses tensor::DeepCopy to create deep copies of indices and values tensors\n\n3) Memory management:\n   - Uses ctx->allocate_output to allocate output tensor\n   - Uses ctx->allocate_temp to allocate a temporary scalar tensor\n   - All tensor allocations are properly checked with OP_REQUIRES_OK\n\n4) The code uses a lambda function CoordinatesToFlatIndex that:\n   - Checks for empty strides (handles case of reducing all dimensions)\n   - Uses CHECK_EQ to ensure coordinate and stride sizes match\n   - Performs safe arithmetic to compute flat indices\n\n5) The main loop:\n   - Uses sp.group() to iterate over groups\n   - Calls Op::template Run<T> to compute reduction\n   - Uses CoordinatesToFlatIndex to compute output index\n   - Writes result to out_flat with bounds checking via the index calculation\n\n6) Key security considerations:\n   - All input sizes are validated through the framework's mechanisms\n   - The deep copy prevents any potential stateful issues\n   - Index calculations are bounded by the shape and strides\n   - The code uses checked operations (CHECK_EQ) for array size validation\n   - All memory accesses are within bounds due to proper stride calculations\n\n7) The code does not perform any unsafe operations like:\n   - Buffer overflows\n   - Unchecked array accesses\n   - Direct memory manipulation\n   - String formatting with user input\n   - Unvalidated input parsing\n\n8) The framework's context (OpKernelContext) provides safety guarantees for tensor operations, and all operations are properly checked with OP_REQUIRES_OK.\n\n(2) NO: No security vulnerability."}
{"idx": 211090, "project": "cifs-utils", "commit_id": "f6eae44a3d05b6515a59651e6bed8b6dde689aec", "project_url": "https://github.com/piastry/cifs-utils", "commit_url": "http://git.samba.org/?p=cifs-utils.git;a=commitdiff;h=f6eae44a3d05b6515a59651e6bed8b6dde689aec", "commit_message": "mtab: handle ENOSPC/EFBIG condition properly when altering mtab\n\nIt's possible that when mount.cifs goes to append the mtab that there\nwon't be enough space to do so, and the mntent won't be appended to the\nfile in its entirety.\n\nAdd a my_endmntent routine that will fflush and then fsync the FILE if\nthat succeeds. If either fails then it will truncate the file back to\nits provided size. It will then call endmntent unconditionally.\n\nHave add_mtab call fstat on the opened mtab file in order to get the\nsize of the file before it has been appended. Assuming that that\nsucceeds, use my_endmntent to ensure that the file is not corrupted\nbefore closing it. It's possible that we'll have a small race window\nwhere the mtab is incorrect, but it should be quickly corrected.\n\nThis was reported some time ago as CVE-2011-1678:\n\n    http://openwall.com/lists/oss-security/2011/03/04/9\n\n...and it seems to fix the reproducer that I was able to come up with.\n\nSigned-off-by: Jeff Layton <jlayton@samba.org>\nReviewed-by: Suresh Jayaraman <sjayaraman@suse.de>", "ground_truth": 1, "cwe": ["CWE-20"], "cve": "CVE-2011-1678", "cve_desc": "smbfs in Samba 3.5.8 and earlier attempts to use (1) mount.cifs to append to the /etc/mtab file and (2) umount.cifs to append to the /etc/mtab.tmp file without first checking whether resource limits would interfere, which allows local users to trigger corruption of the /etc/mtab file via a process with a small RLIMIT_FSIZE value, a related issue to CVE-2011-1089.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `add_mtab` is responsible for adding an entry to the `/etc/mtab` file (or similar mount table), which tracks currently mounted filesystems.\n\n2. The function starts by retrieving the real UID using `getuid()`. If the user is not root (uid != 0), it attempts to get the username via `getusername(uid)` and stores it in `mount_user`.\n\n3. The function then calls `setreuid(geteuid(), -1)`, which sets the real UID to the effective UID. This is intended to drop privileges and prevent unprivileged users from sending signals to the process. This is a reasonable security practice.\n\n4. Signal handling is modified using `sigfillset` and `sigprocmask` to block all signals. This prevents signal interference during critical operations, which is a good defensive measure.\n\n5. The function calls `toggle_dac_capability(1, 1)` to enable DAC (Discretionary Access Control) capability, likely to allow writing to `/etc/mtab`. This is necessary for the operation but must be handled carefully.\n\n6. The function locks the mtab file using `lock_mtab()` to prevent race conditions. This is a good practice.\n\n7. It opens the mtab file in append mode using `setmntent(MOUNTED, \"a+\")`. This is correct for adding entries.\n\n8. The `mntent` structure is populated:\n   - `mnt_fsname` = `devname` (device name)\n   - `mnt_dir` = `mountpoint`\n   - `mnt_type` = `fstype` (filesystem type)\n   - `mnt_opts` is allocated with `calloc(MTAB_OPTIONS_LEN, 1)` and then populated based on flags (ro/rw, mand, noexec, nosuid, nodev, sync) and optionally the `user=` option if `mount_user` is set.\n\n9. The `strlcat` function is used to append options. `strlcat` is safe because it takes a size limit and prevents buffer overflow, as long as the total length does not exceed `MTAB_OPTIONS_LEN`.\n\n10. The `mountent.mnt_opts` is properly null-terminated by `calloc`, and `strlcat` ensures that the string is null-terminated and does not overflow.\n\n11. The `addmntent` function is used to write the entry to the file. This function is designed to safely write the `mntent` structure to the file.\n\n12. After the operation, the file is closed with `endmntent`, the lock is released, and memory is freed with `SAFE_FREE(mountent.mnt_opts)`.\n\n13. The DAC capability is toggled off at the end.\n\n14. The function returns the result code.\n\nNow, let's look for potential vulnerabilities:\n\n- Input validation: The function does not validate `devname`, `mountpoint`, or `fstype` for malicious content. However, these are not directly used in a way that would lead to command injection or format string vulnerabilities. The `addmntent` function is designed to safely write the mount entry, and the `mntent` structure is not used in a way that allows arbitrary code execution.\n\n- `mount_user` is obtained via `getusername(uid)`. This function is assumed to be safe and return a valid username. However, if `getusername` is not properly implemented (e.g., returns a string that could be manipulated), it could lead to a buffer overflow or injection. But the code uses `strlcat` with a fixed size (`MTAB_OPTIONS_LEN`), which prevents overflow.\n\n- The `strlcat` calls are all bounded by `MTAB_OPTIONS_LEN`, so no buffer overflow is possible in the `mnt_opts` string.\n\n- The use of `setmntent` and `addmntent` is standard and safe for this purpose.\n\n- The function properly handles errors and cleans up resources (locks, file, memory).\n\n- The signal masking and privilege dropping are correctly implemented.\n\n- The only potential concern is that `devname`, `mountpoint`, and `fstype` are passed directly to `mntent` without validation. However, these are not used in a context that allows arbitrary command execution or format string attacks. The `addmntent` function is designed to handle such data safely.\n\nConclusion: The code uses safe string functions (`strlcat`), properly manages resources, handles errors, and avoids common vulnerabilities like buffer overflows, race conditions, and privilege escalation. The use of `addmntent` ensures that the mount table entry is written safely.\n\n(2) NO: No security vulnerability."}
{"idx": 195398, "project": "v4l2loopback", "commit_id": "e4cd225557486c420f6a34411f98c575effd43dd", "project_url": "https://github.com/umlaeute/v4l2loopback", "commit_url": "https://github.com/umlaeute/v4l2loopback/commit/e4cd225557486c420f6a34411f98c575effd43dd", "commit_message": "add explicit format specifier to printf() invocations\n\nCWE-134", "ground_truth": 1, "cwe": ["CWE-134"], "cve": "CVE-2022-2652", "cve_desc": "Depending on the way the format strings in the card label are crafted it's possible to leak kernel stack memory. There is also the possibility for DoS due to the v4l2loopback kernel module crashing when providing the card label on request (reproduce e.g. with many %s modifiers in a row).", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `vidioc_querycap` is a V4L2 (Video4Linux2) ioctl handler that fills a `v4l2_capability` structure with device information.\n\n2. The function retrieves the device context (`dev`) using `v4l2loopback_getdevice(file)`. This is a standard way to get device-specific data, and assuming the function is properly implemented, this should be safe.\n\n3. The variable `labellen` is calculated as the minimum of `sizeof(cap->card)` and `sizeof(dev->card_label)`. This ensures that the copy into `cap->card` will not exceed the size of the destination buffer. This is a good defensive programming practice.\n\n4. `strlcpy(cap->driver, \"v4l2 loopback\", sizeof(cap->driver))` is used to copy a fixed string into `cap->driver`. `strlcpy` is safe because it guarantees null termination and bounds checking.\n\n5. `snprintf(cap->card, labellen, dev->card_label)` copies the card label into `cap->card` with a size limit (`labellen`), which is the smaller of the two buffer sizes. This prevents buffer overflow.\n\n6. `snprintf(cap->bus_info, sizeof(cap->bus_info), \"platform:v4l2loopback-%03d\", device_nr)` uses `snprintf` with a known buffer size and format string. The format string is static and safe, and the `device_nr` is an integer that is formatted as a 3-digit number. This is safe as long as `device_nr` is not excessively large (e.g., > 999), but even then, `snprintf` will not overflow because it respects the buffer size.\n\n7. The version field is set conditionally based on kernel version. The value `V4L2LOOPBACK_VERSION_CODE` is a constant, and this assignment is safe.\n\n8. The `capabilities` variable is built from known flags (`V4L2_CAP_STREAMING`, `V4L2_CAP_READWRITE`, and optionally `V4L2_CAP_VIDEO_M2M` and capture/output flags based on device state). These are all well-defined constants and not derived from user input.\n\n9. The `dev->vdev->device_caps` assignment is conditional on kernel version, but the value being assigned is `capabilities`, which is computed from known constants and device state.\n\n10. `memset(cap->reserved, 0, sizeof(cap->reserved))` clears the reserved field, which is good practice to avoid information leakage.\n\n11. All string copying uses safe functions (`strlcpy`, `snprintf`) with proper buffer size checks.\n\n12. No user-controlled input is directly used in string formatting or copying without bounds checking.\n\n13. The only potential concern is `dev->card_label` \u2014 if this is user-controlled or can be set by a malicious user, and if it's longer than `sizeof(cap->card)`, then `labellen` ensures it won't overflow `cap->card`. But since `labellen` is the minimum of the two sizes, it's safe.\n\n14. The `device_nr` is derived from `video_get_drvdata(dev->vdev)`, which is a kernel driver data pointer. This is internal state and not user-controlled.\n\nConclusion: All buffer operations are bounded and use safe functions. No known vulnerabilities such as buffer overflows, format string issues, or unsafe string copies are present.\n\n(2) NO: No security vulnerability."}
{"idx": 197666, "project": "njs", "commit_id": "eafe4c7a326b163612f10861392622b5da5b1792", "project_url": "https://github.com/nginx/njs", "commit_url": "https://github.com/nginx/njs/commit/eafe4c7a326b163612f10861392622b5da5b1792", "commit_message": "Fixed Array.prototype.lastIndexOf() with unicode string as \"this\".\n\nPreviously, when lastIndexOf() was called with unicode string as \"this\"\nargument and a negative \"fromIndex\" argument null-pointer dererence\nmight occur because njs_string_offset() was called with invalid index\nvalue whereas njs_string_offset() should always be called with valid\nindex argument.\n\nThe fix is to verify that from index is valid.\n\nThis closes #482 issue on Github.", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-31307", "cve_desc": "Nginx NJS v0.7.2 was discovered to contain a segmentation violation in the function njs_string_offset at src/njs_string.c.", "vuln": 1, "reasoning": "Let's analyze the provided C code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `njs_object_iterate_reverse` is designed to iterate over elements of an array, string, or object in reverse order (from `from` to `to`). It uses a handler function (`handler`) to process each element or property.\n\nKey inputs:\n- `args->value`: The value to iterate over (can be array, string, or object).\n- `args->from`, `args->to`: The range of indices to iterate over (inclusive).\n- `handler`: A callback to process each item.\n\nThe function handles three types:\n1. Arrays (fast and slow paths).\n2. Strings (byte/ASCII and UTF-8).\n3. General objects (via indices or direct property access).\n\n---\n\n### Step 2: Check for buffer overflows or out-of-bounds access\n\n#### Array handling:\n```c\nfrom += 1;\nwhile (from-- > to) {\n    if (njs_slow_path(!array->object.fast_array)) {\n        goto process_object;\n    }\n\n    if (njs_fast_path(from < array->length && njs_is_valid(&array->start[from]))) {\n        ret = handler(vm, args, &array->start[from], from);\n    } else {\n        entry = njs_value_arg(&njs_value_invalid);\n        ret = njs_value_property_i64(vm, value, from, &prop);\n        if (njs_slow_path(ret != NJS_DECLINED)) {\n            if (ret == NJS_ERROR) {\n                return NJS_ERROR;\n            }\n            entry = &prop;\n        }\n        ret = handler(vm, args, entry, from);\n    }\n    ...\n}\n```\n- `from` is incremented by 1 before the loop: `from += 1`.\n- The loop condition is `from-- > to`, so it iterates from `from` down to `to + 1`.\n- The index `from` is used to access `array->start[from]` only if `from < array->length` and valid.\n- If not valid, it falls back to `njs_value_property_i64`, which is safe as it's a property lookup.\n\n\u26a0\ufe0f **Potential issue**: `from` is incremented before the loop, but `from` is passed in from `args->from`. If `args->from` is very large (e.g., `INT64_MAX`), then `from += 1` could cause **integer overflow** (signed integer overflow), which is **undefined behavior** in C.\n\nThis is critical: `from` is `int64_t`, and if `args->from` is `INT64_MAX`, then `from += 1` becomes `INT64_MIN` (wraparound). Then the loop condition `from-- > to` will be true for a very long time, potentially iterating over invalid memory.\n\nThis could lead to:\n- Out-of-bounds memory access.\n- Infinite loop (if `to` is small).\n- Crash or memory corruption.\n\nThis is a **classic integer overflow vulnerability**.\n\n---\n\n### Step 3: Check string handling\n\n#### ASCII/byte string:\n```c\np = string_prop.start + from;\ni = from + 1;\nwhile (i-- > to) {\n    (void) njs_string_new(vm, &character, p, 1, 1);\n    ...\n    p--;\n}\n```\n- `p` starts at `string_prop.start + from`.\n- If `from` is larger than the string length, `p` will point beyond the string buffer.\n- `p--` is used to move backward, but no bounds check is done on `p` before dereferencing.\n\n\u26a0\ufe0f **Problem**: If `from` is greater than or equal to `length`, then `p = string_prop.start + from` points beyond the string. Then `p--` may access invalid memory.\n\nEven though the loop condition is `i-- > to`, it doesn't validate that `from` is within bounds. So if `from` is too large, this leads to **buffer over-read** (reading past the string buffer).\n\nSimilarly, in the UTF-8 case:\n```c\np = njs_string_offset(string_prop.start, end, from);\np = njs_utf8_next(p, end);\n...\nwhile (i-- > to) {\n    pos = njs_utf8_prev(p);\n    (void) njs_string_new(vm, &character, pos, p - pos, 1);\n    p = pos;\n}\n```\n- `njs_string_offset` may return `end` if `from` is out of bounds.\n- But if `from` is too large, `p` could be `end`, and `njs_utf8_next(p, end)` returns `end`, then `njs_utf8_prev(p)` on `end` is undefined behavior.\n\nSo again, **no bounds check on `from` relative to string length**.\n\n---\n\n### Step 4: Object iteration\n\n```c\nif (!njs_fast_object(from - to)) {\n    keys = njs_array_indices(vm, value);\n    ...\n    while (i > 0) {\n        idx = njs_string_to_index(&keys->start[--i]);\n        if (idx < to || idx > from) {\n            continue;\n        }\n        ...\n    }\n}\n```\n- `njs_array_indices` returns an array of numeric indices.\n- `idx` is checked to be within `[to, from]`.\n- This is safe.\n\nBut the `njs_fast_object` check is based on `from - to`, which could be negative or very large \u2014 but that\u2019s not directly a vulnerability.\n\nHowever, the **main issue** is that `from` and `to` are not validated against the actual size of the data structure (array length, string length, or object property count) before use.\n\n---\n\n### Step 5: Overall analysis\n\n- The function **does not validate** that `from` and `to` are within the valid range of the data being iterated.\n- `from` is incremented unconditionally (`from += 1`) before the loop, which can cause **signed integer overflow** if `from` is `INT64_MAX`.\n- This leads to **undefined behavior**, potentially causing:\n  - Infinite loops.\n  - Out-of-bounds memory access.\n  - Crash or memory corruption.\n- In string handling, `from` is used to index into a string buffer without bounds checking, leading to **buffer over-read**.\n- These are **serious security vulnerabilities** (e.g., denial of service, memory corruption, potential code execution).\n\n---\n\n### Conclusion\n\nDespite the use of `njs_slow_path` and `njs_fast_path` macros (which are for performance), the code lacks proper bounds checking on user-controlled input (`from`, `to`) and performs unsafe arithmetic that can lead to integer overflow and memory access violations.\n\n(1) YES: A security vulnerability detected."}
{"idx": 196841, "project": "furnace", "commit_id": "0eb02422d5161767e9983bdaa5c429762d3477ce", "project_url": "https://github.com/tildearrow/furnace", "commit_url": "https://github.com/tildearrow/furnace/commit/0eb02422d5161767e9983bdaa5c429762d3477ce", "commit_message": "fix possible pattern crash\n\nissue #325", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2022-1289", "cve_desc": "A denial of service vulnerability was found in tildearrow Furnace. It has been classified as problematic. This is due to an incomplete fix of CVE-2022-1211. It is possible to initiate the attack remotely but it requires user interaction. The issue got fixed with the patch 0eb02422d5161767e9983bdaa5c429762d3477ce.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Overview**:\n   - The function `FurnaceGUI::patternRow` is responsible for rendering a single row in a pattern editor UI (likely in a music tracker application like Furnace).\n   - It uses ImGui (a dear imgui library) to render UI elements such as row numbers, notes, instruments, volumes, and effects.\n   - The function takes parameters including row index `i`, playback state `isPlaying`, line height, number of channels `chans`, order index `ord`, and a cache of pattern pointers `patCache`.\n\n2. **Input Validation**:\n   - The function performs several bounds checks:\n     - `if (ord < 0 || ord >= e->song.ordersLen)` \u2192 prevents out-of-bounds access to `e->song.ordersLen`.\n     - `if (i < 0 || i >= e->song.patLen)` \u2192 prevents out-of-bounds access to pattern data.\n     - `if (cursorPosY < -lineHeight || cursorPosY > ImGui::GetWindowSize().y)` \u2192 skips rendering if the row is not visible.\n   - These checks are sufficient to prevent buffer overflows or out-of-bounds memory access based on user-controlled indices.\n\n3. **Buffer Usage**:\n   - A static character array `id[32]` is used to format strings for ImGui widgets (e.g., `sprintf(id, \"%s##PN_%d_%d\", ...)`).\n   - The format string uses `noteName(...)`, which returns a string (likely a note name like \"C#4\"), and then appends `##PN_%d_%d` as an ImGui ID suffix.\n   - The `sprintf` usage is **potentially dangerous** if `noteName` returns a string longer than 20 characters (since `id` is 32 bytes, and the format adds `##PN_` + two integers, which can be up to ~10 chars total). However:\n     - `noteName` is likely a fixed-length function returning a string like \"C#4\", \"D5\", etc. \u2014 typically 3\u20135 characters.\n     - The total length of the format string is bounded: `noteName` (max ~5) + `\"##PN_\"` (5) + two integers (max ~6 each) \u2192 total ~17 characters.\n     - Therefore, `sprintf(id, ...)` will not overflow `id[32]` under normal conditions.\n\n4. **ImGui ID Safety**:\n   - ImGui uses unique IDs for widgets. The `##` syntax in the format string ensures that the ID is unique per widget instance (e.g., `PN_0_0`, `PN_1_0`, etc.).\n   - The use of `##` is correct and safe \u2014 it prevents ID collisions and is a standard ImGui pattern.\n\n5. **Memory Access Safety**:\n   - The function accesses `patCache[j]`, which is a pointer to `const DivPattern*`.\n   - It then accesses `pat->data[i][0]`, `pat->data[i][1]`, etc.\n   - The bounds checks on `i` and `j` (via `i < e->song.patLen` and `j < chans`) ensure that `patCache[j]` is valid and that `i` is within the pattern's row range.\n   - The `pat->data` array is assumed to be properly allocated and managed by the application.\n\n6. **No User Input Directly to String Formatting**:\n   - The only user-controlled input is `i`, `j`, `ord`, and `patCache`, which are all validated before use.\n   - The `noteName` function is not user-controlled \u2014 it's a deterministic function based on pattern data.\n   - No user input is directly passed to `sprintf` without validation.\n\n7. **No Dynamic Memory Allocation or System Calls**:\n   - The function does not perform any dynamic memory allocation, file I/O, or system calls.\n   - No use of unsafe functions like `strcpy`, `gets`, or `sprintf` with untrusted input.\n\n8. **Security Implications**:\n   - The only potential risk is `sprintf` with a fixed-size buffer (`id[32]`), but as analyzed, the input is bounded and safe.\n   - No buffer overflow, use-after-free, or injection vulnerabilities are present.\n   - The code follows defensive programming practices: bounds checks, early returns, and safe string formatting.\n\n(2) NO: No security vulnerability."}
{"idx": 196316, "project": "barebox", "commit_id": "0a9f9a7410681e55362f8311537ebc7be9ad0fbe", "project_url": "https://github.com/saschahauer/barebox", "commit_url": "https://github.com/saschahauer/barebox/commit/0a9f9a7410681e55362f8311537ebc7be9ad0fbe", "commit_message": "crypto: digest: use crypto_memneq()\n\nWhen verifying a digest it is important not to leak timing information\nthrough memcmp(). Use crypto_memneq() instead.\n\nSigned-off-by: Sascha Hauer <s.hauer@pengutronix.de>", "ground_truth": 1, "cwe": ["CWE-200"], "cve": "CVE-2021-37847", "cve_desc": "crypto/digest.c in Pengutronix barebox through 2021.07.0 leaks timing information because memcmp is used during digest verification.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `digest_generic_verify` is designed to verify a message digest by comparing a computed digest (from a digest context `d`) with a provided digest `md`.\n\n2. The function first determines the length of the digest using `digest_length(d)`, which returns the expected length of the digest (e.g., 20 for SHA-1, 32 for SHA-256).\n\n3. It allocates a temporary buffer `tmp` of size `len` using `xmalloc(len)`. This is a safe allocation since it's based on the known digest length.\n\n4. It then calls `digest_final(d, tmp)` to compute the digest from the context `d` and store it in `tmp`. This function is expected to write exactly `len` bytes into `tmp`.\n\n5. The function checks if `digest_final` returned an error (`ret != 0`). If so, it jumps to `end` and returns the error.\n\n6. It then compares the computed digest (`tmp`) with the provided digest (`md`) using `memcmp(md, tmp, len)`. The result of `memcmp` is used to set `ret` to `-EINVAL` if they differ, or `0` if they match.\n\n7. Finally, it frees the allocated buffer `tmp` and returns `ret`.\n\nNow, consider potential security issues:\n\n- The length `len` is obtained from `digest_length(d)`, which is assumed to be a trusted function returning the correct digest size. If this function is not properly validated or is influenced by user input, it could be a vector for attack. However, in this code, there is no indication that `d` is user-controlled or that `digest_length` is untrusted.\n\n- The buffer `tmp` is allocated with exactly `len` bytes, and `digest_final` is expected to write exactly `len` bytes. This avoids buffer overflow.\n\n- The `memcmp` call uses `len` as the size, which is consistent with the expected digest length. No off-by-one or underflow issues are present.\n\n- The use of `xmalloc` (assuming it's a safe wrapper around `malloc`) and proper `free` ensures no memory leaks.\n\n- The comparison is done in constant time? Not necessarily \u2014 `memcmp` is not guaranteed to be constant-time, but this is not a critical issue in this context because the comparison is only between two known digests (not secret data), and the result is not used in a way that would leak timing information (e.g., in authentication). However, if this function is used in a context where timing side-channel attacks are possible (e.g., password hashing verification), then `memcmp` could be a concern. But the function is named `digest_generic_verify`, suggesting it's for general-purpose digest verification, not for secret comparisons.\n\n- There is no input validation of `md` \u2014 but `md` is expected to be a pointer to a buffer of size `len`. If `md` is not of the correct length, this could lead to a buffer overflow. However, the function uses `len` from `digest_length(d)` to determine the size, and `memcmp` is called with `len`. So if `md` is shorter than `len`, `memcmp` will read past the end of `md`, which is a buffer over-read (a security issue).\n\nWait \u2014 this is critical: `memcmp(md, tmp, len)` will read `len` bytes from `md`. But if `md` is not guaranteed to be at least `len` bytes long, this is a buffer over-read (a security vulnerability). The function does not validate the length of `md` before using it.\n\nFor example, if `md` is a pointer to a buffer of size 16, but `len` is 32 (e.g., SHA-256), then `memcmp` will read 32 bytes from `md`, but only 16 are valid \u2014 this leads to undefined behavior and potential information disclosure.\n\nTherefore, the function assumes that `md` is at least `len` bytes long, but there is no check to ensure this.\n\nThis is a security vulnerability: an attacker could pass a short `md` buffer, leading to a buffer over-read.\n\n(1) YES: A security vulnerability detected."}
{"idx": 197499, "project": "gpac", "commit_id": "dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/dc7de8d3d604426c7a6e628d90cb9fb88e7b4c2c", "commit_message": "fixed #2212", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-2453", "cve_desc": "Use After Free in GitHub repository gpac/gpac prior to 2.1-DEV.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Buffer Handling**:\n   - The function `BD_DecMFFieldVec` takes a bitstream (`GF_BitStream *bs`) as input, which is read using `gf_bs_read_int(bs, 5)` and `gf_bs_read_int(bs, NbBits)`.\n   - The number of fields (`nbFields`) is derived from the bitstream, with `NbBits` determining the number of bits used to encode `nbFields`. This is a common technique in binary protocols.\n   - The value of `NbBits` is read using 5 bits, so it can range from 0 to 31. This means `nbFields` can be up to 2^31 - 1, which is a very large number (over 2 billion).\n   - However, the code later uses `nbFields` in a loop: `for (i=0; i<nbFields; i++)`. If `nbFields` is extremely large (e.g., 2^31 - 1), this loop could cause a denial of service (DoS) by consuming excessive CPU and memory resources.\n\n2. **Memory Allocation and Resource Management**:\n   - For non-MFNODE fields, the code calls `gf_sg_vrml_mf_alloc(field->far_ptr, field->fieldType, nbFields)` to allocate memory for `nbFields` elements.\n   - For MFNODE fields, it dynamically creates nodes via `gf_bifs_dec_node(codec, bs, field->NDTtype)` and adds them to a list.\n   - If `nbFields` is unbounded (e.g., due to malicious bitstream), this could lead to:\n     - Memory exhaustion (heap exhaustion).\n     - Excessive CPU usage due to large loops.\n     - Potential integer overflow if `nbFields` is so large that it causes arithmetic overflow in subsequent operations.\n\n3. **Lack of Bounds Checking on `nbFields`**:\n   - Although `NbBits` is limited to 5 bits (so `nbFields` is at most 2^31 - 1), this is still a very large number.\n   - The code does not validate whether `nbFields` is reasonable or within expected bounds (e.g., a maximum of 1000 or 10000).\n   - There is no check like `if (nbFields > MAX_ALLOWED_FIELDS) return GF_INVALID_PARAMETER;`.\n   - This makes the code vulnerable to a **resource exhaustion attack** (a form of DoS), where a malicious bitstream can cause the decoder to allocate massive amounts of memory or spin in a loop for an extremely long time.\n\n4. **Security Implications**:\n   - While there is no direct buffer overflow or code execution vulnerability (e.g., no use of unsafe string functions or unchecked array indexing), the lack of bounds checking on `nbFields` leads to a **critical resource exhaustion vulnerability**.\n   - This is a well-known class of vulnerabilities in binary parsers and decoders (e.g., in MPEG-4 BIFS, ISO/IEC 14496-1), where unbounded values from the bitstream can be exploited to crash or hang the system.\n\n5. **Comparison to Known Vulnerabilities**:\n   - Similar vulnerabilities have been found in other BIFS decoders (e.g., in GPAC), where unbounded `nbFields` values led to DoS.\n   - The absence of a maximum limit on `nbFields` is a design flaw that can be exploited.\n\nConclusion: The code does not perform any bounds checking on the number of fields (`nbFields`) derived from the bitstream, which can be made arbitrarily large (up to 2^31 - 1). This can lead to resource exhaustion (memory and CPU), resulting in a denial of service. This is a security vulnerability, even if it's not a traditional buffer overflow or code execution issue.\n\n(1) YES: A security vulnerability detected."}
{"idx": 204534, "project": "admesh", "commit_id": "e84d8353f1347e1f26f0a95770d92ba14e6ede38", "project_url": "https://github.com/admesh/admesh", "commit_url": "https://github.com/admesh/admesh/commit/e84d8353f1347e1f26f0a95770d92ba14e6ede38", "commit_message": "Fix heap buffer overflow in stl_update_connects_remove_1\n\n\n- Add argument value check to the stl_update_connects_remove_1\n- Add neighbor value check in stl_remove_degenerate\n\nFixes https://github.com/admesh/admesh/issues/28\nMerges https://github.com/admesh/admesh/pull/55", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2018-25033", "cve_desc": "ADMesh through 0.98.4 has a heap-based buffer over-read in stl_update_connects_remove_1 (called from stl_remove_degenerate) in connect.c in libadmesh.a.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `stl_remove_degenerate` is designed to remove degenerate facets from an STL file representation. A degenerate facet is one where two or more vertices are identical, making it geometrically invalid (e.g., a line or point instead of a triangle).\n\n2. The function first checks if `stl->error` is set \u2014 if so, it returns early. This is safe and expected behavior.\n\n3. It checks if all three vertices of the facet are equal using `memcmp`. If so, it calls `stl_remove_facet` to remove the facet. This is a valid case for degeneracy.\n\n4. Then it checks pairwise equality of vertices:\n   - If vertex 0 == vertex 1 \u2192 edge1=1, edge2=2, edge3=0\n   - If vertex 1 == vertex 2 \u2192 edge1=0, edge2=2, edge3=1\n   - If vertex 2 == vertex 0 \u2192 edge1=0, edge2=1, edge3=2\n   - Otherwise, no degeneracy \u2192 return\n\n   This logic correctly identifies degenerate edges (two vertices equal) and assigns the indices of the two equal vertices and the third (unequal) one.\n\n5. It retrieves neighbor indices for the two edges (edge1 and edge2) from `stl->neighbors_start[facet].neighbor[edge1]` and `edge2`. These are used to update connectivity.\n\n6. It checks if neighbor1 or neighbor2 is -1 (no neighbor), and if so, calls `stl_update_connects_remove_1(stl, neighbor)` \u2014 which appears to be a helper to update connectivity when a neighbor is removed.\n\n7. It then retrieves `vnot1`, `vnot2`, `vnot3` \u2014 which seem to represent which vertex is not part of the edge (i.e., the opposite vertex). These are used to update neighbor relationships.\n\n8. It updates the neighbor and which_vertex_not fields in the neighboring facets:\n   - For neighbor1: updates its neighbor at position `(vnot1 + 1) % 3` to neighbor2, and its `which_vertex_not` to vnot2.\n   - For neighbor2: similarly updates to point to neighbor1.\n\n   This is a standard operation in mesh connectivity updates when removing a degenerate edge.\n\n9. Then it removes the facet via `stl_remove_facet(stl, facet)`.\n\n10. Finally, if neighbor3 (the third neighbor) is not -1, it calls `stl_update_connects_remove_1(stl, neighbor3)` and sets the corresponding neighbor entry to -1.\n\nNow, let\u2019s look for potential vulnerabilities:\n\n- **Bounds checking**: The code uses `edge1`, `edge2`, `edge3` as indices into the `neighbor` and `which_vertex_not` arrays. These are derived from the `memcmp` checks and are only set to 0, 1, or 2 \u2014 valid indices for a triangle (3 edges). So no out-of-bounds access.\n\n- **Null pointer dereference**: The function assumes `stl` is valid and `stl->facet_start` and `stl->neighbors_start` are properly allocated. But the function does not validate that `facet` is within bounds of `stl->facet_start`. This is a critical issue.\n\n  - The function takes `int facet` as input but does not check if `facet` is within the valid range of facets (e.g., `facet >= 0 && facet < stl->num_facets`). If an attacker can control `facet` (e.g., via malformed input), this could lead to out-of-bounds access into `stl->facet_start` and `stl->neighbors_start`.\n\n  - This is a classic buffer overflow or out-of-bounds access vulnerability, which can lead to memory corruption, crashes, or even code execution.\n\n- **Use of `stl_remove_facet`**: This function is called without checking if `facet` is valid. If `facet` is out of bounds, `stl_remove_facet` may access invalid memory.\n\n- **No input validation on `facet`**: The function does not validate the `facet` parameter before using it to index into `stl->facet_start[facet]` and `stl->neighbors_start[facet]`. This is a serious flaw.\n\n- **Other operations**: The use of `(vnot1 + 1) % 3` is safe because `vnot1` is expected to be 0, 1, or 2 (since it's a vertex index in a triangle), so `(vnot1 + 1) % 3` is always a valid index (0, 1, or 2).\n\nConclusion: The function lacks bounds checking on the `facet` parameter, which can lead to out-of-bounds memory access if `facet` is invalid. This is a security vulnerability (e.g., memory corruption, potential for exploitation).\n\n(1) YES: A security vulnerability detected."}
{"idx": 195801, "project": "php-src", "commit_id": "0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f", "project_url": "https://github.com/php/php-src", "commit_url": "https://github.com/php/php-src/commit/0c8a2a2cd1056b7dc403eacb5d2c0eec6ce47c6f", "commit_message": "Fix for bug #72790 and bug #72799\n\n(cherry picked from commit a14fdb9746262549bbbb96abb87338bacd147e1b)\n\nConflicts:\n\text/wddx/wddx.c", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2016-7132", "cve_desc": "ext/wddx/wddx.c in PHP before 5.6.25 and 7.x before 7.0.10 allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) or possibly have unspecified other impact via an invalid wddxPacket XML document that is mishandled in a wddx_deserialize call, as demonstrated by a stray element inside a boolean element, leading to incorrect pop processing.", "vuln": 1, "reasoning": "Let's analyze the provided C code step-by-step, focusing on potential security vulnerabilities.\n\n1. **Context and Purpose**:\n   - This function `php_wddx_pop_element` is part of a WDDX (Web Distributed Data eXchange) parser in PHP.\n   - It is called when an XML element is closed (i.e., the end tag is encountered).\n   - It manages a stack (`wddx_stack`) of parsed data elements, handling different types like strings, numbers, arrays, objects, etc.\n   - The function processes the data based on the element name (e.g., `EL_STRING`, `EL_OBJECT`, `EL_STRUCT`, etc.).\n\n2. **Input Validation and Memory Management**:\n   - The function checks for `stack->top == 0` and returns early \u2014 this prevents accessing an empty stack.\n   - It uses `strcmp` to compare element names (e.g., `EL_STRING`, `EL_BINARY`) \u2014 these are likely defined constants, so no injection risk here.\n   - The function uses `efree()` to free memory allocated via `emalloc()` or `estrdup()` \u2014 this is correct for PHP's memory management.\n   - `zval_ptr_dtor()` is used to properly destroy zvals (PHP's internal variable representation), which prevents memory leaks.\n\n3. **Base64 Decoding**:\n   - For `EL_BINARY`, the code calls `php_base64_decode` on `ent1->data` (which is a string).\n   - The decoded result is assigned back to `ent1->data` using `ZVAL_STR`.\n   - This is safe as long as `php_base64_decode` properly validates input (e.g., checks for invalid base64 characters).\n   - However, if the input is malformed or extremely large, it could lead to memory exhaustion or denial of service (DoS), but this is not a direct code execution vulnerability unless the decoder has a flaw.\n\n4. **Object Handling and `__wakeup()`**:\n   - The code calls `call_user_function_ex` to invoke `__wakeup()` on deserialized objects.\n   - This is a **known security risk** in PHP: deserializing untrusted data and calling `__wakeup()` can lead to **arbitrary code execution** if the object has a malicious `__wakeup()` method.\n   - This is a classic **deserialization vulnerability**.\n   - The function does not validate or sanitize the data before calling `__wakeup()`, and the data comes from user-controlled XML input (WDDX).\n   - This is a well-documented attack vector (e.g., CVE-2017-7881, CVE-2018-14817).\n\n5. **Class Name Handling**:\n   - The code uses `zend_hash_find_ptr(EG(class_table), Z_STR(ent1->data))` to look up a class by name.\n   - It then uses `object_init_ex(&obj, pce)` to instantiate the class.\n   - If the class name is user-controlled and not properly validated, it could lead to instantiation of unexpected classes, especially if `pce` is set to `PHP_IC_ENTRY` (incomplete class), which may allow bypassing class existence checks.\n   - However, this is mitigated by the fact that `zend_hash_find_ptr` checks the class table, and `PHP_IC_ENTRY` is a special placeholder \u2014 but still, this could be exploited in combination with other vulnerabilities.\n\n6. **Memory Safety**:\n   - The code uses `efree(ent1)` and `zval_ptr_dtor` appropriately.\n   - No buffer overflows or use-after-free are evident.\n   - The stack is managed correctly with `stack->top--`.\n\n7. **Overall Risk Assessment**:\n   - The most critical issue is the **unrestricted call to `__wakeup()`** on deserialized objects from untrusted input.\n   - This is a **well-known and severe vulnerability** in PHP applications.\n   - Even if the rest of the code is safe, this single call can lead to remote code execution if an attacker can craft a malicious WDDX payload.\n\n(1) YES: A security vulnerability detected."}
{"idx": 202081, "project": "vim", "commit_id": "d25f003342aca9889067f2e839963dfeccf1fe05", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/d25f003342aca9889067f2e839963dfeccf1fe05", "commit_message": "patch 9.0.0011: reading beyond the end of the line with put command\n\nProblem:    Reading beyond the end of the line with put command.\nSolution:   Adjust the end mark position.", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-2264", "cve_desc": "Heap-based Buffer Overflow in GitHub repository vim/vim prior to 9.0.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `do_put` is part of the Vim text editor (likely from the `put.c` file). It handles the `put` operation (e.g., `p`, `P`, `:put`) that inserts text from a register into the buffer. The function supports various modes:\n- Character mode (`MCHAR`)\n- Line mode (`MLINE`)\n- Block mode (`MBLOCK`)\n- Special registers (e.g., `=`, `.`, `%`, `#`, `:`)\n\nIt processes the register content, handles cursor positioning, undo, visual mode, indentation, and text insertion.\n\n---\n\n### Step 2: Identify potential security concerns\n\nSecurity vulnerabilities in such code typically arise from:\n- Buffer overflows (e.g., `strcpy`, `strcat`, unsafe memory copying)\n- Use of untrusted input without validation\n- Memory allocation errors leading to use-after-free or heap corruption\n- Improper handling of user-controlled data in string operations\n- Use of unsafe functions like `strcpy`, `strcat`, `sprintf`, etc.\n\nLet\u2019s examine key parts:\n\n#### A. Input sources\n- `regname`: register name (e.g., `\"a`, `=`, `.`, etc.) \u2014 controlled by user.\n- `expr_result`: result of an expression (e.g., `=1+2`) \u2014 user-provided expression.\n- `dir`, `count`, `flags`: user-controlled via commands.\n- `y_array`: array of strings from the register \u2014 potentially user-controlled (e.g., from a file or register).\n\nThese are all user-controlled inputs, so any use of them in string operations must be carefully checked.\n\n#### B. String handling and memory allocation\n\nThe function uses:\n- `vim_strchr`, `vim_strnsave`, `vim_strsave`, `STRLEN`, `STRMOVE`, `STRCPY`, `STRCAT`\n- `alloc()`, `vim_free()`, `mch_memmove`, `vim_memset`\n\nThese are safe if used correctly.\n\nLet\u2019s look at critical sections:\n\n##### 1. Block mode insertion (`y_type == MBLOCK`)\n- `y_array` is used to store lines.\n- `yanklen = (int)STRLEN(y_array[i]);` \u2014 safe, as `STRLEN` is safe.\n- `totlen = count * (yanklen + spaces) + bd.startspaces + bd.endspaces;`\n- Then: `newp = alloc(totlen + oldlen + 1);` \u2014 allocation size is computed from `count`, `yanklen`, `spaces`, etc.\n\nBut before allocation, there is a **multiplication overflow check**:\n```c\nif (yanklen + spaces != 0\n     && count > ((INT_MAX - (bd.startspaces + bd.endspaces))\n                        / (yanklen + spaces)))\n{\n    emsg(_(e_resulting_text_too_long));\n    break;\n}\n```\nThis is **correct and safe** \u2014 it prevents integer overflow in the `totlen` calculation.\n\n##### 2. Character/line mode insertion\n- Similar checks exist:\n```c\nif (count > INT_MAX / yanklen)\n    emsg(_(e_resulting_text_too_long));\n```\nThis prevents overflow in `totlen = count * yanklen`.\n\n##### 3. Memory copying\n- `mch_memmove(newp, oldp, (size_t)bd.textcol);` \u2014 safe, bounds checked via `bd.textcol`.\n- `mch_memmove(ptr, y_array[i], (size_t)yanklen);` \u2014 `yanklen` comes from `STRLEN`, so it's safe.\n- `STRMOVE(ptr, oldp + bd.textcol + delcount);` \u2014 safe, as `oldp + bd.textcol + delcount` is within bounds.\n\n##### 4. User-controlled register content\n- `get_yank_register(regname, FALSE);` \u2014 retrieves content from a register.\n- `get_spec_reg(regname, &insert_string, &allocated, TRUE);` \u2014 handles special registers like `=`, `%`, `#`, etc.\n- `expr_result` is used directly if `regname == '='` \u2014 this is **evaluated code**, but it's **not executed** \u2014 it's just a string result.\n\nImportant: The `=` register evaluates an expression and returns a string. However, **Vim does not execute arbitrary code** here \u2014 it only evaluates expressions in a safe context (e.g., `:echo =1+2`), and the result is a string. So no code execution occurs.\n\n##### 5. Use of `stuffcharReadbuff` and `stuff_inserted`\n- These are used to simulate keystrokes (e.g., `a`, `o`, `i`) \u2014 but only when `regname == '.'` (the `.` register).\n- This is **not a security issue** because it's part of Vim\u2019s internal macro playback mechanism and is not exposed to arbitrary user input in a dangerous way.\n\n##### 6. Memory management\n- `alloc()` and `vim_free()` are used correctly.\n- `y_array` is freed only if `regname == '='` \u2014 correct.\n- `allocated` flag ensures `insert_string` is freed only if allocated.\n\nNo use-after-free or double-free.\n\n##### 7. No use of unsafe string functions\n- No `strcpy`, `strcat`, `sprintf`, `gets`, etc.\n- All string operations use `STRLEN`, `STRCPY`, `STRCAT`, `vim_strsave`, `vim_strnsave`, `mch_memmove`, `vim_memset` \u2014 all safe.\n\n##### 8. No format string vulnerabilities\n- No `printf`, `sprintf`, `vsprintf` with user input.\n\n##### 9. No command injection\n- The code does not execute shell commands or system calls.\n\n---\n\n### Step 3: Conclusion\n\nAfter thorough analysis:\n- All user-controlled inputs are properly validated.\n- No buffer overflows due to unchecked string copying.\n- Integer overflow is prevented with explicit checks.\n- Memory allocation and deallocation are safe.\n- No code execution, no injection, no unsafe functions.\n- Special register `=` is evaluated safely \u2014 no arbitrary code execution.\n\nThis code is part of Vim\u2019s core and is known for its robustness and security.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 195074, "project": "gpac", "commit_id": "a69b567b8c95c72f9560c873c5ab348be058f340", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/a69b567b8c95c72f9560c873c5ab348be058f340", "commit_message": "fixed #1895", "ground_truth": 1, "cwe": ["CWE-415"], "cve": "CVE-2021-40571", "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a double-free vulnerability in the ilst_box_read function in box_code_apple.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Size Handling**:\n   - The function `gf_odf_av1_cfg_read_bs_size` takes a `GF_BitStream *bs` and a `u32 size` parameter.\n   - If `size` is 0, it uses `gf_bs_available(bs)` to determine how many bytes are available in the bitstream. This is acceptable as long as the bitstream is properly bounded.\n   - The function then allocates a new `GF_AV1Config` structure using `gf_odf_av1_cfg_new()`, which is a safe allocation.\n\n2. **Reading Fixed-Size Fields**:\n   - The function reads several fixed-size fields (1, 7, 3, 5, etc.) from the bitstream using `gf_bs_read_int()`. These are all bounded and do not exceed the size of the data type, so no buffer overflow is possible here.\n\n3. **Reserved Field Check**:\n   - The code reads a 3-bit reserved field and checks that it is zero. If not, it logs a debug message and returns NULL. This is a good security practice to reject malformed or non-compliant data.\n\n4. **Initial Presentation Delay Handling**:\n   - The function reads a flag (`initial_presentation_delay_present`) and conditionally reads a 4-bit value. If the flag is not set, it skips 4 bits (using `gf_bs_read_int(bs, 4)`), which is safe and expected behavior.\n\n5. **Loop for Parsing OBU (OBU = OBU Header)**:\n   - The loop processes OBU entries from the bitstream until `size` is exhausted.\n   - It uses `gf_av1_parse_obu()` to parse the OBU type and size. This function is assumed to be safe and properly bounds its reads.\n   - The function then checks `if (size < obu_size)` before processing the OBU. This is critical: if the remaining size is less than the OBU size, it logs a warning and breaks out of the loop. This prevents reading beyond the expected data length and avoids potential buffer overflows.\n\n6. **Memory Allocation and Copying**:\n   - For each OBU, it allocates memory for `a->obu` using `gf_malloc((size_t)obu_size)`. This is safe because `obu_size` is obtained from `gf_av1_parse_obu()`, which should validate the size.\n   - It then seeks back to the start of the OBU and reads exactly `obu_size` bytes into the allocated buffer using `gf_bs_read_data()`. This is safe because:\n     - The size is validated via `if (size < obu_size)` check.\n     - The read is limited to `obu_size` bytes.\n     - The buffer is allocated with exactly that size.\n\n7. **Bounds Checking and Loop Termination**:\n   - The loop condition is `while (size)`, and `size` is decremented by `obu_size` after each OBU.\n   - The check `if (size < obu_size)` ensures that the function does not attempt to read more data than available, preventing buffer overflows.\n\n8. **Error Handling and Cleanup**:\n   - If any allocation fails (`GF_SAFEALLOC` or `gf_malloc`), the function breaks out of the loop and returns `NULL` after cleanup (e.g., `gf_free(a)`).\n   - The function calls `gf_av1_reset_state(&state, GF_TRUE)` before returning, which is good hygiene.\n\n9. **No Use of Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, or other unsafe string functions.\n   - All data copying is done with explicit size limits (`gf_bs_read_data` with `obu_size`), and memory is allocated based on that size.\n\n10. **Assumptions**:\n    - The function `gf_av1_parse_obu()` is assumed to be correctly implemented and not allow arbitrary size values (e.g., it should not return a size larger than the available data).\n    - The `gf_bs_available(bs)` call is trusted to return a correct value.\n\nConclusion: The code performs proper bounds checking, validates input, uses safe memory allocation, and avoids unsafe operations. The critical check `if (size < obu_size)` prevents reading beyond the expected data length, which is the main defense against buffer overflows in this context.\n\n(2) NO: No security vulnerability."}
{"idx": 195274, "project": "tensorflow", "commit_id": "0a365c029e437be0349c31f8d4c9926b69fa3fa1", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/0a365c029e437be0349c31f8d4c9926b69fa3fa1", "commit_message": "Prevent null pointer dereference in constant folding.\n\nUnder certain conditions, an invalid protobuf saved model with invalid nodes would be loaded. During optimization phase, Grappler optimizer will then dereference a null pointer.\n\nPiperOrigin-RevId: 409683530\nChange-Id: I1f10340a7ec384bc9bc587300390f1078cf5caa0", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-23589", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, Grappler component of TensorFlow can trigger a null pointer dereference. There are 2 places where this can occur, for the same malicious alteration of a `SavedModel` file (fixing the first one would trigger the same dereference in the second place). First, during constant folding, the `GraphDef` might not have the required nodes for the binary operation. If a node is missing, the correposning `mul_*child` would be null, and the dereference in the subsequent line would be incorrect. We have a similar issue during `IsIdentityConsumingSwitch`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context**: This function `ConstantFolding::MulConvPushDown` is part of a graph optimization pass in a machine learning framework (likely TensorFlow or similar). It performs a transformation on a computational graph: pushing a multiplication operation (Mul) down into a Convolution operation (Conv2D/Conv3D) when one of the inputs to the Mul is a constant and the other is a Conv node.\n\n2. **Input Validation and Safety Checks**:\n   - The function checks if the node is a Mul operation and has exactly two non-control inputs.\n   - It verifies that one of the Mul's children is a constant (via `IsReallyConstant`) and the other is a Conv2D or Conv3D node.\n   - It checks device compatibility (all nodes on the same device).\n   - It ensures that the Conv node is safe to modify: no more than one non-control output, not in `nodes_to_preserve_`, and has at least two inputs.\n   - It validates shapes: the output shapes of Mul and Conv must be symbolically equal.\n   - It checks that the convolution's second input (filter) has a valid shape for multiplication with the constant.\n   - It ensures the new node name does not already exist in the graph.\n   - It handles control dependencies carefully using `MaybeRemoveControlInput` and `MaybeAddControlInput` to avoid introducing cycles.\n\n3. **Graph Manipulation**:\n   - The function rewrites the graph by:\n     - Renaming the Conv node to the original Mul node's name.\n     - Renaming the Mul node to a new name (`merged_input`).\n     - Updating input references in the Conv node to point to the new Mul node.\n     - Updating the Mul node to point to the constant input.\n     - Adding the new Mul node back into the graph via `node_map_->AddNode`.\n\n4. **Security Considerations**:\n   - The function operates on a computational graph, not on user input directly.\n   - All operations are internal to a graph optimization pass.\n   - There is no direct handling of untrusted input (e.g., no parsing of user data, no string formatting, no memory copying without bounds checks).\n   - The function performs extensive validation before any mutation:\n     - Type checks (is it a Mul? is it a Conv?).\n     - Constant checks.\n     - Shape compatibility.\n     - Name uniqueness.\n     - Control dependency safety.\n   - The graph is modified only if all conditions are met, and the changes are deterministic and safe within the framework's internal logic.\n\n5. **Potential Risks**:\n   - Could there be a use-after-free or dangling pointer? No \u2014 the code uses `node_map_->GetNode()` and `node_map_->UpdateInput()`, which are assumed to be safe in the context of the framework.\n   - Could there be a denial-of-service via infinite loop? No \u2014 the function is a one-time transformation with no loops.\n   - Could there be a memory corruption? No \u2014 no buffer overflows, no unsafe string operations, no raw pointer arithmetic.\n   - Could this be exploited to execute arbitrary code? Unlikely \u2014 this is a static graph optimization, not a runtime interpreter.\n\n6. **Conclusion**:\n   - The code is part of a well-structured, safety-checked optimization pass.\n   - All critical operations are guarded by validation checks.\n   - There is no evidence of unsafe memory access, injection, or untrusted input handling.\n   - The function is designed to be safe and idempotent within the framework.\n\n(2) NO: No security vulnerability."}
{"idx": 209801, "project": "mujs", "commit_id": "f5b3c703e18725e380b83427004632e744f85a6f", "project_url": "https://github.com/ccxvii/mujs", "commit_url": "https://github.com/ccxvii/mujs/commit/f5b3c703e18725e380b83427004632e744f85a6f", "commit_message": "Issue #161: Cope with empty programs in mujs-pp.", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-30975", "cve_desc": "In Artifex MuJS through 1.2.0, jsP_dumpsyntax in jsdump.c has a NULL pointer dereference, as demonstrated by mujs-pp.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `jsP_dumpsyntax` takes three parameters:\n   - `js_State *J`: a pointer to the JavaScript interpreter state (likely used for context, but not directly used in this function).\n   - `js_Ast *prog`: a pointer to an abstract syntax tree (AST) representing a JavaScript program.\n   - `int dominify`: an integer flag that controls formatting behavior (e.g., minification).\n\n2. The function sets a global variable `minify` to the value of `dominify`. This suggests that `minify` is a global or static variable used elsewhere in the code to control output formatting.\n\n3. The function checks the type of the AST node:\n   - If `prog->type == AST_LIST`, it calls `pstmlist(-1, prog)` to dump a list of statements.\n   - Otherwise, it calls `pstm(0, prog)` to dump a single statement, followed by `nl()` to output a newline.\n\n4. After dumping the AST, if `minify > 1`, it outputs an additional newline via `putchar('\\n')`.\n\n5. Key observations:\n   - The function does not perform any input validation on `prog` (though it checks `prog->type`, which is a field of the AST node).\n   - However, `prog` is assumed to be a valid AST node constructed by the parser, and the function only traverses and outputs it in a formatted way.\n   - The function does not perform any string formatting, memory copying, or user input handling.\n   - It does not use unsafe functions like `strcpy`, `sprintf`, or `strcat` that could lead to buffer overflows.\n   - The output is controlled entirely by the AST structure, which is generated internally by the parser and not directly influenced by external input in this function.\n   - There is no direct manipulation of user-controlled data in a way that could lead to memory corruption or code execution.\n\n6. The only potential concern is the use of a global variable `minify` that is set based on the input parameter. However, this is a simple integer assignment and does not lead to any security issue unless `minify` is used in an unsafe way elsewhere (which is not visible here).\n\n7. Since the function only outputs a formatted representation of a parsed AST and does not handle untrusted input directly, and no unsafe operations are performed, there is no evidence of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 195908, "project": "linux", "commit_id": "e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/e4571b8c5e9ffa1e85c0c671995bd4dcc5c75091", "commit_message": "btrfs: fix NULL pointer dereference when deleting device by invalid id\n\n[BUG]\nIt's easy to trigger NULL pointer dereference, just by removing a\nnon-existing device id:\n\n # mkfs.btrfs -f -m single -d single /dev/test/scratch1 \\\n\t\t\t\t     /dev/test/scratch2\n # mount /dev/test/scratch1 /mnt/btrfs\n # btrfs device remove 3 /mnt/btrfs\n\nThen we have the following kernel NULL pointer dereference:\n\n BUG: kernel NULL pointer dereference, address: 0000000000000000\n #PF: supervisor read access in kernel mode\n #PF: error_code(0x0000) - not-present page\n PGD 0 P4D 0\n Oops: 0000 [#1] PREEMPT SMP NOPTI\n CPU: 9 PID: 649 Comm: btrfs Not tainted 5.14.0-rc3-custom+ #35\n Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015\n RIP: 0010:btrfs_rm_device+0x4de/0x6b0 [btrfs]\n  btrfs_ioctl+0x18bb/0x3190 [btrfs]\n  ? lock_is_held_type+0xa5/0x120\n  ? find_held_lock.constprop.0+0x2b/0x80\n  ? do_user_addr_fault+0x201/0x6a0\n  ? lock_release+0xd2/0x2d0\n  ? __x64_sys_ioctl+0x83/0xb0\n  __x64_sys_ioctl+0x83/0xb0\n  do_syscall_64+0x3b/0x90\n  entry_SYSCALL_64_after_hwframe+0x44/0xae\n\n[CAUSE]\nCommit a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return\nbtrfs_device directly\") moves the \"missing\" device path check into\nbtrfs_rm_device().\n\nBut btrfs_rm_device() itself can have case where it only receives\n@devid, with NULL as @device_path.\n\nIn that case, calling strcmp() on NULL will trigger the NULL pointer\ndereference.\n\nBefore that commit, we handle the \"missing\" case inside\nbtrfs_find_device_by_devspec(), which will not check @device_path at all\nif @devid is provided, thus no way to trigger the bug.\n\n[FIX]\nBefore calling strcmp(), also make sure @device_path is not NULL.\n\nFixes: a27a94c2b0c7 (\"btrfs: Make btrfs_find_device_by_devspec return btrfs_device directly\")\nCC: stable@vger.kernel.org # 5.4+\nReported-by: butt3rflyh4ck <butterflyhuangxx@gmail.com>\nReviewed-by: Anand Jain <anand.jain@oracle.com>\nSigned-off-by: Qu Wenruo <wqu@suse.com>\nReviewed-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>", "ground_truth": 1, "cwe": ["CWE-703"], "cve": "CVE-2021-3739", "cve_desc": "A NULL pointer dereference flaw was found in the btrfs_rm_device function in fs/btrfs/volumes.c in the Linux Kernel, where triggering the bug requires \u2018CAP_SYS_ADMIN\u2019. This flaw allows a local attacker to crash the system or leak kernel internal information. The highest threat from this vulnerability is to system availability.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Function Purpose and Context**:\n   - This function, `btrfs_rm_device`, is part of the Btrfs filesystem and is responsible for removing a device from a Btrfs filesystem.\n   - It handles various checks before removing a device, including:\n     - Validating the number of devices (ensuring RAID constraints are not violated).\n     - Checking if the device is in use (e.g., by a swapfile).\n     - Checking if the device is a target of a replace operation.\n     - Ensuring that removing the device won't leave the filesystem with only one writable device (which could be unsafe).\n   - It uses proper locking mechanisms (`mutex_lock`, `synchronize_rcu`, RCU list operations) to ensure thread safety.\n\n2. **Input Validation**:\n   - The function receives `device_path` and `devid` as inputs.\n   - It uses `btrfs_find_device_by_devspec` to locate the device, which performs a lookup based on `devid` and `device_path`.\n   - The function checks for `IS_ERR(device)` and handles error cases appropriately, including special handling for `missing` device path.\n   - There is no direct string manipulation or user input injection (e.g., no sprintf, strcpy, or format string usage), so no buffer overflow or format string vulnerabilities are present.\n\n3. **Memory and Resource Management**:\n   - The function properly uses `list_del_rcu`, `synchronize_rcu`, and `btrfs_free_device` to safely remove and free the device structure.\n   - It uses `btrfs_close_bdev` to close the block device.\n   - It calls `btrfs_scratch_superblocks` to zero out old superblocks, which is a security best practice to prevent data leakage.\n   - It removes sysfs entries via `btrfs_sysfs_remove_device`, which is correct for cleanup.\n\n4. **Race Condition and Synchronization**:\n   - The function uses `mutex_lock(&uuid_mutex)` and `mutex_lock(&fs_devices->device_list_mutex)` to protect critical sections.\n   - It uses `synchronize_rcu()` after `list_del_rcu`, which is correct for RCU list deletion.\n   - The use of `list_del_rcu` and `synchronize_rcu` indicates awareness of RCU semantics and proper handling of concurrent access.\n\n5. **Error Handling and Cleanup**:\n   - The function has a well-structured error path (`error_undo`) that restores the state if `btrfs_shrink_device` or `btrfs_rm_dev_item` fails.\n   - It properly undoes changes like re-adding the device to the `alloc_list` and incrementing `rw_devices`.\n   - The cleanup path ensures that no resources are leaked.\n\n6. **Potential Issues**:\n   - One comment mentions: \"TODO: the superblock still includes this device in its num_devices counter although write_all_supers() is not locked out. This could give a filesystem state which requires a degraded mount.\"\n     - This is a **comment about a potential future issue**, not a current vulnerability. It's a TODO, not a bug in the current code.\n     - The code still updates `btrfs_set_super_num_devices` correctly, so the superblock is updated.\n     - The comment is about a race condition that might occur if `write_all_supers()` is not synchronized, but the code does not currently have a flaw\u2014it just notes a possible future concern.\n\n7. **No Obvious Vulnerabilities**:\n   - No buffer overflows (no unsafe string or memory copying).\n   - No use of unsafe functions (no `strcpy`, `sprintf`, etc.).\n   - No injection vectors (no SQL, shell, or format string injection).\n   - Proper locking and RCU usage.\n   - Correct error handling and cleanup.\n   - No use of untrusted input in unsafe ways.\n\nConclusion: The code is well-structured, uses proper synchronization, performs input validation, and handles errors safely. The only note is a TODO comment about a potential race condition, but it does not represent a current security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 214160, "project": "linux", "commit_id": "75e5b4849b81e19e9efe1654b30d7f3151c33c2c", "project_url": "https://github.com/torvalds/linux", "commit_url": "https://github.com/torvalds/linux/commit/75e5b4849b81e19e9efe1654b30d7f3151c33c2c", "commit_message": "USB: gadget: validate interface OS descriptor requests\n\nStall the control endpoint in case provided index exceeds array size of\nMAX_CONFIG_INTERFACES or when the retrieved function pointer is null.\n\nSigned-off-by: Szymon Heidrich <szymon.heidrich@gmail.com>\nCc: stable@kernel.org\nSigned-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-25258", "cve_desc": "An issue was discovered in drivers/usb/gadget/composite.c in the Linux kernel before 5.16.10. The USB Gadget subsystem lacks certain validation of interface OS descriptor requests (ones with a large array index and ones associated with NULL function pointer retrieval). Memory corruption might occur.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Understand the context\nThis is a Linux kernel USB composite driver function `composite_setup`, which handles USB control requests (setup stage of USB communication). It processes standard USB requests (like GET_DESCRIPTOR, SET_CONFIGURATION, etc.) and delegates to function drivers when needed.\n\nThe function is part of the USB Gadget framework, where a device emulates a USB peripheral (e.g., a USB mass storage device, CDC ACM, etc.). The code is written in C and runs in kernel space, so any vulnerability could lead to privilege escalation or system compromise.\n\n---\n\n### Step 2: Check for buffer overflows\n- The function uses `req->buf` to store response data (e.g., descriptors).\n- Before copying data into `req->buf`, it uses `min(w_length, size)` to limit the amount copied.\n  - Example: `value = min(w_length, (u16) sizeof cdev->desc); memcpy(req->buf, &cdev->desc, value);`\n  - This ensures that no more than `w_length` bytes are copied, and also respects the actual size of the descriptor.\n- Similarly, in OS descriptor handling:\n  - `w_length = min_t(u16, w_length, USB_COMP_EP0_OS_DESC_BUFSIZ);`\n  - `memset(buf, 0, w_length);` \u2014 safe because `w_length` is capped.\n  - `value = min_t(u16, w_length, value);` before copying via `fill_ext_compat` or `fill_ext_prop`.\n\n\u2705 **No buffer overflow** due to proper bounds checking using `min()` and `min_t()`.\n\n---\n\n### Step 3: Check for use of untrusted input\n- The function receives `ctrl` (a `usb_ctrlrequest` struct) from the USB host \u2014 this is untrusted input.\n- It extracts fields like `wLength`, `wIndex`, `wValue`, `bRequestType`, `bRequest`.\n- These values are used to:\n  - Determine which request to handle.\n  - Index into arrays (e.g., `cdev->config->interface[intf]`).\n  - Control flow (e.g., `switch (ctrl->bRequest)`).\n- However:\n  - `intf = w_index & 0xFF` \u2014 this is used to index into `cdev->config->interface[intf]`.\n  - But the code checks: `if (!cdev->config || intf >= MAX_CONFIG_INTERFACES)` before accessing.\n  - This prevents out-of-bounds access.\n\n\u2705 **Safe bounds checking** on `intf` and other indices.\n\n---\n\n### Step 4: Check for improper handling of `wLength`\n- The code checks: `if (w_length > USB_COMP_EP0_BUFSIZ)` \u2014 this is a critical check.\n- If `w_length` is too large and the request is IN (host reading), it **clamps** `w_length` to `USB_COMP_EP0_BUFSIZ` by modifying `ctrl->wLength` in place (via a cast to `__le16 *`).\n  - This is a **safe mitigation** to prevent excessive memory allocation or copying.\n- The `w_length` is then used in `min()` calls to limit data copied into `req->buf`.\n\n\u2705 **No risk of excessive memory allocation or buffer overflow** due to clamping and `min()` usage.\n\n---\n\n### Step 5: Check for improper use of `memcpy` or `strcpy`\n- All `memcpy` calls are guarded by `min()` to ensure they do not exceed the buffer size.\n- No use of `strcpy`, `strcat`, or similar unsafe functions.\n\n\u2705 **No unsafe string or memory copy operations**.\n\n---\n\n### Step 6: Check for improper handling of function callbacks\n- The code calls function drivers via `f->setup`, `f->get_alt`, `f->set_alt`, etc.\n- These are **function-provided callbacks** and are expected to be safe.\n- However, the code does **not** validate the function's behavior \u2014 but this is not a vulnerability in `composite_setup` itself, as it's the responsibility of the function driver to be secure.\n- The kernel enforces that only registered functions are called, and `f` is validated before use.\n\n\u2705 **No direct vulnerability in this function** \u2014 function driver security is a separate concern.\n\n---\n\n### Step 7: Check for information disclosure or side-channel risks\n- The function logs debug messages with `DBG`, `VDBG`, `ERROR`, etc., using `cdev` and `ctrl` fields.\n- These logs may include untrusted data (e.g., `w_index`, `w_value`), but they are only for debugging and not exposed to the host.\n- No sensitive data is leaked via the control response.\n\n\u2705 **No information disclosure vulnerability**.\n\n---\n\n### Step 8: Check for improper state management\n- The function uses `spin_lock(&cdev->lock)` when calling `set_config`, `f->set_alt`, etc.\n- This ensures thread safety and prevents race conditions.\n\n\u2705 **Proper synchronization**.\n\n---\n\n### Step 9: Check for improper handling of delayed status\n- The code handles `USB_GADGET_DELAYED_STATUS` correctly.\n- It warns if `w_length != 0` \u2014 which is a valid check since delayed status is not supported for non-zero lengths.\n\n\u2705 **Correct handling**.\n\n---\n\n### Step 10: Final assessment\n- All untrusted input is validated.\n- All buffer operations are bounded.\n- No unsafe memory operations.\n- No use of unsafe functions.\n- Proper bounds checking on indices and lengths.\n- Safe handling of large `w_length` values.\n- Function callbacks are only invoked after proper validation.\n\n---\n\n### Conclusion\nThere are **no detectable security vulnerabilities** in this code based on the analysis of buffer overflows, out-of-bounds access, improper input handling, or unsafe memory operations.\n\n(2) NO: No security vulnerability."}
{"idx": 198169, "project": "tensorflow", "commit_id": "5b048e87e4e55990dae6b547add4dae59f4e1c76", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/5b048e87e4e55990dae6b547add4dae59f4e1c76", "commit_message": "Fix a null pointer exception in SVDF\n\nThis is due to not checking that `GetVariableInput` returns non-null tensor.\n\nAlso fix a potential null pointer exception in `GetVariableInput`.\n\nPiperOrigin-RevId: 385160147\nChange-Id: Iadf3f0705b036a9014d27caa5a8bbd91f4c4c401", "ground_truth": 1, "cwe": ["CWE-369"], "cve": "CVE-2021-37681", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of SVDF in TFLite is [vulnerable to a null pointer error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/svdf.cc#L300-L313). The [`GetVariableInput` function](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L115-L119) can return a null pointer but `GetTensorData` assumes that the argument is always a valid tensor. Furthermore, because `GetVariableInput` calls [`GetMutableInput`](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/kernel_util.cc#L82-L90) which might return `nullptr`, the `tensor->is_variable` expression can also trigger a null pointer exception. We have patched the issue in GitHub commit 5b048e87e4e55990dae6b547add4dae59f4e1c76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step.\n\n1. The function `GetVariableInput` takes three parameters:\n   - `context`: A pointer to the TensorFlow Lite context.\n   - `node`: A pointer to the current node in the computation graph.\n   - `index`: An integer index indicating which input tensor to retrieve.\n\n2. It calls `GetMutableInput(context, node, index)` to get a mutable tensor at the given index. This function is expected to return a pointer to a `TfLiteTensor` or possibly `nullptr` if the input is invalid or not available.\n\n3. The function then checks whether the returned tensor has the `is_variable` field set to true. If so, it returns the tensor; otherwise, it returns `nullptr`.\n\n4. The key security consideration here is whether this function can lead to undefined behavior, memory corruption, or access to invalid memory.\n\n5. The function does not perform any bounds checking on the `index` parameter. If `index` is out of bounds (e.g., negative or greater than the number of inputs), `GetMutableInput` may return `nullptr`. However, the function does not validate `index` before passing it to `GetMutableInput`, which could lead to undefined behavior if `GetMutableInput` accesses invalid memory.\n\n6. More critically, if `GetMutableInput` returns a valid tensor pointer, the function dereferences `tensor->is_variable` without checking whether `tensor` is `nullptr`. However, the function already returns `nullptr` if `tensor` is `nullptr` (since `GetMutableInput` returns `nullptr` on invalid input), so the dereference is safe only if `GetMutableInput` is guaranteed to return a valid pointer or `nullptr`.\n\n7. The real issue is that `GetMutableInput` may not validate the `index` parameter, and if `index` is out of bounds, it could return a dangling or invalid pointer. But the function `GetVariableInput` itself does not perform any validation of `index` or check for null after `GetMutableInput`, which is acceptable only if `GetMutableInput` is safe.\n\n8. However, the function does not perform any bounds checking on `index`, and if `GetMutableInput` is not robust against invalid indices, this could lead to memory access violations or crashes. But the function itself does not directly cause a buffer overflow or memory corruption \u2014 it's more about input validation.\n\n9. The function is not directly vulnerable to classic security issues like buffer overflows, use-after-free, or arbitrary memory access, as long as `GetMutableInput` is implemented correctly and bounds-checked.\n\n10. The function's logic is safe: it returns the tensor only if it is marked as a variable, otherwise `nullptr`. This is a valid pattern for accessing variable tensors in TensorFlow Lite.\n\nConclusion: The function does not contain a direct security vulnerability such as buffer overflow, use-after-free, or unsafe memory access. It relies on `GetMutableInput` to handle input validation, and the function itself does not introduce unsafe behavior.\n\n(2) NO: No security vulnerability."}
{"idx": 197466, "project": "tensorflow", "commit_id": "9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/9e82dce6e6bd1f36a57e08fa85af213e2b2f2622", "commit_message": "Fix NPE in restoring code.\n\nPiperOrigin-RevId: 388303253\nChange-Id: Ia8c68568cb854bca538909a182b31a618d68ce55", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-37639", "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. When restoring tensors via raw APIs, if the tensor name is not provided, TensorFlow can be tricked into dereferencing a null pointer. Alternatively, attackers can read memory outside the bounds of heap allocated data by providing some tensor names but not enough for a successful restoration. The [implementation](https://github.com/tensorflow/tensorflow/blob/47a06f40411a69c99f381495f490536972152ac0/tensorflow/core/kernels/save_restore_tensor.cc#L158-L159) retrieves the tensor list corresponding to the `tensor_name` user controlled input and immediately retrieves the tensor at the restoration index (controlled via `preferred_shard` argument). This occurs without validating that the provided list has enough values. If the list is empty this results in dereferencing a null pointer (undefined behavior). If, however, the list has some elements, if the restoration index is outside the bounds this results in heap OOB read. We have patched the issue in GitHub commit 9e82dce6e6bd1f36a57e08fa85af213e2b2f2622. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `RestoreTensor` is part of a TensorFlow-like system for restoring tensors from checkpoint files. It takes inputs including a file pattern, tensor name, and optional shape/slice specifications.\n\n2) Input validation is performed:\n   - The file_pattern input is checked to ensure it's a scalar string (size == 1)\n   - The tensor_name is extracted from input(1) using restore_index\n   - The code checks if the requested tensor exists in the checkpoint file\n   - It validates that the data type matches the expected type\n\n3) The function uses a cache for TensorSliceReader objects, falling back to creating a new one if not found in cache.\n\n4) The shape and slice information is parsed from input(2) if restore_slice is true. The code validates that the parsed shape matches the saved shape.\n\n5) Memory allocation is done via context->allocate_output with the output_shape.\n\n6) The actual data copying is done through reader->CopySliceData, which is called with the tensor_name and slice_to_load.\n\n7) The code uses a switch statement with TF_CALL_SAVE_RESTORE_TYPES macro to handle different data types, ensuring type safety.\n\n8) Critical security aspects:\n   - Input validation is thorough: checks for proper tensor dimensions, type matching, and shape consistency\n   - The file_pattern is used to open checkpoint files, but it's validated as a scalar string\n   - The tensor_name is extracted from input(1) but validated against what exists in the checkpoint\n   - The shape_and_slice specification is parsed and validated against the saved shape\n   - No direct string concatenation or untrusted input is used in file operations\n   - The code uses proper error handling with OP_REQUIRES and OP_REQUIRES_OK\n\n9) There is no evidence of:\n   - Buffer overflows (all operations are bounds-checked)\n   - Path traversal vulnerabilities (file_pattern is validated as scalar)\n   - Injection attacks (no SQL or command injection)\n   - Uncontrolled memory access (all allocations are through context)\n\n10) The code follows secure coding practices: input validation, proper error handling, and type safety.\n\n(2) NO: No security vulnerability."}
{"idx": 197801, "project": "tensorflow", "commit_id": "368af875869a204b4ac552b9ddda59f6a46a56ec", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/368af875869a204b4ac552b9ddda59f6a46a56ec", "commit_message": "Avoid buffer overflow when loading tensors with insufficient data from checkpoints.\n\n`CopyDataFromTensorSliceToTensorSlice` does not (and cannot conveniently)\nprovide any bounds checking on its own, so the size is instead checked prior\nto passing unvalidated data to that function.\n\nPiperOrigin-RevId: 392971286\nChange-Id: If2073b36d4d5eedd386329f56729395fd7effee1", "ground_truth": 1, "cwe": ["CWE-345"], "cve": "CVE-2021-41203", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `CopySliceData` is responsible for copying data from a tensor slice stored in a series of SSTables (sorted string tables) into a provided output buffer `data`.\n\n2) The function first attempts to find the tensor slice using `FindTensorSlice`, and if not found and `all_shards_loaded_` is false, it loads all shards before retrying.\n\n3) The function then iterates over `details`, which contains pairs of `TensorSlice` and filename (SSTable file path), and for each:\n   - It looks up the index of the filename in `fname_to_index_`\n   - Uses that index to access the corresponding SSTable (`sss_[idx]`)\n   - Constructs a key using `EncodeTensorNameSlice(name, slice_s)`\n   - Attempts to retrieve the value from the SSTable via `Get(key, &value)`\n   - Parses the retrieved value as a `SavedTensorSlices` proto\n   - Copies the data from the proto into the output buffer `data`\n\n4) Key security considerations:\n   - The `fname_to_index_` map is used to map filenames to indices. If this map is not properly validated or if filenames are user-controlled, an attacker could potentially manipulate the filename to access unintended SSTables.\n   - However, the filenames come from `details` which is populated by `FindTensorSlice`, which itself is part of a controlled internal data structure. The filenames are not directly user-supplied.\n   - The `EncodeTensorNameSlice` function generates a key based on tensor name and slice. This key is used to look up data in the SSTable. If this key encoding is predictable and not properly validated, it could allow for data leakage or access to unintended slices.\n   - The `ParseProtoUnlimited` function is used to parse the retrieved data. This function is typically used for parsing protocol buffers without size limits, which could be a concern if the input is untrusted. However, in this context, the data comes from the SSTable, which is a trusted storage layer, and the `Get` call already confirms the key exists.\n   - The `CopyDataFromTensorSliceToTensorSlice` function copies data from the parsed proto into the output buffer. This function is likely safe as it operates on known shapes and slices.\n\n5) Critical observation: The function uses `gtl::FindWithDefault(fname_to_index_, fname, -1)` to get the index. If `fname` is not in the map, it returns -1, and then `CHECK_GE(idx, 0)` ensures that the index is valid. This prevents out-of-bounds access.\n\n6) The function does not perform any input validation on `name` or `slice` beyond what is already done in `FindTensorSlice`. However, since this is internal code (part of a tensor checkpoint reader), and the `name` and `slice` are likely derived from trusted metadata (e.g., from a model checkpoint), the risk of external input manipulation is low.\n\n7) There is no evidence of:\n   - Buffer overflows (all operations are bounded by known sizes)\n   - Use of unsafe string functions\n   - Direct user input in key construction without sanitization\n   - Unchecked memory access\n   - Use of unsafe parsing functions on untrusted input (the input is from a trusted SSTable)\n\n8) The use of `ParseProtoUnlimited` is acceptable here because the data is read from a trusted storage layer (SSTable), and the `Get` call already confirms the key exists. The proto is not being parsed from untrusted external input.\n\n9) The function properly checks for errors at each step and returns early on failure, preventing further execution with invalid data.\n\nConclusion: The code follows safe practices. It validates indices, uses trusted storage, performs error checking, and avoids unsafe operations. There is no indication of a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 210700, "project": "squashfs-tools", "commit_id": "79b5a555058eef4e1e7ff220c344d39f8cd09646", "project_url": "https://github.com/plougher/squashfs-tools", "commit_url": "https://github.com/plougher/squashfs-tools/commit/79b5a555058eef4e1e7ff220c344d39f8cd09646", "commit_message": "Unsquashfs: fix write outside destination directory exploit\n\nAn issue on Github (https://github.com/plougher/squashfs-tools/issues/72)\nshows how some specially crafted Squashfs filesystems containing\ninvalid file names (with '/' and ..) can cause Unsquashfs to write\nfiles outside of the destination directory.\n\nThis commit fixes this exploit by checking all names for\nvalidity.\n\nIn doing so I have also added checks for '.' and for names that\nare shorter than they should be (names in the file system should\nnot have '\\0' terminators).\n\nSigned-off-by: Phillip Lougher <phillip@squashfs.org.uk>", "ground_truth": 1, "cwe": ["CWE-22"], "cve": "CVE-2021-40153", "cve_desc": "squashfs_opendir in unsquash-1.c in Squashfs-Tools 4.5 stores the filename in the directory entry; this is then used by unsquashfs to create the new file during the unsquash. The filename is not validated for traversal outside of the destination directory, and thus allows writing to locations outside of the destination.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `squashfs_opendir` is responsible for opening a directory in a SquashFS filesystem, reading its directory entries, and populating a `struct dir` with metadata about the entries.\n\n2. A buffer `buffer` of size `sizeof(squashfs_dir_entry_2) + SQUASHFS_NAME_LEN + 1` is declared and aligned. This buffer is used to hold a single directory entry (`dire`) during processing.\n\n3. The function reads the directory header (`dirh`) from the directory table, validates that `dir_count` is not greater than `SQUASHFS_DIR_COUNT`, which prevents potential integer overflow or excessive memory allocation.\n\n4. For each directory entry:\n   - It copies the entry from `directory_table` into `dire` using `memcpy`.\n   - It checks that `dire->size >= SQUASHFS_NAME_LEN` triggers an error \u2014 this is a valid check to prevent overly long filenames.\n   - It then copies the filename from `directory_table + bytes` into `dire->name`, using `dire->size + 1` bytes (including null terminator).\n   - However, here is a critical issue: `dire->name[dire->size + 1] = '\\0';` is written after copying `dire->size + 1` bytes. But `dire->name` is only allocated with space for `SQUASHFS_NAME_LEN + 1` bytes. If `dire->size` is greater than or equal to `SQUASHFS_NAME_LEN`, the earlier check `if(dire->size >= SQUASHFS_NAME_LEN)` would have already triggered an error and caused a `goto corrupted`. So this check prevents the buffer overflow.\n\n5. The function then copies the name into `dir->dirs[dir->dir_count].name` using `strcpy(dir->dirs[dir->dir_count].name, dire->name);`.\n\n   - The `dir->dirs` array is dynamically allocated using `realloc` in chunks of `DIR_ENT_SIZE`.\n   - The `name` field in `struct dir_ent` is assumed to be a fixed-size array (not shown, but typically defined as `char name[SQUASHFS_NAME_LEN + 1]`).\n   - The `strcpy` is used to copy `dire->name` into `dir->dirs[dir->dir_count].name`.\n\n   However, `dire->name` is copied from `directory_table + bytes` using `memcpy(dire->name, ..., dire->size + 1)`, and `dire->size` is checked to be less than `SQUASHFS_NAME_LEN` (via `if(dire->size >= SQUASHFS_NAME_LEN)`). So `dire->size` is strictly less than `SQUASHFS_NAME_LEN`, meaning the copied name is at most `SQUASHFS_NAME_LEN` characters, and the null terminator is included.\n\n   Therefore, `strcpy` will not overflow `dir->dirs[dir->dir_count].name` because the source string is guaranteed to be shorter than the destination buffer.\n\n6. The function also checks `dir_count > SQUASHFS_DIR_COUNT` and `dire->size >= SQUASHFS_NAME_LEN`, both of which are bounds checks that prevent buffer overflows.\n\n7. The `memcpy` operations are bounded by `sizeof(*dire)` and `dire->size + 1`, and the `dire->size` is validated before use.\n\n8. The only potential issue is the line:\n   ```c\n   dire->name[dire->size + 1] = '\\0';\n   ```\n   But this is redundant because `memcpy(dire->name, ..., dire->size + 1)` already copies the null terminator. However, this is not a vulnerability \u2014 it's just an unnecessary write. It does not cause a buffer overflow because `dire->name` is sized to hold `SQUASHFS_NAME_LEN + 1` bytes, and `dire->size` is validated to be less than `SQUASHFS_NAME_LEN`.\n\n9. All dynamic memory allocations (`malloc`, `realloc`) are checked for failure, and the function exits gracefully on failure.\n\n10. The `goto corrupted` path properly frees allocated memory.\n\nConclusion: All input from the filesystem is validated before being used. The `dire->size` is checked to be less than `SQUASHFS_NAME_LEN`, which ensures that no filename can exceed the buffer size. The `strcpy` is safe because the source is guaranteed to be within bounds. No buffer overflow or other memory corruption vulnerabilities are present.\n\n(2) NO: No security vulnerability."}
{"idx": 200113, "project": "ImageMagick", "commit_id": "389ecc365a7c61404ba078a72c3fa5a3cf1b4101", "project_url": "https://github.com/ImageMagick/ImageMagick", "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/389ecc365a7c61404ba078a72c3fa5a3cf1b4101", "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1221", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2018-14551", "cve_desc": "The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Parsing**:\n   - The function `ReadMATImageV4` reads a MAT file (MATLAB format) and parses its header.\n   - It reads `ldblk` (a long value) from the blob using `ReadBlobLSBLong` or `ReadBlobMSBLong`, depending on the header.\n   - The code checks if `ldblk > 9999` or `ldblk < 0`, and breaks if so. This is a sanity check to prevent parsing malformed headers.\n   - The header type is extracted by decomposing `ldblk` into 4 digits: `HDR.Type[0]` to `HDR.Type[3]`. The code checks that `HDR.Type[3] == 0` and `HDR.Type[2] == 0`, which are expected for valid MAT v4 files. This is a valid validation step.\n\n2. **Size Validation**:\n   - After parsing the header, the code reads `HDR.nameLen` and checks if it exceeds `0xFFFF` (65535). If so, it returns `DestroyImageList(image)`. This prevents potential heap exhaustion or integer overflow due to excessively large name lengths.\n   - The code then skips `HDR.nameLen` bytes using `ReadBlobByte` in a loop. This is safe as long as `HDR.nameLen` is validated, which it is.\n\n3. **Image Dimensions**:\n   - `image->columns` and `image->rows` are set from `HDR.nRows` and `HDR.nCols`. These are read via `ReadBlobLSBLong` or `ReadBlobMSBLong`, which are safe as long as the file is well-formed.\n   - The code checks if `image->columns == 0` or `image->rows == 0`, and returns `DestroyImageList(image)` if so. This prevents zero-sized image allocation.\n\n4. **Memory Allocation and Buffer Handling**:\n   - The code uses `GetQuantumPixels(quantum_info)` to get a pointer to pixel data. This is managed via `QuantumInfo`, which is acquired with `AcquireQuantumInfo` and destroyed with `DestroyQuantumInfo`.\n   - The pixel data is read using `ReadBlob(image, depth/8 * image->columns, (char *) pixels)`. The size is calculated as `depth/8 * columns`, which is correct for the given quantum format.\n   - The `depth` is determined from `HDR.Type[1]` (0 to 4), and the corresponding format is selected. The maximum `depth` is 64 (double precision), so `depth/8` is at most 8 bytes per pixel. The total size is bounded by `image->columns * 8`, which is acceptable as long as `image->columns` is not excessively large.\n   - However, there is no explicit check on `image->columns` or `image->rows` to prevent integer overflow or excessive memory allocation. For example, if `HDR.nRows` or `HDR.nCols` is extremely large (e.g., near `UINT_MAX`), then `image->columns * depth/8` could overflow or cause excessive memory allocation.\n\n5. **Potential Integer Overflow**:\n   - The variable `count = ReadBlob(image, depth/8 * image->columns, (char *) pixels);` uses `depth/8 * image->columns` as the size to read.\n   - If `image->columns` is very large (e.g., 100 million), and `depth` is 64, then `depth/8 * image->columns` becomes 8 * 100e6 = 800e6 bytes (~800 MB), which is acceptable on modern systems but could be abused in a denial-of-service attack.\n   - However, the code does not validate that `image->columns` and `image->rows` are within reasonable bounds (e.g., less than a few million). This could allow an attacker to craft a MAT file with extremely large dimensions, leading to excessive memory consumption or denial of service.\n\n6. **Use of `ReadBlob` and `ReadBlobByte`**:\n   - These functions are used to read data from the blob. They are designed to be safe and return `-1` on error or EOF.\n   - The code checks `count == -1` after `ReadBlob`, which is correct.\n   - The `ReadBlobByte` loop for skipping the name is safe because `HDR.nameLen` is validated to be \u2264 0xFFFF.\n\n7. **Image Rotation and Memory Management**:\n   - The code rotates the image by 90 degrees and appends it to the image list. This is a legitimate operation.\n   - The `DestroyBlob` and `ReferenceBlob` calls are used correctly to manage the blob reference.\n\n8. **Final Checks**:\n   - The code checks `EOFBlob(image)` at the end of the loop and throws an exception if EOF is reached unexpectedly.\n   - The `image_info->number_scenes` and `image->scene` logic is used to limit the number of images read, which is a good practice.\n\n**Critical Issue**:\n- The most significant vulnerability is the lack of bounds checking on `HDR.nRows` and `HDR.nCols` beyond the zero check. These values are used to compute the size of pixel data (`depth/8 * image->columns`), which could lead to integer overflow or excessive memory allocation if the values are maliciously large.\n- For example, if `HDR.nRows` is `0x7FFFFFFF` (2^31 - 1), and `depth` is 64, then `depth/8 * image->columns` becomes `8 * 0x7FFFFFFF = 0x3FFFFFF8`, which is about 1 GB. While this may not cause a buffer overflow, it can lead to denial of service (DoS) by exhausting memory.\n- This is a classic **resource exhaustion** vulnerability, which is a security concern.\n\n**Conclusion**:\n- The code does not have a buffer overflow or arbitrary code execution vulnerability, but it lacks proper bounds checking on image dimensions that could lead to denial of service via excessive memory allocation.\n- This is a known class of vulnerabilities in image parsers (e.g., CVE-2016-1000001, CVE-2017-11176).\n\n(1) YES: A security vulnerability detected."}
{"idx": 213515, "project": "vim", "commit_id": "5c68617d395f9d7b824f68475b24ce3e38d653a3", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/5c68617d395f9d7b824f68475b24ce3e38d653a3", "commit_message": "patch 8.2.4563: \"z=\" in Visual mode may go beyond the end of the line\n\nProblem:    \"z=\" in Visual mode may go beyond the end of the line.\nSolution:   Adjust \"badlen\".", "ground_truth": 1, "cwe": ["CWE-787"], "cve": "CVE-2022-0943", "cve_desc": "Heap-based Buffer Overflow occurs in vim in GitHub repository vim/vim prior to 8.2.4563.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Context and Purpose**:\n   - The function `spell_suggest` is part of a spell-checking system in Vim (likely from the `spell.c` file).\n   - It is responsible for suggesting corrections for a misspelled word under or near the cursor.\n   - It retrieves the current line, identifies the bad word, finds suggestions using `spell_find_suggest`, displays them, and allows the user to select one for replacement.\n\n2. **Input Handling**:\n   - The input to this function is `count`, which is an integer passed from the caller (likely from a user command).\n   - The function uses `curwin->w_cursor` and `ml_get_curline()` to get the current line content.\n   - The word to be corrected is extracted from `line + curwin->w_cursor.col`, and the length is determined via `badlen`.\n   - The function uses `vim_strsave(ml_get_curline())` to make a copy of the current line to prevent it from being freed by autocommands.\n\n3. **Buffer Usage and String Operations**:\n   - A local buffer `wcopy[MAXWLEN + 2]` is used to build the suggested word with possible appended parts.\n   - `vim_strncpy(wcopy, stp->st_word, MAXWLEN)` is used to copy the suggested word. Since `MAXWLEN` is a defined constant (likely 256 or similar), and `stp->st_word` is a suggestion from the spell checker, this copy is bounded by `MAXWLEN`, which prevents overflow.\n   - Later, `vim_strncpy(wcopy + stp->st_wordlen, sug.su_badptr + stp->st_orglen, sug.su_badlen - stp->st_orglen)` is used. The length copied is `sug.su_badlen - stp->st_orglen`, which is at most `MAXWLEN`, and the destination is `wcopy + stp->st_wordlen`, which is within the bounds of `wcopy` as long as `stp->st_wordlen + (sug.su_badlen - stp->st_orglen) < MAXWLEN + 2`. This is safe because `MAXWLEN` is large enough to accommodate typical words and their extensions.\n\n4. **User Input and Display**:\n   - The function uses `vim_snprintf((char *)IObuff, IOSIZE, ...)` to format messages.\n   - `IOSIZE` is a defined constant (likely 2048 or similar), and the format strings are controlled by the code (e.g., `\"Change \\\"%.*s\\\" to:\"`, `\"%2d\"`, `\" \\\"%s\\\"\"`).\n   - The `.*` in `\"%.*s\"` is used with `sug.su_badlen` and `stp->st_orglen`, which are derived from the actual word length and are bounded by `MAXWLEN`. Since `MAXWLEN` is a fixed limit, and `IOSIZE` is large enough, this prevents buffer overflow.\n   - The `msg_puts` and `msg_putchar` functions are used to display output. These are safe because they are not directly copying untrusted input into fixed-size buffers without bounds checking.\n\n5. **Memory Management**:\n   - `vim_strsave`, `vim_strnsave`, `vim_free`, and `alloc` are used appropriately.\n   - `p = alloc(...)` is used to allocate memory for the replacement string, and the size is computed from known values (`STRLEN(line)`, `stp->st_orglen`, `stp->st_wordlen`), so it's bounded.\n   - `mch_memmove` and `STRCPY`/`STRCAT` are used on the allocated buffer `p`, which is sized correctly.\n\n6. **Security Considerations**:\n   - There is no direct use of user-controlled input in unsafe functions like `strcpy`, `strcat`, or `sprintf` without bounds checking.\n   - All string operations use bounded functions (`vim_strncpy`, `vim_snprintf`) with size limits.\n   - The `sug.su_badptr` and `stp->st_word` come from the spell checker, which is internal and not directly influenced by user input in a way that could overflow.\n   - The `badlen` and `sug.su_badlen` are derived from the actual word length and are checked to be non-negative and within bounds.\n\n7. **Potential Risks**:\n   - The only potential risk would be if `MAXWLEN` is too small or if `IOSIZE` is too small, but these are compile-time constants and are typically set to safe values (e.g., 256 or 2048).\n   - The function does not perform any dynamic memory allocation based on untrusted input without bounds checking.\n   - The `vim_snprintf` calls use `.*` with controlled lengths, so no format string injection is possible.\n\n8. **Conclusion**:\n   - All string operations are bounded and use safe functions.\n   - No buffer overflow, format string vulnerability, or memory corruption is present.\n   - The code follows safe practices for handling strings and memory.\n\n(2) NO: No security vulnerability."}
{"idx": 195022, "project": "glewlwyd", "commit_id": "125281f1c0d4b6a8b49f7e55a757205a2ef01fbe", "project_url": "https://github.com/babelouest/glewlwyd", "commit_url": "https://github.com/babelouest/glewlwyd/commit/125281f1c0d4b6a8b49f7e55a757205a2ef01fbe", "commit_message": "Fix update session when auth fail", "ground_truth": 1, "cwe": ["CWE-287"], "cve": "CVE-2021-45379", "cve_desc": "Glewlwyd 2.0.0, fixed in 2.6.1 is affected by an incorrect access control vulnerability. One user can attempt to log in as another user without its password.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to identify any potential security vulnerabilities.\n\n---\n\n### Step 1: Input Validation and Parsing\n- The function `callback_glewlwyd_user_auth` receives a request and parses the JSON body using `ulfius_get_json_body_request(request, NULL)`, which returns a `json_t * j_param`.\n- It checks if `j_param` is `NULL`, and if so, returns a 400 error: `\"Input parameters must be in JSON format\"`. This prevents malformed or missing input.\n\n\u2705 Good: Proper validation of JSON input.\n\n---\n\n### Step 2: Username and Password Handling\n- The code checks if `username` is present and non-empty using `json_string_length(json_object_get(j_param, \"username\"))`.\n- For password-based authentication:\n  - It checks if `password` is present and is a string using `json_is_string`.\n  - If `password` is not a string, it returns a 400 error: `\"password must be a string\"`.\n  - It calls `auth_check_user_credentials` with the username and password.\n\n\u26a0\ufe0f Potential issue: The password is passed directly to `auth_check_user_credentials`. However, this function is assumed to be secure (as it's part of the authentication logic), and the input is already validated as a string. No direct string concatenation or unsafe operations are seen.\n\n\u2705 No evidence of buffer overflow or injection here.\n\n---\n\n### Step 3: Session Management\n- `get_session_id(config, request)` is used to retrieve an existing session ID from cookies.\n- If not found, `generate_session_id()` is called.\n- `user_session_update` is used to update session data (user agent, hostname, username, etc.).\n- A session cookie is set using `ulfius_add_cookie_to_response`, with:\n  - `expires` set via `strftime` to a future time.\n  - `config->cookie_secure` flag used (likely `true` in production, meaning HTTPS-only).\n  - `config->cookie_domain` and path set appropriately.\n\n\u2705 Good: Session ID is generated securely (assuming `generate_session_id` is cryptographically strong), and the cookie is set with proper attributes (secure, domain, path). No insecure cookie flags.\n\n---\n\n### Step 4: Scheme-Based Authentication (Advanced Auth)\n- The code supports alternative authentication schemes (e.g., OAuth, SAML, etc.) via `scheme_type`, `scheme_name`, and `value`.\n- It validates that `scheme_type`, `scheme_name`, and `value` are present and valid (non-empty, `value` is an object).\n- It calls `auth_check_user_scheme` or `auth_check_identify_scheme` with user-provided data.\n\n\u26a0\ufe0f Critical observation: The `value` field is passed directly to `auth_check_user_scheme` as a `json_object_t *`. This is **user-controlled input** and is used in a function that may process it (e.g., parse tokens, validate signatures, etc.).\n\nHowever, the function `auth_check_user_scheme` is not shown, but the code assumes it handles the input safely. The only risk would be if:\n- The function performs unsafe operations (e.g., unbounded string copying, unsafe parsing, etc.).\n- The `value` object contains malicious data that triggers a vulnerability (e.g., nested recursion, large JSON, etc.).\n\nBut the code **does not** directly manipulate or copy the `value` object into a fixed-size buffer. It passes it as a `json_t *` to another function, which is the correct way to handle JSON in C (using `json-c` library).\n\n\u2705 No evidence of buffer overflow or injection in this path.\n\n---\n\n### Step 5: Logging and Error Messages\n- The code logs sensitive information like:\n  - `username` in `y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated...\"...)`\n  - `scheme_type`, `scheme_name`, etc.\n\n\u26a0\ufe0f This is a **security concern** if logs are exposed or stored insecurely. However, logging user credentials or session details is not inherently a vulnerability **if**:\n- Logs are protected (access control, encryption, retention policies).\n- The logs are not exposed via error messages or debug endpoints.\n\nBut in this case, the logs are only used for monitoring and auditing, and the function does not expose the username in the response. So this is **not a direct vulnerability**, but a **best practice issue**.\n\n---\n\n### Step 6: Memory Management\n- `json_decref(j_param)` and `json_decref(j_result)` are called.\n- `o_free(issued_for)` is called.\n- `o_free(session_uid)` is called.\n\n\u2705 All dynamically allocated memory is properly freed.\n\n---\n\n### Step 7: No Direct String Concatenation or Unsafe Functions\n- No use of `strcpy`, `strcat`, `sprintf`, `gets`, etc.\n- No direct manipulation of user input into buffers.\n- All string handling is done via `json_string_value`, which returns a pointer to the string inside the JSON object \u2014 safe as long as the JSON is valid.\n\n---\n\n### Step 8: Cookie and Session Security\n- `config->cookie_secure` is used \u2014 implies HTTPS-only.\n- `config->cookie_domain` is set (likely to prevent cross-site leakage).\n- Path is set to `/` \u2014 correct for session cookies.\n- No `HttpOnly` flag is set, but that\u2019s not shown in the code. However, the function uses `ulfius_add_cookie_to_response`, which may or may not include `HttpOnly`. But since it's not specified, we assume it's not a vulnerability unless proven otherwise.\n\n\u26a0\ufe0f Missing `HttpOnly` flag could make the session vulnerable to XSS if the site has XSS flaws. But **this function does not introduce XSS** \u2014 it only sets a cookie. The absence of `HttpOnly` is a **potential risk**, but not a direct vulnerability **in this function** unless the entire application has XSS.\n\n---\n\n### Final Assessment:\n- All input is validated before use.\n- No unsafe string operations.\n- No buffer overflows.\n- No injection vectors (SQL, command, etc.) \u2014 no such operations are present.\n- Session management is secure (ID generation, cookie setting).\n- Memory is properly managed.\n- Logging of sensitive data is present but not exploitable in this context.\n\nWhile the **absence of `HttpOnly`** in the cookie is a **security best practice gap**, it is not a direct vulnerability **in this function** unless the application is vulnerable to XSS. The function itself does not introduce any exploitable flaw.\n\n---\n\n### \u2705 Conclusion:\n(2) NO: No security vulnerability."}
{"idx": 210944, "project": "vim", "commit_id": "35d21c6830fc2d68aca838424a0e786821c5891c", "project_url": "https://github.com/vim/vim", "commit_url": "https://github.com/vim/vim/commit/35d21c6830fc2d68aca838424a0e786821c5891c", "commit_message": "patch 9.0.0360: crash when invalid line number on :for is ignored\n\nProblem:    Crash when invalid line number on :for is ignored.\nSolution:   Do not check breakpoint for non-existing line.", "ground_truth": 1, "cwe": ["CWE-416"], "cve": "CVE-2022-3099", "cve_desc": "Use After Free in GitHub repository vim/vim prior to 9.0.0360.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context and purpose of the code\n\nThe function `do_cmdline` is part of the Vim editor's internal command execution system. It is responsible for processing a sequence of Vim commands (e.g., from a script, function, or user input), handling command-line parsing, execution, control flow (like `:if`, `:while`, `:for`, `:try`), and error handling.\n\nKey features:\n- It processes command lines, possibly split by `|`.\n- It supports execution from various sources: user input (`getexline`), sourced files (`getsourceline`), or functions (`get_func_line`).\n- It manages nested execution contexts (via `cstack`, `lines_ga`, `call_depth`, etc.).\n- It handles error recovery, debugging, and exception propagation.\n- It uses `fgetline` and `cookie` to abstract the source of input lines.\n\nThis is a core, low-level function in Vim\u2019s execution engine.\n\n---\n\n### Step 2: Look for potential security vulnerabilities\n\nWe are looking for classic vulnerabilities such as:\n- Buffer overflows\n- Use-after-free\n- Memory corruption\n- Uncontrolled input handling (e.g., command injection)\n- Improper bounds checking\n- Use of unsafe functions (e.g., `strcpy`, `strcat`, `sprintf`)\n- Insecure memory management (e.g., `vim_strsave`, `vim_free`, `ga_init2`, etc.)\n\nLet\u2019s examine key aspects:\n\n#### A. Input handling and command parsing\n- The function receives `cmdline` (a command string), `fgetline` (a callback to get next line), and `cookie` (context).\n- It uses `vim_strsave()` to copy strings, which is safe and allocates memory properly.\n- It uses `STRMOVE()` to copy strings \u2014 this is a safe macro that avoids buffer overflow if the destination is large enough.\n- It does **not** use unsafe string functions like `strcpy`, `strcat`, or `sprintf`.\n\n#### B. Memory management\n- Uses `vim_free()` and `VIM_CLEAR()` correctly.\n- Uses `ga_init2()` and `ga_clear()` for dynamic arrays (`lines_ga`), which are safe.\n- `vim_strsave()` is used to copy strings \u2014 safe.\n- No use of `malloc/free` directly, but all memory is managed via Vim\u2019s safe wrappers.\n\n#### C. Command execution and injection\n- The function does **not** directly execute shell commands or system calls.\n- It calls `do_one_cmd()` to execute individual commands \u2014 this is the actual command interpreter.\n- The input is not directly passed to a shell or system function.\n- There is **no** string concatenation with shell commands or external execution.\n- The `cmdline` is processed internally by Vim\u2019s command parser, which is designed to be safe.\n\n#### D. Control flow and recursion\n- The function has recursion protection via `call_depth` and `p_mfd` (maxfuncdepth).\n- It checks for excessive recursion and returns `FAIL` with an error message.\n- This prevents stack overflow from infinite recursion.\n\n#### E. Use of `fgetline` and `cookie`\n- `fgetline` is a callback function passed in, but it is used only to retrieve lines from a source (file, function, etc.).\n- The `cookie` is passed through and used to track context (e.g., function name, breakpoint, debug state).\n- There is no evidence that `fgetline` is called with untrusted input in a way that could lead to code execution.\n- The function validates the `fgetline` callback via `getline_equal()` and `getline_cookie()` \u2014 these are safe checks.\n\n#### F. Error handling and exception propagation\n- The function uses `do_errthrow()` and `do_intthrow()` to handle errors and interrupts.\n- It manages `msg_list`, `cstack`, and `trylevel` carefully.\n- It restores state (`msg_list`, `debug_saved`) before returning.\n- No memory leaks or dangling pointers are evident.\n\n#### G. No direct user input to system\n- No `system()`, `popen()`, `exec()`, or similar calls.\n- No `eval()` or `execute()` used in a way that could lead to arbitrary code execution (though `:execute` is mentioned in comments, it\u2019s handled by `do_one_cmd()`).\n\n---\n\n### Step 3: Consider known vulnerabilities in Vim\n\nVim has had vulnerabilities in the past (e.g., in `:execute`, `:source`, or `:profile`), but they were typically in how user input was parsed or executed, not in the core `do_cmdline` function itself.\n\nThis function is **not** directly responsible for executing arbitrary code \u2014 it only **dispatches** commands to `do_one_cmd()`, which is the actual command interpreter.\n\nThe code here is **well-structured**, uses safe memory management, avoids unsafe string operations, and includes proper bounds checking and recursion limits.\n\n---\n\n### Step 4: Conclusion\n\nAfter a thorough analysis:\n- No buffer overflows.\n- No unsafe string operations.\n- No memory corruption.\n- No command injection (no shell execution).\n- No use of dangerous functions.\n- Proper input validation and error handling.\n- Safe use of dynamic memory and callbacks.\n\nThis function is part of Vim\u2019s secure command execution engine and does not introduce a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 212934, "project": "cyrus-imapd", "commit_id": "621f9e41465b521399f691c241181300fab55995", "project_url": "https://github.com/cyrusimap/cyrus-imapd", "commit_url": "https://github.com/cyrusimap/cyrus-imapd/commit/621f9e41465b521399f691c241181300fab55995", "commit_message": "annotate: don't allow everyone to write shared server entries", "ground_truth": 1, "cwe": ["CWE-732"], "cve": "CVE-2021-32056", "cve_desc": "Cyrus IMAP before 3.2.7, and 3.3.x and 3.4.x before 3.4.1, allows remote authenticated users to bypass intended access restrictions on server annotations and consequently cause replication to stall.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Buffer Handling**:\n   - The function takes several inputs: `entry`, `userid`, `value`, `mailbox`, `mdata`, etc.\n   - The `key` buffer is declared as `char key[MAX_MAILBOX_PATH+1]`, which is a fixed-size buffer. The function calls `make_key(mboxname, uid, entry, userid, key, sizeof(key))` to construct a key.\n   - The `make_key` function is responsible for assembling the key from the components. If `make_key` properly bounds-checks the input and ensures the resulting key does not exceed `sizeof(key)`, then no buffer overflow occurs. However, we must assume `make_key` is correctly implemented (as it's a standard utility), and since `sizeof(key)` is `MAX_MAILBOX_PATH + 1`, it should be safe as long as `MAX_MAILBOX_PATH` is a reasonable limit.\n\n2. **Null Pointer and Input Checks**:\n   - The function checks for `!dest` or `!src` in some contexts, but in this code, the main checks are:\n     - `if (!value->len || value->s == NULL)` \u2014 this is used to set a flag for deletion, but it does not lead to buffer overflow.\n     - `if (!userid) goto out;` \u2014 this is a critical check: if `userid` is NULL, the function returns early. This prevents the use of invalid or malformed user identifiers, which could otherwise be exploited in key construction or access control.\n\n3. **Use of `cyrusdb_store` and `cyrusdb_delete`**:\n   - The function uses `cyrusdb_store` and `cyrusdb_delete` to write or delete data in a database.\n   - The `do { ... } while (r == CYRUSDB_AGAIN);` loop handles retry logic for transient failures, which is safe and standard.\n   - The key and data are passed directly to the database functions. However, the key is constructed via `make_key`, which is assumed to be safe. The data is passed as `data.s` and `data.len`, which are derived from `value` and `modseq`. Since `value` is a `struct buf` and `data` is built using `make_entry`, and `make_entry` is responsible for encoding the data, we assume it's safe.\n\n4. **Security-Critical Checks**:\n   - The check `if (!userid) goto out;` is crucial. It prevents writing annotations with a NULL `userid`, which could otherwise be used to bypass access control or create malformed keys. This is a good security practice.\n   - The function also checks `if (!maywrite)` and returns `IMAP_PERMISSION_DENIED`, which enforces access control.\n   - The `quota_t qdiffs[QUOTA_NUMRESOURCES]` check ensures that storage quotas are respected before writing, preventing abuse of disk space.\n\n5. **Potential Issues**:\n   - The comment says: `// Don't allow new ones to be written` \u2014 this indicates that `userid == NULL` was previously allowed but is now disallowed. The code now enforces this restriction, which is good.\n   - The `make_entry` function is used to build the data to store. If `make_entry` does not properly sanitize or encode the data (e.g., if it includes untrusted input without escaping), it could lead to data corruption or injection. However, since this is internal data (annotation value), and the function is not directly exposing it to external systems (like a web server), the risk is low.\n   - The `syslog` calls use `key_as_string(d, key, keylen)` and `value->s`. If `value->s` contains untrusted data (e.g., binary data with null bytes), `syslog` might truncate or misinterpret it, but this is a logging issue, not a direct security vulnerability (unless it leads to log injection or information disclosure). However, `syslog` is not typically used for untrusted input in this context, and the data is internal.\n\n6. **Overall Security**:\n   - The code performs proper input validation (`userid` check, `value` checks).\n   - It enforces access control (`maywrite`, `ignorequota`).\n   - It respects quotas.\n   - It avoids buffer overflows via fixed-size buffers and proper key construction.\n   - It uses safe database operations with retry logic.\n   - The only potential concern is the use of `value->s` in `syslog`, but since `value->s` is from a `struct buf` that is controlled by the system (not user input), and `syslog` is used for debugging, this is not a critical vulnerability.\n\nConclusion: The code includes multiple security checks, proper input validation, and safe handling of buffers and database operations. There are no obvious buffer overflows, injection vulnerabilities, or access control bypasses.\n\n(2) NO: No security vulnerability."}
{"idx": 197262, "project": "tensorflow", "commit_id": "e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e6cf28c72ba2eb949ca950d834dd6d66bb01cfae", "commit_message": "Validate that matrix dimension sizes in SparseMatMul are positive.\n\nPiperOrigin-RevId: 401149683\nChange-Id: Ib33eafc561a39c8741ece80b2edce6d4aae9a57d", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2021-41219", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for sparse matrix multiplication is vulnerable to undefined behavior via binding a reference to `nullptr`. This occurs whenever the dimensions of `a` or `b` are 0 or less. In the case on one of these is 0, an empty output tensor should be allocated (to conserve the invariant that output tensors are always allocated when the operation is successful) but nothing should be written to it (that is, we should return early from the kernel implementation). Otherwise, attempts to write to this empty tensor would result in heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step:\n\n1. The function `Compute` is part of an OpKernel in TensorFlow, responsible for performing matrix multiplication (or similar operation) based on input tensors `a` and `b`.\n\n2. Input validation:\n   - The code checks that both `a` and `b` are matrices using `TensorShapeUtils::IsMatrix`, and returns an error if not. This prevents malformed inputs from causing undefined behavior.\n   - It verifies that the inner dimensions `k` and `k2` (after considering transposition) are equal, which is required for valid matrix multiplication. This prevents dimension mismatch errors.\n\n3. Output allocation:\n   - The output tensor is allocated with the correct shape `{m, n}` based on the transposed dimensions. The `allocate_output` call is safe because the shape is derived from validated input dimensions.\n\n4. Zero inner dimension handling:\n   - If `k == 0`, the output is filled with zeros using `SetZeroFunctor`. This is a correct and safe handling of edge cases.\n\n5. Type conversion and memory management:\n   - The code uses `std::unique_ptr<Tensor>` to manage temporary tensors (`a_float`, `b_float`, `right_tr`) for type conversion (e.g., from `bfloat16` to `float`). These are properly scoped and automatically cleaned up.\n   - The `BFloat16ToFloat` function is used to convert data, which is a known safe operation when the input size matches the output size (ensured via `NumElements()`).\n\n6. Matrix multiplication:\n   - For dense matrices, the code uses Eigen's `contract` method with proper dimension pairing and device context. The `transpose_a_` and `transpose_b_` flags are used correctly to control the operation.\n   - For sparse cases, the code uses `DoMatMul` with appropriate caching and threading, and handles transposition via `shuffle` and `swap` operations. The `shuffle` operation is applied only on valid tensor shapes (checked via `dim_size(0) != 0` and `dim_size(1) != 0`), preventing out-of-bounds access.\n\n7. Input validation for sparse case:\n   - Before transposing `b`, the code checks that both dimensions of `b` are non-zero. This prevents invalid tensor creation and potential memory access violations.\n\n8. No use of unsafe functions:\n   - There are no calls to `strcpy`, `strcat`, `memcpy` with unbounded sizes, or any other functions that could lead to buffer overflows.\n   - No direct memory manipulation without bounds checking.\n   - No string concatenation with user input (this is numerical computation, not string processing).\n\n9. No injection or code execution risks:\n   - The code operates on tensors and performs mathematical operations. There is no interpretation of input as code, no dynamic evaluation, no command execution, and no exposure to injection attacks (e.g., SQL, XSS, etc.).\n\n10. Thread safety and resource management:\n    - The use of `std::unique_ptr` ensures no memory leaks.\n    - The `eigen_device` is used correctly with proper device context.\n    - The `tensorflow_cpu_worker_threads()` are used appropriately for parallelization.\n\nConclusion: The code performs thorough input validation, uses safe memory management, avoids unsafe operations, and correctly handles edge cases (like zero dimensions). There are no known security vulnerabilities such as buffer overflows, use-after-free, integer overflows, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 199767, "project": "hexchat", "commit_id": "4e061a43b3453a9856d34250c3913175c45afe9d", "project_url": "https://github.com/hexchat/hexchat", "commit_url": "https://github.com/hexchat/hexchat/commit/4e061a43b3453a9856d34250c3913175c45afe9d", "commit_message": "Clean up handling CAP LS", "ground_truth": 1, "cwe": ["CWE-22"], "cve": "CVE-2016-2087", "cve_desc": "Directory traversal vulnerability in the client in HexChat 2.11.0 allows remote IRC servers to read or modify arbitrary files via a .. (dot dot) in the server name.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `inbound_cap_ls` processes a string of IRC capabilities (`extensions_str`) and constructs a CAP REQ message to send to the server.\n\n2. A fixed-size buffer `char buffer[256]` is declared. This buffer is used to build the CAP REQ string.\n\n3. The function starts by copying the string \"CAP REQ :\" into the buffer using `strcpy(buffer, \"CAP REQ :\")`. This is safe because \"CAP REQ :\" is 8 characters long, and the buffer is 256 bytes.\n\n4. Then, the function iterates over each extension in `extensions_str`, which is split using `g_strsplit` into an array of strings. For each extension, it checks if it matches known capability names and appends the extension name to the buffer using `strcat`.\n\n5. The key concern is whether `strcat` can cause a buffer overflow. The buffer is 256 bytes, and the initial \"CAP REQ :\" is 8 bytes. The function appends one extension at a time, each followed by a space.\n\n6. The maximum number of extensions is not bounded by the code, but the input `extensions_str` comes from the server or user, and the number of extensions is limited by the protocol. However, the code does not validate the length of the final string before appending.\n\n7. The worst-case scenario: if `extensions_str` contains many extensions (e.g., hundreds), and each is long (e.g., 20 characters), the total length could exceed 256 bytes. For example, 100 extensions of 20 characters each would require 2000+ characters, far exceeding the buffer size.\n\n8. `strcat` does not check bounds \u2014 it appends until it finds a null terminator. If the buffer overflows, it can corrupt adjacent memory, leading to undefined behavior, crashes, or potential exploitation (e.g., stack overflow, code execution).\n\n9. The code does not perform any length checks before appending to `buffer`. There is no `strncat` or length tracking to prevent overflow.\n\n10. Although the function uses `g_strsplit` and `g_strfreev`, which are safe, the core issue is the unbounded `strcat` usage on a fixed-size buffer.\n\n11. The use of `g_strchomp` at the end is safe, but it doesn't prevent the overflow that occurs during the `strcat` loop.\n\nConclusion: The code is vulnerable to a buffer overflow due to unbounded `strcat` usage on a fixed-size buffer without length checks.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195231, "project": "gpac", "commit_id": "893fb99b606eebfae46cde151846a980e689039b", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/893fb99b606eebfae46cde151846a980e689039b", "commit_message": "fixed #1902", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-40565", "cve_desc": "A Segmentation fault caused by a null pointer dereference vulnerability exists in Gpac through 1.0.1 via the gf_avc_parse_nalu function in av_parsers.c when using mp4box, which causes a denial of service.", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Handling and Buffer Management**:\n   - The function `gf_avc_parse_nalu` takes a `GF_BitStream *bs` and an `AVCState *avc` as inputs.\n   - `gf_bs_read_u8(bs)` reads a single byte from the bitstream, which is used to extract the NAL unit header (`nal_hdr`).\n   - The function enables emulation byte removal via `gf_bs_enable_emulation_byte_removal(bs, GF_TRUE)`, which is a standard and safe practice to prevent emulation prevention bytes from causing parsing issues.\n\n2. **NAL Unit Type Parsing**:\n   - The NAL unit type is extracted using `nal_hdr & 0x1F`, which correctly isolates the 5-bit NAL unit type field.\n   - The code handles various NAL unit types (e.g., IDR slice, non-IDR slice, SPS, PPS, SEI, etc.) with appropriate parsing logic.\n   - For each NAL unit type, the function calls appropriate internal parsing functions (e.g., `avc_parse_slice`, `gf_avc_read_sps_bs_internal`, etc.), which are assumed to be well-behaved and properly validate input.\n\n3. **Memory Operations**:\n   - `memcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo))` copies the current slice state into a local `n_state` structure. This is safe as long as `AVCSliceInfo` is a well-defined structure and the size is known.\n   - Later, `memcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo))` updates the global state. This is also safe because the size is bounded and the structure is not user-controlled.\n\n4. **Bounds and Validation Checks**:\n   - The function performs checks on `avc->s_info.sps` via `assert(avc->s_info.sps)` in one branch. While `assert` is not a runtime check, it is used for debugging and does not affect security in production (though it could be a concern if assertions are disabled).\n   - The code checks for valid NAL unit types and handles unknown types in the `default` case, returning `ret = 1` or `0` based on context. This avoids undefined behavior.\n\n5. **Potential Issues**:\n   - The use of `assert(avc->s_info.sps)` is a concern: if `sps` is null and assertions are disabled, this could lead to a null pointer dereference. However, this is not a direct buffer overflow or memory corruption vulnerability unless the `sps` pointer is used without validation.\n   - The function does not directly read unbounded data from the bitstream into a fixed-size buffer. All parsing is done through structured bitstream reading functions (`gf_bs_read_ue`, `gf_bs_read_u8`, etc.), which are designed to be safe.\n   - The `avc_parse_slice` and `SVC_ReadNal_header_extension` functions are called with proper parameters, and their return values are checked (`ret < 0`), which prevents further processing on error.\n\n6. **No Buffer Overflows or Memory Corruption**:\n   - There are no calls to unsafe functions like `strcpy`, `strcat`, `gets`, or `memcpy` with untrusted sizes.\n   - All data is read from the bitstream using safe, bounded functions.\n   - The `n_state` structure is used as a temporary buffer, and its size is fixed and known.\n\n7. **Control Flow and Logic**:\n   - The logic in the `switch` and `if` statements is complex but does not introduce any obvious vulnerabilities.\n   - The `default` case handles unknown NAL unit types safely by comparing with known types and returning appropriate values.\n\n8. **Conclusion**:\n   - The code performs proper input validation, uses safe bitstream reading functions, avoids unsafe memory operations, and handles edge cases appropriately.\n   - There are no signs of buffer overflows, use-after-free, null pointer dereferences (in production), or other classic security vulnerabilities.\n   - The only potential issue is the `assert(avc->s_info.sps)` which could lead to a crash if `sps` is null and assertions are disabled, but this is a logic error rather than a security vulnerability in the traditional sense (e.g., remote code execution, data leakage).\n\n(2) NO: No security vulnerability."}
{"idx": 216767, "project": "core", "commit_id": "ed4b7d5d1b30964216d61d3090a7b47a957f5b26", "project_url": "https://github.com/LibreOffice/core", "commit_url": "https://github.com/dovecot/core/commit/ed4b7d5d1b30964216d61d3090a7b47a957f5b26", "commit_message": "lib-smtp: smtp-command-parser - Fix infinite loop occurring when command stream ends in UTF-8 character.\n\nBroken by 8f08f1944be438a2422b604c08e5060b5c7bd72f.", "ground_truth": 1, "cwe": ["CWE-835"], "cve": "CVE-2020-7046", "cve_desc": "lib-smtp in submission-login and lmtp in Dovecot 2.3.9 before 2.3.9.3 mishandles truncated UTF-8 data in command parameters, as demonstrated by the unauthenticated triggering of a submission-login infinite loop.", "vuln": 0, "reasoning": "Let's analyze the code step by step:\n\n1. The function `smtp_command_parse_parameters` is responsible for parsing parameters in an SMTP command or AUTH response.\n\n2. It starts by determining the maximum allowed size for the parameters based on whether this is an AUTH response or a regular command:\n   ```c\n   uoff_t max_size = (parser->auth_response ?\n       parser->limits.max_auth_size :\n       parser->limits.max_parameters_size);\n   ```\n   This is a reasonable approach to enforce different limits for different contexts.\n\n3. The function then iterates through the input buffer (`parser->cur + parser->state.poff` to `parser->end`) to parse characters:\n   - For AUTH responses, it treats each byte as a single character (no UTF-8 decoding).\n   - For regular commands, it uses `uni_utf8_get_char_n` to decode UTF-8 characters safely, with bounds checking via `(p - parser->end)`.\n\n4. The UTF-8 decoding is done safely:\n   - `uni_utf8_get_char_n` returns negative on invalid UTF-8, and the function reports an error and returns -1 in that case.\n   - This prevents invalid UTF-8 from being processed, which is a good security practice.\n\n5. The function checks if the character is valid:\n   - For non-UTF-8 (AUTH response) or ASCII-only (ch & 0x80 == 0), it uses `smtp_char_is_textstr` to validate the character.\n   - For non-ASCII (UTF-8), it allows valid UTF-8 characters, which is acceptable for SMTP command parameters.\n\n6. After parsing, it checks if the length exceeds `max_size`:\n   ```c\n   if (max_size > 0 && (uoff_t)(p - parser->cur) > max_size)\n   ```\n   This prevents buffer overflow by limiting the size of the parsed parameters.\n\n7. The function trims trailing whitespace (SP and HTAB) from the end of the parameter:\n   ```c\n   while (mp > parser->cur && (*(mp-1) == ' ' || *(mp-1) == '\\t'))\n       mp--;\n   ```\n   This is safe because it only moves `mp` backward from `p`, and `mp` is always \u2265 `parser->cur`.\n\n8. It checks for a leading space after the command name (only for non-AUTH responses):\n   ```c\n   if (!parser->auth_response && mp > parser->cur && *parser->cur == ' ')\n   ```\n   This prevents malformed commands like \"CMD  param\", which is a valid SMTP interoperability check.\n\n9. Finally, it uses `i_strdup_until(parser->cur, mp)` to copy the parsed parameters into a new string. This function:\n   - Copies from `parser->cur` to `mp` (non-inclusive of `mp`).\n   - Is assumed to be safe (as it's a standard library function in the context of the codebase).\n   - Does not copy beyond `mp`, so no buffer overflow.\n\n10. The function updates `parser->cur` and `parser->state.poff` correctly.\n\nKey security considerations:\n- UTF-8 validation is properly enforced.\n- Input length is bounded by `max_size`.\n- No unsafe string operations (like `strcpy`, `strcat`) are used.\n- Memory allocation is done via `i_strdup_until`, which is safe if implemented correctly.\n- All input is validated before being processed.\n\nNo buffer overflows, no injection vulnerabilities, no unsafe memory access.\n\n(2) NO: No security vulnerability."}
{"idx": 195264, "project": "pcre2", "commit_id": "d4fa336fbcc388f89095b184ba6d99422cfc676c", "project_url": "https://github.com/PCRE2Project/pcre2", "commit_url": "https://github.com/PCRE2Project/pcre2/commit/d4fa336fbcc388f89095b184ba6d99422cfc676c", "commit_message": "Fix incorrect value reading in JIT.", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-1586", "cve_desc": "An out-of-bounds read vulnerability was discovered in the PCRE2 library in the compile_xclass_matchingpath() function of the pcre2_jit_compile.c file. This involves a unicode property matching issue in JIT-compiled regular expressions. The issue occurs because the character was not fully read in case-less matching within JIT.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThe function `compile_xclass_matchingpath` is part of a PCRE2 (Perl Compatible Regular Expressions) compiler, specifically handling the compilation of character class matching logic (e.g., `[a-z]`, `\\d`, `\\p{L}`, etc.). It generates low-level machine code (via SLJIT) to match characters against a character class.\n\nThe function processes a character class definition (`cc`) that may include:\n- Single characters (`XCL_SINGLE`)\n- Ranges (`XCL_RANGE`)\n- Unicode properties (`XCL_PROP`, `XCL_NOTPROP`)\n- Special categories like `\\p{L}`, `\\p{Lu}`, etc.\n\nIt uses a compiler backend (SLJIT) to generate efficient machine code for matching.\n\n---\n\n### Step 2: Identify potential vulnerabilities\nWe are looking for:\n- Buffer overflows\n- Integer overflows/underflows\n- Use-after-free or null pointer dereferences\n- Improper bounds checking\n- Unsafe memory access\n- Incorrect handling of user-controlled input (e.g., regex patterns)\n\nLet\u2019s examine key aspects:\n\n#### A. Input validation\nThe input `cc` is a pointer to a compiled character class structure. This is **not user input directly**, but rather **compiled regex bytecode** generated by the PCRE2 parser. Therefore, the input is assumed to be valid and well-formed by the time it reaches this function (as per PCRE2\u2019s design).\n\nThe function uses `GETCHARINCTEST(c, cc)` macro, which safely reads a character from `cc` and advances the pointer. This macro is designed to prevent buffer overflows by checking bounds (as per PCRE2\u2019s internal safety mechanisms).\n\n#### B. Bounds checking in loops\nThe loop:\n```c\nwhile (*cc != XCL_END)\n```\nis used to iterate through the character class data. The `XCL_END` marker is used to terminate the class, and the code assumes this marker is present. This is a standard pattern in PCRE2, and the parser ensures that all character class structures are properly terminated.\n\n#### C. Unicode handling\nThe code includes extensive Unicode support (`#ifdef SUPPORT_UNICODE`). It uses:\n- `PRIV(ucd_stage1)`, `PRIV(ucd_stage2)`, `PRIV(ucd_records)`, etc. \u2014 these are precomputed tables.\n- `OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);` \u2014 memory access via computed index.\n\nHowever, all memory accesses are:\n- Based on valid indices derived from the character class data.\n- Checked via `GETCHARINCTEST` and `SLJIT_ASSERT` checks.\n- The `cc` pointer is advanced safely using macros that prevent out-of-bounds access.\n\n#### D. Use of `SLJIT_ASSERT`\nThe code uses `SLJIT_ASSERT` extensively, especially around:\n- `SLJIT_ASSERT(compares > 0);`\n- `SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);`\n- `SLJIT_ASSERT(other_cases[0] != NOTACHAR && ...);`\n\nThese are **debug-time checks** that ensure internal consistency. In production builds, they are typically disabled, but the logic is still safe because:\n- The input is compiled from trusted regex parsing.\n- The structure of `cc` is validated earlier in the compilation pipeline.\n\n#### E. Memory access safety\nAll memory accesses (e.g., `SLJIT_MEM1(TMP1), (sljit_sw)cc`) are:\n- Based on valid, bounded indices.\n- Checked via `GETCHARINCTEST` and `cc` pointer arithmetic.\n- No direct user input is used to index into memory without bounds checks.\n\n#### F. No dynamic allocation or unsafe string operations\nThere are no calls to `strcpy`, `malloc`, `memcpy`, etc. The code operates on fixed-size data structures and uses safe pointer arithmetic.\n\n#### G. No format string or injection vulnerabilities\nThis is not a string formatting function. It's a compiler backend generating machine code from structured data.\n\n---\n\n### Step 3: Conclusion\nThe function is part of a well-established, security-hardened regex engine (PCRE2). It:\n- Processes compiled regex bytecode (not raw user input).\n- Uses safe macros (`GETCHARINCTEST`) to prevent buffer overflows.\n- Employs bounds checks and assertions.\n- Does not perform unsafe memory operations.\n- Is designed to be robust against malformed or malicious regex patterns (which are already validated earlier in the pipeline).\n\nThere is **no evidence of a security vulnerability** in this code.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 210273, "project": "mongo", "commit_id": "f3604b901d688c194de5e430c7fbab060c9dc8e0", "project_url": "https://github.com/mongodb/mongo", "commit_url": "https://github.com/mongodb/mongo/commit/f3604b901d688c194de5e430c7fbab060c9dc8e0", "commit_message": "SERVER-59071 Treat '$sample' as unsharded when connecting directly to shards", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2021-32037", "cve_desc": "An authorized user may trigger an invariant which may result in denial of service or server exit if a relevant aggregation request is sent to a shard. Usually, the requests are sent via mongos and special privileges are required in order to know the address of the shards and to log in to the shards of an auth enabled environment.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step-by-step to determine whether there is a security vulnerability.\n\n1. **Context and Purpose**:\n   - The function `createRandomCursorExecutor` is part of a database query execution system (likely MongoDB).\n   - It creates a plan executor for a `$sample` aggregation stage, using either a random cursor (for efficient sampling) or falling back to a collection scan (collscan) if conditions aren't met.\n   - It uses a `TrialStage` to dynamically choose between two plans based on early trial results.\n\n2. **Input Validation and Safety Checks**:\n   - The function checks for valid input parameters: `coll`, `expCtx`, `sampleSize`, `numRecords`, and `bucketUnpacker`.\n   - It validates that the collection is locked (`invariant` on collection lock mode), which is a good practice to prevent race conditions.\n   - It checks for null pointers and invalid states (e.g., `!bucketUnpacker && numRecords`).\n   - It performs bounds checks on `sampleSize` relative to `numRecords` and `gTimeseriesBucketMaxCount`, using safe thresholds (e.g., 5% and 1%).\n   - It uses `std::make_unique` and `std::move` correctly, avoiding raw pointers and ensuring RAII.\n\n3. **Use of `TrialStage` for Fallback**:\n   - The `TrialStage` is used to run a trial of the optimized plan (e.g., random cursor or `SampleFromTimeseriesBucket`) against a backup plan (e.g., `CollectionScan`).\n   - The decision to use the optimized plan is based on observed performance (advanced/work ratio), which is a safe, runtime-based heuristic.\n   - The fallback mechanism is robust: if the trial fails (e.g., too many orphaned docs, low bucket fullness), it defaults to the safe backup plan.\n\n4. **No User Input Directly Injected**:\n   - The function does not directly process untrusted user input in a way that could lead to injection (e.g., no string concatenation, no SQL/JS execution).\n   - All parameters are numeric or structured (e.g., `CollectionPtr`, `ExpressionContext`), and their values are validated against safe thresholds.\n\n5. **No Buffer Overflows, Memory Corruption, or Unsafe Operations**:\n   - No use of unsafe C-style functions (e.g., `strcpy`, `strcat`).\n   - No manual memory management; all resources are managed via smart pointers (`std::unique_ptr`, `std::make_unique`).\n   - No off-by-one errors or integer overflows are evident in the logic (e.g., `sampleSize > numRecords * kMaxSampleRatioForRandCursor` is safe as long as `numRecords` is non-negative, which is assumed).\n\n6. **No Known Exploitable Flaws**:\n   - The code uses `invariant` to assert internal state, which is acceptable in debug builds and helps catch logic errors.\n   - The `kMaxPresampleSize` is used safely (100) and not exposed to user control.\n   - The `minAdvancedToWorkRatio` is computed with `std::max` and `std::min` to prevent invalid values (e.g., NaN), and the `kMinBucketFullness` guard prevents using inefficient plans on empty or nearly empty buckets.\n\n7. **Conclusion**:\n   - The code is well-structured, uses safe C++ practices, performs input validation, and includes fallback mechanisms.\n   - There are no signs of buffer overflows, injection vulnerabilities, use-after-free, or other classic security issues.\n   - The logic is defensive and avoids unsafe assumptions.\n\n(2) NO: No security vulnerability."}
{"idx": 196698, "project": "tensorflow", "commit_id": "67bfd9feeecfb3c61d80f0e46d89c170fbee682b", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/67bfd9feeecfb3c61d80f0e46d89c170fbee682b", "commit_message": "Make SparseFillEmptyRows validate that the length of `values` must be equal to the number of index tuples.\n\nPiperOrigin-RevId: 399969549\nChange-Id: I3c2f2ca1c1d2cc88bb5951c6958b38c16e9436c8", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2021-41224", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the implementation of `SparseFillEmptyRows` can be made to trigger a heap OOB access. This occurs whenever the size of `indices` does not match the size of `values`. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a C++ implementation of an operation kernel (likely in TensorFlow) that processes sparse tensors and fills empty rows with default values.\n\n2) The function takes an OpKernelContext and an optional DoneCallback. It validates input tensors:\n   - dense_shape must be a vector\n   - indices must be a matrix\n   - values must be a vector\n   - default_value must be a scalar\n   - dense_shape cannot be empty\n\n3) All input validation is performed using OP_REQUIRES_ASYNC macros, which check conditions and call the done callback with an error if validation fails.\n\n4) The function uses a functor (SparseFillEmptyRows) to perform the actual computation, passing the validated inputs.\n\n5) The code properly validates all input tensor shapes and types before processing, preventing invalid or malformed inputs from causing undefined behavior.\n\n6) There are no obvious buffer overflows, use-after-free issues, or unsafe memory operations.\n\n7) The function does not directly handle user input in a way that could lead to injection attacks or other common vulnerabilities.\n\n8) The only potential concern is the TODO comment about adding additional shape checks between values, indices, and dense_shape, but this is a missing validation rather than an active vulnerability.\n\n9) The code follows proper error handling patterns with early returns on invalid inputs, and uses the framework's built-in validation mechanisms.\n\n10) No evidence of unsafe operations, memory corruption, or exploitable conditions.\n\n(2) NO: No security vulnerability."}
{"idx": 214335, "project": "ceph", "commit_id": "be7679007c3dfab3e19c22c38c36ccac91828e3b", "project_url": "https://github.com/ceph/ceph", "commit_url": "https://github.com/ceph/ceph/commit/be7679007c3dfab3e19c22c38c36ccac91828e3b", "commit_message": "rgw: reject control characters in response-header actions\n\nS3 GetObject permits overriding response header values, but those inputs\nneed to be validated to insure only characters that are valid in an HTTP\nheader value are present.\n\nCredit: Initial vulnerability discovery by William Bowling (@wcbowling)\nCredit: Further vulnerability discovery by Robin H. Johnson <rjohnson@digitalocean.com>\nSigned-off-by: Robin H. Johnson <rjohnson@digitalocean.com>", "ground_truth": 1, "cwe": ["CWE-79"], "cve": "CVE-2020-1760", "cve_desc": "A flaw was found in the Ceph Object Gateway, where it supports request sent by an anonymous user in Amazon S3. This flaw could lead to potential XSS attacks due to the lack of proper neutralization of untrusted input.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step-by-step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `send_response_data` is part of an S3-compatible object storage system (likely Ceph RGW). It is responsible for:\n- Preparing HTTP response headers.\n- Sending metadata and object data.\n- Handling various attributes, custom headers, and content types.\n- Managing response body (metadata and object data).\n\nIt uses `bufferlist`, `dump_header`, `dump_body`, `dump_content_length`, etc., which are internal utilities for constructing HTTP responses.\n\n---\n\n### Step 2: Look for potential security issues\n\n#### A. **Header Injection / Header Smuggling**\n- The function uses `dump_header(s, key, value)` multiple times, where `key` and `value` come from:\n  - `response_attrs` (populated from `s->info.args` and `attrs`)\n  - `attrs` (object metadata, possibly from user input)\n  - `crypt_http_responses` (possibly from config or internal logic)\n  - `rgw_to_http_attrs` mapping\n- The `key` values are derived from:\n  - `p->http_attr` (from `resp_attr_params`)\n  - `aiter->second` (from `rgw_to_http_attrs`)\n  - `name` (from `iter->first`, e.g., `RGW_ATTR_META_PREFIX` + user metadata)\n- The `value` comes from:\n  - `val` (from `s->info.args.get(...)`)\n  - `iter->second` (from `attrs`, which may contain user-provided metadata)\n  - `ss.str()` (from JSON-encoded metadata)\n  - `iter->second.to_str()` (from bufferlist)\n\n\u26a0\ufe0f **Critical concern**: If any of these keys or values contain newline characters (`\\n` or `\\r\\n`), they could be used to inject additional HTTP headers or manipulate the response structure \u2014 a classic **HTTP header injection** vulnerability.\n\nHowever, the code does **not** sanitize or validate the content of headers before passing them to `dump_header(s, key, value)`.\n\nBut wait \u2014 does `dump_header` perform any sanitization?\n\nLooking at the code, we don\u2019t see the implementation of `dump_header`, but in typical Ceph RGW code:\n- `dump_header` is designed to safely write headers.\n- It **does not** allow arbitrary newlines in header values.\n- It typically uses `ceph::encode` or similar safe mechanisms that escape or reject invalid characters.\n\nBut crucially: **the code does not explicitly validate or sanitize header keys or values**.\n\nMoreover, the `response_attrs` map is populated from `s->info.args.get(...)`, which comes from the client request. If a malicious client sends a header like:\n```\nx-amz-meta-foo: value\\r\\nX-Injected-Header: evil\n```\nand this is mapped to a header via `rgw_to_http_attrs`, it could result in:\n```\nX-Injected-Header: evil\n```\nbeing injected into the response.\n\nEven if `dump_header` is safe, **if the header key is user-controlled and contains `\\n`, it could break the header structure**.\n\nBut in this code:\n- The `key` is derived from `p->http_attr`, `aiter->second`, or `name` (after stripping prefix).\n- These are **not** directly user-controlled \u2014 they are from predefined constants or mappings.\n- The only user-controlled input is the **value** of the header.\n\nSo the **key** is safe (from known constants), but the **value** is user-controlled.\n\nNow, does `dump_header` sanitize values?\n\nIn Ceph RGW, `dump_header` typically uses `ceph::encode` or similar, which **does not allow newlines in header values** \u2014 it would break the HTTP format. But if the value contains `\\n`, it may cause:\n- Malformed headers\n- Header injection\n- Potential bypass of security checks\n\nBut again, in practice, `dump_header` in RGW is designed to be safe \u2014 it uses `put_header` with proper escaping.\n\nHowever, **the code does not explicitly validate or sanitize the values** before passing them to `dump_header`.\n\nBut let\u2019s look deeper.\n\n#### B. **User Metadata Handling**\n- User metadata is passed via `RGW_ATTR_META_PREFIX` (e.g., `x-amz-meta-...`).\n- The code does:\n  ```cpp\n  else if (strncmp(name, RGW_ATTR_META_PREFIX, sizeof(RGW_ATTR_META_PREFIX)-1) == 0) {\n    name += sizeof(RGW_ATTR_PREFIX) - 1;\n    dump_header(s, name, iter->second);\n  }\n  ```\n  Wait \u2014 there\u2019s a **bug here**:\n  - `name += sizeof(RGW_ATTR_PREFIX) - 1;`\n  - But `RGW_ATTR_PREFIX` is likely `\"x-amz-meta-\"`, so `sizeof(RGW_ATTR_PREFIX) - 1` is the length of the prefix.\n  - But `name` is already `iter->first`, which is `RGW_ATTR_META_PREFIX + ...`, so this is correct.\n\nBut the **real issue** is: **the value `iter->second` is passed directly to `dump_header`**.\n\nIf `iter->second` contains `\\n`, and `dump_header` does not escape it, this could lead to header injection.\n\nBut again, in Ceph RGW, `dump_header` uses `put_header` which **does not allow newlines** \u2014 it would be rejected or escaped.\n\nSo unless there\u2019s a flaw in `dump_header`, this is safe.\n\n#### C. **Content-Type Handling**\n- The code sets `content_type` from `content_type_str` if not set.\n- If `content_type` is not set, it defaults to `\"binary/octet-stream\"`.\n- The `content_type` is used in `end_header(s, this, content_type)`.\n\nBut `content_type` is derived from:\n- `content_type_str = val;` (from `s->info.args.get(\"response-content-type\")`)\n- Or from `rgw_bl_str(iter->second)` (from `RGW_ATTR_CONTENT_TYPE`)\n\n\u26a0\ufe0f **Risk**: If a malicious client sets `response-content-type` to a value with `\\n`, and `end_header` does not sanitize it, it could inject headers.\n\nBut again, `end_header` is a safe function in RGW \u2014 it uses `put_header` and validates the content.\n\n#### D. **Buffer Overflow / Memory Safety**\n- The function uses `bufferlist`, `bl.c_str() + bl_ofs`, `bl_len`.\n- It calls `dump_body(s, bl.c_str() + bl_ofs, bl_len)` \u2014 this is safe as long as `bl_len` is valid and within bounds.\n- `bl_len` is passed from caller \u2014 no bounds checking is done here, but `bufferlist` is designed to be safe.\n\nNo obvious buffer overflow.\n\n#### E. **Error Handling and Input Validation**\n- The code checks for `op_ret`, `sent_header`, `custom_http_ret`, etc.\n- It uses `decode_attr_bl_single_value`, `decode`, `encode_json`, etc., which are safe if used correctly.\n- `try/catch` blocks are used for `decode` and `decode_json`, so exceptions are caught.\n\nNo obvious unhandled exceptions.\n\n#### F. **Use of `dump_body` with `bufferlist`**\n- `dump_body(s, metadata_bl)` \u2014 `metadata_bl` is a `bufferlist` from `ss.str()`, which is safe.\n- `dump_body(s, bl.c_str() + bl_ofs, bl_len)` \u2014 again, safe if `bl_len` is valid.\n\nNo obvious issues.\n\n---\n\n### Step 3: Final Assessment\n\n- The code **does not sanitize or validate** user-controlled header values before passing them to `dump_header` or `dump_body`.\n- However, in the **context of Ceph RGW**, the `dump_header` and `dump_body` functions are **designed to be secure** \u2014 they use safe encoding and reject malformed headers.\n- The `response_attrs` map is populated from user input, but the **keys are not user-controlled** \u2014 they are from predefined constants.\n- The **values** are user-controlled, but `dump_header` likely escapes or rejects newlines.\n- There is **no evidence of direct string concatenation** or unsafe formatting (like `sprintf` or `printf` with user input).\n- The code uses `bufferlist` and safe encoding mechanisms.\n\nTherefore, **despite the potential risk of header injection**, the **actual implementation in Ceph RGW** mitigates this via safe header dumping functions.\n\n---\n\n### Conclusion\n\nAfter careful analysis, there is **no evidence of a security vulnerability** in this code, assuming the underlying `dump_header`, `dump_body`, and `put_header` functions are implemented securely (which they are in Ceph RGW).\n\n(2) NO: No security vulnerability."}
{"idx": 194963, "project": "ImageMagick6", "commit_id": "dc070da861a015d3c97488fdcca6063b44d47a7b", "project_url": "https://github.com/ImageMagick/ImageMagick6", "commit_url": "https://github.com/ImageMagick/ImageMagick6/commit/dc070da861a015d3c97488fdcca6063b44d47a7b", "commit_message": "https://github.com/ImageMagick/ImageMagick/pull/5034", "ground_truth": 1, "cwe": ["CWE-704"], "cve": "CVE-2022-32547", "cve_desc": "In ImageMagick, there is load of misaligned address for type 'double', which requires 8 byte alignment and for type 'float', which requires 4 byte alignment at MagickCore/property.c. Whenever crafted or untrusted input is processed by ImageMagick, this causes a negative impact to application availability or other problems related to undefined behavior.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the function's purpose\nThe function `GetEXIFProperty` is designed to extract specific EXIF metadata from an image's EXIF profile. It parses EXIF data (a structured format used in image files) and returns a requested property (e.g., \"exif:DateTime\", \"exif:Make\", etc.) as a string. It supports:\n- Retrieving all tags (`*`)\n- Retrieving tags by ID (`!`)\n- Retrieving tags by hex ID (`@` or `#`)\n- Retrieving tags by name (e.g., \"exif:DateTime\")\n\nIt uses a stack-based traversal (`directory_stack`) to follow nested IFDs (Image File Directories), such as Exif, GPS, and Interoperability IFDs.\n\n---\n\n### Step 2: Identify potential vulnerabilities\n\n#### A. **Buffer handling and string formatting**\n- The function uses `FormatLocaleString` to format output into `buffer[MaxTextExtent]`, which is a fixed-size buffer.\n- `MaxTextExtent` is not defined in the snippet, but in ImageMagick, it's typically 2048 or similar \u2014 a reasonable size.\n- The code checks: `if (length >= (MaxTextExtent-1)) length=MaxTextExtent-1;` \u2014 this prevents buffer overflow in `FormatLocaleString`.\n- Also, `buffer[length-2] = '\\0';` is used to null-terminate the string safely when multiple values are joined.\n\n\u2705 **No buffer overflow in `buffer`** due to bounds checking.\n\n#### B. **Memory allocation and use of `AcquireQuantumMemory`**\n- The function uses `AcquireQuantumMemory((size_t) number_bytes + 1UL, sizeof(*value))` to allocate memory for string values.\n- This is safe because:\n  - It checks `~((size_t) number_bytes) >= 1` to prevent overflow in the allocation size.\n  - It adds 1 for null termination.\n- The allocated memory is properly freed via `DestroyString(value)`.\n\n\u2705 **No integer overflow or underflow in memory allocation.**\n\n#### C. **Input validation and bounds checking**\n- The function validates:\n  - `profile == NULL` \u2192 returns early.\n  - `property == NULL` or empty \u2192 returns early.\n  - `strlen(property) <= 5` \u2192 returns early.\n  - `ReadPropertyByte` checks for expected EXIF header (`0x45 0x78 0x69 0x66`).\n  - Endian check (`0x4949` or `0x4D4D`) \u2014 valid.\n  - Version check (`0x002a`) \u2014 valid.\n  - Offset validation: `(offset < 0) || (size_t) offset >= length` \u2192 returns early.\n  - All pointer accesses are checked against `exif` and `length`.\n\n\u2705 **All pointer and offset accesses are bounded.**\n\n#### D. **Stack-based IFD traversal**\n- The function uses `directory_stack[MaxDirectoryStack]` (16 entries) to traverse nested IFDs.\n- It checks `level < (MaxDirectoryStack - 2)` before pushing new entries.\n- It also checks for duplicate IFD entries: `for (i=0; i < level; i++) if (directory_stack[i].directory == (exif+tag_offset1)) break;` \u2014 prevents infinite recursion or stack overflow.\n\n\u2705 **Stack depth is limited and checked. No stack overflow.**\n\n#### E. **Use of `ReadPropertySignedLong` and `ReadPropertyUnsignedShort`**\n- These functions are assumed to be safe wrappers that read from `exif` with bounds checking.\n- The code checks `if (q > (exif+length-12))` before reading \u2014 prevents reading past the buffer.\n- All `ReadProperty*` calls are used with validated offsets.\n\n\u2705 **No out-of-bounds reads.**\n\n#### F. **String handling and `SubstituteString`**\n- `SubstituteString` is used to replace `exif:` with `exif:thumbnail:` \u2014 this is safe if the string is properly null-terminated.\n- `key` is allocated via `AcquireString` and freed via `DestroyString`.\n\n\u2705 **No string injection or format string vulnerability.**\n\n#### G. **No use of unsafe functions**\n- No `strcpy`, `sprintf`, `gets`, `strcat`, etc.\n- All string formatting uses `FormatLocaleString` with length limits.\n- No direct user input into format strings.\n\n\u2705 **No format string vulnerability.**\n\n#### H. **Potential for integer overflow in `number_bytes`**\n- `number_bytes = (size_t) components * tag_bytes[format];`\n- `components` is read from `ReadPropertySignedLong`, so it can be negative.\n- But the code checks: `if (components < 0) break;` \u2014 so negative values are rejected early.\n- Also: `if (number_bytes < components)` \u2014 this checks for overflow (if multiplication wraps around).\n\n\u2705 **Integer overflow is prevented.**\n\n---\n\n### Step 3: Final assessment\nThe code:\n- Performs strict bounds checking on all input and offsets.\n- Uses safe memory allocation with overflow checks.\n- Prevents buffer overflows via length limits.\n- Limits stack depth and prevents infinite recursion.\n- Avoids unsafe string operations.\n- Validates all EXIF structure integrity.\n\nThere are **no exploitable vulnerabilities** in the code as presented.\n\n---\n\n(2) NO: No security vulnerability."}
{"idx": 194994, "project": "tensorflow", "commit_id": "c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c79ccba517dbb1a0ccb9b01ee3bd2a63748b60dd", "commit_message": "Fix memory leak when a graph node is invalid.\n\nIf a graph node is invalid but a kernel is created then we set the kernel back to `nullptr` but we forget to delete it. Hence, we get a memory leak.\n\nPiperOrigin-RevId: 408968108\nChange-Id: I1d8a9d0d8988ed5e08be8b9f2004ce1b4cd11b7c", "ground_truth": 1, "cwe": ["CWE-401"], "cve": "CVE-2022-23578", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. If a graph node is invalid, TensorFlow can leak memory in the implementation of `ImmutableExecutorState::Initialize`. Here, we set `item->kernel` to `nullptr` but it is a simple `OpKernel*` pointer so the memory that was previously allocated to it would leak. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine whether there is a security vulnerability.\n\n1. **Code Context and Purpose**:\n   - The function `ImmutableExecutorState::Initialize` is part of a TensorFlow-like execution engine.\n   - It initializes internal data structures (`frame_info_`, `pending_ids_`, `root_nodes_`, etc.) based on a `Graph` object.\n   - It processes each node in the graph, sets up kernel creation, frame information, control flow tracking, and pending counts.\n   - It uses `TF_RETURN_IF_ERROR` macros, which are TensorFlow's error propagation mechanism (similar to `return` on error).\n\n2. **Input Validation and Error Handling**:\n   - The function takes a `const Graph& graph` as input. The graph is assumed to be provided by the system or user.\n   - The function uses `TF_RETURN_IF_ERROR` to propagate errors from `gview_.Initialize(&graph)` and `BuildControlFlowInfo(...)`, which are critical for safety.\n   - It checks for invalid node types (e.g., `IsSink`, `IsSwitch`, etc.) and handles them appropriately.\n   - It uses `GetNodeAttr` to extract attributes like `\"send_device\"`, `\"recv_device\"`, `\"frame_name\"`, `\"parallel_iterations\"`, etc., and checks for errors via `TF_RETURN_IF_ERROR`.\n\n3. **Memory and Buffer Safety**:\n   - The code uses `absl::make_unique<std::vector<const NodeItem*>>()` to safely allocate vectors.\n   - `pending_ids_.resize(gview_.num_nodes())` ensures the vector is sized to match the number of nodes.\n   - `frame_info_[frame_name].get()` and `EnsureFrameInfo(...)` are used to manage frame information safely via `std::unique_ptr`.\n   - `const_tensors_.emplace_back(*const_tensor)` performs a shallow copy of a tensor \u2014 this is safe as long as the original tensor is valid and not freed prematurely.\n   - `std::unique_ptr<bool[]> outputs_required` is used for output tracking \u2014 no raw `new`/`delete` used, so no memory leak risk.\n   - `pending_ids_[id] = ...` uses `id` as an index into a vector of size `gview_.num_nodes()`, which is validated via `resize` \u2014 so no out-of-bounds access.\n\n4. **Control Flow and Logic**:\n   - The code carefully tracks control flow nodes (`Enter`, `Exit`, `Switch`, `Merge`, `NextIteration`) and sets flags accordingly.\n   - It checks for inconsistent `parallel_iterations` values and logs a warning \u2014 this is a correctness issue, not a security vulnerability.\n   - The `GetMaxPendingCounts` function is called safely, and the result is used to create a `PendingCountsLayout` handle \u2014 no known unsafe operations.\n\n5. **Potential Security Concerns**:\n   - **No user input directly processed**: The graph is not user-provided in a raw form; it's a structured internal representation. The code does not parse strings from untrusted sources directly.\n   - **No string formatting or injection**: There is no use of `sprintf`, `strcpy`, `strcat`, or similar unsafe functions. No dynamic SQL, shell commands, or template injection.\n   - **No buffer overflows**: All indexing is bounded by `gview_.num_nodes()` and `n->id()`, which are derived from the graph structure. The `id` is used as an index into `pending_ids_` and `frame_info_`, both of which are properly sized.\n   - **No unsafe pointer arithmetic**: All pointers are managed via `gview_.node(id)` and `EnsureFrameInfo(...)`, which are safe abstractions.\n   - **No use of unsafe functions**: No `gets`, `strcpy`, `sprintf`, `system`, `exec`, etc.\n\n6. **Error Handling and Robustness**:\n   - The code uses `TF_RETURN_IF_ERROR` extensively, which ensures that any failure in attribute retrieval or initialization is caught early.\n   - The use of `CHECK(item->kernel)` ensures that kernel creation is successful before proceeding.\n   - The `InitializePending` call is made only after all `pending_ids_` are initialized \u2014 correct ordering.\n\n7. **Conclusion**:\n   - The code is well-structured, uses safe C++ practices (smart pointers, RAII, bounds-checked indexing), and includes comprehensive error handling.\n   - There are no signs of buffer overflows, use-after-free, null pointer dereferences, or injection vulnerabilities.\n   - The only potential issue is a warning about inconsistent `parallel_iterations`, but this is a logic/consistency issue, not a security vulnerability.\n\n(2) NO: No security vulnerability."}
{"idx": 195017, "project": "gpac", "commit_id": "ad18ece95fa064efc0995c4ab2c985f77fb166ec", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/ad18ece95fa064efc0995c4ab2c985f77fb166ec", "commit_message": "fixed #1904", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-40576", "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the gf_isom_get_payt_count function in hint_track.c, which allows attackers to cause a denial of service.", "vuln": 1, "reasoning": "Let's think step-by-step.\n\n1. The function `GetHintFormat` takes a pointer to a `GF_TrackBox` structure (`trak`) and attempts to retrieve the format (subType) of a hint media header box (`GF_HintMediaHeaderBox`).\n\n2. It first casts `trak->Media->information->InfoHeader` to `GF_HintMediaHeaderBox *` and assigns it to `hmhd`.\n\n3. It checks if `hmhd->type` is not `GF_ISOM_BOX_TYPE_HMHD`. If not, it returns 0. This is a valid check to ensure the box is of the expected type.\n\n4. Then it checks if `hmhd` is NULL or if `hmhd->subType` is NULL. If either condition is true, it proceeds to a fallback mechanism:\n   - It retrieves the first box from `trak->Media->information->sampleTable->SampleDescription->child_boxes` using `gf_list_get`.\n   - If `hmhd` is NULL, it returns the type of the first box (if it exists), otherwise 0.\n   - If `a` (the first box) exists, it assigns `a->type` to `hmhd->subType`.\n\n5. The critical issue arises here: the code modifies `hmhd->subType` by assigning `a->type` to it, but **`hmhd` might be NULL** at this point. However, the code checks `if (!hmhd)` before attempting to access `hmhd->subType`, so the assignment `hmhd->subType = a->type;` is only executed if `hmhd` is not NULL.\n\n6. But wait: the condition is `if (!hmhd || !hmhd->subType)`. So if `hmhd` is NULL, the code enters the block and checks `if (!hmhd)` \u2014 which is true \u2014 and then returns `a ? a->type : 0`. It does **not** attempt to assign to `hmhd->subType` in this case.\n\n7. However, if `hmhd` is not NULL but `hmhd->subType` is NULL, then the code proceeds to:\n   - Get the first box `a`.\n   - If `a` exists, it assigns `a->type` to `hmhd->subType`.\n\n8. The problem: **`hmhd` is a pointer to a structure that may have been allocated, but its `subType` field is being modified without ensuring that the structure is valid or that the memory is writable.** However, the main concern is not memory corruption per se, but rather **a potential use-after-free or null pointer dereference**.\n\n9. But more importantly: **the function returns `hmhd->subType` at the end, but if `hmhd` was NULL, the function returns `a ? a->type : 0` \u2014 which is safe.**\n\n10. However, there is a **critical flaw**: the function does not validate that `hmhd` is a valid `GF_HintMediaHeaderBox` structure before accessing `hmhd->subType`. But the initial cast is done without checking if the `InfoHeader` is actually a `GF_HintMediaHeaderBox`. This is a **type confusion vulnerability**.\n\n11. Specifically: `trak->Media->information->InfoHeader` is cast to `GF_HintMediaHeaderBox *` without checking if it's actually of that type. The function only checks `hmhd->type` later. But if the `InfoHeader` is not a `GF_HintMediaHeaderBox`, then the cast is invalid, and accessing `hmhd->type` or `hmhd->subType` leads to **undefined behavior** (reading from invalid memory).\n\n12. This is a **classic type confusion vulnerability**: the code assumes the structure is of a certain type based on a cast, but does not verify it before accessing members. If an attacker controls the input (e.g., a malformed MP4 file), they could make `InfoHeader` point to a different box type, leading to memory corruption or arbitrary code execution.\n\n13. The check `if (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)` is too late \u2014 it's after the cast and access. The cast itself is unsafe.\n\nTherefore, this code has a **security vulnerability due to unsafe type casting and lack of validation before accessing structure members**.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195019, "project": "tensorflow", "commit_id": "6b5adc0877de832b2a7c189532dbbbc64622eeb6", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/6b5adc0877de832b2a7c189532dbbbc64622eeb6", "commit_message": "Prevent `CHECK`-fail when building reference tensor.\n\nThe tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.\n\nInstead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.\n\nPiperOrigin-RevId: 409662503\nChange-Id: I5892f831fde7f276cd7ab34519cf6b8061c71a59", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2022-23588", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that Grappler optimizer would attempt to build a tensor using a reference `dtype`. This would result in a crash due to a `CHECK`-fail in the `Tensor` constructor as reference types are not allowed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `ConstantFolding::EvaluateOneFoldable` is part of a tensor computation framework (likely TensorFlow), responsible for evaluating constant expressions at compile time (constant folding).\n\n2) The function processes input nodes, validates that they are constant, extracts their tensor values from the `attr().at(\"value\")` field, and creates Tensor objects from `TensorProto` data.\n\n3) Key operations:\n   - It parses input nodes and checks if they are constant using `IsReallyConstant()`.\n   - It validates that the \"value\" attribute exists and that the dtype is not DT_INVALID.\n   - It creates new `Tensor` objects using `new Tensor(...)` and populates them via `FromProto()`.\n   - It uses `delete` to clean up tensors in a cleanup lambda.\n\n4) Memory management:\n   - Tensors are allocated with `new` and stored in `TensorVector inputs` and `output_tensors`.\n   - A cleanup lambda is set up with `gtl::MakeCleanup` to delete all tensors at the end.\n   - The cleanup is guaranteed to run due to RAII (scope exit), so no memory leaks are expected.\n\n5) Input validation:\n   - The function checks for null pointers and invalid types.\n   - It validates that inputs are constant and have valid tensor values.\n   - It checks for `DT_INVALID` dtype, which is a good defensive check.\n\n6) Potential issues:\n   - The function uses `new` and `delete` directly, but the cleanup lambda ensures proper deallocation.\n   - `FromProto()` is used to reconstruct tensors from `TensorProto`. This is a standard and safe operation in TensorFlow, provided the proto is well-formed.\n   - There is no user-controlled input directly passed to `FromProto()` in a way that could lead to arbitrary code execution \u2014 the input comes from the graph definition, which is trusted in this context (constant folding is a compile-time optimization).\n   - The function does not perform any unsafe operations like buffer overflows, format string vulnerabilities, or direct memory manipulation.\n\n7) Security implications:\n   - The function operates on a trusted graph representation (NodeDefs) and does not accept untrusted input from external sources.\n   - The `TensorProto` is validated before being used.\n   - No dynamic code execution, no unsafe string formatting, no direct memory copying without bounds checks.\n\n8) Conclusion:\n   - The code follows safe memory management practices with RAII.\n   - Input validation is thorough.\n   - No known security vulnerabilities such as buffer overflows, use-after-free, or injection attacks are present.\n   - The function is part of a well-structured, secure system (TensorFlow) and follows best practices.\n\n(2) NO: No security vulnerability."}
{"idx": 195023, "project": "tensorflow", "commit_id": "a68f68061e263a88321c104a6c911fe5598050a8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/a68f68061e263a88321c104a6c911fe5598050a8", "commit_message": "Replace faulty overflow check with a builder for `TensorShape`.\n\nPrevents an integer overflow that was not caught before.\n\nPiperOrigin-RevId: 415381595\nChange-Id: I76585ddedc912bd9f4a390aeafa8e2ced1a28863", "ground_truth": 1, "cwe": ["CWE-190"], "cve": "CVE-2022-23568", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AddManySparseToTensorsMap` is vulnerable to an integer overflow which results in a `CHECK`-fail when building new `TensorShape` objects (so, an assert failure based denial of service). We are missing some validation on the shapes of the input tensors as well as directly constructing a large `TensorShape` with user-provided dimensions. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Bounds Checking**:\n   - The code uses `OP_REQUIRES_OK` and `OP_REQUIRES` to validate inputs:\n     - `input_indices`, `input_values`, and `input_shape` are checked for validity.\n     - It verifies that `input_indices` is a matrix, `input_values` and `input_shape` are vectors.\n     - It checks that the number of values matches the first dimension of indices, and that the number of dimensions matches the second dimension of indices.\n     - It ensures the rank of the input shape is greater than 1.\n   - These checks are robust and prevent malformed or unexpected input from causing undefined behavior.\n\n2. **Overflow Prevention**:\n   - The code computes `new_num_elements` by multiplying dimensions of the shape using `MultiplyWithoutOverflow`, which is a safe function designed to detect overflow.\n   - If overflow occurs, `overflow_ocurred` is set to true, and the function returns an error via `OP_REQUIRES(context, !overflow_ocurred, ...)`.\n   - This prevents integer overflow that could lead to buffer overflows or memory corruption.\n\n3. **Memory and Buffer Safety**:\n   - All tensor allocations (e.g., `output_indices`, `output_values`, `empty_indices`, `empty_values`) are done with explicit shapes derived from input data, but the sizes are validated:\n     - `num_entries` comes from `values.size()`, which is a valid size from the input.\n     - The loop bounds are based on `num_entries`, which is guaranteed to be non-negative and derived from input.\n   - The `for` loop over `num_entries` is safe because it uses `i < num_entries`, and `num_entries` is a valid size from a tensor.\n\n4. **Index and Range Safety**:\n   - The code checks that `b > -1 && b < N` when processing batch entries, where `N = input_shape_vec(0)`. This ensures that the batch index is within valid bounds.\n   - The `visited` set is used to track which batch indices were processed, and any missing ones are filled with empty sparse tensors.\n   - The `for (int64_t b = 0; b < N; ++b)` loop is safe because `N` is derived from `input_shape_vec(0)`, which was validated earlier.\n\n5. **Use of Safe APIs**:\n   - The code uses `SparseTensor::Create`, `map->AddSparseTensor`, and other TensorFlow kernel utilities that are designed to be safe and validate their inputs.\n   - The `std::iota` and `std::unordered_set` are used correctly and safely.\n\n6. **No Direct User Input to Unsafe Functions**:\n   - There are no calls to `strcpy`, `strcat`, `sprintf`, or any other unsafe string or memory manipulation functions.\n   - No dynamic memory allocation without bounds checking.\n   - No use of raw pointers or manual memory management that could lead to buffer overflows or use-after-free.\n\n7. **No Injection or Code Execution Risks**:\n   - The code does not construct strings from user input that are then executed (e.g., no `eval`, `exec`, or `innerHTML`-like behavior).\n   - It does not interpret user data as code or script.\n\n8. **Error Handling and Defense in Depth**:\n   - The code uses `OP_REQUIRES` and `OP_REQUIRES_OK` extensively to fail fast on invalid inputs.\n   - It validates every assumption about tensor shapes and sizes before using them.\n\nConclusion: The code performs comprehensive input validation, uses safe arithmetic (with overflow detection), avoids unsafe memory operations, and ensures all indices and sizes are within bounds. There are no known security vulnerabilities such as buffer overflows, integer overflows, use-after-free, or injection attacks.\n\n(2) NO: No security vulnerability."}
{"idx": 195028, "project": "tensorflow", "commit_id": "ab51e5b813573dc9f51efa335aebcf2994125ee9", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/ab51e5b813573dc9f51efa335aebcf2994125ee9", "commit_message": "Prevent memory leak in decoding PNG images.\n\nPiperOrigin-RevId: 409300653\nChange-Id: I6182124c545989cef80cefd439b659095920763b", "ground_truth": 1, "cwe": ["CWE-401"], "cve": "CVE-2022-23585", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When decoding PNG images TensorFlow can produce a memory leak if the image is invalid. After calling `png::CommonInitDecode(..., &decode)`, the `decode` value contains allocated buffers which can only be freed by calling `png::CommonFreeDecode(&decode)`. However, several error case in the function implementation invoke the `OP_REQUIRES` macro which immediately terminates the execution of the function, without allowing for the memory free to occur. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine if there is a security vulnerability.\n\n1. **Input Validation and Initialization**:\n   - The function `DecodePngV2` takes a `StringPiece input` representing the PNG data.\n   - It initializes a `png::DecodeContext` using `png::CommonInitDecode`, which performs initial parsing of the PNG file. This function is expected to validate the PNG header and basic structure.\n   - `OP_REQUIRES` ensures that initialization succeeds; otherwise, it returns an error. This prevents processing malformed or malicious PNGs at an early stage.\n\n2. **Size Validation**:\n   - The code extracts `width` and `height` from the decode context and casts them to `int`.\n   - It performs several checks:\n     - Ensures `width` and `height` are positive and do not overflow `int` (via comparison with `1LL << 27`).\n     - Ensures `total_size = width * height` does not exceed `1LL << 29`, which is 536,870,912 pixels.\n   - These checks are critical to prevent integer overflow and excessive memory allocation.\n   - The use of `int64_t` for intermediate calculations prevents overflow during multiplication.\n   - The thresholds (27 bits for width/height, 29 bits for total size) are conservative and prevent allocation of unreasonably large buffers.\n\n3. **Memory Allocation**:\n   - The output tensor is allocated using `context->allocate_output` with a shape based on `height`, `width`, and `channels`.\n   - The allocation size is bounded by the prior checks, so the memory requested is within safe limits.\n   - For `DT_FLOAT`, a temporary `uint16[]` buffer is allocated, but its size is also bounded by `height * width * channels`, which is already validated.\n\n4. **Data Processing**:\n   - For `DT_UINT8` and `DT_UINT16`, `png::CommonFinishDecode` is used to decode the image data into the output tensor.\n   - For `DT_FLOAT`, the image is first decoded into a `uint16` buffer (lossless), then converted to `float` using Eigen's device and casting.\n   - The conversion uses a scale factor (`1. / std::numeric_limits<uint16>::max()`), which is safe and does not cause overflow.\n\n5. **Security Checks for Op Type**:\n   - The code checks `op_type_` and returns an error if the operation is not appropriate (e.g., trying to decode PNG with `DecodeBmp` or `DecodeAndCropJpeg`).\n   - This prevents misuse of the function and ensures correct behavior.\n\n6. **No Buffer Overflows or Unsafe Operations**:\n   - All memory accesses are bounded by validated dimensions.\n   - No use of unsafe functions like `strcpy`, `memcpy` without size checks, or direct pointer arithmetic without bounds.\n   - The use of `reinterpret_cast` is safe because the output tensor's data is guaranteed to be contiguous and of the correct size.\n\n7. **No Known Vulnerabilities**:\n   - The code performs comprehensive input validation, size checks, and bounds checking.\n   - It avoids integer overflow via `int64_t` intermediate calculations.\n   - Memory allocation is only performed after size validation.\n   - The use of `unique_ptr` for temporary buffers ensures no memory leaks.\n\nConclusion: The code includes robust safeguards against buffer overflows, integer overflows, and excessive memory allocation. All critical operations are protected by validation checks.\n\n(2) NO: No security vulnerability."}
{"idx": 195029, "project": "tensorflow", "commit_id": "c99d98cd189839dcf51aee94e7437b54b31f8abd", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/c99d98cd189839dcf51aee94e7437b54b31f8abd", "commit_message": "Handle invalid inputs instead of crashing.\n\nPiperOrigin-RevId: 409549744\nChange-Id: I7f5935b34b53f7e426a5462fcc027bdbf5dcda24", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2022-23592", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. TensorFlow's type inference can cause a heap out of bounds read as the bounds checking is done in a `DCHECK` (which is a no-op during production). An attacker can control the `input_idx` variable such that `ix` would be larger than the number of values in `node_t.args`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is part of a type inference system in a computational graph framework (likely TensorFlow or similar). It performs forward type inference on a node by collecting input types from connected edges.\n\n2) The function first checks if a forward type function (fwd_type_fn) exists. If not, it returns early - this is safe.\n\n3) It initializes vectors to track input nodes and their output indices. It iterates through incoming edges, skipping control edges, and populates input_nodes and input_idx based on edge information.\n\n4) The code includes DASSERTs to validate that dst_input() is within bounds of input_nodes.size(), which prevents out-of-bounds access.\n\n5) It checks if any input node is null, and if so, clears type info and returns. This prevents processing with incomplete inputs.\n\n6) It uses a static FullTypeDef* no_type = new FullTypeDef() as a placeholder for unknown types. This is a static variable, but it's only used as a reference and not modified.\n\n7) The input_types vector is populated by referencing the experimental_type of input nodes. It checks that the output index is valid (using DASSERT) and extracts the appropriate type argument.\n\n8) The type inference function is called with the input types, and the result is used to update the node's experimental_type if it's not unset.\n\n9) The code uses ValueOrDie() which will crash if the inference returns an error, but this is likely intentional for debugging/development.\n\n10) The code properly validates all inputs, uses bounds checking, and handles null/invalid inputs gracefully. There are no buffer overflows, use-after-free issues, or memory corruption risks.\n\n11) The static no_type object is created once and reused, but since it's only used as a reference and not modified, and the code doesn't rely on its lifetime beyond the function scope, this is safe.\n\n12) There are no obvious security vulnerabilities such as buffer overflows, use-after-free, null pointer dereferences, or improper input validation.\n\n(2) NO: No security vulnerability."}
{"idx": 195038, "project": "mruby", "commit_id": "27d1e0132a0804581dca28df042e7047fd27eaa8", "project_url": "https://github.com/mruby/mruby", "commit_url": "https://github.com/mruby/mruby/commit/27d1e0132a0804581dca28df042e7047fd27eaa8", "commit_message": "array.c: fix `mrb_ary_shift_m` initialization bug.\n\nThe `ARY_PTR` and `ARY_LEN` may be modified in `mrb_get_args`.", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-4188", "cve_desc": "mruby is vulnerable to NULL Pointer Dereference", "vuln": 0, "reasoning": "Let's analyze the provided C code step by step:\n\n1. The function `mrb_ary_shift_m` is a Ruby MRI (Matz's Ruby Interpreter) extension function that shifts elements from the beginning of an array. It takes a Ruby array (`self`) and an optional integer argument `n` (number of elements to shift).\n\n2. The function first retrieves the array structure (`a`) and its length (`len`). It then checks for optional argument `n` using `mrb_get_args`. If no argument is provided, it calls `mrb_ary_shift` (which shifts one element), otherwise proceeds with `n`.\n\n3. `ary_modify_check(mrb, a)` ensures the array is not frozen before modification, which is a standard safety check.\n\n4. The function checks for edge cases:\n   - If the array is empty (`len == 0`) or `n == 0`, it returns a new empty array.\n   - If `n < 0`, it raises an `ArgumentError` \u2014 this prevents negative shifts.\n   - If `n > len`, it sets `n = len` \u2014 this ensures we don't try to shift more elements than exist.\n\n5. It creates a new array `val` containing the first `n` elements using `mrb_ary_new_from_values`, which safely copies `n` elements from the start of the array.\n\n6. The function then handles two cases:\n   - If the array is shared (`ARY_SHARED_P(a)`), it simply adjusts the pointer and length by skipping `n` elements. This is safe because shared arrays are immutable in the sense that they are not modified in place \u2014 the pointer adjustment is valid and safe.\n   - If the array is not shared:\n     - If the array is large enough (`len > ARY_SHIFT_SHARED_MIN`), it converts it to a shared array and jumps to `L_SHIFT`, which is safe.\n     - Otherwise, it performs a manual shift by copying elements from `ptr + n` back to `ptr`, effectively removing the first `n` elements.\n\n7. The manual shift loop:\n   ```c\n   while (size--) {\n     *ptr = *(ptr+n);\n     ++ptr;\n   }\n   ```\n   This copies `len - n` elements from the array starting at index `n` to the beginning. This is a standard in-place array shift and is safe as long as `n <= len`, which is already enforced earlier.\n\n8. The function then sets the new length with `ARY_SET_LEN(a, len - n)`.\n\n9. Finally, it returns the `val` array containing the shifted elements.\n\nKey security considerations:\n- Input validation: `n` is checked for negative values and clamped to `len`, preventing out-of-bounds access.\n- Array bounds: All operations are bounded by `len` and `n`, and `n` is validated before any memory access.\n- Memory safety: The `mrb_ary_new_from_values` function safely creates a new array from the first `n` elements.\n- No use of unsafe functions like `strcpy`, `memcpy` without bounds, or direct pointer arithmetic without checks.\n- The manual shift loop is bounded by `size = len - n`, which is non-negative and correctly calculated.\n\nNo buffer overflows, use-after-free, or memory corruption vulnerabilities are present. The code follows safe practices for array manipulation in a garbage-collected environment (MRI Ruby), with proper bounds checking and memory management.\n\n(2) NO: No security vulnerability."}
{"idx": 195039, "project": "tensorflow", "commit_id": "e7f497570abb6b4ae5af4970620cd880e4c0c904", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e7f497570abb6b4ae5af4970620cd880e4c0c904", "commit_message": "Fix segfault on OOM in Conv2D.\n\nPiperOrigin-RevId: 404655317\nChange-Id: I33588dbd3f5d0fef980e3c908bf5515a9ee09ce7", "ground_truth": 1, "cwe": ["CWE-354"], "cve": "CVE-2021-41206", "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions several TensorFlow operations are missing validation for the shapes of the tensor arguments involved in the call. Depending on the API, this can result in undefined behavior and segfault or `CHECK`-fail related crashes but in some scenarios writes and reads from heap populated arrays are also possible. We have discovered these issues internally via tooling while working on improving/testing GPU op determinism. As such, we don't have reproducers and there will be multiple fixes for these issues. These fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code is a C++ template function implementing grouped convolution for a machine learning framework (likely TensorFlow or similar), operating on tensors with CPU device execution via Eigen.\n\n2) The function takes several parameters including input tensor, filter tensor, stride/dilation values, padding configuration, and output tensor. All inputs are validated through the framework's type system and bounds checking.\n\n3) The core operations involve:\n   - Validating data format (only NHWC supported)\n   - Computing group dimensions based on input depth and filter depth\n   - Shuffling input and filter tensors to group as leading dimension\n   - Performing convolution on each group separately in a loop\n   - Shuffling output back to original format\n\n4) Key security considerations:\n   - All tensor dimensions are derived from tensor metadata (dim_size) which is validated by the framework\n   - Array indices are computed from tensor dimensions and group counts, but all bounds are checked by the framework's tensor operations\n   - The code uses Eigen's device-aware operations with proper synchronization via BlockingCounter\n   - No user-controlled data is directly used in array indexing or memory operations without framework-level bounds checking\n   - The shuffle operations use fixed, compile-time known indices (shuffle array with fixed values)\n   - The loop over num_groups is bounded by the computed group count, which itself comes from valid tensor dimensions\n\n5) The code does not perform any:\n   - Direct memory copying without bounds checking\n   - Unchecked array indexing\n   - String manipulation with user input\n   - Dynamic memory allocation without bounds\n   - Use of unsafe functions\n\n6) All tensor operations are performed through the framework's safe tensor interface, which enforces bounds checking and type safety. The Eigen device operations are properly synchronized.\n\n7) The only potential concern would be if the input tensor dimensions were corrupted or maliciously crafted, but this would be a framework-level issue, not a vulnerability in this specific code. The code itself correctly handles the tensor dimensions it receives.\n\n(2) NO: No security vulnerability."}
{"idx": 195040, "project": "tensorflow", "commit_id": "e21af685e1828f7ca65038307df5cc06de4479e8", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/e21af685e1828f7ca65038307df5cc06de4479e8", "commit_message": "Fix Null-pointer dereference in BuildXlaCompilationCache\n\nIf ConfigProto is not used, then use the default settings which is to allow all devices.\n\nPiperOrigin-RevId: 420391800\nChange-Id: I88161ad7042990aef678e77b597a2fb2c8f815be", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2022-23595", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. When building an XLA compilation cache, if default settings are used, TensorFlow triggers a null pointer dereference. In the default scenario, all devices are allowed, so `flr->config_proto` is `nullptr`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's analyze the provided C++ code step by step to determine if there are any security vulnerabilities.\n\n1. **Input Validation and Error Handling**:\n   - The function takes several parameters: `device`, `flr`, `platform_info`, and `cache`. These are all well-defined objects from TensorFlow/XLA infrastructure.\n   - The function checks for the presence of `platform_info.xla_device_metadata()` and handles it appropriately by creating a `XlaCompilationCache` using the client and JIT device type from that metadata.\n   - If no metadata is present, it attempts to get a platform via `se::MultiPlatformManager::PlatformWithId(platform_info.platform_id())`. This is a standard way to retrieve a platform, and the code checks if the result is valid (`if (!platform.ok()) return platform.status();`), which prevents use of invalid or null platforms.\n\n2. **Compiler Retrieval**:\n   - The code attempts to get an XLA compiler for the platform using `xla::Compiler::GetForPlatform(...)`. It checks the status and handles the case where the compiler is not found.\n   - The error handling for `error::NOT_FOUND` is appropriate: it returns a descriptive error message indicating that the compiler is not available, which is a reasonable fallback in cases like unit tests or missing JIT support.\n\n3. **Client Options and Device Configuration**:\n   - `xla::LocalClientOptions` is configured with:\n     - The platform (from `platform.ValueOrDie()`).\n     - Intra-op parallelism threads from the device's CPU worker threads.\n     - Allowed GPU devices parsed from `flr->config_proto()->gpu_options().visible_device_list()`.\n   - The `ParseVisibleDeviceList` function is used to parse the visible GPU list into a set of integers. This is a safe operation as long as the input is well-formed, and the code uses `TF_ASSIGN_OR_RETURN` to propagate errors.\n   - The `set_allowed_devices(gpu_ids)` call restricts the client to only use the allowed devices, which is a security best practice to prevent unauthorized access to hardware.\n\n4. **Client Creation**:\n   - `xla::ClientLibrary::GetOrCreateLocalClient(client_options)` is used to create a local XLA client. The code checks the status of the result and returns an error if creation fails. This prevents use of an invalid or uninitialized client.\n\n5. **Device Registration Check**:\n   - The code checks if there is a JIT device registered for the given `platform_info.device_type().type()` using `XlaOpRegistry::GetCompilationDevice(...)`. If not, it returns an `InvalidArgument` error.\n   - This ensures that only supported and registered device types are used for compilation, preventing misuse of unregistered or unsupported devices.\n\n6. **Cache Initialization**:\n   - The `XlaCompilationCache` is created using:\n     - The `client.ValueOrDie()` (a valid XLA client).\n     - The compilation device name from the registration.\n   - The cache is assigned to `*cache` via a pointer, and the function returns `Status::OK()`.\n\n7. **Memory Management**:\n   - The function uses `new XlaCompilationCache(...)` to allocate memory. While this is a raw `new`, it is consistent with the codebase's pattern (e.g., in TensorFlow/XLA), and the ownership is assumed to be transferred to the caller. There is no indication of a memory leak or use-after-free in this function, as the caller is expected to manage the lifetime of the returned `XlaCompilationCache*`.\n\n8. **Security Considerations**:\n   - No user input is directly processed or concatenated into strings or commands.\n   - All inputs are from trusted internal components (e.g., `platform_info`, `flr`, `device`), which are part of the TensorFlow runtime and validated earlier.\n   - The code does not perform any unsafe operations like buffer overflows, format string vulnerabilities, or unsafe memory access.\n   - The use of `ValueOrDie()` is safe here because the code has already checked the status of the `StatusOr` objects (e.g., `platform`, `compiler_for_platform`, `client`), so `ValueOrDie()` is only called when the status is OK.\n\n9. **Conclusion**:\n   - The code follows secure coding practices: input validation, error propagation, safe configuration, and use of registered/allowed devices.\n   - There are no obvious security vulnerabilities such as buffer overflows, injection attacks, or improper access control.\n\n(2) NO: No security vulnerability."}
{"idx": 195059, "project": "tensorflow", "commit_id": "92dba16749fae36c246bec3f9ba474d9ddeb7662", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662", "commit_message": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.\n\nPiperOrigin-RevId: 409187354\nChange-Id: I369c249cca32e6c56ec193f0ebbf2f2768fc7d43", "ground_truth": 1, "cwe": ["CWE-617"], "cve": "CVE-2022-23579", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `SafeToRemoveIdentity` determines whether an Identity node (or IdentityN node) can be safely removed during graph optimization in a computational graph (likely TensorFlow or similar).\n\n2) The function performs several checks:\n   - First, it returns true if the node is not an Identity or IdentityN node (meaning non-Identity nodes are always considered safe to remove).\n   - It checks if the node is in `nodes_to_preserve_` \u2014 if so, it returns false (cannot remove).\n   - If `fetch_nodes_known_` is false, it returns false (conservative behavior: output values may be needed).\n   - It checks if the node has no inputs \u2014 if so, it returns false (invalid node).\n   - It retrieves the input node and checks if it's a Variable or Recv node \u2014 if so, returns false (cannot remove Identity that feeds into these).\n   - It iterates over consumers of the node:\n     - If the node has more than one input and a consumer is a Retval or Merge, it returns false.\n     - If the input node is a Switch, it checks if the Identity node is a control dependency of the consumer \u2014 if so, returns false.\n\n3) The function uses `CHECK(input != nullptr)` to ensure the input node exists, which is a defensive programming practice.\n\n4) All checks are focused on graph semantics and correctness, not on input validation, memory safety, or data integrity in the context of untrusted input.\n\n5) There is no use of unsafe string operations, buffer overflows, format strings, or direct user input handling.\n\n6) The function operates on a well-defined internal graph representation, and all operations are on known, validated nodes.\n\n7) The logic is about graph optimization safety, not about handling untrusted data or exposing system-level vulnerabilities.\n\n8) No evidence of buffer overflows, use-after-free, null pointer dereferences (except for the CHECK which is a debug assertion), or injection attacks.\n\n9) The function is part of a static analysis or optimization pass, and its behavior is deterministic and safe within the system's internal constraints.\n\nConclusion: The code is well-structured, uses defensive checks, and does not exhibit any known security vulnerabilities.\n\n(2) NO: No security vulnerability."}
{"idx": 195063, "project": "gpac", "commit_id": "5f2c2a16d30229b6241f02fa28e3d6b810d64858", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/5f2c2a16d30229b6241f02fa28e3d6b810d64858", "commit_message": "fixed #1905", "ground_truth": 1, "cwe": ["CWE-476"], "cve": "CVE-2021-40575", "cve_desc": "The binary MP4Box in Gpac 1.0.1 has a null pointer dereference vulnerability in the mpgviddmx_process function in reframe_mpgvid.c, which allows attackers to cause a denial of service. This vulnerability is possibly due to an incomplete fix for CVE-2021-40566.", "vuln": 0, "reasoning": "Let's analyze the provided code step by step to determine whether there is a security vulnerability.\n\n---\n\n### Step 1: Understand the context\nThe function `mpgviddmx_process` is part of a media filter (likely in GPAC, a multimedia framework) that processes MPEG video data (MPEG-1/2 or H.263). It handles packetized video streams, parses start codes, reassembles fragmented headers, and dispatches parsed video frames to output.\n\nKey components:\n- Input packet (`pck`) from an input PID (`ctx->ipid`)\n- Output packet (`dst_pck`) to an output PID (`ctx->opid`)\n- Buffer management using `ctx->hdr_store` to accumulate partial headers\n- Use of `gf_bs_new`, `gf_bs_reassign_buffer`, `gf_m4v_parser_*` for bitstream parsing\n- Handling of fragmented data, byte offsets, timestamps, and frame boundaries\n\n---\n\n### Step 2: Identify potential vulnerabilities\n\n#### A. Buffer Overflows / Memory Corruption\n- The code uses `memcpy` and `gf_realloc` with sizes derived from `pck_size`, `ctx->hdr_store_size`, and `remain`.\n- `ctx->hdr_store` is dynamically allocated via `gf_realloc` based on `ctx->hdr_store_alloc`.\n- The allocation logic:\n  ```c\n  if (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size) {\n      ctx->hdr_store_alloc = ctx->hdr_store_size + pck_size;\n      ctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n  }\n  ```\n  This is **correct** \u2014 it ensures the buffer is large enough before copying.\n\n- `memcpy(ctx->hdr_store + ctx->hdr_store_size, data, sizeof(char)*pck_size);` \u2014 here, `pck_size` is from `gf_filter_pck_get_data`, which is trusted input from the filter framework. The size is checked against the buffer capacity, so no overflow occurs.\n\n- Later, when copying into `ctx->hdr_store`, the code uses `ctx->bytes_in_header` and `current` values, but these are derived from `remain` and `pck_size`, which are bounded by the input packet size.\n\n- **No buffer overflow** is evident here.\n\n#### B. Use of `memcpy` with untrusted input\n- The input data (`data`) comes from `gf_filter_pck_get_data(pck, &pck_size)` \u2014 this is part of a media processing pipeline and is not directly user-controlled in a traditional sense, but could be from a malicious source.\n- However, the code **does not copy unbounded data** into fixed-size buffers without bounds checking.\n- All `memcpy` calls are bounded by `pck_size`, `remain`, or `ctx->hdr_store_size`, which are validated or updated safely.\n\n#### C. Integer Overflows / Underflows\n- The code uses `u32`, `s32`, `u64`, etc., and performs arithmetic like:\n  ```c\n  ctx->hdr_store_size += pck_size;\n  ```\n  But `pck_size` is from `gf_filter_pck_get_data`, which returns a size that is guaranteed to be non-negative and within the packet bounds.\n\n- `remain -= current;` \u2014 `current` is from `mpgviddmx_next_start_code`, which returns a non-negative value (or -1). The code checks `current >= 0` with `assert`, so no underflow occurs.\n\n- `size -= 3;` \u2014 only if `size >= 3`, as asserted.\n\n- No integer overflows are evident.\n\n#### D. Use of `assert` for bounds checking\n- The code uses `assert(remain >= current);` and similar checks.\n- While `assert` is not a runtime safety mechanism (it can be disabled), the **logic is sound** and the conditions are **redundant with prior checks** (e.g., `current < remain` is checked earlier).\n- However, the use of `assert` in this context is **not a vulnerability** \u2014 it's a debugging aid, and the actual logic prevents invalid access.\n\n#### E. Memory leaks or resource management\n- `gf_filter_pck_unref(ctx->src_pck)` is called before reassigning.\n- `gf_filter_pck_ref_props(&ctx->src_pck)` is used correctly.\n- `gf_filter_pid_drop_packet(ctx->ipid)` is called at the end \u2014 this is correct.\n- No obvious memory leaks.\n\n#### F. Use of `gf_bs_reassign_buffer` and `gf_m4v_parser_*`\n- These are part of a well-designed bitstream parser framework.\n- The parser is initialized with `gf_bs_new` and reinitialized with `gf_bs_reassign_buffer` \u2014 this is safe as long as the buffer and size are valid.\n- The parser functions (`gf_m4v_parse_config`, `gf_m4v_parse_frame`) are internal and assume valid input \u2014 but the code ensures that the buffer is properly sized and aligned before calling them.\n\n#### G. Potential for infinite loop or denial of service?\n- The `while (remain)` loop processes data incrementally.\n- Each iteration reduces `remain` by at least 4 (start code) or more.\n- The loop terminates when `remain` becomes 0 or when a packet is fully processed.\n- No infinite loop is possible.\n\n#### H. Input validation\n- The code checks for `!pck` and `gf_filter_pid_is_eos` \u2014 correct.\n- It validates `ctx->bs` and `ctx->vparser` before use.\n- It handles partial headers and reassembles them safely.\n\n---\n\n### Step 3: Conclusion\nAfter a thorough analysis:\n- There are **no buffer overflows**, **integer overflows**, **unbounded memory copies**, or **unsafe pointer arithmetic**.\n- All dynamic memory operations are bounded and validated.\n- The code uses safe practices: bounds checking, proper buffer management, and use of safe APIs.\n- The use of `assert` is not a vulnerability in this context.\n- The logic for handling fragmented video data (e.g., partial headers) is correct and secure.\n\n---\n\n### Final Answer:\n(2) NO: No security vulnerability."}
{"idx": 195069, "project": "gpac", "commit_id": "f1ae01d745200a258cdf62622f71754c37cb6c30", "project_url": "https://github.com/gpac/gpac", "commit_url": "https://github.com/gpac/gpac/commit/f1ae01d745200a258cdf62622f71754c37cb6c30", "commit_message": "fixed #1900", "ground_truth": 1, "cwe": ["CWE-120"], "cve": "CVE-2021-40568", "cve_desc": "A buffer overflow vulnerability exists in Gpac through 1.0.1 via a malformed MP4 file in the svc_parse_slice function in av_parsers.c, which allows attackers to cause a denial of service, even code execution and escalation of privileges.", "vuln": 1, "reasoning": "Let's analyze the code step by step:\n\n1. The function `svc_parse_slice` parses a slice in an AVC (H.264) bitstream and populates the `AVCSliceInfo` structure.\n\n2. The function reads several values from the bitstream using `gf_bs_read_ue_log` (unsigned exponential-Golomb) and `gf_bs_read_int_log` (signed/unsigned integer with specified bit length), which are designed to safely read variable-length encoded data.\n\n3. Input validation is performed:\n   - `si->slice_type > 9` returns -1: This checks that the slice type is within valid range (0\u20139). Since H.264 defines slice types 0\u20139, this is a valid bounds check.\n   - `pps_id > 255` returns -1: This ensures PPS ID is within the valid range (0\u2013255), which is correct since PPS IDs are 8-bit values.\n   - `si->pps->slice_group_count == 0` returns -2: This checks that the PPS has a valid slice group count, preventing use of invalid PPS data.\n   - `si->sps->log2_max_frame_num == 0` returns -2: This ensures the SPS has valid frame number length, which is necessary for correct decoding.\n\n4. The function uses `si->sps->log2_max_frame_num` as the bit length for reading `frame_num`, which is correct and safe because it's derived from the SPS (which is validated earlier).\n\n5. The `field_pic_flag` and `bottom_field_flag` are read conditionally based on `frame_mbs_only_flag`, and the bit length is correctly set to 1, which is safe.\n\n6. `idr_pic_id` is read only for IDR slices, which is correct and safe.\n\n7. The `poc_type` logic correctly handles different picture order count methods, and the `delta_poc` values are read only when appropriate, with proper conditional checks.\n\n8. `redundant_pic_cnt` is read only if `redundant_pic_cnt_present` is set, which is safe.\n\n9. All array accesses are validated:\n   - `si->pps = &avc->pps[pps_id]` is safe because `pps_id` is checked to be \u2264 255, and `avc->pps` is assumed to be an array of size at least 256 (typical for H.264).\n   - `si->sps = &avc->sps[si->pps->sps_id + GF_SVC_SSPS_ID_SHIFT]` \u2014 this is a potential concern. The `sps_id` is read from the PPS, which comes from the bitstream. However, the code does not validate that `sps_id` is within bounds of the `avc->sps` array. If `sps_id` is too large, this could lead to out-of-bounds access.\n\n10. The `GF_SVC_SSPS_ID_SHIFT` is a constant (likely 1 or 2), but the code does not validate that `sps_id + GF_SVC_SSPS_ID_SHIFT` is within the bounds of `avc->sps`. This is a critical vulnerability: an attacker could craft a bitstream with an invalid `sps_id` (e.g., 1000) to cause a buffer overflow or memory corruption when accessing `avc->sps`.\n\n11. Although the `sps` pointer is checked for `log2_max_frame_num == 0`, this check is only performed after the array access, so the out-of-bounds access may already have occurred.\n\nTherefore, the code lacks bounds checking on `sps_id` before using it to index into `avc->sps`, which can lead to a buffer overflow or memory corruption if the bitstream is malicious.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195091, "project": "tensorflow", "commit_id": "35f0fabb4c178253a964d7aabdbb15c6a398b69a", "project_url": "https://github.com/tensorflow/tensorflow", "commit_url": "https://github.com/tensorflow/tensorflow/commit/35f0fabb4c178253a964d7aabdbb15c6a398b69a", "commit_message": "Avoid Segfault for scalar shapes.\n\nCalling tensor::FromElementsOp with an empty vector of elements and no type\ncauses a segfault. We need to let the FromElementsOp know which scalar type it\nshould have.\nAlso add back the DynamicBroadcastInDimOp canonicalization patterns, which\npreviously prevented this bug from happening.\nAdd a regression test that demonstrates the bug.\n\nPiperOrigin-RevId: 417561444\nChange-Id: I6d1d6cfb71aabbad6102422625a00bbe253ac95a", "ground_truth": 1, "cwe": ["CWE-754"], "cve": "CVE-2022-23593", "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The `simplifyBroadcast` function in the MLIR-TFRT infrastructure in TensorFlow is vulnerable to a segfault (hence, denial of service), if called with scalar shapes. If all shapes are scalar, then `maxRank` is 0, so we build an empty `SmallVector`. The fix will be included in TensorFlow 2.8.0. This is the only affected version.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The function `simplifyBroadcast` is part of a compiler infrastructure (likely MLIR) that simplifies tensor broadcast operations by analyzing shape components.\n\n2) The function takes:\n   - `analysis`: A ShapeComponentAnalysis object for symbolic shape analysis\n   - `shapes`: A range of values representing tensor shapes\n   - `loc`: Location information for error reporting\n   - `builder`: An operation builder for creating new IR operations\n\n3) The function performs:\n   - Finding the maximum rank among input shapes\n   - Analyzing each shape's dimensions in reverse order\n   - Checking for dimension compatibility (non-1 dimensions must match)\n   - Building a result shape from compatible dimensions\n   - Creating a new tensor::FromElementsOp to represent the simplified shape\n\n4) Key security considerations:\n   - The function operates on symbolic shape analysis, not user input\n   - All operations are within the compiler's internal IR construction\n   - There are no string operations, memory copies, or external data handling\n   - The function validates shape compatibility and returns early on mismatch\n   - All operations use the provided builder and are type-safe\n   - No untrusted data is directly manipulated or passed to unsafe functions\n\n5) The function is essentially a shape simplification pass that:\n   - Performs static analysis of tensor shapes\n   - Constructs new IR operations safely\n   - Returns early on invalid conditions\n   - Uses proper type checking and bounds validation\n\n6) There are no buffer overflows, use-after-free, null pointer dereferences, or other classic security vulnerabilities. The code is operating within the safe bounds of the compiler's internal data structures and IR construction.\n\n(2) NO: No security vulnerability."}
{"idx": 195095, "project": "e2guardian", "commit_id": "eae46a7e2a57103aadca903c4a24cca94dc502a2", "project_url": "https://github.com/e2guardian/e2guardian", "commit_url": "https://github.com/e2guardian/e2guardian/commit/eae46a7e2a57103aadca903c4a24cca94dc502a2", "commit_message": "Fix bug #707 cert hostnames not being checked\n- only happened when openssl v1.1 is used", "ground_truth": 1, "cwe": ["CWE-295"], "cve": "CVE-2021-44273", "cve_desc": "e2guardian v5.4.x <= v5.4.3r is affected by missing SSL certificate validation in the SSL MITM engine. In standalone mode (i.e., acting as a proxy or a transparent proxy), with SSL MITM enabled, e2guardian, if built with OpenSSL v1.1.x, did not validate hostnames in certificates of the web servers that it connected to, and thus was itself vulnerable to MITM attacks.", "vuln": 1, "reasoning": "Let's analyze the provided code step by step to determine if there are any security vulnerabilities.\n\n1. **SSL Context Creation**:\n   - The code creates an SSL context using `SSL_CTX_new(SSLv23_client_method())` for older OpenSSL versions (< 1.1.0) or `TLS_client_method()` for newer versions. This is appropriate for a client-side SSL/TLS connection.\n   - Using `TLS_client_method()` in modern OpenSSL is secure and recommended.\n\n2. **Error Handling and Resource Management**:\n   - The code checks for `ctx == NULL` after creation and logs an error if it fails. It then cleans up by calling `SSL_CTX_free(ctx)` and setting `ctx = NULL`. This is good practice to prevent memory leaks and use-after-free issues.\n   - Similarly, when `SSL_CTX_set_timeout`, `SSL_CTX_load_verify_locations`, `X509_VERIFY_PARAM_new`, and `SSL_CTX_set1_param` fail, the code properly frees allocated resources (`SSL_CTX_free`, `X509_VERIFY_PARAM_free`) and returns an error code. This prevents resource leaks.\n\n3. **Certificate Verification Setup**:\n   - The code attempts to load certificates from a provided `certificate_path`. If not provided, it falls back to default system certificate paths via `SSL_CTX_set_default_verify_paths()`. This is a secure default behavior.\n   - It uses `X509_VERIFY_PARAM_set_flags(x509_param, X509_V_FLAG_TRUSTED_FIRST)` to prioritize trusted certificates. This is a reasonable security enhancement to avoid potential trust chain issues.\n\n4. **SSL Connection Setup**:\n   - `SSL_new(ctx)` creates a new SSL object.\n   - `SSL_set_options(ssl, SSL_OP_ALL)` is used. This is a known issue: `SSL_OP_ALL` includes many legacy and potentially insecure options (e.g., enabling SSLv3, weak ciphers, etc.). While it may be used for compatibility, it is **not recommended in production** as it can weaken security by enabling outdated or vulnerable protocols and ciphers.\n   - However, note that `SSL_OP_ALL` is often used in older codebases for compatibility but is a **security risk** because it enables insecure features. This is a **known vulnerability** in SSL/TLS configuration.\n\n5. **Hostname Verification**:\n   - `SSL_set_tlsext_host_name(ssl, hostname.c_str())` is used to set the SNI (Server Name Indication) extension. This is good practice and helps prevent certain MITM attacks by ensuring the server is correctly identified.\n\n6. **Blocking Mode**:\n   - The code explicitly comments out non-blocking I/O setup (`BIO_set_nbio`), and uses blocking mode. While this may affect performance, it does not introduce a security vulnerability.\n\n7. **Error Logging and Cleanup**:\n   - All error paths include proper cleanup of `ssl`, `ctx`, and `x509_param`, preventing resource leaks and use-after-free scenarios.\n\n8. **Final State**:\n   - Only after a successful `SSL_connect` is `isssl = true` set. This ensures the socket is not used in SSL mode until fully initialized.\n\n### Critical Security Issue:\n- The use of `SSL_OP_ALL` is problematic. It enables a wide range of options, including insecure ones like SSLv3, weak ciphers, and other deprecated features. This can lead to downgrade attacks or exposure to known vulnerabilities (e.g., POODLE, BEAST).\n- Best practice is to **explicitly disable insecure protocols and ciphers** and only enable secure ones (e.g., TLS 1.2 or 1.3). Using `SSL_OP_ALL` undermines this.\n\n### Conclusion:\nDespite proper error handling and resource management, the use of `SSL_OP_ALL` introduces a significant security vulnerability by enabling potentially insecure SSL/TLS options.\n\n(1) YES: A security vulnerability detected."}
{"idx": 195220, "project": "tmate-ssh-server", "commit_id": "1c020d1f5ca462f5b150b46a027aaa1bbe3c9596", "project_url": "https://github.com/tmate-io/tmate-ssh-server", "commit_url": "https://github.com/tmate-io/tmate-ssh-server/commit/1c020d1f5ca462f5b150b46a027aaa1bbe3c9596", "commit_message": "Harden /tmp/tmate directory\n\nSuggested by Matthias Gerstner", "ground_truth": 1, "cwe": ["CWE-362"], "cve": "CVE-2021-44512", "cve_desc": "World-writable permissions on the /tmp/tmate/sessions directory in tmate-ssh-server 2.3.0 allow a local attacker to compromise the integrity of session handling, or obtain the read-write session ID from a read-only session symlink in this directory.", "vuln": 0, "reasoning": "Let's think step-by-step:\n\n1) The code uses `getopt` to parse command-line arguments, which is a standard and safe way to handle CLI options.\n\n2) For string options ('b', 'h', 'k', 'w'), the code uses `xstrdup(optarg)` to copy the argument value into a dynamically allocated string. This is safe as long as `xstrdup` properly handles memory allocation and null termination, which is typical in well-written code.\n\n3) For numeric options ('p', 'q', 'z'), the code uses `atoi(optarg)` to convert the string to an integer. This is potentially dangerous because `atoi` does not validate the input \u2014 it will silently convert any leading digits and stop at the first non-digit character. For example, if optarg is \"123abc\", `atoi` returns 123, but if it's \"abc123\", it returns 0. This could allow an attacker to pass malformed input that might lead to unexpected behavior, especially if the value is used in a context where a valid port number is expected (e.g., 0 to 65535). However, `atoi` is not inherently a buffer overflow vulnerability, but it can lead to logic errors or unexpected behavior.\n\n4) The code checks for `tmate_settings->tmate_host` being null and defaults to `get_full_hostname()` \u2014 this is a reasonable fallback.\n\n5) The code creates directories using `mkdir` with specific permissions (0701, 0703, 0700), and checks for `EEXIST` to avoid errors when the directory already exists. This is safe.\n\n6) The `chmod` calls are used to set appropriate permissions on the directories. The permissions are restrictive (e.g., 0701 for the root dir, 0700 for jail), which is good for security.\n\n7) The `tmate_ssh_server_main` function is called with the parsed settings. The only potential risk would be if the `bind_addr` or `ssh_port` values are used in a way that could lead to binding to unexpected interfaces or ports, but the code does not show any direct use of `bind_addr` in a way that could cause a buffer overflow.\n\n8) The `xstrdup` function is used for string arguments \u2014 assuming it's a safe wrapper around `strdup`, this is safe.\n\n9) The `cmdline` and `cmdline_end` are set to `*argv` and `*envp`, but these are not used in a way that suggests they are being processed or passed to unsafe functions.\n\n10) The main concern is the use of `atoi` for port numbers. While `atoi` is not a buffer overflow vulnerability per se, it can lead to incorrect port values (e.g., 0 or very large numbers) if the input is malformed. However, this is not a direct security vulnerability like buffer overflow or injection, but rather a potential logic flaw.\n\n11) There is no evidence of unsafe string copying (e.g., `strcpy`, `strcat`), no use of `sprintf`, no direct use of user input in system calls without validation, and no use of `exec` with untrusted input.\n\n12) The code does not appear to have any obvious buffer overflows, format string vulnerabilities, or injection flaws.\n\nConclusion: While the use of `atoi` is not ideal (prefer `strtol` with bounds checking), it does not constitute a direct security vulnerability in this context. The code is well-structured, uses safe functions, and applies proper input validation where needed.\n\n(2) NO: No security vulnerability."}
{"idx": 195230, "project": "pjproject", "commit_id": "f74c1fc22b760d2a24369aa72c74c4a9ab985859", "project_url": "https://github.com/pjsip/pjproject", "commit_url": "https://github.com/pjsip/pjproject/commit/f74c1fc22b760d2a24369aa72c74c4a9ab985859", "commit_message": "Merge pull request from GHSA-r374-qrwv-86hh", "ground_truth": 1, "cwe": ["CWE-125"], "cve": "CVE-2021-43845", "cve_desc": "PJSIP is a free and open source multimedia communication library. In version 2.11.1 and prior, if incoming RTCP XR message contain block, the data field is not checked against the received packet size, potentially resulting in an out-of-bound read access. This affects all users that use PJMEDIA and RTCP XR. A malicious actor can send a RTCP XR message with an invalid packet size.", "vuln": 1, "reasoning": "Let's analyze the provided C code step by step to determine if there are any security vulnerabilities.\n\n---\n\n### Step 1: Input validation and bounds checking\n\nThe function `pjmedia_rtcp_xr_rx_rtcp_xr` processes a received RTCP XR packet (`pkt`) of size `size`. The function starts by casting the packet to a `pjmedia_rtcp_xr_pkt` structure and extracting the common header.\n\n- `rtcp_xr->common.pt != RTCP_XR` \u2192 checks if the packet type is correct. This is a valid sanity check.\n- `pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);` \u2192 extracts the length field from the header, converting from network byte order.\n- `if ((pkt_len + 1) > (size / 4)) return;` \u2192 this checks whether the packet length (in 32-bit words) exceeds the available data size. Since `size` is in bytes, dividing by 4 gives the number of 32-bit words. The condition ensures that the total length (in words) does not exceed the available data.\n\nThis is a **critical bounds check**. It prevents the parser from reading beyond the buffer. However, note that `pkt_len` is derived from the packet itself, which is untrusted. But the check `(pkt_len + 1) > (size / 4)` ensures that the total number of 32-bit words in the packet does not exceed the available data. This is a **correct and safe** bounds check.\n\n---\n\n### Step 2: Parsing report blocks in a loop\n\nThe code uses a `while` loop to iterate over report blocks:\n\n```c\nwhile ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n```\n\n- `rb_hdr` is a pointer to the current report block.\n- The loop condition ensures that `rb_hdr` does not go beyond the expected end of the packet (based on `pkt_len`).\n- Inside the loop:\n  - `rb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);` \u2192 reads the length of the current block.\n  - Then, `rb_hdr = (pjmedia_rtcp_xr_rb_header*) ((pj_int32_t*)rb_hdr + rb_len + 1);` \u2192 advances the pointer by `rb_len + 1` 32-bit words.\n\nThis is **dangerous** if not properly bounded. Let's analyze:\n\n- The loop condition is based on `pkt_len`, which is derived from the packet.\n- The pointer advancement uses `rb_len`, which is also from the packet.\n- But there is **no check** that `rb_len` is valid (e.g., not negative, not too large) or that the pointer advancement stays within the buffer.\n\nEven though the loop condition checks `rb_hdr < pkt + pkt_len`, the `rb_len` value could be **maliciously large**, causing `rb_hdr + rb_len + 1` to go far beyond the buffer, even if the loop condition is still true.\n\nFor example:\n- Suppose `rb_len` is 0xFFFF (65535), and `pkt_len` is 100.\n- The loop condition may still be true (since `rb_hdr` is near the start), but advancing by `rb_len + 1` (65536) will cause a massive pointer jump, potentially leading to **out-of-bounds memory access** or **integer overflow**.\n\nMoreover, `rb_len` is read from the packet and converted from network byte order. If the packet is crafted with a large `rb_len`, this can cause **integer overflow** or **buffer overflow** when advancing the pointer.\n\nThis is a **classic off-by-one or integer overflow vulnerability** in a parser.\n\n---\n\n### Step 3: Use of `pj_ntohs` and `pj_ntohl`\n\nThe code uses `pj_ntohs` and `pj_ntohl` to convert from network byte order. These are safe as long as the input is valid. However, since the input comes from an untrusted source (network packet), and `rb_len` is derived from it, this is **not sufficient** to prevent exploitation.\n\n---\n\n### Step 4: No additional bounds checks on `rb_len`\n\nThere is **no check** that `rb_len` is within a reasonable range (e.g., `rb_len > 0 && rb_len < MAX_BLOCK_SIZE`), nor is there a check that `rb_len + 1` does not cause integer overflow when added to the pointer.\n\nEven though the loop condition uses `pkt_len`, the `rb_len` value can be so large that `rb_hdr + rb_len + 1` overflows or goes far beyond the buffer, **bypassing the loop condition** due to pointer arithmetic overflow.\n\nThis is a **known vulnerability pattern** in network protocol parsers: **lack of bounds checking on length fields from untrusted input**.\n\n---\n\n### Step 5: Other parts of the code (e.g., parsing stats, VoIP metrics)\n\nThe rest of the code (handling `rb_rr_time`, `rb_dlrr`, `rb_stats`, `rb_voip_mtc`) is safe **if** the pointer `rb_hdr` is valid and within bounds. But since the pointer advancement is not properly bounded, the entire parsing loop is unsafe.\n\n---\n\n### Conclusion\n\nThe code **fails to validate the `rb_len` field** from the packet before using it to advance the pointer. This allows an attacker to craft a packet with a maliciously large `rb_len`, causing the pointer to jump out of bounds, leading to **buffer overflow**, **memory corruption**, or **arbitrary code execution**.\n\nThis is a **serious security vulnerability**.\n\n(1) YES: A security vulnerability detected."}
